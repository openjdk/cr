<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030  bool is_CAS(int opcode, bool maybe_volatile);
 1031 
 1032   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1033 
 1034   bool unnecessary_acquire(const Node *barrier);
 1035   bool needs_acquiring_load(const Node *load);
 1036 
 1037   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1038 
 1039   bool unnecessary_release(const Node *barrier);
 1040   bool unnecessary_volatile(const Node *barrier);
 1041   bool needs_releasing_store(const Node *store);
 1042 
 1043   // predicate controlling translation of CompareAndSwapX
 1044   bool needs_acquiring_load_exclusive(const Node *load);
 1045 
 1046   // predicate controlling addressing modes
 1047   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1048 %}
 1049 
 1050 source %{
 1051 
 1052   // Derived RegMask with conditionally allocatable registers
 1053 
 1054   RegMask _ANY_REG32_mask;
 1055   RegMask _ANY_REG_mask;
 1056   RegMask _PTR_REG_mask;
 1057   RegMask _NO_SPECIAL_REG32_mask;
 1058   RegMask _NO_SPECIAL_REG_mask;
 1059   RegMask _NO_SPECIAL_PTR_REG_mask;
 1060 
 1061   void reg_mask_init() {
 1062     // We derive below RegMask(s) from the ones which are auto-generated from
 1063     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1064     // registers conditionally reserved.
 1065 
 1066     _ANY_REG32_mask = _ALL_REG32_mask;
 1067     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1068 
 1069     _ANY_REG_mask = _ALL_REG_mask;
 1070 
 1071     _PTR_REG_mask = _ALL_REG_mask;
 1072 
 1073     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1074     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1075 
 1076     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1077     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1078 
 1079     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1080     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1081 
 1082     // r27 is not allocatable when compressed oops is on, compressed klass
 1083     // pointers doesn&#39;t use r27 after JDK-8234794
 1084     if (UseCompressedOops) {
 1085       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1086       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1087       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1088     }
 1089 
 1090     // r29 is not allocatable when PreserveFramePointer is on
 1091     if (PreserveFramePointer) {
 1092       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1093       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1094       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1095     }
 1096   }
 1097 
 1098   // Optimizaton of volatile gets and puts
 1099   // -------------------------------------
 1100   //
 1101   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1102   // use to implement volatile reads and writes. For a volatile read
 1103   // we simply need
 1104   //
 1105   //   ldar&lt;x&gt;
 1106   //
 1107   // and for a volatile write we need
 1108   //
 1109   //   stlr&lt;x&gt;
 1110   //
 1111   // Alternatively, we can implement them by pairing a normal
 1112   // load/store with a memory barrier. For a volatile read we need
 1113   //
 1114   //   ldr&lt;x&gt;
 1115   //   dmb ishld
 1116   //
 1117   // for a volatile write
 1118   //
 1119   //   dmb ish
 1120   //   str&lt;x&gt;
 1121   //   dmb ish
 1122   //
 1123   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1124   // sequences. These are normally translated to an instruction
 1125   // sequence like the following
 1126   //
 1127   //   dmb      ish
 1128   // retry:
 1129   //   ldxr&lt;x&gt;   rval raddr
 1130   //   cmp       rval rold
 1131   //   b.ne done
 1132   //   stlxr&lt;x&gt;  rval, rnew, rold
 1133   //   cbnz      rval retry
 1134   // done:
 1135   //   cset      r0, eq
 1136   //   dmb ishld
 1137   //
 1138   // Note that the exclusive store is already using an stlxr
 1139   // instruction. That is required to ensure visibility to other
 1140   // threads of the exclusive write (assuming it succeeds) before that
 1141   // of any subsequent writes.
 1142   //
 1143   // The following instruction sequence is an improvement on the above
 1144   //
 1145   // retry:
 1146   //   ldaxr&lt;x&gt;  rval raddr
 1147   //   cmp       rval rold
 1148   //   b.ne done
 1149   //   stlxr&lt;x&gt;  rval, rnew, rold
 1150   //   cbnz      rval retry
 1151   // done:
 1152   //   cset      r0, eq
 1153   //
 1154   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1155   // visibility of prior writes in the case that the swap is
 1156   // successful. Crucially we don&#39;t have to worry about the case where
 1157   // the swap is not successful since no valid program should be
 1158   // relying on visibility of prior changes by the attempting thread
 1159   // in the case where the CAS fails.
 1160   //
 1161   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1162   // an ldaxr instruction since that will provide all the guarantees we
 1163   // require regarding observation of changes made by other threads
 1164   // before any change to the CAS address observed by the load.
 1165   //
 1166   // In order to generate the desired instruction sequence we need to
 1167   // be able to identify specific &#39;signature&#39; ideal graph node
 1168   // sequences which i) occur as a translation of a volatile reads or
 1169   // writes or CAS operations and ii) do not occur through any other
 1170   // translation or graph transformation. We can then provide
 1171   // alternative aldc matching rules which translate these node
 1172   // sequences to the desired machine code sequences. Selection of the
 1173   // alternative rules can be implemented by predicates which identify
 1174   // the relevant node sequences.
 1175   //
 1176   // The ideal graph generator translates a volatile read to the node
 1177   // sequence
 1178   //
 1179   //   LoadX[mo_acquire]
 1180   //   MemBarAcquire
 1181   //
 1182   // As a special case when using the compressed oops optimization we
 1183   // may also see this variant
 1184   //
 1185   //   LoadN[mo_acquire]
 1186   //   DecodeN
 1187   //   MemBarAcquire
 1188   //
 1189   // A volatile write is translated to the node sequence
 1190   //
 1191   //   MemBarRelease
 1192   //   StoreX[mo_release] {CardMark}-optional
 1193   //   MemBarVolatile
 1194   //
 1195   // n.b. the above node patterns are generated with a strict
 1196   // &#39;signature&#39; configuration of input and output dependencies (see
 1197   // the predicates below for exact details). The card mark may be as
 1198   // simple as a few extra nodes or, in a few GC configurations, may
 1199   // include more complex control flow between the leading and
 1200   // trailing memory barriers. However, whatever the card mark
 1201   // configuration these signatures are unique to translated volatile
 1202   // reads/stores -- they will not appear as a result of any other
 1203   // bytecode translation or inlining nor as a consequence of
 1204   // optimizing transforms.
 1205   //
 1206   // We also want to catch inlined unsafe volatile gets and puts and
 1207   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1208   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1209   //
 1210   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1211   // normal volatile put node sequence containing an extra cpuorder
 1212   // membar
 1213   //
 1214   //   MemBarRelease
 1215   //   MemBarCPUOrder
 1216   //   StoreX[mo_release] {CardMark}-optional
 1217   //   MemBarCPUOrder
 1218   //   MemBarVolatile
 1219   //
 1220   // n.b. as an aside, a cpuorder membar is not itself subject to
 1221   // matching and translation by adlc rules.  However, the rule
 1222   // predicates need to detect its presence in order to correctly
 1223   // select the desired adlc rules.
 1224   //
 1225   // Inlined unsafe volatile gets manifest as a slightly different
 1226   // node sequence to a normal volatile get because of the
 1227   // introduction of some CPUOrder memory barriers to bracket the
 1228   // Load. However, but the same basic skeleton of a LoadX feeding a
 1229   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1230   // present
 1231   //
 1232   //   MemBarCPUOrder
 1233   //        ||       \\
 1234   //   MemBarCPUOrder LoadX[mo_acquire]
 1235   //        ||            |
 1236   //        ||       {DecodeN} optional
 1237   //        ||       /
 1238   //     MemBarAcquire
 1239   //
 1240   // In this case the acquire membar does not directly depend on the
 1241   // load. However, we can be sure that the load is generated from an
 1242   // inlined unsafe volatile get if we see it dependent on this unique
 1243   // sequence of membar nodes. Similarly, given an acquire membar we
 1244   // can know that it was added because of an inlined unsafe volatile
 1245   // get if it is fed and feeds a cpuorder membar and if its feed
 1246   // membar also feeds an acquiring load.
 1247   //
 1248   // Finally an inlined (Unsafe) CAS operation is translated to the
 1249   // following ideal graph
 1250   //
 1251   //   MemBarRelease
 1252   //   MemBarCPUOrder
 1253   //   CompareAndSwapX {CardMark}-optional
 1254   //   MemBarCPUOrder
 1255   //   MemBarAcquire
 1256   //
 1257   // So, where we can identify these volatile read and write
 1258   // signatures we can choose to plant either of the above two code
 1259   // sequences. For a volatile read we can simply plant a normal
 1260   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1261   // also choose to inhibit translation of the MemBarAcquire and
 1262   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1263   //
 1264   // When we recognise a volatile store signature we can choose to
 1265   // plant at a dmb ish as a translation for the MemBarRelease, a
 1266   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1267   // Alternatively, we can inhibit translation of the MemBarRelease
 1268   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1269   // instruction.
 1270   //
 1271   // when we recognise a CAS signature we can choose to plant a dmb
 1272   // ish as a translation for the MemBarRelease, the conventional
 1273   // macro-instruction sequence for the CompareAndSwap node (which
 1274   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1275   // Alternatively, we can elide generation of the dmb instructions
 1276   // and plant the alternative CompareAndSwap macro-instruction
 1277   // sequence (which uses ldaxr&lt;x&gt;).
 1278   //
 1279   // Of course, the above only applies when we see these signature
 1280   // configurations. We still want to plant dmb instructions in any
 1281   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1282   // MemBarVolatile. For example, at the end of a constructor which
 1283   // writes final/volatile fields we will see a MemBarRelease
 1284   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1285   // constructed object being visible without making the
 1286   // final/volatile field writes visible.
 1287   //
 1288   // n.b. the translation rules below which rely on detection of the
 1289   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1290   // If we see anything other than the signature configurations we
 1291   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1292   // and translate acquire, release and volatile membars to the
 1293   // relevant dmb instructions.
 1294   //
 1295 
 1296   // is_CAS(int opcode, bool maybe_volatile)
 1297   //
 1298   // return true if opcode is one of the possible CompareAndSwapX
 1299   // values otherwise false.
 1300 
 1301   bool is_CAS(int opcode, bool maybe_volatile)
 1302   {
 1303     switch(opcode) {
 1304       // We handle these
 1305     case Op_CompareAndSwapI:
 1306     case Op_CompareAndSwapL:
 1307     case Op_CompareAndSwapP:
 1308     case Op_CompareAndSwapN:
 1309     case Op_ShenandoahCompareAndSwapP:
 1310     case Op_ShenandoahCompareAndSwapN:
 1311     case Op_CompareAndSwapB:
 1312     case Op_CompareAndSwapS:
 1313     case Op_GetAndSetI:
 1314     case Op_GetAndSetL:
 1315     case Op_GetAndSetP:
 1316     case Op_GetAndSetN:
 1317     case Op_GetAndAddI:
 1318     case Op_GetAndAddL:
 1319       return true;
 1320     case Op_CompareAndExchangeI:
 1321     case Op_CompareAndExchangeN:
 1322     case Op_CompareAndExchangeB:
 1323     case Op_CompareAndExchangeS:
 1324     case Op_CompareAndExchangeL:
 1325     case Op_CompareAndExchangeP:
 1326     case Op_WeakCompareAndSwapB:
 1327     case Op_WeakCompareAndSwapS:
 1328     case Op_WeakCompareAndSwapI:
 1329     case Op_WeakCompareAndSwapL:
 1330     case Op_WeakCompareAndSwapP:
 1331     case Op_WeakCompareAndSwapN:
 1332     case Op_ShenandoahWeakCompareAndSwapP:
 1333     case Op_ShenandoahWeakCompareAndSwapN:
 1334     case Op_ShenandoahCompareAndExchangeP:
 1335     case Op_ShenandoahCompareAndExchangeN:
 1336       return maybe_volatile;
 1337     default:
 1338       return false;
 1339     }
 1340   }
 1341 
 1342   // helper to determine the maximum number of Phi nodes we may need to
 1343   // traverse when searching from a card mark membar for the merge mem
 1344   // feeding a trailing membar or vice versa
 1345 
 1346 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1347 
 1348 bool unnecessary_acquire(const Node *barrier)
 1349 {
 1350   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1351 
 1352   if (UseBarriersForVolatile) {
 1353     // we need to plant a dmb
 1354     return false;
 1355   }
 1356 
 1357   MemBarNode* mb = barrier-&gt;as_MemBar();
 1358 
 1359   if (mb-&gt;trailing_load()) {
 1360     return true;
 1361   }
 1362 
 1363   if (mb-&gt;trailing_load_store()) {
 1364     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1365     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1366     return is_CAS(load_store-&gt;Opcode(), true);
 1367   }
 1368 
 1369   return false;
 1370 }
 1371 
 1372 bool needs_acquiring_load(const Node *n)
 1373 {
 1374   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1375   if (UseBarriersForVolatile) {
 1376     // we use a normal load and a dmb
 1377     return false;
 1378   }
 1379 
 1380   LoadNode *ld = n-&gt;as_Load();
 1381 
 1382   return ld-&gt;is_acquire();
 1383 }
 1384 
 1385 bool unnecessary_release(const Node *n)
 1386 {
 1387   assert((n-&gt;is_MemBar() &amp;&amp;
 1388 	  n-&gt;Opcode() == Op_MemBarRelease),
 1389 	 &quot;expecting a release membar&quot;);
 1390 
 1391   if (UseBarriersForVolatile) {
 1392     // we need to plant a dmb
 1393     return false;
 1394   }
 1395 
 1396   MemBarNode *barrier = n-&gt;as_MemBar();
 1397   if (!barrier-&gt;leading()) {
 1398     return false;
 1399   } else {
 1400     Node* trailing = barrier-&gt;trailing_membar();
 1401     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1402     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1403     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1404 
 1405     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1406     if (mem-&gt;is_Store()) {
 1407       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1408       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1409       return true;
 1410     } else {
 1411       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1412       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1413       return is_CAS(mem-&gt;Opcode(), true);
 1414     }
 1415   }
 1416   return false;
 1417 }
 1418 
 1419 bool unnecessary_volatile(const Node *n)
 1420 {
 1421   // assert n-&gt;is_MemBar();
 1422   if (UseBarriersForVolatile) {
 1423     // we need to plant a dmb
 1424     return false;
 1425   }
 1426 
 1427   MemBarNode *mbvol = n-&gt;as_MemBar();
 1428 
 1429   bool release = mbvol-&gt;trailing_store();
 1430   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1431 #ifdef ASSERT
 1432   if (release) {
 1433     Node* leading = mbvol-&gt;leading_membar();
 1434     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1435     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1436     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1437   }
 1438 #endif
 1439 
 1440   return release;
 1441 }
 1442 
 1443 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1444 
 1445 bool needs_releasing_store(const Node *n)
 1446 {
 1447   // assert n-&gt;is_Store();
 1448   if (UseBarriersForVolatile) {
 1449     // we use a normal store and dmb combination
 1450     return false;
 1451   }
 1452 
 1453   StoreNode *st = n-&gt;as_Store();
 1454 
 1455   return st-&gt;trailing_membar() != NULL;
 1456 }
 1457 
 1458 // predicate controlling translation of CAS
 1459 //
 1460 // returns true if CAS needs to use an acquiring load otherwise false
 1461 
 1462 bool needs_acquiring_load_exclusive(const Node *n)
 1463 {
 1464   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1465   if (UseBarriersForVolatile) {
 1466     return false;
 1467   }
 1468 
 1469   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1470   if (is_CAS(n-&gt;Opcode(), false)) {
 1471     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1472   } else {
 1473     return ldst-&gt;trailing_membar() != NULL;
 1474   }
 1475 
 1476   // so we can just return true here
 1477   return true;
 1478 }
 1479 
 1480 #define __ _masm.
 1481 
 1482 // advance declarations for helper functions to convert register
 1483 // indices to register objects
 1484 
 1485 // the ad file has to provide implementations of certain methods
 1486 // expected by the generic code
 1487 //
 1488 // REQUIRED FUNCTIONALITY
 1489 
 1490 //=============================================================================
 1491 
 1492 // !!!!! Special hack to get all types of calls to specify the byte offset
 1493 //       from the start of the call to the point where the return address
 1494 //       will point.
 1495 
 1496 int MachCallStaticJavaNode::ret_addr_offset()
 1497 {
 1498   // call should be a simple bl
 1499   int off = 4;
 1500   return off;
 1501 }
 1502 
 1503 int MachCallDynamicJavaNode::ret_addr_offset()
 1504 {
 1505   return 16; // movz, movk, movk, bl
 1506 }
 1507 
 1508 int MachCallRuntimeNode::ret_addr_offset() {
 1509   // for generated stubs the call will be
 1510   //   far_call(addr)
 1511   // for real runtime callouts it will be six instructions
 1512   // see aarch64_enc_java_to_runtime
 1513   //   adr(rscratch2, retaddr)
 1514   //   lea(rscratch1, RuntimeAddress(addr)
 1515   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1516   //   blr(rscratch1)
 1517   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1518   if (cb) {
 1519     return MacroAssembler::far_branch_size();
 1520   } else {
 1521     return 6 * NativeInstruction::instruction_size;
 1522   }
 1523 }
 1524 
 1525 // Indicate if the safepoint node needs the polling page as an input
 1526 
 1527 // the shared code plants the oop data at the start of the generated
 1528 // code for the safepoint node and that needs ot be at the load
 1529 // instruction itself. so we cannot plant a mov of the safepoint poll
 1530 // address followed by a load. setting this to true means the mov is
 1531 // scheduled as a prior instruction. that&#39;s better for scheduling
 1532 // anyway.
 1533 
 1534 bool SafePointNode::needs_polling_address_input()
 1535 {
 1536   return true;
 1537 }
 1538 
 1539 //=============================================================================
 1540 
 1541 #ifndef PRODUCT
 1542 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1543   st-&gt;print(&quot;BREAKPOINT&quot;);
 1544 }
 1545 #endif
 1546 
 1547 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1548   MacroAssembler _masm(&amp;cbuf);
 1549   __ brk(0);
 1550 }
 1551 
 1552 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1553   return MachNode::size(ra_);
 1554 }
 1555 
 1556 //=============================================================================
 1557 
 1558 #ifndef PRODUCT
 1559   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1560     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1561   }
 1562 #endif
 1563 
 1564   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1565     MacroAssembler _masm(&amp;cbuf);
 1566     for (int i = 0; i &lt; _count; i++) {
 1567       __ nop();
 1568     }
 1569   }
 1570 
 1571   uint MachNopNode::size(PhaseRegAlloc*) const {
 1572     return _count * NativeInstruction::instruction_size;
 1573   }
 1574 
 1575 //=============================================================================
 1576 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1577 
 1578 int Compile::ConstantTable::calculate_table_base_offset() const {
 1579   return 0;  // absolute addressing, no offset
 1580 }
 1581 
 1582 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1583 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1584   ShouldNotReachHere();
 1585 }
 1586 
 1587 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1588   // Empty encoding
 1589 }
 1590 
 1591 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1592   return 0;
 1593 }
 1594 
 1595 #ifndef PRODUCT
 1596 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1597   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1598 }
 1599 #endif
 1600 
 1601 #ifndef PRODUCT
 1602 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1603   Compile* C = ra_-&gt;C;
 1604 
 1605   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1606 
 1607   if (C-&gt;need_stack_bang(framesize))
 1608     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1609 
 1610   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1611     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1612     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1613     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1614   } else {
 1615     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1616     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1617     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1618     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1619   }
 1620 }
 1621 #endif
 1622 
 1623 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1624   Compile* C = ra_-&gt;C;
 1625   MacroAssembler _masm(&amp;cbuf);
 1626 
 1627   // n.b. frame size includes space for return pc and rfp
 1628   const long framesize = C-&gt;frame_size_in_bytes();
 1629   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1630 
 1631   // insert a nop at the start of the prolog so we can patch in a
 1632   // branch if we need to invalidate the method later
 1633   __ nop();
 1634 
 1635   if (C-&gt;clinit_barrier_on_entry()) {
 1636     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1637 
 1638     Label L_skip_barrier;
 1639 
 1640     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1641     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1642     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1643     __ bind(L_skip_barrier);
 1644   }
 1645 
 1646   int bangsize = C-&gt;bang_size_in_bytes();
 1647   if (C-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1648     __ generate_stack_overflow_check(bangsize);
 1649 
 1650   __ build_frame(framesize);
 1651 
 1652   if (VerifyStackAtCalls) {
 1653     Unimplemented();
 1654   }
 1655 
 1656   C-&gt;set_frame_complete(cbuf.insts_size());
 1657 
 1658   if (C-&gt;has_mach_constant_base_node()) {
 1659     // NOTE: We set the table base offset here because users might be
 1660     // emitted before MachConstantBaseNode.
 1661     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
 1662     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1663   }
 1664 }
 1665 
 1666 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1667 {
 1668   return MachNode::size(ra_); // too many variables; just compute it
 1669                               // the hard way
 1670 }
 1671 
 1672 int MachPrologNode::reloc() const
 1673 {
 1674   return 0;
 1675 }
 1676 
 1677 //=============================================================================
 1678 
 1679 #ifndef PRODUCT
 1680 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1681   Compile* C = ra_-&gt;C;
 1682   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1683 
 1684   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1685 
 1686   if (framesize == 0) {
 1687     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1688   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1689     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1690     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1691   } else {
 1692     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1693     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1694     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1695   }
 1696 
 1697   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1698     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1699     st-&gt;print(&quot;mov  rscratch1, #0x%lx\n\t&quot;, p2i(os::get_polling_page()));
 1700     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1701   }
 1702 }
 1703 #endif
 1704 
 1705 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1706   Compile* C = ra_-&gt;C;
 1707   MacroAssembler _masm(&amp;cbuf);
 1708   int framesize = C-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1709 
 1710   __ remove_frame(framesize);
 1711 
 1712   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1713     __ reserved_stack_check();
 1714   }
 1715 
 1716   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1717     __ read_polling_page(rscratch1, os::get_polling_page(), relocInfo::poll_return_type);
 1718   }
 1719 }
 1720 
 1721 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1722   // Variable size. Determine dynamically.
 1723   return MachNode::size(ra_);
 1724 }
 1725 
 1726 int MachEpilogNode::reloc() const {
 1727   // Return number of relocatable values contained in this instruction.
 1728   return 1; // 1 for polling page.
 1729 }
 1730 
 1731 const Pipeline * MachEpilogNode::pipeline() const {
 1732   return MachNode::pipeline_class();
 1733 }
 1734 
 1735 // This method seems to be obsolete. It is declared in machnode.hpp
 1736 // and defined in all *.ad files, but it is never called. Should we
 1737 // get rid of it?
 1738 int MachEpilogNode::safepoint_offset() const {
 1739   assert(do_polling(), &quot;no return for this epilog node&quot;);
 1740   return 4;
 1741 }
 1742 
 1743 //=============================================================================
 1744 
 1745 // Figure out which register class each belongs in: rc_int, rc_float or
 1746 // rc_stack.
 1747 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1748 
 1749 static enum RC rc_class(OptoReg::Name reg) {
 1750 
 1751   if (reg == OptoReg::Bad) {
 1752     return rc_bad;
 1753   }
 1754 
 1755   // we have 30 int registers * 2 halves
 1756   // (rscratch1 and rscratch2 are omitted)
 1757   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1758 
 1759   if (reg &lt; slots_of_int_registers) {
 1760     return rc_int;
 1761   }
 1762 
 1763   // we have 32 float register * 4 halves
 1764   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1765     return rc_float;
 1766   }
 1767 
 1768   // Between float regs &amp; stack is the flags regs.
 1769   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1770 
 1771   return rc_stack;
 1772 }
 1773 
 1774 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1775   Compile* C = ra_-&gt;C;
 1776 
 1777   // Get registers to move.
 1778   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1779   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1780   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1781   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1782 
 1783   enum RC src_hi_rc = rc_class(src_hi);
 1784   enum RC src_lo_rc = rc_class(src_lo);
 1785   enum RC dst_hi_rc = rc_class(dst_hi);
 1786   enum RC dst_lo_rc = rc_class(dst_lo);
 1787 
 1788   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1789 
 1790   if (src_hi != OptoReg::Bad) {
 1791     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1792            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1793            &quot;expected aligned-adjacent pairs&quot;);
 1794   }
 1795 
 1796   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1797     return 0;            // Self copy, no move.
 1798   }
 1799 
 1800   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1801               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1802   int src_offset = ra_-&gt;reg2offset(src_lo);
 1803   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1804 
 1805   if (bottom_type()-&gt;isa_vect() != NULL) {
 1806     uint ireg = ideal_reg();
 1807     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1808     if (cbuf) {
 1809       MacroAssembler _masm(cbuf);
 1810       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1811       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812         // stack-&gt;stack
 1813         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1814         if (ireg == Op_VecD) {
 1815           __ unspill(rscratch1, true, src_offset);
 1816           __ spill(rscratch1, true, dst_offset);
 1817         } else {
 1818           __ spill_copy128(src_offset, dst_offset);
 1819         }
 1820       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1821         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1822                ireg == Op_VecD ? __ T8B : __ T16B,
 1823                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1824       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1825         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1826                        ireg == Op_VecD ? __ D : __ Q,
 1827                        ra_-&gt;reg2offset(dst_lo));
 1828       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1829         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1830                        ireg == Op_VecD ? __ D : __ Q,
 1831                        ra_-&gt;reg2offset(src_lo));
 1832       } else {
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836   } else if (cbuf) {
 1837     MacroAssembler _masm(cbuf);
 1838     switch (src_lo_rc) {
 1839     case rc_int:
 1840       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1841         if (is64) {
 1842             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1843                    as_Register(Matcher::_regEncode[src_lo]));
 1844         } else {
 1845             MacroAssembler _masm(cbuf);
 1846             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1847                     as_Register(Matcher::_regEncode[src_lo]));
 1848         }
 1849       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1850         if (is64) {
 1851             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1852                      as_Register(Matcher::_regEncode[src_lo]));
 1853         } else {
 1854             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         }
 1857       } else {                    // gpr --&gt; stack spill
 1858         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1859         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1860       }
 1861       break;
 1862     case rc_float:
 1863       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1864         if (is64) {
 1865             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1866                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1867         } else {
 1868             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         }
 1871       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1872           if (cbuf) {
 1873             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1875         } else {
 1876             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         }
 1879       } else {                    // fpr --&gt; stack spill
 1880         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1881         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1882                  is64 ? __ D : __ S, dst_offset);
 1883       }
 1884       break;
 1885     case rc_stack:
 1886       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1887         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1888       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1889         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1890                    is64 ? __ D : __ S, src_offset);
 1891       } else {                    // stack --&gt; stack copy
 1892         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1893         __ unspill(rscratch1, is64, src_offset);
 1894         __ spill(rscratch1, is64, dst_offset);
 1895       }
 1896       break;
 1897     default:
 1898       assert(false, &quot;bad rc_class for spill&quot;);
 1899       ShouldNotReachHere();
 1900     }
 1901   }
 1902 
 1903   if (st) {
 1904     st-&gt;print(&quot;spill &quot;);
 1905     if (src_lo_rc == rc_stack) {
 1906       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1907     } else {
 1908       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1909     }
 1910     if (dst_lo_rc == rc_stack) {
 1911       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1912     } else {
 1913       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1914     }
 1915     if (bottom_type()-&gt;isa_vect() != NULL) {
 1916       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1917     } else {
 1918       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1919     }
 1920   }
 1921 
 1922   return 0;
 1923 
 1924 }
 1925 
 1926 #ifndef PRODUCT
 1927 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1928   if (!ra_)
 1929     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1930   else
 1931     implementation(NULL, ra_, false, st);
 1932 }
 1933 #endif
 1934 
 1935 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1936   implementation(&amp;cbuf, ra_, false, NULL);
 1937 }
 1938 
 1939 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1940   return MachNode::size(ra_);
 1941 }
 1942 
 1943 //=============================================================================
 1944 
 1945 #ifndef PRODUCT
 1946 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1947   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1948   int reg = ra_-&gt;get_reg_first(this);
 1949   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1950             Matcher::regName[reg], offset);
 1951 }
 1952 #endif
 1953 
 1954 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1955   MacroAssembler _masm(&amp;cbuf);
 1956 
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg    = ra_-&gt;get_encode(this);
 1959 
 1960   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1961     __ add(as_Register(reg), sp, offset);
 1962   } else {
 1963     ShouldNotReachHere();
 1964   }
 1965 }
 1966 
 1967 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1968   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1969   return 4;
 1970 }
 1971 
 1972 //=============================================================================
 1973 
 1974 #ifndef PRODUCT
 1975 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1976 {
 1977   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 1978   if (UseCompressedClassPointers) {
 1979     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1980     if (CompressedKlassPointers::shift() != 0) {
 1981       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 1982     }
 1983   } else {
 1984    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 1985   }
 1986   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 1987   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 1988 }
 1989 #endif
 1990 
 1991 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1992 {
 1993   // This is the unverified entry point.
 1994   MacroAssembler _masm(&amp;cbuf);
 1995 
 1996   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1997   Label skip;
 1998   // TODO
 1999   // can we avoid this skip and still use a reloc?
 2000   __ br(Assembler::EQ, skip);
 2001   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2002   __ bind(skip);
 2003 }
 2004 
 2005 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2006 {
 2007   return MachNode::size(ra_);
 2008 }
 2009 
 2010 // REQUIRED EMIT CODE
 2011 
 2012 //=============================================================================
 2013 
 2014 // Emit exception handler code.
 2015 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2016 {
 2017   // mov rscratch1 #exception_blob_entry_point
 2018   // br rscratch1
 2019   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2020   // That&#39;s why we must use the macroassembler to generate a handler.
 2021   MacroAssembler _masm(&amp;cbuf);
 2022   address base = __ start_a_stub(size_exception_handler());
 2023   if (base == NULL) {
 2024     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2025     return 0;  // CodeBuffer::expand failed
 2026   }
 2027   int offset = __ offset();
 2028   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2029   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2030   __ end_a_stub();
 2031   return offset;
 2032 }
 2033 
 2034 // Emit deopt handler code.
 2035 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2036 {
 2037   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2038   // That&#39;s why we must use the macroassembler to generate a handler.
 2039   MacroAssembler _masm(&amp;cbuf);
 2040   address base = __ start_a_stub(size_deopt_handler());
 2041   if (base == NULL) {
 2042     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2043     return 0;  // CodeBuffer::expand failed
 2044   }
 2045   int offset = __ offset();
 2046 
 2047   __ adr(lr, __ pc());
 2048   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2049 
 2050   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2051   __ end_a_stub();
 2052   return offset;
 2053 }
 2054 
 2055 // REQUIRED MATCHER CODE
 2056 
 2057 //=============================================================================
 2058 
 2059 const bool Matcher::match_rule_supported(int opcode) {
 2060   if (!has_match_rule(opcode))
 2061     return false;
 2062 
 2063   bool ret_value = true;
 2064   switch (opcode) {
 2065     case Op_CacheWB:
 2066     case Op_CacheWBPreSync:
 2067     case Op_CacheWBPostSync:
 2068       if (!VM_Version::supports_data_cache_line_flush()) {
 2069         ret_value = false;
 2070       }
 2071       break;
 2072   }
 2073 
 2074   return ret_value; // Per default match rules are supported.
 2075 }
 2076 
 2077 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2078 
 2079   // TODO
 2080   // identify extra cases that we might want to provide match rules for
 2081   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
 2082   bool ret_value = match_rule_supported(opcode);
 2083   // Add rules here.
 2084 
 2085   return ret_value;  // Per default match rules are supported.
 2086 }
 2087 
 2088 const bool Matcher::has_predicated_vectors(void) {
 2089   return false;
 2090 }
 2091 
 2092 const int Matcher::float_pressure(int default_pressure_threshold) {
 2093   return default_pressure_threshold;
 2094 }
 2095 
 2096 int Matcher::regnum_to_fpu_offset(int regnum)
 2097 {
 2098   Unimplemented();
 2099   return 0;
 2100 }
 2101 
 2102 // Is this branch offset short enough that a short branch can be used?
 2103 //
 2104 // NOTE: If the platform does not provide any short branch variants, then
 2105 //       this method should return false for offset 0.
 2106 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2107   // The passed offset is relative to address of the branch.
 2108 
 2109   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2110 }
 2111 
 2112 const bool Matcher::isSimpleConstant64(jlong value) {
 2113   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2114   // Probably always true, even if a temp register is required.
 2115   return true;
 2116 }
 2117 
 2118 // true just means we have fast l2f conversion
 2119 const bool Matcher::convL2FSupported(void) {
 2120   return true;
 2121 }
 2122 
 2123 // Vector width in bytes.
 2124 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2125   int size = MIN2(16,(int)MaxVectorSize);
 2126   // Minimum 2 values in vector
 2127   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2128   // But never &lt; 4
 2129   if (size &lt; 4) size = 0;
 2130   return size;
 2131 }
 2132 
 2133 // Limits on vector size (number of elements) loaded into vector.
 2134 const int Matcher::max_vector_size(const BasicType bt) {
 2135   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2136 }
 2137 const int Matcher::min_vector_size(const BasicType bt) {
 2138 //  For the moment limit the vector size to 8 bytes
 2139     int size = 8 / type2aelembytes(bt);
 2140     if (size &lt; 2) size = 2;
 2141     return size;
 2142 }
 2143 
 2144 // Vector ideal reg.
 2145 const uint Matcher::vector_ideal_reg(int len) {
 2146   switch(len) {
 2147     case  8: return Op_VecD;
 2148     case 16: return Op_VecX;
 2149   }
 2150   ShouldNotReachHere();
 2151   return 0;
 2152 }
 2153 
 2154 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 2155   switch(size) {
 2156     case  8: return Op_VecD;
 2157     case 16: return Op_VecX;
 2158   }
 2159   ShouldNotReachHere();
 2160   return 0;
 2161 }
 2162 
 2163 // AES support not yet implemented
 2164 const bool Matcher::pass_original_key_for_aes() {
 2165   return false;
 2166 }
 2167 
 2168 // aarch64 supports misaligned vectors store/load.
 2169 const bool Matcher::misaligned_vectors_ok() {
 2170   return true;
 2171 }
 2172 
 2173 // false =&gt; size gets scaled to BytesPerLong, ok.
 2174 const bool Matcher::init_array_count_is_in_bytes = false;
 2175 
 2176 // Use conditional move (CMOVL)
 2177 const int Matcher::long_cmove_cost() {
 2178   // long cmoves are no more expensive than int cmoves
 2179   return 0;
 2180 }
 2181 
 2182 const int Matcher::float_cmove_cost() {
 2183   // float cmoves are no more expensive than int cmoves
 2184   return 0;
 2185 }
 2186 
 2187 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2188 const bool Matcher::require_postalloc_expand = false;
 2189 
 2190 // Do we need to mask the count passed to shift instructions or does
 2191 // the cpu only look at the lower 5/6 bits anyway?
 2192 const bool Matcher::need_masked_shift_count = false;
 2193 
 2194 // No support for generic vector operands.
 2195 const bool Matcher::supports_generic_vector_operands  = false;
 2196 
 2197 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2198   ShouldNotReachHere(); // generic vector operands not supported
 2199   return NULL;
 2200 }
 2201 
 2202 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2203   ShouldNotReachHere();  // generic vector operands not supported
 2204   return false;
 2205 }
 2206 
 2207 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2208   ShouldNotReachHere();  // generic vector operands not supported
 2209   return false;
 2210 }
 2211 
 2212 // This affects two different things:
 2213 //  - how Decode nodes are matched
 2214 //  - how ImplicitNullCheck opportunities are recognized
 2215 // If true, the matcher will try to remove all Decodes and match them
 2216 // (as operands) into nodes. NullChecks are not prepared to deal with
 2217 // Decodes by final_graph_reshaping().
 2218 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2219 // for a NullCheck. The matcher matches the Decode node into a register.
 2220 // Implicit_null_check optimization moves the Decode along with the
 2221 // memory operation back up before the NullCheck.
 2222 bool Matcher::narrow_oop_use_complex_address() {
 2223   return CompressedOops::shift() == 0;
 2224 }
 2225 
 2226 bool Matcher::narrow_klass_use_complex_address() {
 2227 // TODO
 2228 // decide whether we need to set this to true
 2229   return false;
 2230 }
 2231 
 2232 bool Matcher::const_oop_prefer_decode() {
 2233   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2234   return CompressedOops::base() == NULL;
 2235 }
 2236 
 2237 bool Matcher::const_klass_prefer_decode() {
 2238   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2239   return CompressedKlassPointers::base() == NULL;
 2240 }
 2241 
 2242 // Is it better to copy float constants, or load them directly from
 2243 // memory?  Intel can load a float constant from a direct address,
 2244 // requiring no extra registers.  Most RISCs will have to materialize
 2245 // an address into a register first, so they would do better to copy
 2246 // the constant from stack.
 2247 const bool Matcher::rematerialize_float_constants = false;
 2248 
 2249 // If CPU can load and store mis-aligned doubles directly then no
 2250 // fixup is needed.  Else we split the double into 2 integer pieces
 2251 // and move it piece-by-piece.  Only happens when passing doubles into
 2252 // C code as the Java calling convention forces doubles to be aligned.
 2253 const bool Matcher::misaligned_doubles_ok = true;
 2254 
 2255 // No-op on amd64
 2256 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2257   Unimplemented();
 2258 }
 2259 
 2260 // Advertise here if the CPU requires explicit rounding operations to
 2261 // implement the UseStrictFP mode.
 2262 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2263 
 2264 // Are floats converted to double when stored to stack during
 2265 // deoptimization?
 2266 bool Matcher::float_in_double() { return false; }
 2267 
 2268 // Do ints take an entire long register or just half?
 2269 // The relevant question is how the int is callee-saved:
 2270 // the whole long is written but de-opt&#39;ing will have to extract
 2271 // the relevant 32 bits.
 2272 const bool Matcher::int_in_long = true;
 2273 
 2274 // Return whether or not this register is ever used as an argument.
 2275 // This function is used on startup to build the trampoline stubs in
 2276 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2277 // call in the trampoline, and arguments in those registers not be
 2278 // available to the callee.
 2279 bool Matcher::can_be_java_arg(int reg)
 2280 {
 2281   return
 2282     reg ==  R0_num || reg == R0_H_num ||
 2283     reg ==  R1_num || reg == R1_H_num ||
 2284     reg ==  R2_num || reg == R2_H_num ||
 2285     reg ==  R3_num || reg == R3_H_num ||
 2286     reg ==  R4_num || reg == R4_H_num ||
 2287     reg ==  R5_num || reg == R5_H_num ||
 2288     reg ==  R6_num || reg == R6_H_num ||
 2289     reg ==  R7_num || reg == R7_H_num ||
 2290     reg ==  V0_num || reg == V0_H_num ||
 2291     reg ==  V1_num || reg == V1_H_num ||
 2292     reg ==  V2_num || reg == V2_H_num ||
 2293     reg ==  V3_num || reg == V3_H_num ||
 2294     reg ==  V4_num || reg == V4_H_num ||
 2295     reg ==  V5_num || reg == V5_H_num ||
 2296     reg ==  V6_num || reg == V6_H_num ||
 2297     reg ==  V7_num || reg == V7_H_num;
 2298 }
 2299 
 2300 bool Matcher::is_spillable_arg(int reg)
 2301 {
 2302   return can_be_java_arg(reg);
 2303 }
 2304 
 2305 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2306   return false;
 2307 }
 2308 
 2309 RegMask Matcher::divI_proj_mask() {
 2310   ShouldNotReachHere();
 2311   return RegMask();
 2312 }
 2313 
 2314 // Register for MODI projection of divmodI.
 2315 RegMask Matcher::modI_proj_mask() {
 2316   ShouldNotReachHere();
 2317   return RegMask();
 2318 }
 2319 
 2320 // Register for DIVL projection of divmodL.
 2321 RegMask Matcher::divL_proj_mask() {
 2322   ShouldNotReachHere();
 2323   return RegMask();
 2324 }
 2325 
 2326 // Register for MODL projection of divmodL.
 2327 RegMask Matcher::modL_proj_mask() {
 2328   ShouldNotReachHere();
 2329   return RegMask();
 2330 }
 2331 
 2332 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2333   return FP_REG_mask();
 2334 }
 2335 
 2336 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2337   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2338     Node* u = addp-&gt;fast_out(i);
 2339     if (u-&gt;is_Mem()) {
 2340       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2341       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2342       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2343         return false;
 2344       }
 2345     }
 2346   }
 2347   return true;
 2348 }
 2349 
 2350 const bool Matcher::convi2l_type_required = false;
 2351 
 2352 // Should the Matcher clone shifts on addressing modes, expecting them
 2353 // to be subsumed into complex addressing expressions or compute them
 2354 // into registers?
 2355 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2356   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2357     return true;
 2358   }
 2359 
 2360   Node *off = m-&gt;in(AddPNode::Offset);
 2361   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2362       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2363       // Are there other uses besides address expressions?
 2364       !is_visited(off)) {
 2365     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2366     mstack.push(off-&gt;in(2), Visit);
 2367     Node *conv = off-&gt;in(1);
 2368     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2369         // Are there other uses besides address expressions?
 2370         !is_visited(conv)) {
 2371       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2372       mstack.push(conv-&gt;in(1), Pre_Visit);
 2373     } else {
 2374       mstack.push(conv, Pre_Visit);
 2375     }
 2376     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2377     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2378     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2379     return true;
 2380   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2381              // Are there other uses besides address expressions?
 2382              !is_visited(off)) {
 2383     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2384     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2385     mstack.push(off-&gt;in(1), Pre_Visit);
 2386     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2387     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2388     return true;
 2389   }
 2390   return false;
 2391 }
 2392 
 2393 void Compile::reshape_address(AddPNode* addp) {
 2394 }
 2395 
 2396 
 2397 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2398   MacroAssembler _masm(&amp;cbuf);                                          \
 2399   {                                                                     \
 2400     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2401     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2402     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2403     __ INSN(REG, as_Register(BASE));                                    \
 2404   }
 2405 
 2406 
 2407 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2408   {
 2409     Address::extend scale;
 2410 
 2411     // Hooboy, this is fugly.  We need a way to communicate to the
 2412     // encoder that the index needs to be sign extended, so we have to
 2413     // enumerate all the cases.
 2414     switch (opcode) {
 2415     case INDINDEXSCALEDI2L:
 2416     case INDINDEXSCALEDI2LN:
 2417     case INDINDEXI2L:
 2418     case INDINDEXI2LN:
 2419       scale = Address::sxtw(size);
 2420       break;
 2421     default:
 2422       scale = Address::lsl(size);
 2423     }
 2424 
 2425     if (index == -1) {
 2426       return Address(base, disp);
 2427     } else {
 2428       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2429       return Address(base, as_Register(index), scale);
 2430     }
 2431   }
 2432 
 2433 
 2434 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2435 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2436 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2437 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2438                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2439 
 2440   // Used for all non-volatile memory accesses.  The use of
 2441   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2442   // offsets is something of a kludge.
 2443   static void loadStore(MacroAssembler masm, mem_insn insn,
 2444                         Register reg, int opcode,
 2445                         Register base, int index, int scale, int disp,
 2446                         int size_in_memory)
 2447   {
 2448     Address addr = mem2address(opcode, base, index, scale, disp);
 2449     if (addr.getMode() == Address::base_plus_offset) {
 2450       /* If we get an out-of-range offset it is a bug in the compiler,
 2451          so we assert here. */
 2452       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2453              &quot;c2 compiler bug&quot;);
 2454       /* Fix up any out-of-range offsets. */
 2455       assert_different_registers(rscratch1, base);
 2456       assert_different_registers(rscratch1, reg);
 2457       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2458     }
 2459     (masm.*insn)(reg, addr);
 2460   }
 2461 
 2462   static void loadStore(MacroAssembler masm, mem_float_insn insn,
 2463                         FloatRegister reg, int opcode,
 2464                         Register base, int index, int size, int disp,
 2465                         int size_in_memory)
 2466   {
 2467     Address::extend scale;
 2468 
 2469     switch (opcode) {
 2470     case INDINDEXSCALEDI2L:
 2471     case INDINDEXSCALEDI2LN:
 2472       scale = Address::sxtw(size);
 2473       break;
 2474     default:
 2475       scale = Address::lsl(size);
 2476     }
 2477 
 2478     if (index == -1) {
 2479       /* If we get an out-of-range offset it is a bug in the compiler,
 2480          so we assert here. */
 2481       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2482       /* Fix up any out-of-range offsets. */
 2483       assert_different_registers(rscratch1, base);
 2484       Address addr = Address(base, disp);
 2485       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2486       (masm.*insn)(reg, addr);
 2487     } else {
 2488       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2489       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2490     }
 2491   }
 2492 
 2493   static void loadStore(MacroAssembler masm, mem_vector_insn insn,
 2494                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2495                         int opcode, Register base, int index, int size, int disp)
 2496   {
 2497     if (index == -1) {
 2498       (masm.*insn)(reg, T, Address(base, disp));
 2499     } else {
 2500       assert(disp == 0, &quot;unsupported address mode&quot;);
 2501       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2502     }
 2503   }
 2504 
 2505 %}
 2506 
 2507 
 2508 
 2509 //----------ENCODING BLOCK-----------------------------------------------------
 2510 // This block specifies the encoding classes used by the compiler to
 2511 // output byte streams.  Encoding classes are parameterized macros
 2512 // used by Machine Instruction Nodes in order to generate the bit
 2513 // encoding of the instruction.  Operands specify their base encoding
 2514 // interface with the interface keyword.  There are currently
 2515 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2516 // COND_INTER.  REG_INTER causes an operand to generate a function
 2517 // which returns its register number when queried.  CONST_INTER causes
 2518 // an operand to generate a function which returns the value of the
 2519 // constant when queried.  MEMORY_INTER causes an operand to generate
 2520 // four functions which return the Base Register, the Index Register,
 2521 // the Scale Value, and the Offset Value of the operand when queried.
 2522 // COND_INTER causes an operand to generate six functions which return
 2523 // the encoding code (ie - encoding bits for the instruction)
 2524 // associated with each basic boolean condition for a conditional
 2525 // instruction.
 2526 //
 2527 // Instructions specify two basic values for encoding.  Again, a
 2528 // function is available to check if the constant displacement is an
 2529 // oop. They use the ins_encode keyword to specify their encoding
 2530 // classes (which must be a sequence of enc_class names, and their
 2531 // parameters, specified in the encoding block), and they use the
 2532 // opcode keyword to specify, in order, their primary, secondary, and
 2533 // tertiary opcode.  Only the opcode sections which a particular
 2534 // instruction needs for encoding need to be specified.
 2535 encode %{
 2536   // Build emit functions for each basic byte or larger field in the
 2537   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2538   // from C++ code in the enc_class source block.  Emit functions will
 2539   // live in the main source block for now.  In future, we can
 2540   // generalize this by adding a syntax that specifies the sizes of
 2541   // fields in an order, so that the adlc can build the emit functions
 2542   // automagically
 2543 
 2544   // catch all for unimplemented encodings
 2545   enc_class enc_unimplemented %{
 2546     MacroAssembler _masm(&amp;cbuf);
 2547     __ unimplemented(&quot;C2 catch all&quot;);
 2548   %}
 2549 
 2550   // BEGIN Non-volatile memory access
 2551 
 2552   // This encoding class is generated automatically from ad_encode.m4.
 2553   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2554   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2555     Register dst_reg = as_Register($dst$$reg);
 2556     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2557                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2558   %}
 2559 
 2560   // This encoding class is generated automatically from ad_encode.m4.
 2561   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2562   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2563     Register dst_reg = as_Register($dst$$reg);
 2564     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2565                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2566   %}
 2567 
 2568   // This encoding class is generated automatically from ad_encode.m4.
 2569   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2570   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2571     Register dst_reg = as_Register($dst$$reg);
 2572     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2573                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2574   %}
 2575 
 2576   // This encoding class is generated automatically from ad_encode.m4.
 2577   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2578   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2579     Register dst_reg = as_Register($dst$$reg);
 2580     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2581                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2582   %}
 2583 
 2584   // This encoding class is generated automatically from ad_encode.m4.
 2585   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2586   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2587     Register dst_reg = as_Register($dst$$reg);
 2588     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2589                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2590   %}
 2591 
 2592   // This encoding class is generated automatically from ad_encode.m4.
 2593   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2594   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2595     Register dst_reg = as_Register($dst$$reg);
 2596     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2597                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2598   %}
 2599 
 2600   // This encoding class is generated automatically from ad_encode.m4.
 2601   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2602   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2603     Register dst_reg = as_Register($dst$$reg);
 2604     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2605                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2606   %}
 2607 
 2608   // This encoding class is generated automatically from ad_encode.m4.
 2609   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2610   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2611     Register dst_reg = as_Register($dst$$reg);
 2612     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2613                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2614   %}
 2615 
 2616   // This encoding class is generated automatically from ad_encode.m4.
 2617   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2618   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2619     Register dst_reg = as_Register($dst$$reg);
 2620     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2621                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2622   %}
 2623 
 2624   // This encoding class is generated automatically from ad_encode.m4.
 2625   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2626   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2627     Register dst_reg = as_Register($dst$$reg);
 2628     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2629                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2630   %}
 2631 
 2632   // This encoding class is generated automatically from ad_encode.m4.
 2633   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2634   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2635     Register dst_reg = as_Register($dst$$reg);
 2636     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2637                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2638   %}
 2639 
 2640   // This encoding class is generated automatically from ad_encode.m4.
 2641   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2642   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2643     Register dst_reg = as_Register($dst$$reg);
 2644     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2645                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2646   %}
 2647 
 2648   // This encoding class is generated automatically from ad_encode.m4.
 2649   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2650   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2651     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2652     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2653                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2654   %}
 2655 
 2656   // This encoding class is generated automatically from ad_encode.m4.
 2657   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2658   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2659     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2660     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2661                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2662   %}
 2663 
 2664   // This encoding class is generated automatically from ad_encode.m4.
 2665   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2666   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2667     Register src_reg = as_Register($src$$reg);
 2668     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2669                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2670   %}
 2671 
 2672   // This encoding class is generated automatically from ad_encode.m4.
 2673   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2674   enc_class aarch64_enc_strb0(memory1 mem) %{
 2675     MacroAssembler _masm(&amp;cbuf);
 2676     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2677                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2678   %}
 2679 
 2680   // This encoding class is generated automatically from ad_encode.m4.
 2681   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2682   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2683     Register src_reg = as_Register($src$$reg);
 2684     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2685                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2686   %}
 2687 
 2688   // This encoding class is generated automatically from ad_encode.m4.
 2689   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2690   enc_class aarch64_enc_strh0(memory2 mem) %{
 2691     MacroAssembler _masm(&amp;cbuf);
 2692     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2693                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2694   %}
 2695 
 2696   // This encoding class is generated automatically from ad_encode.m4.
 2697   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2698   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2699     Register src_reg = as_Register($src$$reg);
 2700     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2701                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2702   %}
 2703 
 2704   // This encoding class is generated automatically from ad_encode.m4.
 2705   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2706   enc_class aarch64_enc_strw0(memory4 mem) %{
 2707     MacroAssembler _masm(&amp;cbuf);
 2708     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2709                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2710   %}
 2711 
 2712   // This encoding class is generated automatically from ad_encode.m4.
 2713   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2714   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2715     Register src_reg = as_Register($src$$reg);
 2716     // we sometimes get asked to store the stack pointer into the
 2717     // current thread -- we cannot do that directly on AArch64
 2718     if (src_reg == r31_sp) {
 2719       MacroAssembler _masm(&amp;cbuf);
 2720       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2721       __ mov(rscratch2, sp);
 2722       src_reg = rscratch2;
 2723     }
 2724     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2725                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2726   %}
 2727 
 2728   // This encoding class is generated automatically from ad_encode.m4.
 2729   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2730   enc_class aarch64_enc_str0(memory8 mem) %{
 2731     MacroAssembler _masm(&amp;cbuf);
 2732     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2733                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2734   %}
 2735 
 2736   // This encoding class is generated automatically from ad_encode.m4.
 2737   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2738   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2739     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2740     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2741                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2742   %}
 2743 
 2744   // This encoding class is generated automatically from ad_encode.m4.
 2745   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2746   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2747     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2748     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2749                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2750   %}
 2751 
 2752   // This encoding class is generated automatically from ad_encode.m4.
 2753   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2754   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2755     MacroAssembler _masm(&amp;cbuf);
 2756     address con = (address)$src$$constant;
 2757     // need to do this the hard way until we can manage relocs
 2758     // for 32 bit constants
 2759     __ movoop(rscratch2, (jobject)con);
 2760     if (con) __ encode_heap_oop_not_null(rscratch2);
 2761     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2762                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2763   %}
 2764 
 2765   // This encoding class is generated automatically from ad_encode.m4.
 2766   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2767   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2768     MacroAssembler _masm(&amp;cbuf);
 2769     address con = (address)$src$$constant;
 2770     // need to do this the hard way until we can manage relocs
 2771     // for 32 bit constants
 2772     __ movoop(rscratch2, (jobject)con);
 2773     __ encode_klass_not_null(rscratch2);
 2774     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2775                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2776   %}
 2777 
 2778   // This encoding class is generated automatically from ad_encode.m4.
 2779   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2780   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2781       MacroAssembler _masm(&amp;cbuf);
 2782       __ membar(Assembler::StoreStore);
 2783       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2784                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2785   %}
 2786 
 2787   // END Non-volatile memory access
 2788 
 2789   // Vector loads and stores
 2790   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2791     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2792     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2793        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2794   %}
 2795 
 2796   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2797     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2798     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2799        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2800   %}
 2801 
 2802   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2803     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2804     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2805        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2806   %}
 2807 
 2808   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2809     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2810     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2811        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2812   %}
 2813 
 2814   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2815     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2816     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2817        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2818   %}
 2819 
 2820   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2821     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2822     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2823        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2824   %}
 2825 
 2826   // volatile loads and stores
 2827 
 2828   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2829     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2830                  rscratch1, stlrb);
 2831   %}
 2832 
 2833   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2834     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2835                  rscratch1, stlrh);
 2836   %}
 2837 
 2838   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2839     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2840                  rscratch1, stlrw);
 2841   %}
 2842 
 2843 
 2844   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2845     Register dst_reg = as_Register($dst$$reg);
 2846     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2847              rscratch1, ldarb);
 2848     __ sxtbw(dst_reg, dst_reg);
 2849   %}
 2850 
 2851   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2852     Register dst_reg = as_Register($dst$$reg);
 2853     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2854              rscratch1, ldarb);
 2855     __ sxtb(dst_reg, dst_reg);
 2856   %}
 2857 
 2858   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2859     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2860              rscratch1, ldarb);
 2861   %}
 2862 
 2863   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2864     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2865              rscratch1, ldarb);
 2866   %}
 2867 
 2868   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2869     Register dst_reg = as_Register($dst$$reg);
 2870     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2871              rscratch1, ldarh);
 2872     __ sxthw(dst_reg, dst_reg);
 2873   %}
 2874 
 2875   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2876     Register dst_reg = as_Register($dst$$reg);
 2877     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2878              rscratch1, ldarh);
 2879     __ sxth(dst_reg, dst_reg);
 2880   %}
 2881 
 2882   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2883     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2884              rscratch1, ldarh);
 2885   %}
 2886 
 2887   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2888     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2889              rscratch1, ldarh);
 2890   %}
 2891 
 2892   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2893     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2894              rscratch1, ldarw);
 2895   %}
 2896 
 2897   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2898     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2899              rscratch1, ldarw);
 2900   %}
 2901 
 2902   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2903     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2904              rscratch1, ldar);
 2905   %}
 2906 
 2907   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2908     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2909              rscratch1, ldarw);
 2910     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2911   %}
 2912 
 2913   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2914     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2915              rscratch1, ldar);
 2916     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2917   %}
 2918 
 2919   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2920     Register src_reg = as_Register($src$$reg);
 2921     // we sometimes get asked to store the stack pointer into the
 2922     // current thread -- we cannot do that directly on AArch64
 2923     if (src_reg == r31_sp) {
 2924         MacroAssembler _masm(&amp;cbuf);
 2925       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2926       __ mov(rscratch2, sp);
 2927       src_reg = rscratch2;
 2928     }
 2929     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2930                  rscratch1, stlr);
 2931   %}
 2932 
 2933   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2934     {
 2935       MacroAssembler _masm(&amp;cbuf);
 2936       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2937       __ fmovs(rscratch2, src_reg);
 2938     }
 2939     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2940                  rscratch1, stlrw);
 2941   %}
 2942 
 2943   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2944     {
 2945       MacroAssembler _masm(&amp;cbuf);
 2946       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2947       __ fmovd(rscratch2, src_reg);
 2948     }
 2949     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2950                  rscratch1, stlr);
 2951   %}
 2952 
 2953   // synchronized read/update encodings
 2954 
 2955   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 2956     MacroAssembler _masm(&amp;cbuf);
 2957     Register dst_reg = as_Register($dst$$reg);
 2958     Register base = as_Register($mem$$base);
 2959     int index = $mem$$index;
 2960     int scale = $mem$$scale;
 2961     int disp = $mem$$disp;
 2962     if (index == -1) {
 2963        if (disp != 0) {
 2964         __ lea(rscratch1, Address(base, disp));
 2965         __ ldaxr(dst_reg, rscratch1);
 2966       } else {
 2967         // TODO
 2968         // should we ever get anything other than this case?
 2969         __ ldaxr(dst_reg, base);
 2970       }
 2971     } else {
 2972       Register index_reg = as_Register(index);
 2973       if (disp == 0) {
 2974         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 2975         __ ldaxr(dst_reg, rscratch1);
 2976       } else {
 2977         __ lea(rscratch1, Address(base, disp));
 2978         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 2979         __ ldaxr(dst_reg, rscratch1);
 2980       }
 2981     }
 2982   %}
 2983 
 2984   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 2985     MacroAssembler _masm(&amp;cbuf);
 2986     Register src_reg = as_Register($src$$reg);
 2987     Register base = as_Register($mem$$base);
 2988     int index = $mem$$index;
 2989     int scale = $mem$$scale;
 2990     int disp = $mem$$disp;
 2991     if (index == -1) {
 2992        if (disp != 0) {
 2993         __ lea(rscratch2, Address(base, disp));
 2994         __ stlxr(rscratch1, src_reg, rscratch2);
 2995       } else {
 2996         // TODO
 2997         // should we ever get anything other than this case?
 2998         __ stlxr(rscratch1, src_reg, base);
 2999       }
 3000     } else {
 3001       Register index_reg = as_Register(index);
 3002       if (disp == 0) {
 3003         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3004         __ stlxr(rscratch1, src_reg, rscratch2);
 3005       } else {
 3006         __ lea(rscratch2, Address(base, disp));
 3007         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3008         __ stlxr(rscratch1, src_reg, rscratch2);
 3009       }
 3010     }
 3011     __ cmpw(rscratch1, zr);
 3012   %}
 3013 
 3014   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3015     MacroAssembler _masm(&amp;cbuf);
 3016     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3017     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3018                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3019                /*weak*/ false, noreg);
 3020   %}
 3021 
 3022   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3023     MacroAssembler _masm(&amp;cbuf);
 3024     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3025     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3026                Assembler::word, /*acquire*/ false, /*release*/ true,
 3027                /*weak*/ false, noreg);
 3028   %}
 3029 
 3030   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3031     MacroAssembler _masm(&amp;cbuf);
 3032     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3033     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3034                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3035                /*weak*/ false, noreg);
 3036   %}
 3037 
 3038   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3039     MacroAssembler _masm(&amp;cbuf);
 3040     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3041     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3042                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3043                /*weak*/ false, noreg);
 3044   %}
 3045 
 3046 
 3047   // The only difference between aarch64_enc_cmpxchg and
 3048   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3049   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3050   // lock.
 3051   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3052     MacroAssembler _masm(&amp;cbuf);
 3053     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3054     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3055                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3056                /*weak*/ false, noreg);
 3057   %}
 3058 
 3059   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3060     MacroAssembler _masm(&amp;cbuf);
 3061     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3062     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3063                Assembler::word, /*acquire*/ true, /*release*/ true,
 3064                /*weak*/ false, noreg);
 3065   %}
 3066 
 3067   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3068     MacroAssembler _masm(&amp;cbuf);
 3069     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3070     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3071                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3072                /*weak*/ false, noreg);
 3073   %}
 3074 
 3075   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3076     MacroAssembler _masm(&amp;cbuf);
 3077     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3078     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3079                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3080                /*weak*/ false, noreg);
 3081   %}
 3082 
 3083   // auxiliary used for CompareAndSwapX to set result register
 3084   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3085     MacroAssembler _masm(&amp;cbuf);
 3086     Register res_reg = as_Register($res$$reg);
 3087     __ cset(res_reg, Assembler::EQ);
 3088   %}
 3089 
 3090   // prefetch encodings
 3091 
 3092   enc_class aarch64_enc_prefetchw(memory mem) %{
 3093     MacroAssembler _masm(&amp;cbuf);
 3094     Register base = as_Register($mem$$base);
 3095     int index = $mem$$index;
 3096     int scale = $mem$$scale;
 3097     int disp = $mem$$disp;
 3098     if (index == -1) {
 3099       __ prfm(Address(base, disp), PSTL1KEEP);
 3100     } else {
 3101       Register index_reg = as_Register(index);
 3102       if (disp == 0) {
 3103         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3104       } else {
 3105         __ lea(rscratch1, Address(base, disp));
 3106 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3107       }
 3108     }
 3109   %}
 3110 
 3111   /// mov envcodings
 3112 
 3113   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3114     MacroAssembler _masm(&amp;cbuf);
 3115     u_int32_t con = (u_int32_t)$src$$constant;
 3116     Register dst_reg = as_Register($dst$$reg);
 3117     if (con == 0) {
 3118       __ movw(dst_reg, zr);
 3119     } else {
 3120       __ movw(dst_reg, con);
 3121     }
 3122   %}
 3123 
 3124   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3125     MacroAssembler _masm(&amp;cbuf);
 3126     Register dst_reg = as_Register($dst$$reg);
 3127     u_int64_t con = (u_int64_t)$src$$constant;
 3128     if (con == 0) {
 3129       __ mov(dst_reg, zr);
 3130     } else {
 3131       __ mov(dst_reg, con);
 3132     }
 3133   %}
 3134 
 3135   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3136     MacroAssembler _masm(&amp;cbuf);
 3137     Register dst_reg = as_Register($dst$$reg);
 3138     address con = (address)$src$$constant;
 3139     if (con == NULL || con == (address)1) {
 3140       ShouldNotReachHere();
 3141     } else {
 3142       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3143       if (rtype == relocInfo::oop_type) {
 3144         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3145       } else if (rtype == relocInfo::metadata_type) {
 3146         __ mov_metadata(dst_reg, (Metadata*)con);
 3147       } else {
 3148         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3149         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3150           __ mov(dst_reg, con);
 3151         } else {
 3152           unsigned long offset;
 3153           __ adrp(dst_reg, con, offset);
 3154           __ add(dst_reg, dst_reg, offset);
 3155         }
 3156       }
 3157     }
 3158   %}
 3159 
 3160   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3161     MacroAssembler _masm(&amp;cbuf);
 3162     Register dst_reg = as_Register($dst$$reg);
 3163     __ mov(dst_reg, zr);
 3164   %}
 3165 
 3166   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3167     MacroAssembler _masm(&amp;cbuf);
 3168     Register dst_reg = as_Register($dst$$reg);
 3169     __ mov(dst_reg, (u_int64_t)1);
 3170   %}
 3171 
 3172   enc_class aarch64_enc_mov_poll_page(iRegP dst, immPollPage src) %{
 3173     MacroAssembler _masm(&amp;cbuf);
 3174     address page = (address)$src$$constant;
 3175     Register dst_reg = as_Register($dst$$reg);
 3176     unsigned long off;
 3177     __ adrp(dst_reg, Address(page, relocInfo::poll_type), off);
 3178     assert(off == 0, &quot;assumed offset == 0&quot;);
 3179   %}
 3180 
 3181   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3182     MacroAssembler _masm(&amp;cbuf);
 3183     __ load_byte_map_base($dst$$Register);
 3184   %}
 3185 
 3186   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3187     MacroAssembler _masm(&amp;cbuf);
 3188     Register dst_reg = as_Register($dst$$reg);
 3189     address con = (address)$src$$constant;
 3190     if (con == NULL) {
 3191       ShouldNotReachHere();
 3192     } else {
 3193       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3194       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3195       __ set_narrow_oop(dst_reg, (jobject)con);
 3196     }
 3197   %}
 3198 
 3199   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3200     MacroAssembler _masm(&amp;cbuf);
 3201     Register dst_reg = as_Register($dst$$reg);
 3202     __ mov(dst_reg, zr);
 3203   %}
 3204 
 3205   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3206     MacroAssembler _masm(&amp;cbuf);
 3207     Register dst_reg = as_Register($dst$$reg);
 3208     address con = (address)$src$$constant;
 3209     if (con == NULL) {
 3210       ShouldNotReachHere();
 3211     } else {
 3212       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3213       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3214       __ set_narrow_klass(dst_reg, (Klass *)con);
 3215     }
 3216   %}
 3217 
 3218   // arithmetic encodings
 3219 
 3220   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3221     MacroAssembler _masm(&amp;cbuf);
 3222     Register dst_reg = as_Register($dst$$reg);
 3223     Register src_reg = as_Register($src1$$reg);
 3224     int32_t con = (int32_t)$src2$$constant;
 3225     // add has primary == 0, subtract has primary == 1
 3226     if ($primary) { con = -con; }
 3227     if (con &lt; 0) {
 3228       __ subw(dst_reg, src_reg, -con);
 3229     } else {
 3230       __ addw(dst_reg, src_reg, con);
 3231     }
 3232   %}
 3233 
 3234   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3235     MacroAssembler _masm(&amp;cbuf);
 3236     Register dst_reg = as_Register($dst$$reg);
 3237     Register src_reg = as_Register($src1$$reg);
 3238     int32_t con = (int32_t)$src2$$constant;
 3239     // add has primary == 0, subtract has primary == 1
 3240     if ($primary) { con = -con; }
 3241     if (con &lt; 0) {
 3242       __ sub(dst_reg, src_reg, -con);
 3243     } else {
 3244       __ add(dst_reg, src_reg, con);
 3245     }
 3246   %}
 3247 
 3248   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3249     MacroAssembler _masm(&amp;cbuf);
 3250    Register dst_reg = as_Register($dst$$reg);
 3251    Register src1_reg = as_Register($src1$$reg);
 3252    Register src2_reg = as_Register($src2$$reg);
 3253     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3254   %}
 3255 
 3256   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3257     MacroAssembler _masm(&amp;cbuf);
 3258    Register dst_reg = as_Register($dst$$reg);
 3259    Register src1_reg = as_Register($src1$$reg);
 3260    Register src2_reg = as_Register($src2$$reg);
 3261     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3262   %}
 3263 
 3264   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3265     MacroAssembler _masm(&amp;cbuf);
 3266    Register dst_reg = as_Register($dst$$reg);
 3267    Register src1_reg = as_Register($src1$$reg);
 3268    Register src2_reg = as_Register($src2$$reg);
 3269     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3270   %}
 3271 
 3272   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3273     MacroAssembler _masm(&amp;cbuf);
 3274    Register dst_reg = as_Register($dst$$reg);
 3275    Register src1_reg = as_Register($src1$$reg);
 3276    Register src2_reg = as_Register($src2$$reg);
 3277     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3278   %}
 3279 
 3280   // compare instruction encodings
 3281 
 3282   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3283     MacroAssembler _masm(&amp;cbuf);
 3284     Register reg1 = as_Register($src1$$reg);
 3285     Register reg2 = as_Register($src2$$reg);
 3286     __ cmpw(reg1, reg2);
 3287   %}
 3288 
 3289   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3290     MacroAssembler _masm(&amp;cbuf);
 3291     Register reg = as_Register($src1$$reg);
 3292     int32_t val = $src2$$constant;
 3293     if (val &gt;= 0) {
 3294       __ subsw(zr, reg, val);
 3295     } else {
 3296       __ addsw(zr, reg, -val);
 3297     }
 3298   %}
 3299 
 3300   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3301     MacroAssembler _masm(&amp;cbuf);
 3302     Register reg1 = as_Register($src1$$reg);
 3303     u_int32_t val = (u_int32_t)$src2$$constant;
 3304     __ movw(rscratch1, val);
 3305     __ cmpw(reg1, rscratch1);
 3306   %}
 3307 
 3308   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3309     MacroAssembler _masm(&amp;cbuf);
 3310     Register reg1 = as_Register($src1$$reg);
 3311     Register reg2 = as_Register($src2$$reg);
 3312     __ cmp(reg1, reg2);
 3313   %}
 3314 
 3315   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3316     MacroAssembler _masm(&amp;cbuf);
 3317     Register reg = as_Register($src1$$reg);
 3318     int64_t val = $src2$$constant;
 3319     if (val &gt;= 0) {
 3320       __ subs(zr, reg, val);
 3321     } else if (val != -val) {
 3322       __ adds(zr, reg, -val);
 3323     } else {
 3324     // aargh, Long.MIN_VALUE is a special case
 3325       __ orr(rscratch1, zr, (u_int64_t)val);
 3326       __ subs(zr, reg, rscratch1);
 3327     }
 3328   %}
 3329 
 3330   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3331     MacroAssembler _masm(&amp;cbuf);
 3332     Register reg1 = as_Register($src1$$reg);
 3333     u_int64_t val = (u_int64_t)$src2$$constant;
 3334     __ mov(rscratch1, val);
 3335     __ cmp(reg1, rscratch1);
 3336   %}
 3337 
 3338   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3339     MacroAssembler _masm(&amp;cbuf);
 3340     Register reg1 = as_Register($src1$$reg);
 3341     Register reg2 = as_Register($src2$$reg);
 3342     __ cmp(reg1, reg2);
 3343   %}
 3344 
 3345   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3346     MacroAssembler _masm(&amp;cbuf);
 3347     Register reg1 = as_Register($src1$$reg);
 3348     Register reg2 = as_Register($src2$$reg);
 3349     __ cmpw(reg1, reg2);
 3350   %}
 3351 
 3352   enc_class aarch64_enc_testp(iRegP src) %{
 3353     MacroAssembler _masm(&amp;cbuf);
 3354     Register reg = as_Register($src$$reg);
 3355     __ cmp(reg, zr);
 3356   %}
 3357 
 3358   enc_class aarch64_enc_testn(iRegN src) %{
 3359     MacroAssembler _masm(&amp;cbuf);
 3360     Register reg = as_Register($src$$reg);
 3361     __ cmpw(reg, zr);
 3362   %}
 3363 
 3364   enc_class aarch64_enc_b(label lbl) %{
 3365     MacroAssembler _masm(&amp;cbuf);
 3366     Label *L = $lbl$$label;
 3367     __ b(*L);
 3368   %}
 3369 
 3370   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3371     MacroAssembler _masm(&amp;cbuf);
 3372     Label *L = $lbl$$label;
 3373     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3377     MacroAssembler _masm(&amp;cbuf);
 3378     Label *L = $lbl$$label;
 3379     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3380   %}
 3381 
 3382   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3383   %{
 3384      Register sub_reg = as_Register($sub$$reg);
 3385      Register super_reg = as_Register($super$$reg);
 3386      Register temp_reg = as_Register($temp$$reg);
 3387      Register result_reg = as_Register($result$$reg);
 3388 
 3389      Label miss;
 3390      MacroAssembler _masm(&amp;cbuf);
 3391      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3392                                      NULL, &amp;miss,
 3393                                      /*set_cond_codes:*/ true);
 3394      if ($primary) {
 3395        __ mov(result_reg, zr);
 3396      }
 3397      __ bind(miss);
 3398   %}
 3399 
 3400   enc_class aarch64_enc_java_static_call(method meth) %{
 3401     MacroAssembler _masm(&amp;cbuf);
 3402 
 3403     address addr = (address)$meth$$method;
 3404     address call;
 3405     if (!_method) {
 3406       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3407       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3408     } else {
 3409       int method_index = resolved_method_index(cbuf);
 3410       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3411                                                   : static_call_Relocation::spec(method_index);
 3412       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3413 
 3414       // Emit stub for static call
 3415       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3416       if (stub == NULL) {
 3417         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3418         return;
 3419       }
 3420     }
 3421     if (call == NULL) {
 3422       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3423       return;
 3424     }
 3425   %}
 3426 
 3427   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3428     MacroAssembler _masm(&amp;cbuf);
 3429     int method_index = resolved_method_index(cbuf);
 3430     address call = __ ic_call((address)$meth$$method, method_index);
 3431     if (call == NULL) {
 3432       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3433       return;
 3434     }
 3435   %}
 3436 
 3437   enc_class aarch64_enc_call_epilog() %{
 3438     MacroAssembler _masm(&amp;cbuf);
 3439     if (VerifyStackAtCalls) {
 3440       // Check that stack depth is unchanged: find majik cookie on stack
 3441       __ call_Unimplemented();
 3442     }
 3443   %}
 3444 
 3445   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3446     MacroAssembler _masm(&amp;cbuf);
 3447 
 3448     // some calls to generated routines (arraycopy code) are scheduled
 3449     // by C2 as runtime calls. if so we can call them using a br (they
 3450     // will be in a reachable segment) otherwise we have to use a blr
 3451     // which loads the absolute address into a register.
 3452     address entry = (address)$meth$$method;
 3453     CodeBlob *cb = CodeCache::find_blob(entry);
 3454     if (cb) {
 3455       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3456       if (call == NULL) {
 3457         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3458         return;
 3459       }
 3460     } else {
 3461       Label retaddr;
 3462       __ adr(rscratch2, retaddr);
 3463       __ lea(rscratch1, RuntimeAddress(entry));
 3464       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3465       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3466       __ blr(rscratch1);
 3467       __ bind(retaddr);
 3468       __ add(sp, sp, 2 * wordSize);
 3469     }
 3470   %}
 3471 
 3472   enc_class aarch64_enc_rethrow() %{
 3473     MacroAssembler _masm(&amp;cbuf);
 3474     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3475   %}
 3476 
 3477   enc_class aarch64_enc_ret() %{
 3478     MacroAssembler _masm(&amp;cbuf);
 3479     __ ret(lr);
 3480   %}
 3481 
 3482   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3483     MacroAssembler _masm(&amp;cbuf);
 3484     Register target_reg = as_Register($jump_target$$reg);
 3485     __ br(target_reg);
 3486   %}
 3487 
 3488   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3489     MacroAssembler _masm(&amp;cbuf);
 3490     Register target_reg = as_Register($jump_target$$reg);
 3491     // exception oop should be in r0
 3492     // ret addr has been popped into lr
 3493     // callee expects it in r3
 3494     __ mov(r3, lr);
 3495     __ br(target_reg);
 3496   %}
 3497 
 3498   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3499     MacroAssembler _masm(&amp;cbuf);
 3500     Register oop = as_Register($object$$reg);
 3501     Register box = as_Register($box$$reg);
 3502     Register disp_hdr = as_Register($tmp$$reg);
 3503     Register tmp = as_Register($tmp2$$reg);
 3504     Label cont;
 3505     Label object_has_monitor;
 3506     Label cas_failed;
 3507 
 3508     assert_different_registers(oop, box, tmp, disp_hdr);
 3509 
 3510     // Load markWord from object into displaced_header.
 3511     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3512 
 3513     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3514       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3515     }
 3516 
 3517     // Check for existing monitor
 3518     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3519 
 3520     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3521     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3522 
 3523     // Initialize the box. (Must happen before we update the object mark!)
 3524     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3525 
 3526     // Compare object markWord with an unlocked value (tmp) and if
 3527     // equal exchange the stack address of our box with object markWord.
 3528     // On failure disp_hdr contains the possibly locked markWord.
 3529     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3530                /*release*/ true, /*weak*/ false, disp_hdr);
 3531     __ br(Assembler::EQ, cont);
 3532 
 3533     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3534 
 3535     // If the compare-and-exchange succeeded, then we found an unlocked
 3536     // object, will have now locked it will continue at label cont
 3537 
 3538     __ bind(cas_failed);
 3539     // We did not see an unlocked object so try the fast recursive case.
 3540 
 3541     // Check if the owner is self by comparing the value in the
 3542     // markWord of object (disp_hdr) with the stack pointer.
 3543     __ mov(rscratch1, sp);
 3544     __ sub(disp_hdr, disp_hdr, rscratch1);
 3545     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3546     // If condition is true we are cont and hence we can store 0 as the
 3547     // displaced header in the box, which indicates that it is a recursive lock.
 3548     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3549     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3550 
 3551     __ b(cont);
 3552 
 3553     // Handle existing monitor.
 3554     __ bind(object_has_monitor);
 3555 
 3556     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3557     // otherwise m-&gt;owner may contain a thread or a stack address.
 3558     //
 3559     // Try to CAS m-&gt;owner from NULL to current thread.
 3560     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3561     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3562                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3563 
 3564     // Store a non-null value into the box to avoid looking like a re-entrant
 3565     // lock. The fast-path monitor unlock code checks for
 3566     // markWord::monitor_value so use markWord::unused_mark which has the
 3567     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3568     __ mov(tmp, (address)markWord::unused_mark().value());
 3569     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3570 
 3571     __ bind(cont);
 3572     // flag == EQ indicates success
 3573     // flag == NE indicates failure
 3574   %}
 3575 
 3576   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3577     MacroAssembler _masm(&amp;cbuf);
 3578     Register oop = as_Register($object$$reg);
 3579     Register box = as_Register($box$$reg);
 3580     Register disp_hdr = as_Register($tmp$$reg);
 3581     Register tmp = as_Register($tmp2$$reg);
 3582     Label cont;
 3583     Label object_has_monitor;
 3584 
 3585     assert_different_registers(oop, box, tmp, disp_hdr);
 3586 
 3587     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3588       __ biased_locking_exit(oop, tmp, cont);
 3589     }
 3590 
 3591     // Find the lock address and load the displaced header from the stack.
 3592     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3593 
 3594     // If the displaced header is 0, we have a recursive unlock.
 3595     __ cmp(disp_hdr, zr);
 3596     __ br(Assembler::EQ, cont);
 3597 
 3598     // Handle existing monitor.
 3599     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3600     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3601 
 3602     // Check if it is still a light weight lock, this is is true if we
 3603     // see the stack address of the basicLock in the markWord of the
 3604     // object.
 3605 
 3606     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3607                /*release*/ true, /*weak*/ false, tmp);
 3608     __ b(cont);
 3609 
 3610     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3611 
 3612     // Handle existing monitor.
 3613     __ bind(object_has_monitor);
 3614     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3615     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3616     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3617     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3618     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3619     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3620     __ cmp(rscratch1, zr); // Sets flags for result
 3621     __ br(Assembler::NE, cont);
 3622 
 3623     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3624     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3625     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3626     __ cmp(rscratch1, zr); // Sets flags for result
 3627     __ cbnz(rscratch1, cont);
 3628     // need a release store here
 3629     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3630     __ stlr(zr, tmp); // set unowned
 3631 
 3632     __ bind(cont);
 3633     // flag == EQ indicates success
 3634     // flag == NE indicates failure
 3635   %}
 3636 
 3637 %}
 3638 
 3639 //----------FRAME--------------------------------------------------------------
 3640 // Definition of frame structure and management information.
 3641 //
 3642 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3643 //                             |   (to get allocators register number
 3644 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3645 //  r   CALLER     |        |
 3646 //  o     |        +--------+      pad to even-align allocators stack-slot
 3647 //  w     V        |  pad0  |        numbers; owned by CALLER
 3648 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3649 //  h     ^        |   in   |  5
 3650 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3651 //  |     |        |        |  3
 3652 //  |     |        +--------+
 3653 //  V     |        | old out|      Empty on Intel, window on Sparc
 3654 //        |    old |preserve|      Must be even aligned.
 3655 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3656 //        |        |   in   |  3   area for Intel ret address
 3657 //     Owned by    |preserve|      Empty on Sparc.
 3658 //       SELF      +--------+
 3659 //        |        |  pad2  |  2   pad to align old SP
 3660 //        |        +--------+  1
 3661 //        |        | locks  |  0
 3662 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3663 //        |        |  pad1  | 11   pad to align new SP
 3664 //        |        +--------+
 3665 //        |        |        | 10
 3666 //        |        | spills |  9   spills
 3667 //        V        |        |  8   (pad0 slot for callee)
 3668 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3669 //        ^        |  out   |  7
 3670 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3671 //     Owned by    +--------+
 3672 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3673 //        |    new |preserve|      Must be even-aligned.
 3674 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3675 //        |        |        |
 3676 //
 3677 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3678 //         known from SELF&#39;s arguments and the Java calling convention.
 3679 //         Region 6-7 is determined per call site.
 3680 // Note 2: If the calling convention leaves holes in the incoming argument
 3681 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3682 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3683 //         incoming area, as the Java calling convention is completely under
 3684 //         the control of the AD file.  Doubles can be sorted and packed to
 3685 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3686 //         varargs C calling conventions.
 3687 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3688 //         even aligned with pad0 as needed.
 3689 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3690 //           (the latter is true on Intel but is it false on AArch64?)
 3691 //         region 6-11 is even aligned; it may be padded out more so that
 3692 //         the region from SP to FP meets the minimum stack alignment.
 3693 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3694 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3695 //         SP meets the minimum alignment.
 3696 
 3697 frame %{
 3698   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3699   stack_direction(TOWARDS_LOW);
 3700 
 3701   // These three registers define part of the calling convention
 3702   // between compiled code and the interpreter.
 3703 
 3704   // Inline Cache Register or methodOop for I2C.
 3705   inline_cache_reg(R12);
 3706 
 3707   // Method Oop Register when calling interpreter.
 3708   interpreter_method_oop_reg(R12);
 3709 
 3710   // Number of stack slots consumed by locking an object
 3711   sync_stack_slots(2);
 3712 
 3713   // Compiled code&#39;s Frame Pointer
 3714   frame_pointer(R31);
 3715 
 3716   // Interpreter stores its frame pointer in a register which is
 3717   // stored to the stack by I2CAdaptors.
 3718   // I2CAdaptors convert from interpreted java to compiled java.
 3719   interpreter_frame_pointer(R29);
 3720 
 3721   // Stack alignment requirement
 3722   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3723 
 3724   // Number of stack slots between incoming argument block and the start of
 3725   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3726   // EPILOG must remove this many slots. aarch64 needs two slots for
 3727   // return address and fp.
 3728   // TODO think this is correct but check
 3729   in_preserve_stack_slots(4);
 3730 
 3731   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3732   // for calls to C.  Supports the var-args backing area for register parms.
 3733   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3734 
 3735   // The after-PROLOG location of the return address.  Location of
 3736   // return address specifies a type (REG or STACK) and a number
 3737   // representing the register number (i.e. - use a register name) or
 3738   // stack slot.
 3739   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3740   // Otherwise, it is above the locks and verification slot and alignment word
 3741   // TODO this may well be correct but need to check why that - 2 is there
 3742   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3743   // which folds in the space used for monitors
 3744   return_addr(STACK - 2 +
 3745               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3746                         Compile::current()-&gt;fixed_slots()),
 3747                        stack_alignment_in_slots()));
 3748 
 3749   // Body of function which returns an integer array locating
 3750   // arguments either in registers or in stack slots.  Passed an array
 3751   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3752   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3753   // arguments for a CALLEE.  Incoming stack arguments are
 3754   // automatically biased by the preserve_stack_slots field above.
 3755 
 3756   calling_convention
 3757   %{
 3758     // No difference between ingoing/outgoing just pass false
 3759     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3760   %}
 3761 
 3762   c_calling_convention
 3763   %{
 3764     // This is obviously always outgoing
 3765     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3766   %}
 3767 
 3768   // Location of compiled Java return values.  Same as C for now.
 3769   return_value
 3770   %{
 3771     // TODO do we allow ideal_reg == Op_RegN???
 3772     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3773            &quot;only return normal values&quot;);
 3774 
 3775     static const int lo[Op_RegL + 1] = { // enum name
 3776       0,                                 // Op_Node
 3777       0,                                 // Op_Set
 3778       R0_num,                            // Op_RegN
 3779       R0_num,                            // Op_RegI
 3780       R0_num,                            // Op_RegP
 3781       V0_num,                            // Op_RegF
 3782       V0_num,                            // Op_RegD
 3783       R0_num                             // Op_RegL
 3784     };
 3785 
 3786     static const int hi[Op_RegL + 1] = { // enum name
 3787       0,                                 // Op_Node
 3788       0,                                 // Op_Set
 3789       OptoReg::Bad,                      // Op_RegN
 3790       OptoReg::Bad,                      // Op_RegI
 3791       R0_H_num,                          // Op_RegP
 3792       OptoReg::Bad,                      // Op_RegF
 3793       V0_H_num,                          // Op_RegD
 3794       R0_H_num                           // Op_RegL
 3795     };
 3796 
 3797     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3798   %}
 3799 %}
 3800 
 3801 //----------ATTRIBUTES---------------------------------------------------------
 3802 //----------Operand Attributes-------------------------------------------------
 3803 op_attrib op_cost(1);        // Required cost attribute
 3804 
 3805 //----------Instruction Attributes---------------------------------------------
 3806 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3807 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3808 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3809                                 // a non-matching short branch variant
 3810                                 // of some long branch?
 3811 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3812                                 // be a power of 2) specifies the
 3813                                 // alignment that some part of the
 3814                                 // instruction (not necessarily the
 3815                                 // start) requires.  If &gt; 1, a
 3816                                 // compute_padding() function must be
 3817                                 // provided for the instruction
 3818 
 3819 //----------OPERANDS-----------------------------------------------------------
 3820 // Operand definitions must precede instruction definitions for correct parsing
 3821 // in the ADLC because operands constitute user defined types which are used in
 3822 // instruction definitions.
 3823 
 3824 //----------Simple Operands----------------------------------------------------
 3825 
 3826 // Integer operands 32 bit
 3827 // 32 bit immediate
 3828 operand immI()
 3829 %{
 3830   match(ConI);
 3831 
 3832   op_cost(0);
 3833   format %{ %}
 3834   interface(CONST_INTER);
 3835 %}
 3836 
 3837 // 32 bit zero
 3838 operand immI0()
 3839 %{
 3840   predicate(n-&gt;get_int() == 0);
 3841   match(ConI);
 3842 
 3843   op_cost(0);
 3844   format %{ %}
 3845   interface(CONST_INTER);
 3846 %}
 3847 
 3848 // 32 bit unit increment
 3849 operand immI_1()
 3850 %{
 3851   predicate(n-&gt;get_int() == 1);
 3852   match(ConI);
 3853 
 3854   op_cost(0);
 3855   format %{ %}
 3856   interface(CONST_INTER);
 3857 %}
 3858 
 3859 // 32 bit unit decrement
 3860 operand immI_M1()
 3861 %{
 3862   predicate(n-&gt;get_int() == -1);
 3863   match(ConI);
 3864 
 3865   op_cost(0);
 3866   format %{ %}
 3867   interface(CONST_INTER);
 3868 %}
 3869 
 3870 // Shift values for add/sub extension shift
 3871 operand immIExt()
 3872 %{
 3873   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3874   match(ConI);
 3875 
 3876   op_cost(0);
 3877   format %{ %}
 3878   interface(CONST_INTER);
 3879 %}
 3880 
 3881 operand immI_le_4()
 3882 %{
 3883   predicate(n-&gt;get_int() &lt;= 4);
 3884   match(ConI);
 3885 
 3886   op_cost(0);
 3887   format %{ %}
 3888   interface(CONST_INTER);
 3889 %}
 3890 
 3891 operand immI_31()
 3892 %{
 3893   predicate(n-&gt;get_int() == 31);
 3894   match(ConI);
 3895 
 3896   op_cost(0);
 3897   format %{ %}
 3898   interface(CONST_INTER);
 3899 %}
 3900 
 3901 operand immI_8()
 3902 %{
 3903   predicate(n-&gt;get_int() == 8);
 3904   match(ConI);
 3905 
 3906   op_cost(0);
 3907   format %{ %}
 3908   interface(CONST_INTER);
 3909 %}
 3910 
 3911 operand immI_16()
 3912 %{
 3913   predicate(n-&gt;get_int() == 16);
 3914   match(ConI);
 3915 
 3916   op_cost(0);
 3917   format %{ %}
 3918   interface(CONST_INTER);
 3919 %}
 3920 
 3921 operand immI_24()
 3922 %{
 3923   predicate(n-&gt;get_int() == 24);
 3924   match(ConI);
 3925 
 3926   op_cost(0);
 3927   format %{ %}
 3928   interface(CONST_INTER);
 3929 %}
 3930 
 3931 operand immI_32()
 3932 %{
 3933   predicate(n-&gt;get_int() == 32);
 3934   match(ConI);
 3935 
 3936   op_cost(0);
 3937   format %{ %}
 3938   interface(CONST_INTER);
 3939 %}
 3940 
 3941 operand immI_48()
 3942 %{
 3943   predicate(n-&gt;get_int() == 48);
 3944   match(ConI);
 3945 
 3946   op_cost(0);
 3947   format %{ %}
 3948   interface(CONST_INTER);
 3949 %}
 3950 
 3951 operand immI_56()
 3952 %{
 3953   predicate(n-&gt;get_int() == 56);
 3954   match(ConI);
 3955 
 3956   op_cost(0);
 3957   format %{ %}
 3958   interface(CONST_INTER);
 3959 %}
 3960 
 3961 operand immI_63()
 3962 %{
 3963   predicate(n-&gt;get_int() == 63);
 3964   match(ConI);
 3965 
 3966   op_cost(0);
 3967   format %{ %}
 3968   interface(CONST_INTER);
 3969 %}
 3970 
 3971 operand immI_64()
 3972 %{
 3973   predicate(n-&gt;get_int() == 64);
 3974   match(ConI);
 3975 
 3976   op_cost(0);
 3977   format %{ %}
 3978   interface(CONST_INTER);
 3979 %}
 3980 
 3981 operand immI_255()
 3982 %{
 3983   predicate(n-&gt;get_int() == 255);
 3984   match(ConI);
 3985 
 3986   op_cost(0);
 3987   format %{ %}
 3988   interface(CONST_INTER);
 3989 %}
 3990 
 3991 operand immI_65535()
 3992 %{
 3993   predicate(n-&gt;get_int() == 65535);
 3994   match(ConI);
 3995 
 3996   op_cost(0);
 3997   format %{ %}
 3998   interface(CONST_INTER);
 3999 %}
 4000 
 4001 operand immL_255()
 4002 %{
 4003   predicate(n-&gt;get_long() == 255L);
 4004   match(ConL);
 4005 
 4006   op_cost(0);
 4007   format %{ %}
 4008   interface(CONST_INTER);
 4009 %}
 4010 
 4011 operand immL_65535()
 4012 %{
 4013   predicate(n-&gt;get_long() == 65535L);
 4014   match(ConL);
 4015 
 4016   op_cost(0);
 4017   format %{ %}
 4018   interface(CONST_INTER);
 4019 %}
 4020 
 4021 operand immL_4294967295()
 4022 %{
 4023   predicate(n-&gt;get_long() == 4294967295L);
 4024   match(ConL);
 4025 
 4026   op_cost(0);
 4027   format %{ %}
 4028   interface(CONST_INTER);
 4029 %}
 4030 
 4031 operand immL_bitmask()
 4032 %{
 4033   predicate((n-&gt;get_long() != 0)
 4034             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4035             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4036   match(ConL);
 4037 
 4038   op_cost(0);
 4039   format %{ %}
 4040   interface(CONST_INTER);
 4041 %}
 4042 
 4043 operand immI_bitmask()
 4044 %{
 4045   predicate((n-&gt;get_int() != 0)
 4046             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4047             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4048   match(ConI);
 4049 
 4050   op_cost(0);
 4051   format %{ %}
 4052   interface(CONST_INTER);
 4053 %}
 4054 
 4055 // Scale values for scaled offset addressing modes (up to long but not quad)
 4056 operand immIScale()
 4057 %{
 4058   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4059   match(ConI);
 4060 
 4061   op_cost(0);
 4062   format %{ %}
 4063   interface(CONST_INTER);
 4064 %}
 4065 
 4066 // 26 bit signed offset -- for pc-relative branches
 4067 operand immI26()
 4068 %{
 4069   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4070   match(ConI);
 4071 
 4072   op_cost(0);
 4073   format %{ %}
 4074   interface(CONST_INTER);
 4075 %}
 4076 
 4077 // 19 bit signed offset -- for pc-relative loads
 4078 operand immI19()
 4079 %{
 4080   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4081   match(ConI);
 4082 
 4083   op_cost(0);
 4084   format %{ %}
 4085   interface(CONST_INTER);
 4086 %}
 4087 
 4088 // 12 bit unsigned offset -- for base plus immediate loads
 4089 operand immIU12()
 4090 %{
 4091   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4092   match(ConI);
 4093 
 4094   op_cost(0);
 4095   format %{ %}
 4096   interface(CONST_INTER);
 4097 %}
 4098 
 4099 operand immLU12()
 4100 %{
 4101   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4102   match(ConL);
 4103 
 4104   op_cost(0);
 4105   format %{ %}
 4106   interface(CONST_INTER);
 4107 %}
 4108 
 4109 // Offset for scaled or unscaled immediate loads and stores
 4110 operand immIOffset()
 4111 %{
 4112   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4113   match(ConI);
 4114 
 4115   op_cost(0);
 4116   format %{ %}
 4117   interface(CONST_INTER);
 4118 %}
 4119 
 4120 operand immIOffset1()
 4121 %{
 4122   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4123   match(ConI);
 4124 
 4125   op_cost(0);
 4126   format %{ %}
 4127   interface(CONST_INTER);
 4128 %}
 4129 
 4130 operand immIOffset2()
 4131 %{
 4132   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4133   match(ConI);
 4134 
 4135   op_cost(0);
 4136   format %{ %}
 4137   interface(CONST_INTER);
 4138 %}
 4139 
 4140 operand immIOffset4()
 4141 %{
 4142   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4143   match(ConI);
 4144 
 4145   op_cost(0);
 4146   format %{ %}
 4147   interface(CONST_INTER);
 4148 %}
 4149 
 4150 operand immIOffset8()
 4151 %{
 4152   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4153   match(ConI);
 4154 
 4155   op_cost(0);
 4156   format %{ %}
 4157   interface(CONST_INTER);
 4158 %}
 4159 
 4160 operand immIOffset16()
 4161 %{
 4162   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4163   match(ConI);
 4164 
 4165   op_cost(0);
 4166   format %{ %}
 4167   interface(CONST_INTER);
 4168 %}
 4169 
 4170 operand immLoffset()
 4171 %{
 4172   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4173   match(ConL);
 4174 
 4175   op_cost(0);
 4176   format %{ %}
 4177   interface(CONST_INTER);
 4178 %}
 4179 
 4180 operand immLoffset1()
 4181 %{
 4182   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4183   match(ConL);
 4184 
 4185   op_cost(0);
 4186   format %{ %}
 4187   interface(CONST_INTER);
 4188 %}
 4189 
 4190 operand immLoffset2()
 4191 %{
 4192   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4193   match(ConL);
 4194 
 4195   op_cost(0);
 4196   format %{ %}
 4197   interface(CONST_INTER);
 4198 %}
 4199 
 4200 operand immLoffset4()
 4201 %{
 4202   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4203   match(ConL);
 4204 
 4205   op_cost(0);
 4206   format %{ %}
 4207   interface(CONST_INTER);
 4208 %}
 4209 
 4210 operand immLoffset8()
 4211 %{
 4212   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4213   match(ConL);
 4214 
 4215   op_cost(0);
 4216   format %{ %}
 4217   interface(CONST_INTER);
 4218 %}
 4219 
 4220 operand immLoffset16()
 4221 %{
 4222   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4223   match(ConL);
 4224 
 4225   op_cost(0);
 4226   format %{ %}
 4227   interface(CONST_INTER);
 4228 %}
 4229 
 4230 // 32 bit integer valid for add sub immediate
 4231 operand immIAddSub()
 4232 %{
 4233   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4234   match(ConI);
 4235   op_cost(0);
 4236   format %{ %}
 4237   interface(CONST_INTER);
 4238 %}
 4239 
 4240 // 32 bit unsigned integer valid for logical immediate
 4241 // TODO -- check this is right when e.g the mask is 0x80000000
 4242 operand immILog()
 4243 %{
 4244   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4245   match(ConI);
 4246 
 4247   op_cost(0);
 4248   format %{ %}
 4249   interface(CONST_INTER);
 4250 %}
 4251 
 4252 // Integer operands 64 bit
 4253 // 64 bit immediate
 4254 operand immL()
 4255 %{
 4256   match(ConL);
 4257 
 4258   op_cost(0);
 4259   format %{ %}
 4260   interface(CONST_INTER);
 4261 %}
 4262 
 4263 // 64 bit zero
 4264 operand immL0()
 4265 %{
 4266   predicate(n-&gt;get_long() == 0);
 4267   match(ConL);
 4268 
 4269   op_cost(0);
 4270   format %{ %}
 4271   interface(CONST_INTER);
 4272 %}
 4273 
 4274 // 64 bit unit increment
 4275 operand immL_1()
 4276 %{
 4277   predicate(n-&gt;get_long() == 1);
 4278   match(ConL);
 4279 
 4280   op_cost(0);
 4281   format %{ %}
 4282   interface(CONST_INTER);
 4283 %}
 4284 
 4285 // 64 bit unit decrement
 4286 operand immL_M1()
 4287 %{
 4288   predicate(n-&gt;get_long() == -1);
 4289   match(ConL);
 4290 
 4291   op_cost(0);
 4292   format %{ %}
 4293   interface(CONST_INTER);
 4294 %}
 4295 
 4296 // 32 bit offset of pc in thread anchor
 4297 
 4298 operand immL_pc_off()
 4299 %{
 4300   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4301                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4302   match(ConL);
 4303 
 4304   op_cost(0);
 4305   format %{ %}
 4306   interface(CONST_INTER);
 4307 %}
 4308 
 4309 // 64 bit integer valid for add sub immediate
 4310 operand immLAddSub()
 4311 %{
 4312   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4313   match(ConL);
 4314   op_cost(0);
 4315   format %{ %}
 4316   interface(CONST_INTER);
 4317 %}
 4318 
 4319 // 64 bit integer valid for logical immediate
 4320 operand immLLog()
 4321 %{
 4322   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4323   match(ConL);
 4324   op_cost(0);
 4325   format %{ %}
 4326   interface(CONST_INTER);
 4327 %}
 4328 
 4329 // Long Immediate: low 32-bit mask
 4330 operand immL_32bits()
 4331 %{
 4332   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4333   match(ConL);
 4334   op_cost(0);
 4335   format %{ %}
 4336   interface(CONST_INTER);
 4337 %}
 4338 
 4339 // Pointer operands
 4340 // Pointer Immediate
 4341 operand immP()
 4342 %{
 4343   match(ConP);
 4344 
 4345   op_cost(0);
 4346   format %{ %}
 4347   interface(CONST_INTER);
 4348 %}
 4349 
 4350 // NULL Pointer Immediate
 4351 operand immP0()
 4352 %{
 4353   predicate(n-&gt;get_ptr() == 0);
 4354   match(ConP);
 4355 
 4356   op_cost(0);
 4357   format %{ %}
 4358   interface(CONST_INTER);
 4359 %}
 4360 
 4361 // Pointer Immediate One
 4362 // this is used in object initialization (initial object header)
 4363 operand immP_1()
 4364 %{
 4365   predicate(n-&gt;get_ptr() == 1);
 4366   match(ConP);
 4367 
 4368   op_cost(0);
 4369   format %{ %}
 4370   interface(CONST_INTER);
 4371 %}
 4372 
 4373 // Polling Page Pointer Immediate
 4374 operand immPollPage()
 4375 %{
 4376   predicate((address)n-&gt;get_ptr() == os::get_polling_page());
 4377   match(ConP);
 4378 
 4379   op_cost(0);
 4380   format %{ %}
 4381   interface(CONST_INTER);
 4382 %}
 4383 
 4384 // Card Table Byte Map Base
 4385 operand immByteMapBase()
 4386 %{
 4387   // Get base of card map
 4388   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4389             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4390   match(ConP);
 4391 
 4392   op_cost(0);
 4393   format %{ %}
 4394   interface(CONST_INTER);
 4395 %}
 4396 
 4397 // Pointer Immediate Minus One
 4398 // this is used when we want to write the current PC to the thread anchor
 4399 operand immP_M1()
 4400 %{
 4401   predicate(n-&gt;get_ptr() == -1);
 4402   match(ConP);
 4403 
 4404   op_cost(0);
 4405   format %{ %}
 4406   interface(CONST_INTER);
 4407 %}
 4408 
 4409 // Pointer Immediate Minus Two
 4410 // this is used when we want to write the current PC to the thread anchor
 4411 operand immP_M2()
 4412 %{
 4413   predicate(n-&gt;get_ptr() == -2);
 4414   match(ConP);
 4415 
 4416   op_cost(0);
 4417   format %{ %}
 4418   interface(CONST_INTER);
 4419 %}
 4420 
 4421 // Float and Double operands
 4422 // Double Immediate
 4423 operand immD()
 4424 %{
 4425   match(ConD);
 4426   op_cost(0);
 4427   format %{ %}
 4428   interface(CONST_INTER);
 4429 %}
 4430 
 4431 // Double Immediate: +0.0d
 4432 operand immD0()
 4433 %{
 4434   predicate(jlong_cast(n-&gt;getd()) == 0);
 4435   match(ConD);
 4436 
 4437   op_cost(0);
 4438   format %{ %}
 4439   interface(CONST_INTER);
 4440 %}
 4441 
 4442 // constant &#39;double +0.0&#39;.
 4443 operand immDPacked()
 4444 %{
 4445   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4446   match(ConD);
 4447   op_cost(0);
 4448   format %{ %}
 4449   interface(CONST_INTER);
 4450 %}
 4451 
 4452 // Float Immediate
 4453 operand immF()
 4454 %{
 4455   match(ConF);
 4456   op_cost(0);
 4457   format %{ %}
 4458   interface(CONST_INTER);
 4459 %}
 4460 
 4461 // Float Immediate: +0.0f.
 4462 operand immF0()
 4463 %{
 4464   predicate(jint_cast(n-&gt;getf()) == 0);
 4465   match(ConF);
 4466 
 4467   op_cost(0);
 4468   format %{ %}
 4469   interface(CONST_INTER);
 4470 %}
 4471 
 4472 //
 4473 operand immFPacked()
 4474 %{
 4475   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4476   match(ConF);
 4477   op_cost(0);
 4478   format %{ %}
 4479   interface(CONST_INTER);
 4480 %}
 4481 
 4482 // Narrow pointer operands
 4483 // Narrow Pointer Immediate
 4484 operand immN()
 4485 %{
 4486   match(ConN);
 4487 
 4488   op_cost(0);
 4489   format %{ %}
 4490   interface(CONST_INTER);
 4491 %}
 4492 
 4493 // Narrow NULL Pointer Immediate
 4494 operand immN0()
 4495 %{
 4496   predicate(n-&gt;get_narrowcon() == 0);
 4497   match(ConN);
 4498 
 4499   op_cost(0);
 4500   format %{ %}
 4501   interface(CONST_INTER);
 4502 %}
 4503 
 4504 operand immNKlass()
 4505 %{
 4506   match(ConNKlass);
 4507 
 4508   op_cost(0);
 4509   format %{ %}
 4510   interface(CONST_INTER);
 4511 %}
 4512 
 4513 // Integer 32 bit Register Operands
 4514 // Integer 32 bitRegister (excludes SP)
 4515 operand iRegI()
 4516 %{
 4517   constraint(ALLOC_IN_RC(any_reg32));
 4518   match(RegI);
 4519   match(iRegINoSp);
 4520   op_cost(0);
 4521   format %{ %}
 4522   interface(REG_INTER);
 4523 %}
 4524 
 4525 // Integer 32 bit Register not Special
 4526 operand iRegINoSp()
 4527 %{
 4528   constraint(ALLOC_IN_RC(no_special_reg32));
 4529   match(RegI);
 4530   op_cost(0);
 4531   format %{ %}
 4532   interface(REG_INTER);
 4533 %}
 4534 
 4535 // Integer 64 bit Register Operands
 4536 // Integer 64 bit Register (includes SP)
 4537 operand iRegL()
 4538 %{
 4539   constraint(ALLOC_IN_RC(any_reg));
 4540   match(RegL);
 4541   match(iRegLNoSp);
 4542   op_cost(0);
 4543   format %{ %}
 4544   interface(REG_INTER);
 4545 %}
 4546 
 4547 // Integer 64 bit Register not Special
 4548 operand iRegLNoSp()
 4549 %{
 4550   constraint(ALLOC_IN_RC(no_special_reg));
 4551   match(RegL);
 4552   match(iRegL_R0);
 4553   format %{ %}
 4554   interface(REG_INTER);
 4555 %}
 4556 
 4557 // Pointer Register Operands
 4558 // Pointer Register
 4559 operand iRegP()
 4560 %{
 4561   constraint(ALLOC_IN_RC(ptr_reg));
 4562   match(RegP);
 4563   match(iRegPNoSp);
 4564   match(iRegP_R0);
 4565   //match(iRegP_R2);
 4566   //match(iRegP_R4);
 4567   //match(iRegP_R5);
 4568   match(thread_RegP);
 4569   op_cost(0);
 4570   format %{ %}
 4571   interface(REG_INTER);
 4572 %}
 4573 
 4574 // Pointer 64 bit Register not Special
 4575 operand iRegPNoSp()
 4576 %{
 4577   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4578   match(RegP);
 4579   // match(iRegP);
 4580   // match(iRegP_R0);
 4581   // match(iRegP_R2);
 4582   // match(iRegP_R4);
 4583   // match(iRegP_R5);
 4584   // match(thread_RegP);
 4585   op_cost(0);
 4586   format %{ %}
 4587   interface(REG_INTER);
 4588 %}
 4589 
 4590 // Pointer 64 bit Register R0 only
 4591 operand iRegP_R0()
 4592 %{
 4593   constraint(ALLOC_IN_RC(r0_reg));
 4594   match(RegP);
 4595   // match(iRegP);
 4596   match(iRegPNoSp);
 4597   op_cost(0);
 4598   format %{ %}
 4599   interface(REG_INTER);
 4600 %}
 4601 
 4602 // Pointer 64 bit Register R1 only
 4603 operand iRegP_R1()
 4604 %{
 4605   constraint(ALLOC_IN_RC(r1_reg));
 4606   match(RegP);
 4607   // match(iRegP);
 4608   match(iRegPNoSp);
 4609   op_cost(0);
 4610   format %{ %}
 4611   interface(REG_INTER);
 4612 %}
 4613 
 4614 // Pointer 64 bit Register R2 only
 4615 operand iRegP_R2()
 4616 %{
 4617   constraint(ALLOC_IN_RC(r2_reg));
 4618   match(RegP);
 4619   // match(iRegP);
 4620   match(iRegPNoSp);
 4621   op_cost(0);
 4622   format %{ %}
 4623   interface(REG_INTER);
 4624 %}
 4625 
 4626 // Pointer 64 bit Register R3 only
 4627 operand iRegP_R3()
 4628 %{
 4629   constraint(ALLOC_IN_RC(r3_reg));
 4630   match(RegP);
 4631   // match(iRegP);
 4632   match(iRegPNoSp);
 4633   op_cost(0);
 4634   format %{ %}
 4635   interface(REG_INTER);
 4636 %}
 4637 
 4638 // Pointer 64 bit Register R4 only
 4639 operand iRegP_R4()
 4640 %{
 4641   constraint(ALLOC_IN_RC(r4_reg));
 4642   match(RegP);
 4643   // match(iRegP);
 4644   match(iRegPNoSp);
 4645   op_cost(0);
 4646   format %{ %}
 4647   interface(REG_INTER);
 4648 %}
 4649 
 4650 // Pointer 64 bit Register R5 only
 4651 operand iRegP_R5()
 4652 %{
 4653   constraint(ALLOC_IN_RC(r5_reg));
 4654   match(RegP);
 4655   // match(iRegP);
 4656   match(iRegPNoSp);
 4657   op_cost(0);
 4658   format %{ %}
 4659   interface(REG_INTER);
 4660 %}
 4661 
 4662 // Pointer 64 bit Register R10 only
 4663 operand iRegP_R10()
 4664 %{
 4665   constraint(ALLOC_IN_RC(r10_reg));
 4666   match(RegP);
 4667   // match(iRegP);
 4668   match(iRegPNoSp);
 4669   op_cost(0);
 4670   format %{ %}
 4671   interface(REG_INTER);
 4672 %}
 4673 
 4674 // Long 64 bit Register R0 only
 4675 operand iRegL_R0()
 4676 %{
 4677   constraint(ALLOC_IN_RC(r0_reg));
 4678   match(RegL);
 4679   match(iRegLNoSp);
 4680   op_cost(0);
 4681   format %{ %}
 4682   interface(REG_INTER);
 4683 %}
 4684 
 4685 // Long 64 bit Register R2 only
 4686 operand iRegL_R2()
 4687 %{
 4688   constraint(ALLOC_IN_RC(r2_reg));
 4689   match(RegL);
 4690   match(iRegLNoSp);
 4691   op_cost(0);
 4692   format %{ %}
 4693   interface(REG_INTER);
 4694 %}
 4695 
 4696 // Long 64 bit Register R3 only
 4697 operand iRegL_R3()
 4698 %{
 4699   constraint(ALLOC_IN_RC(r3_reg));
 4700   match(RegL);
 4701   match(iRegLNoSp);
 4702   op_cost(0);
 4703   format %{ %}
 4704   interface(REG_INTER);
 4705 %}
 4706 
 4707 // Long 64 bit Register R11 only
 4708 operand iRegL_R11()
 4709 %{
 4710   constraint(ALLOC_IN_RC(r11_reg));
 4711   match(RegL);
 4712   match(iRegLNoSp);
 4713   op_cost(0);
 4714   format %{ %}
 4715   interface(REG_INTER);
 4716 %}
 4717 
 4718 // Pointer 64 bit Register FP only
 4719 operand iRegP_FP()
 4720 %{
 4721   constraint(ALLOC_IN_RC(fp_reg));
 4722   match(RegP);
 4723   // match(iRegP);
 4724   op_cost(0);
 4725   format %{ %}
 4726   interface(REG_INTER);
 4727 %}
 4728 
 4729 // Register R0 only
 4730 operand iRegI_R0()
 4731 %{
 4732   constraint(ALLOC_IN_RC(int_r0_reg));
 4733   match(RegI);
 4734   match(iRegINoSp);
 4735   op_cost(0);
 4736   format %{ %}
 4737   interface(REG_INTER);
 4738 %}
 4739 
 4740 // Register R2 only
 4741 operand iRegI_R2()
 4742 %{
 4743   constraint(ALLOC_IN_RC(int_r2_reg));
 4744   match(RegI);
 4745   match(iRegINoSp);
 4746   op_cost(0);
 4747   format %{ %}
 4748   interface(REG_INTER);
 4749 %}
 4750 
 4751 // Register R3 only
 4752 operand iRegI_R3()
 4753 %{
 4754   constraint(ALLOC_IN_RC(int_r3_reg));
 4755   match(RegI);
 4756   match(iRegINoSp);
 4757   op_cost(0);
 4758   format %{ %}
 4759   interface(REG_INTER);
 4760 %}
 4761 
 4762 
 4763 // Register R4 only
 4764 operand iRegI_R4()
 4765 %{
 4766   constraint(ALLOC_IN_RC(int_r4_reg));
 4767   match(RegI);
 4768   match(iRegINoSp);
 4769   op_cost(0);
 4770   format %{ %}
 4771   interface(REG_INTER);
 4772 %}
 4773 
 4774 
 4775 // Pointer Register Operands
 4776 // Narrow Pointer Register
 4777 operand iRegN()
 4778 %{
 4779   constraint(ALLOC_IN_RC(any_reg32));
 4780   match(RegN);
 4781   match(iRegNNoSp);
 4782   op_cost(0);
 4783   format %{ %}
 4784   interface(REG_INTER);
 4785 %}
 4786 
 4787 operand iRegN_R0()
 4788 %{
 4789   constraint(ALLOC_IN_RC(r0_reg));
 4790   match(iRegN);
 4791   op_cost(0);
 4792   format %{ %}
 4793   interface(REG_INTER);
 4794 %}
 4795 
 4796 operand iRegN_R2()
 4797 %{
 4798   constraint(ALLOC_IN_RC(r2_reg));
 4799   match(iRegN);
 4800   op_cost(0);
 4801   format %{ %}
 4802   interface(REG_INTER);
 4803 %}
 4804 
 4805 operand iRegN_R3()
 4806 %{
 4807   constraint(ALLOC_IN_RC(r3_reg));
 4808   match(iRegN);
 4809   op_cost(0);
 4810   format %{ %}
 4811   interface(REG_INTER);
 4812 %}
 4813 
 4814 // Integer 64 bit Register not Special
 4815 operand iRegNNoSp()
 4816 %{
 4817   constraint(ALLOC_IN_RC(no_special_reg32));
 4818   match(RegN);
 4819   op_cost(0);
 4820   format %{ %}
 4821   interface(REG_INTER);
 4822 %}
 4823 
 4824 // heap base register -- used for encoding immN0
 4825 
 4826 operand iRegIHeapbase()
 4827 %{
 4828   constraint(ALLOC_IN_RC(heapbase_reg));
 4829   match(RegI);
 4830   op_cost(0);
 4831   format %{ %}
 4832   interface(REG_INTER);
 4833 %}
 4834 
 4835 // Float Register
 4836 // Float register operands
 4837 operand vRegF()
 4838 %{
 4839   constraint(ALLOC_IN_RC(float_reg));
 4840   match(RegF);
 4841 
 4842   op_cost(0);
 4843   format %{ %}
 4844   interface(REG_INTER);
 4845 %}
 4846 
 4847 // Double Register
 4848 // Double register operands
 4849 operand vRegD()
 4850 %{
 4851   constraint(ALLOC_IN_RC(double_reg));
 4852   match(RegD);
 4853 
 4854   op_cost(0);
 4855   format %{ %}
 4856   interface(REG_INTER);
 4857 %}
 4858 
 4859 operand vecD()
 4860 %{
 4861   constraint(ALLOC_IN_RC(vectord_reg));
 4862   match(VecD);
 4863 
 4864   op_cost(0);
 4865   format %{ %}
 4866   interface(REG_INTER);
 4867 %}
 4868 
 4869 operand vecX()
 4870 %{
 4871   constraint(ALLOC_IN_RC(vectorx_reg));
 4872   match(VecX);
 4873 
 4874   op_cost(0);
 4875   format %{ %}
 4876   interface(REG_INTER);
 4877 %}
 4878 
 4879 operand vRegD_V0()
 4880 %{
 4881   constraint(ALLOC_IN_RC(v0_reg));
 4882   match(RegD);
 4883   op_cost(0);
 4884   format %{ %}
 4885   interface(REG_INTER);
 4886 %}
 4887 
 4888 operand vRegD_V1()
 4889 %{
 4890   constraint(ALLOC_IN_RC(v1_reg));
 4891   match(RegD);
 4892   op_cost(0);
 4893   format %{ %}
 4894   interface(REG_INTER);
 4895 %}
 4896 
 4897 operand vRegD_V2()
 4898 %{
 4899   constraint(ALLOC_IN_RC(v2_reg));
 4900   match(RegD);
 4901   op_cost(0);
 4902   format %{ %}
 4903   interface(REG_INTER);
 4904 %}
 4905 
 4906 operand vRegD_V3()
 4907 %{
 4908   constraint(ALLOC_IN_RC(v3_reg));
 4909   match(RegD);
 4910   op_cost(0);
 4911   format %{ %}
 4912   interface(REG_INTER);
 4913 %}
 4914 
 4915 operand vRegD_V4()
 4916 %{
 4917   constraint(ALLOC_IN_RC(v4_reg));
 4918   match(RegD);
 4919   op_cost(0);
 4920   format %{ %}
 4921   interface(REG_INTER);
 4922 %}
 4923 
 4924 operand vRegD_V5()
 4925 %{
 4926   constraint(ALLOC_IN_RC(v5_reg));
 4927   match(RegD);
 4928   op_cost(0);
 4929   format %{ %}
 4930   interface(REG_INTER);
 4931 %}
 4932 
 4933 operand vRegD_V6()
 4934 %{
 4935   constraint(ALLOC_IN_RC(v6_reg));
 4936   match(RegD);
 4937   op_cost(0);
 4938   format %{ %}
 4939   interface(REG_INTER);
 4940 %}
 4941 
 4942 operand vRegD_V7()
 4943 %{
 4944   constraint(ALLOC_IN_RC(v7_reg));
 4945   match(RegD);
 4946   op_cost(0);
 4947   format %{ %}
 4948   interface(REG_INTER);
 4949 %}
 4950 
 4951 operand vRegD_V8()
 4952 %{
 4953   constraint(ALLOC_IN_RC(v8_reg));
 4954   match(RegD);
 4955   op_cost(0);
 4956   format %{ %}
 4957   interface(REG_INTER);
 4958 %}
 4959 
 4960 operand vRegD_V9()
 4961 %{
 4962   constraint(ALLOC_IN_RC(v9_reg));
 4963   match(RegD);
 4964   op_cost(0);
 4965   format %{ %}
 4966   interface(REG_INTER);
 4967 %}
 4968 
 4969 operand vRegD_V10()
 4970 %{
 4971   constraint(ALLOC_IN_RC(v10_reg));
 4972   match(RegD);
 4973   op_cost(0);
 4974   format %{ %}
 4975   interface(REG_INTER);
 4976 %}
 4977 
 4978 operand vRegD_V11()
 4979 %{
 4980   constraint(ALLOC_IN_RC(v11_reg));
 4981   match(RegD);
 4982   op_cost(0);
 4983   format %{ %}
 4984   interface(REG_INTER);
 4985 %}
 4986 
 4987 operand vRegD_V12()
 4988 %{
 4989   constraint(ALLOC_IN_RC(v12_reg));
 4990   match(RegD);
 4991   op_cost(0);
 4992   format %{ %}
 4993   interface(REG_INTER);
 4994 %}
 4995 
 4996 operand vRegD_V13()
 4997 %{
 4998   constraint(ALLOC_IN_RC(v13_reg));
 4999   match(RegD);
 5000   op_cost(0);
 5001   format %{ %}
 5002   interface(REG_INTER);
 5003 %}
 5004 
 5005 operand vRegD_V14()
 5006 %{
 5007   constraint(ALLOC_IN_RC(v14_reg));
 5008   match(RegD);
 5009   op_cost(0);
 5010   format %{ %}
 5011   interface(REG_INTER);
 5012 %}
 5013 
 5014 operand vRegD_V15()
 5015 %{
 5016   constraint(ALLOC_IN_RC(v15_reg));
 5017   match(RegD);
 5018   op_cost(0);
 5019   format %{ %}
 5020   interface(REG_INTER);
 5021 %}
 5022 
 5023 operand vRegD_V16()
 5024 %{
 5025   constraint(ALLOC_IN_RC(v16_reg));
 5026   match(RegD);
 5027   op_cost(0);
 5028   format %{ %}
 5029   interface(REG_INTER);
 5030 %}
 5031 
 5032 operand vRegD_V17()
 5033 %{
 5034   constraint(ALLOC_IN_RC(v17_reg));
 5035   match(RegD);
 5036   op_cost(0);
 5037   format %{ %}
 5038   interface(REG_INTER);
 5039 %}
 5040 
 5041 operand vRegD_V18()
 5042 %{
 5043   constraint(ALLOC_IN_RC(v18_reg));
 5044   match(RegD);
 5045   op_cost(0);
 5046   format %{ %}
 5047   interface(REG_INTER);
 5048 %}
 5049 
 5050 operand vRegD_V19()
 5051 %{
 5052   constraint(ALLOC_IN_RC(v19_reg));
 5053   match(RegD);
 5054   op_cost(0);
 5055   format %{ %}
 5056   interface(REG_INTER);
 5057 %}
 5058 
 5059 operand vRegD_V20()
 5060 %{
 5061   constraint(ALLOC_IN_RC(v20_reg));
 5062   match(RegD);
 5063   op_cost(0);
 5064   format %{ %}
 5065   interface(REG_INTER);
 5066 %}
 5067 
 5068 operand vRegD_V21()
 5069 %{
 5070   constraint(ALLOC_IN_RC(v21_reg));
 5071   match(RegD);
 5072   op_cost(0);
 5073   format %{ %}
 5074   interface(REG_INTER);
 5075 %}
 5076 
 5077 operand vRegD_V22()
 5078 %{
 5079   constraint(ALLOC_IN_RC(v22_reg));
 5080   match(RegD);
 5081   op_cost(0);
 5082   format %{ %}
 5083   interface(REG_INTER);
 5084 %}
 5085 
 5086 operand vRegD_V23()
 5087 %{
 5088   constraint(ALLOC_IN_RC(v23_reg));
 5089   match(RegD);
 5090   op_cost(0);
 5091   format %{ %}
 5092   interface(REG_INTER);
 5093 %}
 5094 
 5095 operand vRegD_V24()
 5096 %{
 5097   constraint(ALLOC_IN_RC(v24_reg));
 5098   match(RegD);
 5099   op_cost(0);
 5100   format %{ %}
 5101   interface(REG_INTER);
 5102 %}
 5103 
 5104 operand vRegD_V25()
 5105 %{
 5106   constraint(ALLOC_IN_RC(v25_reg));
 5107   match(RegD);
 5108   op_cost(0);
 5109   format %{ %}
 5110   interface(REG_INTER);
 5111 %}
 5112 
 5113 operand vRegD_V26()
 5114 %{
 5115   constraint(ALLOC_IN_RC(v26_reg));
 5116   match(RegD);
 5117   op_cost(0);
 5118   format %{ %}
 5119   interface(REG_INTER);
 5120 %}
 5121 
 5122 operand vRegD_V27()
 5123 %{
 5124   constraint(ALLOC_IN_RC(v27_reg));
 5125   match(RegD);
 5126   op_cost(0);
 5127   format %{ %}
 5128   interface(REG_INTER);
 5129 %}
 5130 
 5131 operand vRegD_V28()
 5132 %{
 5133   constraint(ALLOC_IN_RC(v28_reg));
 5134   match(RegD);
 5135   op_cost(0);
 5136   format %{ %}
 5137   interface(REG_INTER);
 5138 %}
 5139 
 5140 operand vRegD_V29()
 5141 %{
 5142   constraint(ALLOC_IN_RC(v29_reg));
 5143   match(RegD);
 5144   op_cost(0);
 5145   format %{ %}
 5146   interface(REG_INTER);
 5147 %}
 5148 
 5149 operand vRegD_V30()
 5150 %{
 5151   constraint(ALLOC_IN_RC(v30_reg));
 5152   match(RegD);
 5153   op_cost(0);
 5154   format %{ %}
 5155   interface(REG_INTER);
 5156 %}
 5157 
 5158 operand vRegD_V31()
 5159 %{
 5160   constraint(ALLOC_IN_RC(v31_reg));
 5161   match(RegD);
 5162   op_cost(0);
 5163   format %{ %}
 5164   interface(REG_INTER);
 5165 %}
 5166 
 5167 // Flags register, used as output of signed compare instructions
 5168 
 5169 // note that on AArch64 we also use this register as the output for
 5170 // for floating point compare instructions (CmpF CmpD). this ensures
 5171 // that ordered inequality tests use GT, GE, LT or LE none of which
 5172 // pass through cases where the result is unordered i.e. one or both
 5173 // inputs to the compare is a NaN. this means that the ideal code can
 5174 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5175 // (where the comparison should always fail). EQ and NE tests are
 5176 // always generated in ideal code so that unordered folds into the NE
 5177 // case, matching the behaviour of AArch64 NE.
 5178 //
 5179 // This differs from x86 where the outputs of FP compares use a
 5180 // special FP flags registers and where compares based on this
 5181 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5182 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5183 // to explicitly handle the unordered case in branches. x86 also has
 5184 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5185 
 5186 operand rFlagsReg()
 5187 %{
 5188   constraint(ALLOC_IN_RC(int_flags));
 5189   match(RegFlags);
 5190 
 5191   op_cost(0);
 5192   format %{ &quot;RFLAGS&quot; %}
 5193   interface(REG_INTER);
 5194 %}
 5195 
 5196 // Flags register, used as output of unsigned compare instructions
 5197 operand rFlagsRegU()
 5198 %{
 5199   constraint(ALLOC_IN_RC(int_flags));
 5200   match(RegFlags);
 5201 
 5202   op_cost(0);
 5203   format %{ &quot;RFLAGSU&quot; %}
 5204   interface(REG_INTER);
 5205 %}
 5206 
 5207 // Special Registers
 5208 
 5209 // Method Register
 5210 operand inline_cache_RegP(iRegP reg)
 5211 %{
 5212   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5213   match(reg);
 5214   match(iRegPNoSp);
 5215   op_cost(0);
 5216   format %{ %}
 5217   interface(REG_INTER);
 5218 %}
 5219 
 5220 operand interpreter_method_oop_RegP(iRegP reg)
 5221 %{
 5222   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5223   match(reg);
 5224   match(iRegPNoSp);
 5225   op_cost(0);
 5226   format %{ %}
 5227   interface(REG_INTER);
 5228 %}
 5229 
 5230 // Thread Register
 5231 operand thread_RegP(iRegP reg)
 5232 %{
 5233   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5234   match(reg);
 5235   op_cost(0);
 5236   format %{ %}
 5237   interface(REG_INTER);
 5238 %}
 5239 
 5240 operand lr_RegP(iRegP reg)
 5241 %{
 5242   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5243   match(reg);
 5244   op_cost(0);
 5245   format %{ %}
 5246   interface(REG_INTER);
 5247 %}
 5248 
 5249 //----------Memory Operands----------------------------------------------------
 5250 
 5251 operand indirect(iRegP reg)
 5252 %{
 5253   constraint(ALLOC_IN_RC(ptr_reg));
 5254   match(reg);
 5255   op_cost(0);
 5256   format %{ &quot;[$reg]&quot; %}
 5257   interface(MEMORY_INTER) %{
 5258     base($reg);
 5259     index(0xffffffff);
 5260     scale(0x0);
 5261     disp(0x0);
 5262   %}
 5263 %}
 5264 
 5265 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5266 %{
 5267   constraint(ALLOC_IN_RC(ptr_reg));
 5268   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5269   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5270   op_cost(0);
 5271   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5272   interface(MEMORY_INTER) %{
 5273     base($reg);
 5274     index($ireg);
 5275     scale($scale);
 5276     disp(0x0);
 5277   %}
 5278 %}
 5279 
 5280 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5281 %{
 5282   constraint(ALLOC_IN_RC(ptr_reg));
 5283   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5284   match(AddP reg (LShiftL lreg scale));
 5285   op_cost(0);
 5286   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5287   interface(MEMORY_INTER) %{
 5288     base($reg);
 5289     index($lreg);
 5290     scale($scale);
 5291     disp(0x0);
 5292   %}
 5293 %}
 5294 
 5295 operand indIndexI2L(iRegP reg, iRegI ireg)
 5296 %{
 5297   constraint(ALLOC_IN_RC(ptr_reg));
 5298   match(AddP reg (ConvI2L ireg));
 5299   op_cost(0);
 5300   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5301   interface(MEMORY_INTER) %{
 5302     base($reg);
 5303     index($ireg);
 5304     scale(0x0);
 5305     disp(0x0);
 5306   %}
 5307 %}
 5308 
 5309 operand indIndex(iRegP reg, iRegL lreg)
 5310 %{
 5311   constraint(ALLOC_IN_RC(ptr_reg));
 5312   match(AddP reg lreg);
 5313   op_cost(0);
 5314   format %{ &quot;$reg, $lreg&quot; %}
 5315   interface(MEMORY_INTER) %{
 5316     base($reg);
 5317     index($lreg);
 5318     scale(0x0);
 5319     disp(0x0);
 5320   %}
 5321 %}
 5322 
 5323 operand indOffI(iRegP reg, immIOffset off)
 5324 %{
 5325   constraint(ALLOC_IN_RC(ptr_reg));
 5326   match(AddP reg off);
 5327   op_cost(0);
 5328   format %{ &quot;[$reg, $off]&quot; %}
 5329   interface(MEMORY_INTER) %{
 5330     base($reg);
 5331     index(0xffffffff);
 5332     scale(0x0);
 5333     disp($off);
 5334   %}
 5335 %}
 5336 
 5337 operand indOffI1(iRegP reg, immIOffset1 off)
 5338 %{
 5339   constraint(ALLOC_IN_RC(ptr_reg));
 5340   match(AddP reg off);
 5341   op_cost(0);
 5342   format %{ &quot;[$reg, $off]&quot; %}
 5343   interface(MEMORY_INTER) %{
 5344     base($reg);
 5345     index(0xffffffff);
 5346     scale(0x0);
 5347     disp($off);
 5348   %}
 5349 %}
 5350 
 5351 operand indOffI2(iRegP reg, immIOffset2 off)
 5352 %{
 5353   constraint(ALLOC_IN_RC(ptr_reg));
 5354   match(AddP reg off);
 5355   op_cost(0);
 5356   format %{ &quot;[$reg, $off]&quot; %}
 5357   interface(MEMORY_INTER) %{
 5358     base($reg);
 5359     index(0xffffffff);
 5360     scale(0x0);
 5361     disp($off);
 5362   %}
 5363 %}
 5364 
 5365 operand indOffI4(iRegP reg, immIOffset4 off)
 5366 %{
 5367   constraint(ALLOC_IN_RC(ptr_reg));
 5368   match(AddP reg off);
 5369   op_cost(0);
 5370   format %{ &quot;[$reg, $off]&quot; %}
 5371   interface(MEMORY_INTER) %{
 5372     base($reg);
 5373     index(0xffffffff);
 5374     scale(0x0);
 5375     disp($off);
 5376   %}
 5377 %}
 5378 
 5379 operand indOffI8(iRegP reg, immIOffset8 off)
 5380 %{
 5381   constraint(ALLOC_IN_RC(ptr_reg));
 5382   match(AddP reg off);
 5383   op_cost(0);
 5384   format %{ &quot;[$reg, $off]&quot; %}
 5385   interface(MEMORY_INTER) %{
 5386     base($reg);
 5387     index(0xffffffff);
 5388     scale(0x0);
 5389     disp($off);
 5390   %}
 5391 %}
 5392 
 5393 operand indOffI16(iRegP reg, immIOffset16 off)
 5394 %{
 5395   constraint(ALLOC_IN_RC(ptr_reg));
 5396   match(AddP reg off);
 5397   op_cost(0);
 5398   format %{ &quot;[$reg, $off]&quot; %}
 5399   interface(MEMORY_INTER) %{
 5400     base($reg);
 5401     index(0xffffffff);
 5402     scale(0x0);
 5403     disp($off);
 5404   %}
 5405 %}
 5406 
 5407 operand indOffL(iRegP reg, immLoffset off)
 5408 %{
 5409   constraint(ALLOC_IN_RC(ptr_reg));
 5410   match(AddP reg off);
 5411   op_cost(0);
 5412   format %{ &quot;[$reg, $off]&quot; %}
 5413   interface(MEMORY_INTER) %{
 5414     base($reg);
 5415     index(0xffffffff);
 5416     scale(0x0);
 5417     disp($off);
 5418   %}
 5419 %}
 5420 
 5421 operand indOffL1(iRegP reg, immLoffset1 off)
 5422 %{
 5423   constraint(ALLOC_IN_RC(ptr_reg));
 5424   match(AddP reg off);
 5425   op_cost(0);
 5426   format %{ &quot;[$reg, $off]&quot; %}
 5427   interface(MEMORY_INTER) %{
 5428     base($reg);
 5429     index(0xffffffff);
 5430     scale(0x0);
 5431     disp($off);
 5432   %}
 5433 %}
 5434 
 5435 operand indOffL2(iRegP reg, immLoffset2 off)
 5436 %{
 5437   constraint(ALLOC_IN_RC(ptr_reg));
 5438   match(AddP reg off);
 5439   op_cost(0);
 5440   format %{ &quot;[$reg, $off]&quot; %}
 5441   interface(MEMORY_INTER) %{
 5442     base($reg);
 5443     index(0xffffffff);
 5444     scale(0x0);
 5445     disp($off);
 5446   %}
 5447 %}
 5448 
 5449 operand indOffL4(iRegP reg, immLoffset4 off)
 5450 %{
 5451   constraint(ALLOC_IN_RC(ptr_reg));
 5452   match(AddP reg off);
 5453   op_cost(0);
 5454   format %{ &quot;[$reg, $off]&quot; %}
 5455   interface(MEMORY_INTER) %{
 5456     base($reg);
 5457     index(0xffffffff);
 5458     scale(0x0);
 5459     disp($off);
 5460   %}
 5461 %}
 5462 
 5463 operand indOffL8(iRegP reg, immLoffset8 off)
 5464 %{
 5465   constraint(ALLOC_IN_RC(ptr_reg));
 5466   match(AddP reg off);
 5467   op_cost(0);
 5468   format %{ &quot;[$reg, $off]&quot; %}
 5469   interface(MEMORY_INTER) %{
 5470     base($reg);
 5471     index(0xffffffff);
 5472     scale(0x0);
 5473     disp($off);
 5474   %}
 5475 %}
 5476 
 5477 operand indOffL16(iRegP reg, immLoffset16 off)
 5478 %{
 5479   constraint(ALLOC_IN_RC(ptr_reg));
 5480   match(AddP reg off);
 5481   op_cost(0);
 5482   format %{ &quot;[$reg, $off]&quot; %}
 5483   interface(MEMORY_INTER) %{
 5484     base($reg);
 5485     index(0xffffffff);
 5486     scale(0x0);
 5487     disp($off);
 5488   %}
 5489 %}
 5490 
 5491 operand indirectN(iRegN reg)
 5492 %{
 5493   predicate(CompressedOops::shift() == 0);
 5494   constraint(ALLOC_IN_RC(ptr_reg));
 5495   match(DecodeN reg);
 5496   op_cost(0);
 5497   format %{ &quot;[$reg]\t# narrow&quot; %}
 5498   interface(MEMORY_INTER) %{
 5499     base($reg);
 5500     index(0xffffffff);
 5501     scale(0x0);
 5502     disp(0x0);
 5503   %}
 5504 %}
 5505 
 5506 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5507 %{
 5508   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5509   constraint(ALLOC_IN_RC(ptr_reg));
 5510   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5511   op_cost(0);
 5512   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5513   interface(MEMORY_INTER) %{
 5514     base($reg);
 5515     index($ireg);
 5516     scale($scale);
 5517     disp(0x0);
 5518   %}
 5519 %}
 5520 
 5521 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5522 %{
 5523   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5524   constraint(ALLOC_IN_RC(ptr_reg));
 5525   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5526   op_cost(0);
 5527   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5528   interface(MEMORY_INTER) %{
 5529     base($reg);
 5530     index($lreg);
 5531     scale($scale);
 5532     disp(0x0);
 5533   %}
 5534 %}
 5535 
 5536 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5537 %{
 5538   predicate(CompressedOops::shift() == 0);
 5539   constraint(ALLOC_IN_RC(ptr_reg));
 5540   match(AddP (DecodeN reg) (ConvI2L ireg));
 5541   op_cost(0);
 5542   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5543   interface(MEMORY_INTER) %{
 5544     base($reg);
 5545     index($ireg);
 5546     scale(0x0);
 5547     disp(0x0);
 5548   %}
 5549 %}
 5550 
 5551 operand indIndexN(iRegN reg, iRegL lreg)
 5552 %{
 5553   predicate(CompressedOops::shift() == 0);
 5554   constraint(ALLOC_IN_RC(ptr_reg));
 5555   match(AddP (DecodeN reg) lreg);
 5556   op_cost(0);
 5557   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5558   interface(MEMORY_INTER) %{
 5559     base($reg);
 5560     index($lreg);
 5561     scale(0x0);
 5562     disp(0x0);
 5563   %}
 5564 %}
 5565 
 5566 operand indOffIN(iRegN reg, immIOffset off)
 5567 %{
 5568   predicate(CompressedOops::shift() == 0);
 5569   constraint(ALLOC_IN_RC(ptr_reg));
 5570   match(AddP (DecodeN reg) off);
 5571   op_cost(0);
 5572   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5573   interface(MEMORY_INTER) %{
 5574     base($reg);
 5575     index(0xffffffff);
 5576     scale(0x0);
 5577     disp($off);
 5578   %}
 5579 %}
 5580 
 5581 operand indOffLN(iRegN reg, immLoffset off)
 5582 %{
 5583   predicate(CompressedOops::shift() == 0);
 5584   constraint(ALLOC_IN_RC(ptr_reg));
 5585   match(AddP (DecodeN reg) off);
 5586   op_cost(0);
 5587   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5588   interface(MEMORY_INTER) %{
 5589     base($reg);
 5590     index(0xffffffff);
 5591     scale(0x0);
 5592     disp($off);
 5593   %}
 5594 %}
 5595 
 5596 
 5597 
 5598 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5599 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5600 %{
 5601   constraint(ALLOC_IN_RC(ptr_reg));
 5602   match(AddP reg off);
 5603   op_cost(0);
 5604   format %{ &quot;[$reg, $off]&quot; %}
 5605   interface(MEMORY_INTER) %{
 5606     base($reg);
 5607     index(0xffffffff);
 5608     scale(0x0);
 5609     disp($off);
 5610   %}
 5611 %}
 5612 
 5613 //----------Special Memory Operands--------------------------------------------
 5614 // Stack Slot Operand - This operand is used for loading and storing temporary
 5615 //                      values on the stack where a match requires a value to
 5616 //                      flow through memory.
 5617 operand stackSlotP(sRegP reg)
 5618 %{
 5619   constraint(ALLOC_IN_RC(stack_slots));
 5620   op_cost(100);
 5621   // No match rule because this operand is only generated in matching
 5622   // match(RegP);
 5623   format %{ &quot;[$reg]&quot; %}
 5624   interface(MEMORY_INTER) %{
 5625     base(0x1e);  // RSP
 5626     index(0x0);  // No Index
 5627     scale(0x0);  // No Scale
 5628     disp($reg);  // Stack Offset
 5629   %}
 5630 %}
 5631 
 5632 operand stackSlotI(sRegI reg)
 5633 %{
 5634   constraint(ALLOC_IN_RC(stack_slots));
 5635   // No match rule because this operand is only generated in matching
 5636   // match(RegI);
 5637   format %{ &quot;[$reg]&quot; %}
 5638   interface(MEMORY_INTER) %{
 5639     base(0x1e);  // RSP
 5640     index(0x0);  // No Index
 5641     scale(0x0);  // No Scale
 5642     disp($reg);  // Stack Offset
 5643   %}
 5644 %}
 5645 
 5646 operand stackSlotF(sRegF reg)
 5647 %{
 5648   constraint(ALLOC_IN_RC(stack_slots));
 5649   // No match rule because this operand is only generated in matching
 5650   // match(RegF);
 5651   format %{ &quot;[$reg]&quot; %}
 5652   interface(MEMORY_INTER) %{
 5653     base(0x1e);  // RSP
 5654     index(0x0);  // No Index
 5655     scale(0x0);  // No Scale
 5656     disp($reg);  // Stack Offset
 5657   %}
 5658 %}
 5659 
 5660 operand stackSlotD(sRegD reg)
 5661 %{
 5662   constraint(ALLOC_IN_RC(stack_slots));
 5663   // No match rule because this operand is only generated in matching
 5664   // match(RegD);
 5665   format %{ &quot;[$reg]&quot; %}
 5666   interface(MEMORY_INTER) %{
 5667     base(0x1e);  // RSP
 5668     index(0x0);  // No Index
 5669     scale(0x0);  // No Scale
 5670     disp($reg);  // Stack Offset
 5671   %}
 5672 %}
 5673 
 5674 operand stackSlotL(sRegL reg)
 5675 %{
 5676   constraint(ALLOC_IN_RC(stack_slots));
 5677   // No match rule because this operand is only generated in matching
 5678   // match(RegL);
 5679   format %{ &quot;[$reg]&quot; %}
 5680   interface(MEMORY_INTER) %{
 5681     base(0x1e);  // RSP
 5682     index(0x0);  // No Index
 5683     scale(0x0);  // No Scale
 5684     disp($reg);  // Stack Offset
 5685   %}
 5686 %}
 5687 
 5688 // Operands for expressing Control Flow
 5689 // NOTE: Label is a predefined operand which should not be redefined in
 5690 //       the AD file. It is generically handled within the ADLC.
 5691 
 5692 //----------Conditional Branch Operands----------------------------------------
 5693 // Comparison Op  - This is the operation of the comparison, and is limited to
 5694 //                  the following set of codes:
 5695 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5696 //
 5697 // Other attributes of the comparison, such as unsignedness, are specified
 5698 // by the comparison instruction that sets a condition code flags register.
 5699 // That result is represented by a flags operand whose subtype is appropriate
 5700 // to the unsignedness (etc.) of the comparison.
 5701 //
 5702 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5703 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5704 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5705 
 5706 // used for signed integral comparisons and fp comparisons
 5707 
 5708 operand cmpOp()
 5709 %{
 5710   match(Bool);
 5711 
 5712   format %{ &quot;&quot; %}
 5713   interface(COND_INTER) %{
 5714     equal(0x0, &quot;eq&quot;);
 5715     not_equal(0x1, &quot;ne&quot;);
 5716     less(0xb, &quot;lt&quot;);
 5717     greater_equal(0xa, &quot;ge&quot;);
 5718     less_equal(0xd, &quot;le&quot;);
 5719     greater(0xc, &quot;gt&quot;);
 5720     overflow(0x6, &quot;vs&quot;);
 5721     no_overflow(0x7, &quot;vc&quot;);
 5722   %}
 5723 %}
 5724 
 5725 // used for unsigned integral comparisons
 5726 
 5727 operand cmpOpU()
 5728 %{
 5729   match(Bool);
 5730 
 5731   format %{ &quot;&quot; %}
 5732   interface(COND_INTER) %{
 5733     equal(0x0, &quot;eq&quot;);
 5734     not_equal(0x1, &quot;ne&quot;);
 5735     less(0x3, &quot;lo&quot;);
 5736     greater_equal(0x2, &quot;hs&quot;);
 5737     less_equal(0x9, &quot;ls&quot;);
 5738     greater(0x8, &quot;hi&quot;);
 5739     overflow(0x6, &quot;vs&quot;);
 5740     no_overflow(0x7, &quot;vc&quot;);
 5741   %}
 5742 %}
 5743 
 5744 // used for certain integral comparisons which can be
 5745 // converted to cbxx or tbxx instructions
 5746 
 5747 operand cmpOpEqNe()
 5748 %{
 5749   match(Bool);
 5750   op_cost(0);
 5751   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5752             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5753 
 5754   format %{ &quot;&quot; %}
 5755   interface(COND_INTER) %{
 5756     equal(0x0, &quot;eq&quot;);
 5757     not_equal(0x1, &quot;ne&quot;);
 5758     less(0xb, &quot;lt&quot;);
 5759     greater_equal(0xa, &quot;ge&quot;);
 5760     less_equal(0xd, &quot;le&quot;);
 5761     greater(0xc, &quot;gt&quot;);
 5762     overflow(0x6, &quot;vs&quot;);
 5763     no_overflow(0x7, &quot;vc&quot;);
 5764   %}
 5765 %}
 5766 
 5767 // used for certain integral comparisons which can be
 5768 // converted to cbxx or tbxx instructions
 5769 
 5770 operand cmpOpLtGe()
 5771 %{
 5772   match(Bool);
 5773   op_cost(0);
 5774 
 5775   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5776             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5777 
 5778   format %{ &quot;&quot; %}
 5779   interface(COND_INTER) %{
 5780     equal(0x0, &quot;eq&quot;);
 5781     not_equal(0x1, &quot;ne&quot;);
 5782     less(0xb, &quot;lt&quot;);
 5783     greater_equal(0xa, &quot;ge&quot;);
 5784     less_equal(0xd, &quot;le&quot;);
 5785     greater(0xc, &quot;gt&quot;);
 5786     overflow(0x6, &quot;vs&quot;);
 5787     no_overflow(0x7, &quot;vc&quot;);
 5788   %}
 5789 %}
 5790 
 5791 // used for certain unsigned integral comparisons which can be
 5792 // converted to cbxx or tbxx instructions
 5793 
 5794 operand cmpOpUEqNeLtGe()
 5795 %{
 5796   match(Bool);
 5797   op_cost(0);
 5798 
 5799   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5800             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5801             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5802             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5803 
 5804   format %{ &quot;&quot; %}
 5805   interface(COND_INTER) %{
 5806     equal(0x0, &quot;eq&quot;);
 5807     not_equal(0x1, &quot;ne&quot;);
 5808     less(0xb, &quot;lt&quot;);
 5809     greater_equal(0xa, &quot;ge&quot;);
 5810     less_equal(0xd, &quot;le&quot;);
 5811     greater(0xc, &quot;gt&quot;);
 5812     overflow(0x6, &quot;vs&quot;);
 5813     no_overflow(0x7, &quot;vc&quot;);
 5814   %}
 5815 %}
 5816 
 5817 // Special operand allowing long args to int ops to be truncated for free
 5818 
 5819 operand iRegL2I(iRegL reg) %{
 5820 
 5821   op_cost(0);
 5822 
 5823   match(ConvL2I reg);
 5824 
 5825   format %{ &quot;l2i($reg)&quot; %}
 5826 
 5827   interface(REG_INTER)
 5828 %}
 5829 
 5830 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5831 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5832 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5833 
 5834 //----------OPERAND CLASSES----------------------------------------------------
 5835 // Operand Classes are groups of operands that are used as to simplify
 5836 // instruction definitions by not requiring the AD writer to specify
 5837 // separate instructions for every form of operand when the
 5838 // instruction accepts multiple operand types with the same basic
 5839 // encoding and format. The classic case of this is memory operands.
 5840 
 5841 // memory is used to define read/write location for load/store
 5842 // instruction defs. we can turn a memory op into an Address
 5843 
 5844 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5845                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5846 
 5847 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5848                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5849 
 5850 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5851                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5852 
 5853 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5854                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5855 
 5856 // All of the memory operands. For the pipeline description.
 5857 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5858                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5859                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5860 
 5861 
 5862 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5863 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5864 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5865 // can be elided because the 32-bit instruction will just employ the
 5866 // lower 32 bits anyway.
 5867 //
 5868 // n.b. this does not elide all L2I conversions. if the truncated
 5869 // value is consumed by more than one operation then the ConvL2I
 5870 // cannot be bundled into the consuming nodes so an l2i gets planted
 5871 // (actually a movw $dst $src) and the downstream instructions consume
 5872 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5873 // movw is actually redundant but its not too costly.
 5874 
 5875 opclass iRegIorL2I(iRegI, iRegL2I);
 5876 
 5877 //----------PIPELINE-----------------------------------------------------------
 5878 // Rules which define the behavior of the target architectures pipeline.
 5879 
 5880 // For specific pipelines, eg A53, define the stages of that pipeline
 5881 //pipe_desc(ISS, EX1, EX2, WR);
 5882 #define ISS S0
 5883 #define EX1 S1
 5884 #define EX2 S2
 5885 #define WR  S3
 5886 
 5887 // Integer ALU reg operation
 5888 pipeline %{
 5889 
 5890 attributes %{
 5891   // ARM instructions are of fixed length
 5892   fixed_size_instructions;        // Fixed size instructions TODO does
 5893   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5894   // ARM instructions come in 32-bit word units
 5895   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5896   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5897   instruction_fetch_units = 1;       // of 64 bytes
 5898 
 5899   // List of nop instructions
 5900   nops( MachNop );
 5901 %}
 5902 
 5903 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5904 // or description. we do use pipeline classes to introduce fixed
 5905 // latencies
 5906 
 5907 //----------RESOURCES----------------------------------------------------------
 5908 // Resources are the functional units available to the machine
 5909 
 5910 resources( INS0, INS1, INS01 = INS0 | INS1,
 5911            ALU0, ALU1, ALU = ALU0 | ALU1,
 5912            MAC,
 5913            DIV,
 5914            BRANCH,
 5915            LDST,
 5916            NEON_FP);
 5917 
 5918 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5919 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5920 
 5921 // Define the pipeline as a generic 6 stage pipeline
 5922 pipe_desc(S0, S1, S2, S3, S4, S5);
 5923 
 5924 //----------PIPELINE CLASSES---------------------------------------------------
 5925 // Pipeline Classes describe the stages in which input and output are
 5926 // referenced by the hardware pipeline.
 5927 
 5928 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5929 %{
 5930   single_instruction;
 5931   src1   : S1(read);
 5932   src2   : S2(read);
 5933   dst    : S5(write);
 5934   INS01  : ISS;
 5935   NEON_FP : S5;
 5936 %}
 5937 
 5938 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5939 %{
 5940   single_instruction;
 5941   src1   : S1(read);
 5942   src2   : S2(read);
 5943   dst    : S5(write);
 5944   INS01  : ISS;
 5945   NEON_FP : S5;
 5946 %}
 5947 
 5948 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5949 %{
 5950   single_instruction;
 5951   src    : S1(read);
 5952   dst    : S5(write);
 5953   INS01  : ISS;
 5954   NEON_FP : S5;
 5955 %}
 5956 
 5957 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5958 %{
 5959   single_instruction;
 5960   src    : S1(read);
 5961   dst    : S5(write);
 5962   INS01  : ISS;
 5963   NEON_FP : S5;
 5964 %}
 5965 
 5966 pipe_class fp_d2f(vRegF dst, vRegD src)
 5967 %{
 5968   single_instruction;
 5969   src    : S1(read);
 5970   dst    : S5(write);
 5971   INS01  : ISS;
 5972   NEON_FP : S5;
 5973 %}
 5974 
 5975 pipe_class fp_f2d(vRegD dst, vRegF src)
 5976 %{
 5977   single_instruction;
 5978   src    : S1(read);
 5979   dst    : S5(write);
 5980   INS01  : ISS;
 5981   NEON_FP : S5;
 5982 %}
 5983 
 5984 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 5985 %{
 5986   single_instruction;
 5987   src    : S1(read);
 5988   dst    : S5(write);
 5989   INS01  : ISS;
 5990   NEON_FP : S5;
 5991 %}
 5992 
 5993 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 5994 %{
 5995   single_instruction;
 5996   src    : S1(read);
 5997   dst    : S5(write);
 5998   INS01  : ISS;
 5999   NEON_FP : S5;
 6000 %}
 6001 
 6002 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6003 %{
 6004   single_instruction;
 6005   src    : S1(read);
 6006   dst    : S5(write);
 6007   INS01  : ISS;
 6008   NEON_FP : S5;
 6009 %}
 6010 
 6011 pipe_class fp_l2f(vRegF dst, iRegL src)
 6012 %{
 6013   single_instruction;
 6014   src    : S1(read);
 6015   dst    : S5(write);
 6016   INS01  : ISS;
 6017   NEON_FP : S5;
 6018 %}
 6019 
 6020 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6021 %{
 6022   single_instruction;
 6023   src    : S1(read);
 6024   dst    : S5(write);
 6025   INS01  : ISS;
 6026   NEON_FP : S5;
 6027 %}
 6028 
 6029 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6030 %{
 6031   single_instruction;
 6032   src    : S1(read);
 6033   dst    : S5(write);
 6034   INS01  : ISS;
 6035   NEON_FP : S5;
 6036 %}
 6037 
 6038 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6039 %{
 6040   single_instruction;
 6041   src    : S1(read);
 6042   dst    : S5(write);
 6043   INS01  : ISS;
 6044   NEON_FP : S5;
 6045 %}
 6046 
 6047 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6048 %{
 6049   single_instruction;
 6050   src    : S1(read);
 6051   dst    : S5(write);
 6052   INS01  : ISS;
 6053   NEON_FP : S5;
 6054 %}
 6055 
 6056 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6057 %{
 6058   single_instruction;
 6059   src1   : S1(read);
 6060   src2   : S2(read);
 6061   dst    : S5(write);
 6062   INS0   : ISS;
 6063   NEON_FP : S5;
 6064 %}
 6065 
 6066 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6067 %{
 6068   single_instruction;
 6069   src1   : S1(read);
 6070   src2   : S2(read);
 6071   dst    : S5(write);
 6072   INS0   : ISS;
 6073   NEON_FP : S5;
 6074 %}
 6075 
 6076 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6077 %{
 6078   single_instruction;
 6079   cr     : S1(read);
 6080   src1   : S1(read);
 6081   src2   : S1(read);
 6082   dst    : S3(write);
 6083   INS01  : ISS;
 6084   NEON_FP : S3;
 6085 %}
 6086 
 6087 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6088 %{
 6089   single_instruction;
 6090   cr     : S1(read);
 6091   src1   : S1(read);
 6092   src2   : S1(read);
 6093   dst    : S3(write);
 6094   INS01  : ISS;
 6095   NEON_FP : S3;
 6096 %}
 6097 
 6098 pipe_class fp_imm_s(vRegF dst)
 6099 %{
 6100   single_instruction;
 6101   dst    : S3(write);
 6102   INS01  : ISS;
 6103   NEON_FP : S3;
 6104 %}
 6105 
 6106 pipe_class fp_imm_d(vRegD dst)
 6107 %{
 6108   single_instruction;
 6109   dst    : S3(write);
 6110   INS01  : ISS;
 6111   NEON_FP : S3;
 6112 %}
 6113 
 6114 pipe_class fp_load_constant_s(vRegF dst)
 6115 %{
 6116   single_instruction;
 6117   dst    : S4(write);
 6118   INS01  : ISS;
 6119   NEON_FP : S4;
 6120 %}
 6121 
 6122 pipe_class fp_load_constant_d(vRegD dst)
 6123 %{
 6124   single_instruction;
 6125   dst    : S4(write);
 6126   INS01  : ISS;
 6127   NEON_FP : S4;
 6128 %}
 6129 
 6130 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6131 %{
 6132   single_instruction;
 6133   dst    : S5(write);
 6134   src1   : S1(read);
 6135   src2   : S1(read);
 6136   INS01  : ISS;
 6137   NEON_FP : S5;
 6138 %}
 6139 
 6140 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6141 %{
 6142   single_instruction;
 6143   dst    : S5(write);
 6144   src1   : S1(read);
 6145   src2   : S1(read);
 6146   INS0   : ISS;
 6147   NEON_FP : S5;
 6148 %}
 6149 
 6150 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6151 %{
 6152   single_instruction;
 6153   dst    : S5(write);
 6154   src1   : S1(read);
 6155   src2   : S1(read);
 6156   dst    : S1(read);
 6157   INS01  : ISS;
 6158   NEON_FP : S5;
 6159 %}
 6160 
 6161 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6162 %{
 6163   single_instruction;
 6164   dst    : S5(write);
 6165   src1   : S1(read);
 6166   src2   : S1(read);
 6167   dst    : S1(read);
 6168   INS0   : ISS;
 6169   NEON_FP : S5;
 6170 %}
 6171 
 6172 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6173 %{
 6174   single_instruction;
 6175   dst    : S4(write);
 6176   src1   : S2(read);
 6177   src2   : S2(read);
 6178   INS01  : ISS;
 6179   NEON_FP : S4;
 6180 %}
 6181 
 6182 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6183 %{
 6184   single_instruction;
 6185   dst    : S4(write);
 6186   src1   : S2(read);
 6187   src2   : S2(read);
 6188   INS0   : ISS;
 6189   NEON_FP : S4;
 6190 %}
 6191 
 6192 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6193 %{
 6194   single_instruction;
 6195   dst    : S3(write);
 6196   src1   : S2(read);
 6197   src2   : S2(read);
 6198   INS01  : ISS;
 6199   NEON_FP : S3;
 6200 %}
 6201 
 6202 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6203 %{
 6204   single_instruction;
 6205   dst    : S3(write);
 6206   src1   : S2(read);
 6207   src2   : S2(read);
 6208   INS0   : ISS;
 6209   NEON_FP : S3;
 6210 %}
 6211 
 6212 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6213 %{
 6214   single_instruction;
 6215   dst    : S3(write);
 6216   src    : S1(read);
 6217   shift  : S1(read);
 6218   INS01  : ISS;
 6219   NEON_FP : S3;
 6220 %}
 6221 
 6222 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6223 %{
 6224   single_instruction;
 6225   dst    : S3(write);
 6226   src    : S1(read);
 6227   shift  : S1(read);
 6228   INS0   : ISS;
 6229   NEON_FP : S3;
 6230 %}
 6231 
 6232 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6233 %{
 6234   single_instruction;
 6235   dst    : S3(write);
 6236   src    : S1(read);
 6237   INS01  : ISS;
 6238   NEON_FP : S3;
 6239 %}
 6240 
 6241 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6242 %{
 6243   single_instruction;
 6244   dst    : S3(write);
 6245   src    : S1(read);
 6246   INS0   : ISS;
 6247   NEON_FP : S3;
 6248 %}
 6249 
 6250 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6251 %{
 6252   single_instruction;
 6253   dst    : S5(write);
 6254   src1   : S1(read);
 6255   src2   : S1(read);
 6256   INS01  : ISS;
 6257   NEON_FP : S5;
 6258 %}
 6259 
 6260 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6261 %{
 6262   single_instruction;
 6263   dst    : S5(write);
 6264   src1   : S1(read);
 6265   src2   : S1(read);
 6266   INS0   : ISS;
 6267   NEON_FP : S5;
 6268 %}
 6269 
 6270 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6271 %{
 6272   single_instruction;
 6273   dst    : S5(write);
 6274   src1   : S1(read);
 6275   src2   : S1(read);
 6276   INS0   : ISS;
 6277   NEON_FP : S5;
 6278 %}
 6279 
 6280 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6281 %{
 6282   single_instruction;
 6283   dst    : S5(write);
 6284   src1   : S1(read);
 6285   src2   : S1(read);
 6286   INS0   : ISS;
 6287   NEON_FP : S5;
 6288 %}
 6289 
 6290 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6291 %{
 6292   single_instruction;
 6293   dst    : S5(write);
 6294   src    : S1(read);
 6295   INS0   : ISS;
 6296   NEON_FP : S5;
 6297 %}
 6298 
 6299 pipe_class vunop_fp64(vecD dst, vecD src)
 6300 %{
 6301   single_instruction;
 6302   dst    : S5(write);
 6303   src    : S1(read);
 6304   INS01  : ISS;
 6305   NEON_FP : S5;
 6306 %}
 6307 
 6308 pipe_class vunop_fp128(vecX dst, vecX src)
 6309 %{
 6310   single_instruction;
 6311   dst    : S5(write);
 6312   src    : S1(read);
 6313   INS0   : ISS;
 6314   NEON_FP : S5;
 6315 %}
 6316 
 6317 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6318 %{
 6319   single_instruction;
 6320   dst    : S3(write);
 6321   src    : S1(read);
 6322   INS01  : ISS;
 6323   NEON_FP : S3;
 6324 %}
 6325 
 6326 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6327 %{
 6328   single_instruction;
 6329   dst    : S3(write);
 6330   src    : S1(read);
 6331   INS01  : ISS;
 6332   NEON_FP : S3;
 6333 %}
 6334 
 6335 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6336 %{
 6337   single_instruction;
 6338   dst    : S3(write);
 6339   src    : S1(read);
 6340   INS01  : ISS;
 6341   NEON_FP : S3;
 6342 %}
 6343 
 6344 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6345 %{
 6346   single_instruction;
 6347   dst    : S3(write);
 6348   src    : S1(read);
 6349   INS01  : ISS;
 6350   NEON_FP : S3;
 6351 %}
 6352 
 6353 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6354 %{
 6355   single_instruction;
 6356   dst    : S3(write);
 6357   src    : S1(read);
 6358   INS01  : ISS;
 6359   NEON_FP : S3;
 6360 %}
 6361 
 6362 pipe_class vmovi_reg_imm64(vecD dst)
 6363 %{
 6364   single_instruction;
 6365   dst    : S3(write);
 6366   INS01  : ISS;
 6367   NEON_FP : S3;
 6368 %}
 6369 
 6370 pipe_class vmovi_reg_imm128(vecX dst)
 6371 %{
 6372   single_instruction;
 6373   dst    : S3(write);
 6374   INS0   : ISS;
 6375   NEON_FP : S3;
 6376 %}
 6377 
 6378 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6379 %{
 6380   single_instruction;
 6381   dst    : S5(write);
 6382   mem    : ISS(read);
 6383   INS01  : ISS;
 6384   NEON_FP : S3;
 6385 %}
 6386 
 6387 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6388 %{
 6389   single_instruction;
 6390   dst    : S5(write);
 6391   mem    : ISS(read);
 6392   INS01  : ISS;
 6393   NEON_FP : S3;
 6394 %}
 6395 
 6396 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6397 %{
 6398   single_instruction;
 6399   mem    : ISS(read);
 6400   src    : S2(read);
 6401   INS01  : ISS;
 6402   NEON_FP : S3;
 6403 %}
 6404 
 6405 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6406 %{
 6407   single_instruction;
 6408   mem    : ISS(read);
 6409   src    : S2(read);
 6410   INS01  : ISS;
 6411   NEON_FP : S3;
 6412 %}
 6413 
 6414 //------- Integer ALU operations --------------------------
 6415 
 6416 // Integer ALU reg-reg operation
 6417 // Operands needed in EX1, result generated in EX2
 6418 // Eg.  ADD     x0, x1, x2
 6419 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6420 %{
 6421   single_instruction;
 6422   dst    : EX2(write);
 6423   src1   : EX1(read);
 6424   src2   : EX1(read);
 6425   INS01  : ISS; // Dual issue as instruction 0 or 1
 6426   ALU    : EX2;
 6427 %}
 6428 
 6429 // Integer ALU reg-reg operation with constant shift
 6430 // Shifted register must be available in LATE_ISS instead of EX1
 6431 // Eg.  ADD     x0, x1, x2, LSL #2
 6432 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6433 %{
 6434   single_instruction;
 6435   dst    : EX2(write);
 6436   src1   : EX1(read);
 6437   src2   : ISS(read);
 6438   INS01  : ISS;
 6439   ALU    : EX2;
 6440 %}
 6441 
 6442 // Integer ALU reg operation with constant shift
 6443 // Eg.  LSL     x0, x1, #shift
 6444 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6445 %{
 6446   single_instruction;
 6447   dst    : EX2(write);
 6448   src1   : ISS(read);
 6449   INS01  : ISS;
 6450   ALU    : EX2;
 6451 %}
 6452 
 6453 // Integer ALU reg-reg operation with variable shift
 6454 // Both operands must be available in LATE_ISS instead of EX1
 6455 // Result is available in EX1 instead of EX2
 6456 // Eg.  LSLV    x0, x1, x2
 6457 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6458 %{
 6459   single_instruction;
 6460   dst    : EX1(write);
 6461   src1   : ISS(read);
 6462   src2   : ISS(read);
 6463   INS01  : ISS;
 6464   ALU    : EX1;
 6465 %}
 6466 
 6467 // Integer ALU reg-reg operation with extract
 6468 // As for _vshift above, but result generated in EX2
 6469 // Eg.  EXTR    x0, x1, x2, #N
 6470 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6471 %{
 6472   single_instruction;
 6473   dst    : EX2(write);
 6474   src1   : ISS(read);
 6475   src2   : ISS(read);
 6476   INS1   : ISS; // Can only dual issue as Instruction 1
 6477   ALU    : EX1;
 6478 %}
 6479 
 6480 // Integer ALU reg operation
 6481 // Eg.  NEG     x0, x1
 6482 pipe_class ialu_reg(iRegI dst, iRegI src)
 6483 %{
 6484   single_instruction;
 6485   dst    : EX2(write);
 6486   src    : EX1(read);
 6487   INS01  : ISS;
 6488   ALU    : EX2;
 6489 %}
 6490 
 6491 // Integer ALU reg mmediate operation
 6492 // Eg.  ADD     x0, x1, #N
 6493 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6494 %{
 6495   single_instruction;
 6496   dst    : EX2(write);
 6497   src1   : EX1(read);
 6498   INS01  : ISS;
 6499   ALU    : EX2;
 6500 %}
 6501 
 6502 // Integer ALU immediate operation (no source operands)
 6503 // Eg.  MOV     x0, #N
 6504 pipe_class ialu_imm(iRegI dst)
 6505 %{
 6506   single_instruction;
 6507   dst    : EX1(write);
 6508   INS01  : ISS;
 6509   ALU    : EX1;
 6510 %}
 6511 
 6512 //------- Compare operation -------------------------------
 6513 
 6514 // Compare reg-reg
 6515 // Eg.  CMP     x0, x1
 6516 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6517 %{
 6518   single_instruction;
 6519 //  fixed_latency(16);
 6520   cr     : EX2(write);
 6521   op1    : EX1(read);
 6522   op2    : EX1(read);
 6523   INS01  : ISS;
 6524   ALU    : EX2;
 6525 %}
 6526 
 6527 // Compare reg-reg
 6528 // Eg.  CMP     x0, #N
 6529 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6530 %{
 6531   single_instruction;
 6532 //  fixed_latency(16);
 6533   cr     : EX2(write);
 6534   op1    : EX1(read);
 6535   INS01  : ISS;
 6536   ALU    : EX2;
 6537 %}
 6538 
 6539 //------- Conditional instructions ------------------------
 6540 
 6541 // Conditional no operands
 6542 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6543 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6544 %{
 6545   single_instruction;
 6546   cr     : EX1(read);
 6547   dst    : EX2(write);
 6548   INS01  : ISS;
 6549   ALU    : EX2;
 6550 %}
 6551 
 6552 // Conditional 2 operand
 6553 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6554 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6555 %{
 6556   single_instruction;
 6557   cr     : EX1(read);
 6558   src1   : EX1(read);
 6559   src2   : EX1(read);
 6560   dst    : EX2(write);
 6561   INS01  : ISS;
 6562   ALU    : EX2;
 6563 %}
 6564 
 6565 // Conditional 2 operand
 6566 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6567 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6568 %{
 6569   single_instruction;
 6570   cr     : EX1(read);
 6571   src    : EX1(read);
 6572   dst    : EX2(write);
 6573   INS01  : ISS;
 6574   ALU    : EX2;
 6575 %}
 6576 
 6577 //------- Multiply pipeline operations --------------------
 6578 
 6579 // Multiply reg-reg
 6580 // Eg.  MUL     w0, w1, w2
 6581 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6582 %{
 6583   single_instruction;
 6584   dst    : WR(write);
 6585   src1   : ISS(read);
 6586   src2   : ISS(read);
 6587   INS01  : ISS;
 6588   MAC    : WR;
 6589 %}
 6590 
 6591 // Multiply accumulate
 6592 // Eg.  MADD    w0, w1, w2, w3
 6593 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6594 %{
 6595   single_instruction;
 6596   dst    : WR(write);
 6597   src1   : ISS(read);
 6598   src2   : ISS(read);
 6599   src3   : ISS(read);
 6600   INS01  : ISS;
 6601   MAC    : WR;
 6602 %}
 6603 
 6604 // Eg.  MUL     w0, w1, w2
 6605 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6606 %{
 6607   single_instruction;
 6608   fixed_latency(3); // Maximum latency for 64 bit mul
 6609   dst    : WR(write);
 6610   src1   : ISS(read);
 6611   src2   : ISS(read);
 6612   INS01  : ISS;
 6613   MAC    : WR;
 6614 %}
 6615 
 6616 // Multiply accumulate
 6617 // Eg.  MADD    w0, w1, w2, w3
 6618 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6619 %{
 6620   single_instruction;
 6621   fixed_latency(3); // Maximum latency for 64 bit mul
 6622   dst    : WR(write);
 6623   src1   : ISS(read);
 6624   src2   : ISS(read);
 6625   src3   : ISS(read);
 6626   INS01  : ISS;
 6627   MAC    : WR;
 6628 %}
 6629 
 6630 //------- Divide pipeline operations --------------------
 6631 
 6632 // Eg.  SDIV    w0, w1, w2
 6633 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6634 %{
 6635   single_instruction;
 6636   fixed_latency(8); // Maximum latency for 32 bit divide
 6637   dst    : WR(write);
 6638   src1   : ISS(read);
 6639   src2   : ISS(read);
 6640   INS0   : ISS; // Can only dual issue as instruction 0
 6641   DIV    : WR;
 6642 %}
 6643 
 6644 // Eg.  SDIV    x0, x1, x2
 6645 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6646 %{
 6647   single_instruction;
 6648   fixed_latency(16); // Maximum latency for 64 bit divide
 6649   dst    : WR(write);
 6650   src1   : ISS(read);
 6651   src2   : ISS(read);
 6652   INS0   : ISS; // Can only dual issue as instruction 0
 6653   DIV    : WR;
 6654 %}
 6655 
 6656 //------- Load pipeline operations ------------------------
 6657 
 6658 // Load - prefetch
 6659 // Eg.  PFRM    &lt;mem&gt;
 6660 pipe_class iload_prefetch(memory mem)
 6661 %{
 6662   single_instruction;
 6663   mem    : ISS(read);
 6664   INS01  : ISS;
 6665   LDST   : WR;
 6666 %}
 6667 
 6668 // Load - reg, mem
 6669 // Eg.  LDR     x0, &lt;mem&gt;
 6670 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6671 %{
 6672   single_instruction;
 6673   dst    : WR(write);
 6674   mem    : ISS(read);
 6675   INS01  : ISS;
 6676   LDST   : WR;
 6677 %}
 6678 
 6679 // Load - reg, reg
 6680 // Eg.  LDR     x0, [sp, x1]
 6681 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6682 %{
 6683   single_instruction;
 6684   dst    : WR(write);
 6685   src    : ISS(read);
 6686   INS01  : ISS;
 6687   LDST   : WR;
 6688 %}
 6689 
 6690 //------- Store pipeline operations -----------------------
 6691 
 6692 // Store - zr, mem
 6693 // Eg.  STR     zr, &lt;mem&gt;
 6694 pipe_class istore_mem(memory mem)
 6695 %{
 6696   single_instruction;
 6697   mem    : ISS(read);
 6698   INS01  : ISS;
 6699   LDST   : WR;
 6700 %}
 6701 
 6702 // Store - reg, mem
 6703 // Eg.  STR     x0, &lt;mem&gt;
 6704 pipe_class istore_reg_mem(iRegI src, memory mem)
 6705 %{
 6706   single_instruction;
 6707   mem    : ISS(read);
 6708   src    : EX2(read);
 6709   INS01  : ISS;
 6710   LDST   : WR;
 6711 %}
 6712 
 6713 // Store - reg, reg
 6714 // Eg. STR      x0, [sp, x1]
 6715 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6716 %{
 6717   single_instruction;
 6718   dst    : ISS(read);
 6719   src    : EX2(read);
 6720   INS01  : ISS;
 6721   LDST   : WR;
 6722 %}
 6723 
 6724 //------- Store pipeline operations -----------------------
 6725 
 6726 // Branch
 6727 pipe_class pipe_branch()
 6728 %{
 6729   single_instruction;
 6730   INS01  : ISS;
 6731   BRANCH : EX1;
 6732 %}
 6733 
 6734 // Conditional branch
 6735 pipe_class pipe_branch_cond(rFlagsReg cr)
 6736 %{
 6737   single_instruction;
 6738   cr     : EX1(read);
 6739   INS01  : ISS;
 6740   BRANCH : EX1;
 6741 %}
 6742 
 6743 // Compare &amp; Branch
 6744 // EG.  CBZ/CBNZ
 6745 pipe_class pipe_cmp_branch(iRegI op1)
 6746 %{
 6747   single_instruction;
 6748   op1    : EX1(read);
 6749   INS01  : ISS;
 6750   BRANCH : EX1;
 6751 %}
 6752 
 6753 //------- Synchronisation operations ----------------------
 6754 
 6755 // Any operation requiring serialization.
 6756 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6757 pipe_class pipe_serial()
 6758 %{
 6759   single_instruction;
 6760   force_serialization;
 6761   fixed_latency(16);
 6762   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6763   LDST   : WR;
 6764 %}
 6765 
 6766 // Generic big/slow expanded idiom - also serialized
 6767 pipe_class pipe_slow()
 6768 %{
 6769   instruction_count(10);
 6770   multiple_bundles;
 6771   force_serialization;
 6772   fixed_latency(16);
 6773   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6774   LDST   : WR;
 6775 %}
 6776 
 6777 // Empty pipeline class
 6778 pipe_class pipe_class_empty()
 6779 %{
 6780   single_instruction;
 6781   fixed_latency(0);
 6782 %}
 6783 
 6784 // Default pipeline class.
 6785 pipe_class pipe_class_default()
 6786 %{
 6787   single_instruction;
 6788   fixed_latency(2);
 6789 %}
 6790 
 6791 // Pipeline class for compares.
 6792 pipe_class pipe_class_compare()
 6793 %{
 6794   single_instruction;
 6795   fixed_latency(16);
 6796 %}
 6797 
 6798 // Pipeline class for memory operations.
 6799 pipe_class pipe_class_memory()
 6800 %{
 6801   single_instruction;
 6802   fixed_latency(16);
 6803 %}
 6804 
 6805 // Pipeline class for call.
 6806 pipe_class pipe_class_call()
 6807 %{
 6808   single_instruction;
 6809   fixed_latency(100);
 6810 %}
 6811 
 6812 // Define the class for the Nop node.
 6813 define %{
 6814    MachNop = pipe_class_empty;
 6815 %}
 6816 
 6817 %}
 6818 //----------INSTRUCTIONS-------------------------------------------------------
 6819 //
 6820 // match      -- States which machine-independent subtree may be replaced
 6821 //               by this instruction.
 6822 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6823 //               selection to identify a minimum cost tree of machine
 6824 //               instructions that matches a tree of machine-independent
 6825 //               instructions.
 6826 // format     -- A string providing the disassembly for this instruction.
 6827 //               The value of an instruction&#39;s operand may be inserted
 6828 //               by referring to it with a &#39;$&#39; prefix.
 6829 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6830 //               to within an encode class as $primary, $secondary, and $tertiary
 6831 //               rrspectively.  The primary opcode is commonly used to
 6832 //               indicate the type of machine instruction, while secondary
 6833 //               and tertiary are often used for prefix options or addressing
 6834 //               modes.
 6835 // ins_encode -- A list of encode classes with parameters. The encode class
 6836 //               name must have been defined in an &#39;enc_class&#39; specification
 6837 //               in the encode section of the architecture description.
 6838 
 6839 // ============================================================================
 6840 // Memory (Load/Store) Instructions
 6841 
 6842 // Load Instructions
 6843 
 6844 // Load Byte (8 bit signed)
 6845 instruct loadB(iRegINoSp dst, memory1 mem)
 6846 %{
 6847   match(Set dst (LoadB mem));
 6848   predicate(!needs_acquiring_load(n));
 6849 
 6850   ins_cost(4 * INSN_COST);
 6851   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6852 
 6853   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6854 
 6855   ins_pipe(iload_reg_mem);
 6856 %}
 6857 
 6858 // Load Byte (8 bit signed) into long
 6859 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6860 %{
 6861   match(Set dst (ConvI2L (LoadB mem)));
 6862   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6863 
 6864   ins_cost(4 * INSN_COST);
 6865   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6866 
 6867   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6868 
 6869   ins_pipe(iload_reg_mem);
 6870 %}
 6871 
 6872 // Load Byte (8 bit unsigned)
 6873 instruct loadUB(iRegINoSp dst, memory1 mem)
 6874 %{
 6875   match(Set dst (LoadUB mem));
 6876   predicate(!needs_acquiring_load(n));
 6877 
 6878   ins_cost(4 * INSN_COST);
 6879   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6880 
 6881   ins_encode(aarch64_enc_ldrb(dst, mem));
 6882 
 6883   ins_pipe(iload_reg_mem);
 6884 %}
 6885 
 6886 // Load Byte (8 bit unsigned) into long
 6887 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6888 %{
 6889   match(Set dst (ConvI2L (LoadUB mem)));
 6890   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6891 
 6892   ins_cost(4 * INSN_COST);
 6893   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6894 
 6895   ins_encode(aarch64_enc_ldrb(dst, mem));
 6896 
 6897   ins_pipe(iload_reg_mem);
 6898 %}
 6899 
 6900 // Load Short (16 bit signed)
 6901 instruct loadS(iRegINoSp dst, memory2 mem)
 6902 %{
 6903   match(Set dst (LoadS mem));
 6904   predicate(!needs_acquiring_load(n));
 6905 
 6906   ins_cost(4 * INSN_COST);
 6907   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6908 
 6909   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6910 
 6911   ins_pipe(iload_reg_mem);
 6912 %}
 6913 
 6914 // Load Short (16 bit signed) into long
 6915 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6916 %{
 6917   match(Set dst (ConvI2L (LoadS mem)));
 6918   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6919 
 6920   ins_cost(4 * INSN_COST);
 6921   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6922 
 6923   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6924 
 6925   ins_pipe(iload_reg_mem);
 6926 %}
 6927 
 6928 // Load Char (16 bit unsigned)
 6929 instruct loadUS(iRegINoSp dst, memory2 mem)
 6930 %{
 6931   match(Set dst (LoadUS mem));
 6932   predicate(!needs_acquiring_load(n));
 6933 
 6934   ins_cost(4 * INSN_COST);
 6935   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6936 
 6937   ins_encode(aarch64_enc_ldrh(dst, mem));
 6938 
 6939   ins_pipe(iload_reg_mem);
 6940 %}
 6941 
 6942 // Load Short/Char (16 bit unsigned) into long
 6943 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6944 %{
 6945   match(Set dst (ConvI2L (LoadUS mem)));
 6946   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6947 
 6948   ins_cost(4 * INSN_COST);
 6949   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6950 
 6951   ins_encode(aarch64_enc_ldrh(dst, mem));
 6952 
 6953   ins_pipe(iload_reg_mem);
 6954 %}
 6955 
 6956 // Load Integer (32 bit signed)
 6957 instruct loadI(iRegINoSp dst, memory4 mem)
 6958 %{
 6959   match(Set dst (LoadI mem));
 6960   predicate(!needs_acquiring_load(n));
 6961 
 6962   ins_cost(4 * INSN_COST);
 6963   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6964 
 6965   ins_encode(aarch64_enc_ldrw(dst, mem));
 6966 
 6967   ins_pipe(iload_reg_mem);
 6968 %}
 6969 
 6970 // Load Integer (32 bit signed) into long
 6971 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6972 %{
 6973   match(Set dst (ConvI2L (LoadI mem)));
 6974   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6975 
 6976   ins_cost(4 * INSN_COST);
 6977   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 6978 
 6979   ins_encode(aarch64_enc_ldrsw(dst, mem));
 6980 
 6981   ins_pipe(iload_reg_mem);
 6982 %}
 6983 
 6984 // Load Integer (32 bit unsigned) into long
 6985 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 6986 %{
 6987   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 6988   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 6989 
 6990   ins_cost(4 * INSN_COST);
 6991   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6992 
 6993   ins_encode(aarch64_enc_ldrw(dst, mem));
 6994 
 6995   ins_pipe(iload_reg_mem);
 6996 %}
 6997 
 6998 // Load Long (64 bit signed)
 6999 instruct loadL(iRegLNoSp dst, memory8 mem)
 7000 %{
 7001   match(Set dst (LoadL mem));
 7002   predicate(!needs_acquiring_load(n));
 7003 
 7004   ins_cost(4 * INSN_COST);
 7005   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7006 
 7007   ins_encode(aarch64_enc_ldr(dst, mem));
 7008 
 7009   ins_pipe(iload_reg_mem);
 7010 %}
 7011 
 7012 // Load Range
 7013 instruct loadRange(iRegINoSp dst, memory4 mem)
 7014 %{
 7015   match(Set dst (LoadRange mem));
 7016 
 7017   ins_cost(4 * INSN_COST);
 7018   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7019 
 7020   ins_encode(aarch64_enc_ldrw(dst, mem));
 7021 
 7022   ins_pipe(iload_reg_mem);
 7023 %}
 7024 
 7025 // Load Pointer
 7026 instruct loadP(iRegPNoSp dst, memory8 mem)
 7027 %{
 7028   match(Set dst (LoadP mem));
 7029   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7030 
 7031   ins_cost(4 * INSN_COST);
 7032   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7033 
 7034   ins_encode(aarch64_enc_ldr(dst, mem));
 7035 
 7036   ins_pipe(iload_reg_mem);
 7037 %}
 7038 
 7039 // Load Compressed Pointer
 7040 instruct loadN(iRegNNoSp dst, memory4 mem)
 7041 %{
 7042   match(Set dst (LoadN mem));
 7043   predicate(!needs_acquiring_load(n));
 7044 
 7045   ins_cost(4 * INSN_COST);
 7046   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7047 
 7048   ins_encode(aarch64_enc_ldrw(dst, mem));
 7049 
 7050   ins_pipe(iload_reg_mem);
 7051 %}
 7052 
 7053 // Load Klass Pointer
 7054 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7055 %{
 7056   match(Set dst (LoadKlass mem));
 7057   predicate(!needs_acquiring_load(n));
 7058 
 7059   ins_cost(4 * INSN_COST);
 7060   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7061 
 7062   ins_encode(aarch64_enc_ldr(dst, mem));
 7063 
 7064   ins_pipe(iload_reg_mem);
 7065 %}
 7066 
 7067 // Load Narrow Klass Pointer
 7068 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7069 %{
 7070   match(Set dst (LoadNKlass mem));
 7071   predicate(!needs_acquiring_load(n));
 7072 
 7073   ins_cost(4 * INSN_COST);
 7074   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7075 
 7076   ins_encode(aarch64_enc_ldrw(dst, mem));
 7077 
 7078   ins_pipe(iload_reg_mem);
 7079 %}
 7080 
 7081 // Load Float
 7082 instruct loadF(vRegF dst, memory4 mem)
 7083 %{
 7084   match(Set dst (LoadF mem));
 7085   predicate(!needs_acquiring_load(n));
 7086 
 7087   ins_cost(4 * INSN_COST);
 7088   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7089 
 7090   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7091 
 7092   ins_pipe(pipe_class_memory);
 7093 %}
 7094 
 7095 // Load Double
 7096 instruct loadD(vRegD dst, memory8 mem)
 7097 %{
 7098   match(Set dst (LoadD mem));
 7099   predicate(!needs_acquiring_load(n));
 7100 
 7101   ins_cost(4 * INSN_COST);
 7102   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7103 
 7104   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7105 
 7106   ins_pipe(pipe_class_memory);
 7107 %}
 7108 
 7109 
 7110 // Load Int Constant
 7111 instruct loadConI(iRegINoSp dst, immI src)
 7112 %{
 7113   match(Set dst src);
 7114 
 7115   ins_cost(INSN_COST);
 7116   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7117 
 7118   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7119 
 7120   ins_pipe(ialu_imm);
 7121 %}
 7122 
 7123 // Load Long Constant
 7124 instruct loadConL(iRegLNoSp dst, immL src)
 7125 %{
 7126   match(Set dst src);
 7127 
 7128   ins_cost(INSN_COST);
 7129   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7130 
 7131   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7132 
 7133   ins_pipe(ialu_imm);
 7134 %}
 7135 
 7136 // Load Pointer Constant
 7137 
 7138 instruct loadConP(iRegPNoSp dst, immP con)
 7139 %{
 7140   match(Set dst con);
 7141 
 7142   ins_cost(INSN_COST * 4);
 7143   format %{
 7144     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7145   %}
 7146 
 7147   ins_encode(aarch64_enc_mov_p(dst, con));
 7148 
 7149   ins_pipe(ialu_imm);
 7150 %}
 7151 
 7152 // Load Null Pointer Constant
 7153 
 7154 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7155 %{
 7156   match(Set dst con);
 7157 
 7158   ins_cost(INSN_COST);
 7159   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7160 
 7161   ins_encode(aarch64_enc_mov_p0(dst, con));
 7162 
 7163   ins_pipe(ialu_imm);
 7164 %}
 7165 
 7166 // Load Pointer Constant One
 7167 
 7168 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7169 %{
 7170   match(Set dst con);
 7171 
 7172   ins_cost(INSN_COST);
 7173   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7174 
 7175   ins_encode(aarch64_enc_mov_p1(dst, con));
 7176 
 7177   ins_pipe(ialu_imm);
 7178 %}
 7179 
 7180 // Load Poll Page Constant
 7181 
 7182 instruct loadConPollPage(iRegPNoSp dst, immPollPage con)
 7183 %{
 7184   match(Set dst con);
 7185 
 7186   ins_cost(INSN_COST);
 7187   format %{ &quot;adr  $dst, $con\t# Poll Page Ptr&quot; %}
 7188 
 7189   ins_encode(aarch64_enc_mov_poll_page(dst, con));
 7190 
 7191   ins_pipe(ialu_imm);
 7192 %}
 7193 
 7194 // Load Byte Map Base Constant
 7195 
 7196 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7197 %{
 7198   match(Set dst con);
 7199 
 7200   ins_cost(INSN_COST);
 7201   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7202 
 7203   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7204 
 7205   ins_pipe(ialu_imm);
 7206 %}
 7207 
 7208 // Load Narrow Pointer Constant
 7209 
 7210 instruct loadConN(iRegNNoSp dst, immN con)
 7211 %{
 7212   match(Set dst con);
 7213 
 7214   ins_cost(INSN_COST * 4);
 7215   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7216 
 7217   ins_encode(aarch64_enc_mov_n(dst, con));
 7218 
 7219   ins_pipe(ialu_imm);
 7220 %}
 7221 
 7222 // Load Narrow Null Pointer Constant
 7223 
 7224 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7225 %{
 7226   match(Set dst con);
 7227 
 7228   ins_cost(INSN_COST);
 7229   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7230 
 7231   ins_encode(aarch64_enc_mov_n0(dst, con));
 7232 
 7233   ins_pipe(ialu_imm);
 7234 %}
 7235 
 7236 // Load Narrow Klass Constant
 7237 
 7238 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7239 %{
 7240   match(Set dst con);
 7241 
 7242   ins_cost(INSN_COST);
 7243   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7244 
 7245   ins_encode(aarch64_enc_mov_nk(dst, con));
 7246 
 7247   ins_pipe(ialu_imm);
 7248 %}
 7249 
 7250 // Load Packed Float Constant
 7251 
 7252 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7253   match(Set dst con);
 7254   ins_cost(INSN_COST * 4);
 7255   format %{ &quot;fmovs  $dst, $con&quot;%}
 7256   ins_encode %{
 7257     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7258   %}
 7259 
 7260   ins_pipe(fp_imm_s);
 7261 %}
 7262 
 7263 // Load Float Constant
 7264 
 7265 instruct loadConF(vRegF dst, immF con) %{
 7266   match(Set dst con);
 7267 
 7268   ins_cost(INSN_COST * 4);
 7269 
 7270   format %{
 7271     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7272   %}
 7273 
 7274   ins_encode %{
 7275     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7276   %}
 7277 
 7278   ins_pipe(fp_load_constant_s);
 7279 %}
 7280 
 7281 // Load Packed Double Constant
 7282 
 7283 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7284   match(Set dst con);
 7285   ins_cost(INSN_COST);
 7286   format %{ &quot;fmovd  $dst, $con&quot;%}
 7287   ins_encode %{
 7288     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7289   %}
 7290 
 7291   ins_pipe(fp_imm_d);
 7292 %}
 7293 
 7294 // Load Double Constant
 7295 
 7296 instruct loadConD(vRegD dst, immD con) %{
 7297   match(Set dst con);
 7298 
 7299   ins_cost(INSN_COST * 5);
 7300   format %{
 7301     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7302   %}
 7303 
 7304   ins_encode %{
 7305     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7306   %}
 7307 
 7308   ins_pipe(fp_load_constant_d);
 7309 %}
 7310 
 7311 // Store Instructions
 7312 
 7313 // Store CMS card-mark Immediate
 7314 instruct storeimmCM0(immI0 zero, memory1 mem)
 7315 %{
 7316   match(Set mem (StoreCM mem zero));
 7317 
 7318   ins_cost(INSN_COST);
 7319   format %{ &quot;storestore (elided)\n\t&quot;
 7320             &quot;strb zr, $mem\t# byte&quot; %}
 7321 
 7322   ins_encode(aarch64_enc_strb0(mem));
 7323 
 7324   ins_pipe(istore_mem);
 7325 %}
 7326 
 7327 // Store CMS card-mark Immediate with intervening StoreStore
 7328 // needed when using CMS with no conditional card marking
 7329 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7330 %{
 7331   match(Set mem (StoreCM mem zero));
 7332 
 7333   ins_cost(INSN_COST * 2);
 7334   format %{ &quot;storestore\n\t&quot;
 7335             &quot;dmb ishst&quot;
 7336             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7337 
 7338   ins_encode(aarch64_enc_strb0_ordered(mem));
 7339 
 7340   ins_pipe(istore_mem);
 7341 %}
 7342 
 7343 // Store Byte
 7344 instruct storeB(iRegIorL2I src, memory1 mem)
 7345 %{
 7346   match(Set mem (StoreB mem src));
 7347   predicate(!needs_releasing_store(n));
 7348 
 7349   ins_cost(INSN_COST);
 7350   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7351 
 7352   ins_encode(aarch64_enc_strb(src, mem));
 7353 
 7354   ins_pipe(istore_reg_mem);
 7355 %}
 7356 
 7357 
 7358 instruct storeimmB0(immI0 zero, memory1 mem)
 7359 %{
 7360   match(Set mem (StoreB mem zero));
 7361   predicate(!needs_releasing_store(n));
 7362 
 7363   ins_cost(INSN_COST);
 7364   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7365 
 7366   ins_encode(aarch64_enc_strb0(mem));
 7367 
 7368   ins_pipe(istore_mem);
 7369 %}
 7370 
 7371 // Store Char/Short
 7372 instruct storeC(iRegIorL2I src, memory2 mem)
 7373 %{
 7374   match(Set mem (StoreC mem src));
 7375   predicate(!needs_releasing_store(n));
 7376 
 7377   ins_cost(INSN_COST);
 7378   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7379 
 7380   ins_encode(aarch64_enc_strh(src, mem));
 7381 
 7382   ins_pipe(istore_reg_mem);
 7383 %}
 7384 
 7385 instruct storeimmC0(immI0 zero, memory2 mem)
 7386 %{
 7387   match(Set mem (StoreC mem zero));
 7388   predicate(!needs_releasing_store(n));
 7389 
 7390   ins_cost(INSN_COST);
 7391   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7392 
 7393   ins_encode(aarch64_enc_strh0(mem));
 7394 
 7395   ins_pipe(istore_mem);
 7396 %}
 7397 
 7398 // Store Integer
 7399 
 7400 instruct storeI(iRegIorL2I src, memory4 mem)
 7401 %{
 7402   match(Set mem(StoreI mem src));
 7403   predicate(!needs_releasing_store(n));
 7404 
 7405   ins_cost(INSN_COST);
 7406   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7407 
 7408   ins_encode(aarch64_enc_strw(src, mem));
 7409 
 7410   ins_pipe(istore_reg_mem);
 7411 %}
 7412 
 7413 instruct storeimmI0(immI0 zero, memory4 mem)
 7414 %{
 7415   match(Set mem(StoreI mem zero));
 7416   predicate(!needs_releasing_store(n));
 7417 
 7418   ins_cost(INSN_COST);
 7419   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7420 
 7421   ins_encode(aarch64_enc_strw0(mem));
 7422 
 7423   ins_pipe(istore_mem);
 7424 %}
 7425 
 7426 // Store Long (64 bit signed)
 7427 instruct storeL(iRegL src, memory8 mem)
 7428 %{
 7429   match(Set mem (StoreL mem src));
 7430   predicate(!needs_releasing_store(n));
 7431 
 7432   ins_cost(INSN_COST);
 7433   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7434 
 7435   ins_encode(aarch64_enc_str(src, mem));
 7436 
 7437   ins_pipe(istore_reg_mem);
 7438 %}
 7439 
 7440 // Store Long (64 bit signed)
 7441 instruct storeimmL0(immL0 zero, memory8 mem)
 7442 %{
 7443   match(Set mem (StoreL mem zero));
 7444   predicate(!needs_releasing_store(n));
 7445 
 7446   ins_cost(INSN_COST);
 7447   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7448 
 7449   ins_encode(aarch64_enc_str0(mem));
 7450 
 7451   ins_pipe(istore_mem);
 7452 %}
 7453 
 7454 // Store Pointer
 7455 instruct storeP(iRegP src, memory8 mem)
 7456 %{
 7457   match(Set mem (StoreP mem src));
 7458   predicate(!needs_releasing_store(n));
 7459 
 7460   ins_cost(INSN_COST);
 7461   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7462 
 7463   ins_encode(aarch64_enc_str(src, mem));
 7464 
 7465   ins_pipe(istore_reg_mem);
 7466 %}
 7467 
 7468 // Store Pointer
 7469 instruct storeimmP0(immP0 zero, memory8 mem)
 7470 %{
 7471   match(Set mem (StoreP mem zero));
 7472   predicate(!needs_releasing_store(n));
 7473 
 7474   ins_cost(INSN_COST);
 7475   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7476 
 7477   ins_encode(aarch64_enc_str0(mem));
 7478 
 7479   ins_pipe(istore_mem);
 7480 %}
 7481 
 7482 // Store Compressed Pointer
 7483 instruct storeN(iRegN src, memory4 mem)
 7484 %{
 7485   match(Set mem (StoreN mem src));
 7486   predicate(!needs_releasing_store(n));
 7487 
 7488   ins_cost(INSN_COST);
 7489   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7490 
 7491   ins_encode(aarch64_enc_strw(src, mem));
 7492 
 7493   ins_pipe(istore_reg_mem);
 7494 %}
 7495 
 7496 instruct storeImmN0(iRegIHeapbase heapbase, immN0 zero, memory4 mem)
 7497 %{
 7498   match(Set mem (StoreN mem zero));
 7499   predicate(CompressedOops::base() == NULL &amp;&amp;
 7500             CompressedKlassPointers::base() == NULL &amp;&amp;
 7501             (!needs_releasing_store(n)));
 7502 
 7503   ins_cost(INSN_COST);
 7504   format %{ &quot;strw  rheapbase, $mem\t# compressed ptr (rheapbase==0)&quot; %}
 7505 
 7506   ins_encode(aarch64_enc_strw(heapbase, mem));
 7507 
 7508   ins_pipe(istore_reg_mem);
 7509 %}
 7510 
 7511 // Store Float
 7512 instruct storeF(vRegF src, memory4 mem)
 7513 %{
 7514   match(Set mem (StoreF mem src));
 7515   predicate(!needs_releasing_store(n));
 7516 
 7517   ins_cost(INSN_COST);
 7518   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7519 
 7520   ins_encode( aarch64_enc_strs(src, mem) );
 7521 
 7522   ins_pipe(pipe_class_memory);
 7523 %}
 7524 
 7525 // TODO
 7526 // implement storeImmF0 and storeFImmPacked
 7527 
 7528 // Store Double
 7529 instruct storeD(vRegD src, memory8 mem)
 7530 %{
 7531   match(Set mem (StoreD mem src));
 7532   predicate(!needs_releasing_store(n));
 7533 
 7534   ins_cost(INSN_COST);
 7535   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7536 
 7537   ins_encode( aarch64_enc_strd(src, mem) );
 7538 
 7539   ins_pipe(pipe_class_memory);
 7540 %}
 7541 
 7542 // Store Compressed Klass Pointer
 7543 instruct storeNKlass(iRegN src, memory4 mem)
 7544 %{
 7545   predicate(!needs_releasing_store(n));
 7546   match(Set mem (StoreNKlass mem src));
 7547 
 7548   ins_cost(INSN_COST);
 7549   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7550 
 7551   ins_encode(aarch64_enc_strw(src, mem));
 7552 
 7553   ins_pipe(istore_reg_mem);
 7554 %}
 7555 
 7556 // TODO
 7557 // implement storeImmD0 and storeDImmPacked
 7558 
 7559 // prefetch instructions
 7560 // Must be safe to execute with invalid address (cannot fault).
 7561 
 7562 instruct prefetchalloc( memory8 mem ) %{
 7563   match(PrefetchAllocation mem);
 7564 
 7565   ins_cost(INSN_COST);
 7566   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7567 
 7568   ins_encode( aarch64_enc_prefetchw(mem) );
 7569 
 7570   ins_pipe(iload_prefetch);
 7571 %}
 7572 
 7573 //  ---------------- volatile loads and stores ----------------
 7574 
 7575 // Load Byte (8 bit signed)
 7576 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7577 %{
 7578   match(Set dst (LoadB mem));
 7579 
 7580   ins_cost(VOLATILE_REF_COST);
 7581   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7582 
 7583   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7584 
 7585   ins_pipe(pipe_serial);
 7586 %}
 7587 
 7588 // Load Byte (8 bit signed) into long
 7589 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7590 %{
 7591   match(Set dst (ConvI2L (LoadB mem)));
 7592 
 7593   ins_cost(VOLATILE_REF_COST);
 7594   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7595 
 7596   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7597 
 7598   ins_pipe(pipe_serial);
 7599 %}
 7600 
 7601 // Load Byte (8 bit unsigned)
 7602 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7603 %{
 7604   match(Set dst (LoadUB mem));
 7605 
 7606   ins_cost(VOLATILE_REF_COST);
 7607   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7608 
 7609   ins_encode(aarch64_enc_ldarb(dst, mem));
 7610 
 7611   ins_pipe(pipe_serial);
 7612 %}
 7613 
 7614 // Load Byte (8 bit unsigned) into long
 7615 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7616 %{
 7617   match(Set dst (ConvI2L (LoadUB mem)));
 7618 
 7619   ins_cost(VOLATILE_REF_COST);
 7620   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7621 
 7622   ins_encode(aarch64_enc_ldarb(dst, mem));
 7623 
 7624   ins_pipe(pipe_serial);
 7625 %}
 7626 
 7627 // Load Short (16 bit signed)
 7628 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7629 %{
 7630   match(Set dst (LoadS mem));
 7631 
 7632   ins_cost(VOLATILE_REF_COST);
 7633   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7634 
 7635   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7636 
 7637   ins_pipe(pipe_serial);
 7638 %}
 7639 
 7640 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7641 %{
 7642   match(Set dst (LoadUS mem));
 7643 
 7644   ins_cost(VOLATILE_REF_COST);
 7645   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7646 
 7647   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7648 
 7649   ins_pipe(pipe_serial);
 7650 %}
 7651 
 7652 // Load Short/Char (16 bit unsigned) into long
 7653 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7654 %{
 7655   match(Set dst (ConvI2L (LoadUS mem)));
 7656 
 7657   ins_cost(VOLATILE_REF_COST);
 7658   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7659 
 7660   ins_encode(aarch64_enc_ldarh(dst, mem));
 7661 
 7662   ins_pipe(pipe_serial);
 7663 %}
 7664 
 7665 // Load Short/Char (16 bit signed) into long
 7666 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7667 %{
 7668   match(Set dst (ConvI2L (LoadS mem)));
 7669 
 7670   ins_cost(VOLATILE_REF_COST);
 7671   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7672 
 7673   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7674 
 7675   ins_pipe(pipe_serial);
 7676 %}
 7677 
 7678 // Load Integer (32 bit signed)
 7679 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7680 %{
 7681   match(Set dst (LoadI mem));
 7682 
 7683   ins_cost(VOLATILE_REF_COST);
 7684   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7685 
 7686   ins_encode(aarch64_enc_ldarw(dst, mem));
 7687 
 7688   ins_pipe(pipe_serial);
 7689 %}
 7690 
 7691 // Load Integer (32 bit unsigned) into long
 7692 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7693 %{
 7694   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7695 
 7696   ins_cost(VOLATILE_REF_COST);
 7697   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7698 
 7699   ins_encode(aarch64_enc_ldarw(dst, mem));
 7700 
 7701   ins_pipe(pipe_serial);
 7702 %}
 7703 
 7704 // Load Long (64 bit signed)
 7705 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7706 %{
 7707   match(Set dst (LoadL mem));
 7708 
 7709   ins_cost(VOLATILE_REF_COST);
 7710   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7711 
 7712   ins_encode(aarch64_enc_ldar(dst, mem));
 7713 
 7714   ins_pipe(pipe_serial);
 7715 %}
 7716 
 7717 // Load Pointer
 7718 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7719 %{
 7720   match(Set dst (LoadP mem));
 7721   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7722 
 7723   ins_cost(VOLATILE_REF_COST);
 7724   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7725 
 7726   ins_encode(aarch64_enc_ldar(dst, mem));
 7727 
 7728   ins_pipe(pipe_serial);
 7729 %}
 7730 
 7731 // Load Compressed Pointer
 7732 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7733 %{
 7734   match(Set dst (LoadN mem));
 7735 
 7736   ins_cost(VOLATILE_REF_COST);
 7737   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7738 
 7739   ins_encode(aarch64_enc_ldarw(dst, mem));
 7740 
 7741   ins_pipe(pipe_serial);
 7742 %}
 7743 
 7744 // Load Float
 7745 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7746 %{
 7747   match(Set dst (LoadF mem));
 7748 
 7749   ins_cost(VOLATILE_REF_COST);
 7750   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7751 
 7752   ins_encode( aarch64_enc_fldars(dst, mem) );
 7753 
 7754   ins_pipe(pipe_serial);
 7755 %}
 7756 
 7757 // Load Double
 7758 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7759 %{
 7760   match(Set dst (LoadD mem));
 7761 
 7762   ins_cost(VOLATILE_REF_COST);
 7763   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7764 
 7765   ins_encode( aarch64_enc_fldard(dst, mem) );
 7766 
 7767   ins_pipe(pipe_serial);
 7768 %}
 7769 
 7770 // Store Byte
 7771 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7772 %{
 7773   match(Set mem (StoreB mem src));
 7774 
 7775   ins_cost(VOLATILE_REF_COST);
 7776   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7777 
 7778   ins_encode(aarch64_enc_stlrb(src, mem));
 7779 
 7780   ins_pipe(pipe_class_memory);
 7781 %}
 7782 
 7783 // Store Char/Short
 7784 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7785 %{
 7786   match(Set mem (StoreC mem src));
 7787 
 7788   ins_cost(VOLATILE_REF_COST);
 7789   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7790 
 7791   ins_encode(aarch64_enc_stlrh(src, mem));
 7792 
 7793   ins_pipe(pipe_class_memory);
 7794 %}
 7795 
 7796 // Store Integer
 7797 
 7798 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7799 %{
 7800   match(Set mem(StoreI mem src));
 7801 
 7802   ins_cost(VOLATILE_REF_COST);
 7803   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7804 
 7805   ins_encode(aarch64_enc_stlrw(src, mem));
 7806 
 7807   ins_pipe(pipe_class_memory);
 7808 %}
 7809 
 7810 // Store Long (64 bit signed)
 7811 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7812 %{
 7813   match(Set mem (StoreL mem src));
 7814 
 7815   ins_cost(VOLATILE_REF_COST);
 7816   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7817 
 7818   ins_encode(aarch64_enc_stlr(src, mem));
 7819 
 7820   ins_pipe(pipe_class_memory);
 7821 %}
 7822 
 7823 // Store Pointer
 7824 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7825 %{
 7826   match(Set mem (StoreP mem src));
 7827 
 7828   ins_cost(VOLATILE_REF_COST);
 7829   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7830 
 7831   ins_encode(aarch64_enc_stlr(src, mem));
 7832 
 7833   ins_pipe(pipe_class_memory);
 7834 %}
 7835 
 7836 // Store Compressed Pointer
 7837 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7838 %{
 7839   match(Set mem (StoreN mem src));
 7840 
 7841   ins_cost(VOLATILE_REF_COST);
 7842   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7843 
 7844   ins_encode(aarch64_enc_stlrw(src, mem));
 7845 
 7846   ins_pipe(pipe_class_memory);
 7847 %}
 7848 
 7849 // Store Float
 7850 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7851 %{
 7852   match(Set mem (StoreF mem src));
 7853 
 7854   ins_cost(VOLATILE_REF_COST);
 7855   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7856 
 7857   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7858 
 7859   ins_pipe(pipe_class_memory);
 7860 %}
 7861 
 7862 // TODO
 7863 // implement storeImmF0 and storeFImmPacked
 7864 
 7865 // Store Double
 7866 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7867 %{
 7868   match(Set mem (StoreD mem src));
 7869 
 7870   ins_cost(VOLATILE_REF_COST);
 7871   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7872 
 7873   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7874 
 7875   ins_pipe(pipe_class_memory);
 7876 %}
 7877 
 7878 //  ---------------- end of volatile loads and stores ----------------
 7879 
 7880 instruct cacheWB(indirect addr)
 7881 %{
 7882   predicate(VM_Version::supports_data_cache_line_flush());
 7883   match(CacheWB addr);
 7884 
 7885   ins_cost(100);
 7886   format %{&quot;cache wb $addr&quot; %}
 7887   ins_encode %{
 7888     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7889     assert($addr$$disp == 0, &quot;should be&quot;);
 7890     __ cache_wb(Address($addr$$base$$Register, 0));
 7891   %}
 7892   ins_pipe(pipe_slow); // XXX
 7893 %}
 7894 
 7895 instruct cacheWBPreSync()
 7896 %{
 7897   predicate(VM_Version::supports_data_cache_line_flush());
 7898   match(CacheWBPreSync);
 7899 
 7900   ins_cost(100);
 7901   format %{&quot;cache wb presync&quot; %}
 7902   ins_encode %{
 7903     __ cache_wbsync(true);
 7904   %}
 7905   ins_pipe(pipe_slow); // XXX
 7906 %}
 7907 
 7908 instruct cacheWBPostSync()
 7909 %{
 7910   predicate(VM_Version::supports_data_cache_line_flush());
 7911   match(CacheWBPostSync);
 7912 
 7913   ins_cost(100);
 7914   format %{&quot;cache wb postsync&quot; %}
 7915   ins_encode %{
 7916     __ cache_wbsync(false);
 7917   %}
 7918   ins_pipe(pipe_slow); // XXX
 7919 %}
 7920 
 7921 // ============================================================================
 7922 // BSWAP Instructions
 7923 
 7924 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7925   match(Set dst (ReverseBytesI src));
 7926 
 7927   ins_cost(INSN_COST);
 7928   format %{ &quot;revw  $dst, $src&quot; %}
 7929 
 7930   ins_encode %{
 7931     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7932   %}
 7933 
 7934   ins_pipe(ialu_reg);
 7935 %}
 7936 
 7937 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7938   match(Set dst (ReverseBytesL src));
 7939 
 7940   ins_cost(INSN_COST);
 7941   format %{ &quot;rev  $dst, $src&quot; %}
 7942 
 7943   ins_encode %{
 7944     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7945   %}
 7946 
 7947   ins_pipe(ialu_reg);
 7948 %}
 7949 
 7950 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7951   match(Set dst (ReverseBytesUS src));
 7952 
 7953   ins_cost(INSN_COST);
 7954   format %{ &quot;rev16w  $dst, $src&quot; %}
 7955 
 7956   ins_encode %{
 7957     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7958   %}
 7959 
 7960   ins_pipe(ialu_reg);
 7961 %}
 7962 
 7963 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7964   match(Set dst (ReverseBytesS src));
 7965 
 7966   ins_cost(INSN_COST);
 7967   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7968             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7969 
 7970   ins_encode %{
 7971     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7972     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7973   %}
 7974 
 7975   ins_pipe(ialu_reg);
 7976 %}
 7977 
 7978 // ============================================================================
 7979 // Zero Count Instructions
 7980 
 7981 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7982   match(Set dst (CountLeadingZerosI src));
 7983 
 7984   ins_cost(INSN_COST);
 7985   format %{ &quot;clzw  $dst, $src&quot; %}
 7986   ins_encode %{
 7987     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7988   %}
 7989 
 7990   ins_pipe(ialu_reg);
 7991 %}
 7992 
 7993 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 7994   match(Set dst (CountLeadingZerosL src));
 7995 
 7996   ins_cost(INSN_COST);
 7997   format %{ &quot;clz   $dst, $src&quot; %}
 7998   ins_encode %{
 7999     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8000   %}
 8001 
 8002   ins_pipe(ialu_reg);
 8003 %}
 8004 
 8005 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8006   match(Set dst (CountTrailingZerosI src));
 8007 
 8008   ins_cost(INSN_COST * 2);
 8009   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8010             &quot;clzw   $dst, $dst&quot; %}
 8011   ins_encode %{
 8012     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8013     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8014   %}
 8015 
 8016   ins_pipe(ialu_reg);
 8017 %}
 8018 
 8019 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8020   match(Set dst (CountTrailingZerosL src));
 8021 
 8022   ins_cost(INSN_COST * 2);
 8023   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8024             &quot;clz    $dst, $dst&quot; %}
 8025   ins_encode %{
 8026     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8027     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8028   %}
 8029 
 8030   ins_pipe(ialu_reg);
 8031 %}
 8032 
 8033 //---------- Population Count Instructions -------------------------------------
 8034 //
 8035 
 8036 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8037   predicate(UsePopCountInstruction);
 8038   match(Set dst (PopCountI src));
 8039   effect(TEMP tmp);
 8040   ins_cost(INSN_COST * 13);
 8041 
 8042   format %{ &quot;movw   $src, $src\n\t&quot;
 8043             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8044             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8045             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8046             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8047   ins_encode %{
 8048     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8049     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8050     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8051     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8052     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8053   %}
 8054 
 8055   ins_pipe(pipe_class_default);
 8056 %}
 8057 
 8058 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8059   predicate(UsePopCountInstruction);
 8060   match(Set dst (PopCountI (LoadI mem)));
 8061   effect(TEMP tmp);
 8062   ins_cost(INSN_COST * 13);
 8063 
 8064   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8065             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8066             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8067             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8068   ins_encode %{
 8069     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8070     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8071               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8072     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8073     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8074     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8075   %}
 8076 
 8077   ins_pipe(pipe_class_default);
 8078 %}
 8079 
 8080 // Note: Long.bitCount(long) returns an int.
 8081 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8082   predicate(UsePopCountInstruction);
 8083   match(Set dst (PopCountL src));
 8084   effect(TEMP tmp);
 8085   ins_cost(INSN_COST * 13);
 8086 
 8087   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8088             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8089             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8090             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8091   ins_encode %{
 8092     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8093     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8094     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8095     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8096   %}
 8097 
 8098   ins_pipe(pipe_class_default);
 8099 %}
 8100 
 8101 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8102   predicate(UsePopCountInstruction);
 8103   match(Set dst (PopCountL (LoadL mem)));
 8104   effect(TEMP tmp);
 8105   ins_cost(INSN_COST * 13);
 8106 
 8107   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8108             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8109             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8110             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8111   ins_encode %{
 8112     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8113     loadStore(MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8114               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8115     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8116     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8117     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8118   %}
 8119 
 8120   ins_pipe(pipe_class_default);
 8121 %}
 8122 
 8123 // ============================================================================
 8124 // MemBar Instruction
 8125 
 8126 instruct load_fence() %{
 8127   match(LoadFence);
 8128   ins_cost(VOLATILE_REF_COST);
 8129 
 8130   format %{ &quot;load_fence&quot; %}
 8131 
 8132   ins_encode %{
 8133     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8134   %}
 8135   ins_pipe(pipe_serial);
 8136 %}
 8137 
 8138 instruct unnecessary_membar_acquire() %{
 8139   predicate(unnecessary_acquire(n));
 8140   match(MemBarAcquire);
 8141   ins_cost(0);
 8142 
 8143   format %{ &quot;membar_acquire (elided)&quot; %}
 8144 
 8145   ins_encode %{
 8146     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8147   %}
 8148 
 8149   ins_pipe(pipe_class_empty);
 8150 %}
 8151 
 8152 instruct membar_acquire() %{
 8153   match(MemBarAcquire);
 8154   ins_cost(VOLATILE_REF_COST);
 8155 
 8156   format %{ &quot;membar_acquire\n\t&quot;
 8157             &quot;dmb ish&quot; %}
 8158 
 8159   ins_encode %{
 8160     __ block_comment(&quot;membar_acquire&quot;);
 8161     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8162   %}
 8163 
 8164   ins_pipe(pipe_serial);
 8165 %}
 8166 
 8167 
 8168 instruct membar_acquire_lock() %{
 8169   match(MemBarAcquireLock);
 8170   ins_cost(VOLATILE_REF_COST);
 8171 
 8172   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8173 
 8174   ins_encode %{
 8175     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8176   %}
 8177 
 8178   ins_pipe(pipe_serial);
 8179 %}
 8180 
 8181 instruct store_fence() %{
 8182   match(StoreFence);
 8183   ins_cost(VOLATILE_REF_COST);
 8184 
 8185   format %{ &quot;store_fence&quot; %}
 8186 
 8187   ins_encode %{
 8188     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8189   %}
 8190   ins_pipe(pipe_serial);
 8191 %}
 8192 
 8193 instruct unnecessary_membar_release() %{
 8194   predicate(unnecessary_release(n));
 8195   match(MemBarRelease);
 8196   ins_cost(0);
 8197 
 8198   format %{ &quot;membar_release (elided)&quot; %}
 8199 
 8200   ins_encode %{
 8201     __ block_comment(&quot;membar_release (elided)&quot;);
 8202   %}
 8203   ins_pipe(pipe_serial);
 8204 %}
 8205 
 8206 instruct membar_release() %{
 8207   match(MemBarRelease);
 8208   ins_cost(VOLATILE_REF_COST);
 8209 
 8210   format %{ &quot;membar_release\n\t&quot;
 8211             &quot;dmb ish&quot; %}
 8212 
 8213   ins_encode %{
 8214     __ block_comment(&quot;membar_release&quot;);
 8215     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8216   %}
 8217   ins_pipe(pipe_serial);
 8218 %}
 8219 
 8220 instruct membar_storestore() %{
 8221   match(MemBarStoreStore);
 8222   ins_cost(VOLATILE_REF_COST);
 8223 
 8224   format %{ &quot;MEMBAR-store-store&quot; %}
 8225 
 8226   ins_encode %{
 8227     __ membar(Assembler::StoreStore);
 8228   %}
 8229   ins_pipe(pipe_serial);
 8230 %}
 8231 
 8232 instruct membar_release_lock() %{
 8233   match(MemBarReleaseLock);
 8234   ins_cost(VOLATILE_REF_COST);
 8235 
 8236   format %{ &quot;membar_release_lock (elided)&quot; %}
 8237 
 8238   ins_encode %{
 8239     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8240   %}
 8241 
 8242   ins_pipe(pipe_serial);
 8243 %}
 8244 
 8245 instruct unnecessary_membar_volatile() %{
 8246   predicate(unnecessary_volatile(n));
 8247   match(MemBarVolatile);
 8248   ins_cost(0);
 8249 
 8250   format %{ &quot;membar_volatile (elided)&quot; %}
 8251 
 8252   ins_encode %{
 8253     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8254   %}
 8255 
 8256   ins_pipe(pipe_serial);
 8257 %}
 8258 
 8259 instruct membar_volatile() %{
 8260   match(MemBarVolatile);
 8261   ins_cost(VOLATILE_REF_COST*100);
 8262 
 8263   format %{ &quot;membar_volatile\n\t&quot;
 8264              &quot;dmb ish&quot;%}
 8265 
 8266   ins_encode %{
 8267     __ block_comment(&quot;membar_volatile&quot;);
 8268     __ membar(Assembler::StoreLoad);
 8269   %}
 8270 
 8271   ins_pipe(pipe_serial);
 8272 %}
 8273 
 8274 // ============================================================================
 8275 // Cast/Convert Instructions
 8276 
 8277 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8278   match(Set dst (CastX2P src));
 8279 
 8280   ins_cost(INSN_COST);
 8281   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8282 
 8283   ins_encode %{
 8284     if ($dst$$reg != $src$$reg) {
 8285       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8286     }
 8287   %}
 8288 
 8289   ins_pipe(ialu_reg);
 8290 %}
 8291 
 8292 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8293   match(Set dst (CastP2X src));
 8294 
 8295   ins_cost(INSN_COST);
 8296   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8297 
 8298   ins_encode %{
 8299     if ($dst$$reg != $src$$reg) {
 8300       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8301     }
 8302   %}
 8303 
 8304   ins_pipe(ialu_reg);
 8305 %}
 8306 
 8307 // Convert oop into int for vectors alignment masking
 8308 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8309   match(Set dst (ConvL2I (CastP2X src)));
 8310 
 8311   ins_cost(INSN_COST);
 8312   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8313   ins_encode %{
 8314     __ movw($dst$$Register, $src$$Register);
 8315   %}
 8316 
 8317   ins_pipe(ialu_reg);
 8318 %}
 8319 
 8320 // Convert compressed oop into int for vectors alignment masking
 8321 // in case of 32bit oops (heap &lt; 4Gb).
 8322 instruct convN2I(iRegINoSp dst, iRegN src)
 8323 %{
 8324   predicate(CompressedOops::shift() == 0);
 8325   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8326 
 8327   ins_cost(INSN_COST);
 8328   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8329   ins_encode %{
 8330     __ movw($dst$$Register, $src$$Register);
 8331   %}
 8332 
 8333   ins_pipe(ialu_reg);
 8334 %}
 8335 
 8336 
 8337 // Convert oop pointer into compressed form
 8338 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8339   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8340   match(Set dst (EncodeP src));
 8341   effect(KILL cr);
 8342   ins_cost(INSN_COST * 3);
 8343   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8344   ins_encode %{
 8345     Register s = $src$$Register;
 8346     Register d = $dst$$Register;
 8347     __ encode_heap_oop(d, s);
 8348   %}
 8349   ins_pipe(ialu_reg);
 8350 %}
 8351 
 8352 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8353   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8354   match(Set dst (EncodeP src));
 8355   ins_cost(INSN_COST * 3);
 8356   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8357   ins_encode %{
 8358     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8359   %}
 8360   ins_pipe(ialu_reg);
 8361 %}
 8362 
 8363 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8364   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8365             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8366   match(Set dst (DecodeN src));
 8367   ins_cost(INSN_COST * 3);
 8368   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8369   ins_encode %{
 8370     Register s = $src$$Register;
 8371     Register d = $dst$$Register;
 8372     __ decode_heap_oop(d, s);
 8373   %}
 8374   ins_pipe(ialu_reg);
 8375 %}
 8376 
 8377 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8378   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8379             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8380   match(Set dst (DecodeN src));
 8381   ins_cost(INSN_COST * 3);
 8382   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8383   ins_encode %{
 8384     Register s = $src$$Register;
 8385     Register d = $dst$$Register;
 8386     __ decode_heap_oop_not_null(d, s);
 8387   %}
 8388   ins_pipe(ialu_reg);
 8389 %}
 8390 
 8391 // n.b. AArch64 implementations of encode_klass_not_null and
 8392 // decode_klass_not_null do not modify the flags register so, unlike
 8393 // Intel, we don&#39;t kill CR as a side effect here
 8394 
 8395 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8396   match(Set dst (EncodePKlass src));
 8397 
 8398   ins_cost(INSN_COST * 3);
 8399   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8400 
 8401   ins_encode %{
 8402     Register src_reg = as_Register($src$$reg);
 8403     Register dst_reg = as_Register($dst$$reg);
 8404     __ encode_klass_not_null(dst_reg, src_reg);
 8405   %}
 8406 
 8407    ins_pipe(ialu_reg);
 8408 %}
 8409 
 8410 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8411   match(Set dst (DecodeNKlass src));
 8412 
 8413   ins_cost(INSN_COST * 3);
 8414   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8415 
 8416   ins_encode %{
 8417     Register src_reg = as_Register($src$$reg);
 8418     Register dst_reg = as_Register($dst$$reg);
 8419     if (dst_reg != src_reg) {
 8420       __ decode_klass_not_null(dst_reg, src_reg);
 8421     } else {
 8422       __ decode_klass_not_null(dst_reg);
 8423     }
 8424   %}
 8425 
 8426    ins_pipe(ialu_reg);
 8427 %}
 8428 
 8429 instruct checkCastPP(iRegPNoSp dst)
 8430 %{
 8431   match(Set dst (CheckCastPP dst));
 8432 
 8433   size(0);
 8434   format %{ &quot;# checkcastPP of $dst&quot; %}
 8435   ins_encode(/* empty encoding */);
 8436   ins_pipe(pipe_class_empty);
 8437 %}
 8438 
 8439 instruct castPP(iRegPNoSp dst)
 8440 %{
 8441   match(Set dst (CastPP dst));
 8442 
 8443   size(0);
 8444   format %{ &quot;# castPP of $dst&quot; %}
 8445   ins_encode(/* empty encoding */);
 8446   ins_pipe(pipe_class_empty);
 8447 %}
 8448 
 8449 instruct castII(iRegI dst)
 8450 %{
 8451   match(Set dst (CastII dst));
 8452 
 8453   size(0);
 8454   format %{ &quot;# castII of $dst&quot; %}
 8455   ins_encode(/* empty encoding */);
 8456   ins_cost(0);
 8457   ins_pipe(pipe_class_empty);
 8458 %}
 8459 
 8460 instruct castLL(iRegL dst)
 8461 %{
 8462   match(Set dst (CastLL dst));
 8463 
 8464   size(0);
 8465   format %{ &quot;# castLL of $dst&quot; %}
 8466   ins_encode(/* empty encoding */);
 8467   ins_cost(0);
 8468   ins_pipe(pipe_class_empty);
 8469 %}
 8470 
 8471 // ============================================================================
 8472 // Atomic operation instructions
 8473 //
 8474 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8475 // Store{PIL}Conditional instructions using a normal load for the
 8476 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8477 //
 8478 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8479 // pair to lock object allocations from Eden space when not using
 8480 // TLABs.
 8481 //
 8482 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8483 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8484 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8485 // only for 64-bit.
 8486 //
 8487 // We implement LoadPLocked and StorePLocked instructions using,
 8488 // respectively the AArch64 hw load-exclusive and store-conditional
 8489 // instructions. Whereas we must implement each of
 8490 // Store{IL}Conditional using a CAS which employs a pair of
 8491 // instructions comprising a load-exclusive followed by a
 8492 // store-conditional.
 8493 
 8494 
 8495 // Locked-load (linked load) of the current heap-top
 8496 // used when updating the eden heap top
 8497 // implemented using ldaxr on AArch64
 8498 
 8499 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8500 %{
 8501   match(Set dst (LoadPLocked mem));
 8502 
 8503   ins_cost(VOLATILE_REF_COST);
 8504 
 8505   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8506 
 8507   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8508 
 8509   ins_pipe(pipe_serial);
 8510 %}
 8511 
 8512 // Conditional-store of the updated heap-top.
 8513 // Used during allocation of the shared heap.
 8514 // Sets flag (EQ) on success.
 8515 // implemented using stlxr on AArch64.
 8516 
 8517 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8518 %{
 8519   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8520 
 8521   ins_cost(VOLATILE_REF_COST);
 8522 
 8523  // TODO
 8524  // do we need to do a store-conditional release or can we just use a
 8525  // plain store-conditional?
 8526 
 8527   format %{
 8528     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8529     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8530   %}
 8531 
 8532   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8533 
 8534   ins_pipe(pipe_serial);
 8535 %}
 8536 
 8537 
 8538 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8539 // when attempting to rebias a lock towards the current thread.  We
 8540 // must use the acquire form of cmpxchg in order to guarantee acquire
 8541 // semantics in this case.
 8542 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8543 %{
 8544   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8545 
 8546   ins_cost(VOLATILE_REF_COST);
 8547 
 8548   format %{
 8549     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8550     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8551   %}
 8552 
 8553   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8554 
 8555   ins_pipe(pipe_slow);
 8556 %}
 8557 
 8558 // storeIConditional also has acquire semantics, for no better reason
 8559 // than matching storeLConditional.  At the time of writing this
 8560 // comment storeIConditional was not used anywhere by AArch64.
 8561 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8562 %{
 8563   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8564 
 8565   ins_cost(VOLATILE_REF_COST);
 8566 
 8567   format %{
 8568     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8569     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8570   %}
 8571 
 8572   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8573 
 8574   ins_pipe(pipe_slow);
 8575 %}
 8576 
 8577 // standard CompareAndSwapX when we are using barriers
 8578 // these have higher priority than the rules selected by a predicate
 8579 
 8580 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8581 // can&#39;t match them
 8582 
 8583 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8584 
 8585   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8586   ins_cost(2 * VOLATILE_REF_COST);
 8587 
 8588   effect(KILL cr);
 8589 
 8590   format %{
 8591     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8592     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8593   %}
 8594 
 8595   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8596             aarch64_enc_cset_eq(res));
 8597 
 8598   ins_pipe(pipe_slow);
 8599 %}
 8600 
 8601 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8602 
 8603   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8604   ins_cost(2 * VOLATILE_REF_COST);
 8605 
 8606   effect(KILL cr);
 8607 
 8608   format %{
 8609     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8610     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8611   %}
 8612 
 8613   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8614             aarch64_enc_cset_eq(res));
 8615 
 8616   ins_pipe(pipe_slow);
 8617 %}
 8618 
 8619 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8620 
 8621   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8622   ins_cost(2 * VOLATILE_REF_COST);
 8623 
 8624   effect(KILL cr);
 8625 
 8626  format %{
 8627     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8628     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8629  %}
 8630 
 8631  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8632             aarch64_enc_cset_eq(res));
 8633 
 8634   ins_pipe(pipe_slow);
 8635 %}
 8636 
 8637 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8638 
 8639   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8640   ins_cost(2 * VOLATILE_REF_COST);
 8641 
 8642   effect(KILL cr);
 8643 
 8644  format %{
 8645     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8646     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8647  %}
 8648 
 8649  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8650             aarch64_enc_cset_eq(res));
 8651 
 8652   ins_pipe(pipe_slow);
 8653 %}
 8654 
 8655 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8656 
 8657   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8658   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8659   ins_cost(2 * VOLATILE_REF_COST);
 8660 
 8661   effect(KILL cr);
 8662 
 8663  format %{
 8664     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8665     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8666  %}
 8667 
 8668  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8669             aarch64_enc_cset_eq(res));
 8670 
 8671   ins_pipe(pipe_slow);
 8672 %}
 8673 
 8674 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8675 
 8676   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8677   ins_cost(2 * VOLATILE_REF_COST);
 8678 
 8679   effect(KILL cr);
 8680 
 8681  format %{
 8682     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8683     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8684  %}
 8685 
 8686  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8687             aarch64_enc_cset_eq(res));
 8688 
 8689   ins_pipe(pipe_slow);
 8690 %}
 8691 
 8692 // alternative CompareAndSwapX when we are eliding barriers
 8693 
 8694 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8695 
 8696   predicate(needs_acquiring_load_exclusive(n));
 8697   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8698   ins_cost(VOLATILE_REF_COST);
 8699 
 8700   effect(KILL cr);
 8701 
 8702   format %{
 8703     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8704     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8705   %}
 8706 
 8707   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8708             aarch64_enc_cset_eq(res));
 8709 
 8710   ins_pipe(pipe_slow);
 8711 %}
 8712 
 8713 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8714 
 8715   predicate(needs_acquiring_load_exclusive(n));
 8716   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8717   ins_cost(VOLATILE_REF_COST);
 8718 
 8719   effect(KILL cr);
 8720 
 8721   format %{
 8722     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8723     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8724   %}
 8725 
 8726   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8727             aarch64_enc_cset_eq(res));
 8728 
 8729   ins_pipe(pipe_slow);
 8730 %}
 8731 
 8732 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8733 
 8734   predicate(needs_acquiring_load_exclusive(n));
 8735   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8736   ins_cost(VOLATILE_REF_COST);
 8737 
 8738   effect(KILL cr);
 8739 
 8740  format %{
 8741     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8742     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8743  %}
 8744 
 8745  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8746             aarch64_enc_cset_eq(res));
 8747 
 8748   ins_pipe(pipe_slow);
 8749 %}
 8750 
 8751 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8752 
 8753   predicate(needs_acquiring_load_exclusive(n));
 8754   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8755   ins_cost(VOLATILE_REF_COST);
 8756 
 8757   effect(KILL cr);
 8758 
 8759  format %{
 8760     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8761     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8762  %}
 8763 
 8764  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8765             aarch64_enc_cset_eq(res));
 8766 
 8767   ins_pipe(pipe_slow);
 8768 %}
 8769 
 8770 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8771 
 8772   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8773   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8774   ins_cost(VOLATILE_REF_COST);
 8775 
 8776   effect(KILL cr);
 8777 
 8778  format %{
 8779     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8780     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8781  %}
 8782 
 8783  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8784             aarch64_enc_cset_eq(res));
 8785 
 8786   ins_pipe(pipe_slow);
 8787 %}
 8788 
 8789 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8790 
 8791   predicate(needs_acquiring_load_exclusive(n));
 8792   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8793   ins_cost(VOLATILE_REF_COST);
 8794 
 8795   effect(KILL cr);
 8796 
 8797  format %{
 8798     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8799     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8800  %}
 8801 
 8802  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8803             aarch64_enc_cset_eq(res));
 8804 
 8805   ins_pipe(pipe_slow);
 8806 %}
 8807 
 8808 
 8809 // ---------------------------------------------------------------------
 8810 
 8811 
 8812 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8813 
 8814 // Sundry CAS operations.  Note that release is always true,
 8815 // regardless of the memory ordering of the CAS.  This is because we
 8816 // need the volatile case to be sequentially consistent but there is
 8817 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8818 // can&#39;t check the type of memory ordering here, so we always emit a
 8819 // STLXR.
 8820 
 8821 // This section is generated from aarch64_ad_cas.m4
 8822 
 8823 
 8824 
 8825 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8826   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8827   ins_cost(2 * VOLATILE_REF_COST);
 8828   effect(TEMP_DEF res, KILL cr);
 8829   format %{
 8830     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8831   %}
 8832   ins_encode %{
 8833     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8834                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8835                /*weak*/ false, $res$$Register);
 8836     __ sxtbw($res$$Register, $res$$Register);
 8837   %}
 8838   ins_pipe(pipe_slow);
 8839 %}
 8840 
 8841 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8842   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8843   ins_cost(2 * VOLATILE_REF_COST);
 8844   effect(TEMP_DEF res, KILL cr);
 8845   format %{
 8846     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8847   %}
 8848   ins_encode %{
 8849     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8850                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8851                /*weak*/ false, $res$$Register);
 8852     __ sxthw($res$$Register, $res$$Register);
 8853   %}
 8854   ins_pipe(pipe_slow);
 8855 %}
 8856 
 8857 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8858   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8859   ins_cost(2 * VOLATILE_REF_COST);
 8860   effect(TEMP_DEF res, KILL cr);
 8861   format %{
 8862     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8863   %}
 8864   ins_encode %{
 8865     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8866                Assembler::word, /*acquire*/ false, /*release*/ true,
 8867                /*weak*/ false, $res$$Register);
 8868   %}
 8869   ins_pipe(pipe_slow);
 8870 %}
 8871 
 8872 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8873   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8874   ins_cost(2 * VOLATILE_REF_COST);
 8875   effect(TEMP_DEF res, KILL cr);
 8876   format %{
 8877     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8878   %}
 8879   ins_encode %{
 8880     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8881                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8882                /*weak*/ false, $res$$Register);
 8883   %}
 8884   ins_pipe(pipe_slow);
 8885 %}
 8886 
 8887 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8888   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8889   ins_cost(2 * VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::word, /*acquire*/ false, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898   %}
 8899   ins_pipe(pipe_slow);
 8900 %}
 8901 
 8902 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8903   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8904   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8905   ins_cost(2 * VOLATILE_REF_COST);
 8906   effect(TEMP_DEF res, KILL cr);
 8907   format %{
 8908     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8909   %}
 8910   ins_encode %{
 8911     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8912                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8913                /*weak*/ false, $res$$Register);
 8914   %}
 8915   ins_pipe(pipe_slow);
 8916 %}
 8917 
 8918 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8919   predicate(needs_acquiring_load_exclusive(n));
 8920   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8921   ins_cost(VOLATILE_REF_COST);
 8922   effect(TEMP_DEF res, KILL cr);
 8923   format %{
 8924     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8925   %}
 8926   ins_encode %{
 8927     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8928                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8929                /*weak*/ false, $res$$Register);
 8930     __ sxtbw($res$$Register, $res$$Register);
 8931   %}
 8932   ins_pipe(pipe_slow);
 8933 %}
 8934 
 8935 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8936   predicate(needs_acquiring_load_exclusive(n));
 8937   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8938   ins_cost(VOLATILE_REF_COST);
 8939   effect(TEMP_DEF res, KILL cr);
 8940   format %{
 8941     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8942   %}
 8943   ins_encode %{
 8944     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8945                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8946                /*weak*/ false, $res$$Register);
 8947     __ sxthw($res$$Register, $res$$Register);
 8948   %}
 8949   ins_pipe(pipe_slow);
 8950 %}
 8951 
 8952 
 8953 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8954   predicate(needs_acquiring_load_exclusive(n));
 8955   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8956   ins_cost(VOLATILE_REF_COST);
 8957   effect(TEMP_DEF res, KILL cr);
 8958   format %{
 8959     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8960   %}
 8961   ins_encode %{
 8962     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8963                Assembler::word, /*acquire*/ true, /*release*/ true,
 8964                /*weak*/ false, $res$$Register);
 8965   %}
 8966   ins_pipe(pipe_slow);
 8967 %}
 8968 
 8969 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8970   predicate(needs_acquiring_load_exclusive(n));
 8971   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8972   ins_cost(VOLATILE_REF_COST);
 8973   effect(TEMP_DEF res, KILL cr);
 8974   format %{
 8975     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8976   %}
 8977   ins_encode %{
 8978     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8979                Assembler::xword, /*acquire*/ true, /*release*/ true,
 8980                /*weak*/ false, $res$$Register);
 8981   %}
 8982   ins_pipe(pipe_slow);
 8983 %}
 8984 
 8985 
 8986 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8987   predicate(needs_acquiring_load_exclusive(n));
 8988   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8989   ins_cost(VOLATILE_REF_COST);
 8990   effect(TEMP_DEF res, KILL cr);
 8991   format %{
 8992     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8993   %}
 8994   ins_encode %{
 8995     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8996                Assembler::word, /*acquire*/ true, /*release*/ true,
 8997                /*weak*/ false, $res$$Register);
 8998   %}
 8999   ins_pipe(pipe_slow);
 9000 %}
 9001 
 9002 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9003   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9004   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9005   ins_cost(VOLATILE_REF_COST);
 9006   effect(TEMP_DEF res, KILL cr);
 9007   format %{
 9008     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9009   %}
 9010   ins_encode %{
 9011     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9012                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9013                /*weak*/ false, $res$$Register);
 9014   %}
 9015   ins_pipe(pipe_slow);
 9016 %}
 9017 
 9018 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9019   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9020   ins_cost(2 * VOLATILE_REF_COST);
 9021   effect(KILL cr);
 9022   format %{
 9023     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9024     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9025   %}
 9026   ins_encode %{
 9027     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9028                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9029                /*weak*/ true, noreg);
 9030     __ csetw($res$$Register, Assembler::EQ);
 9031   %}
 9032   ins_pipe(pipe_slow);
 9033 %}
 9034 
 9035 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9036   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9037   ins_cost(2 * VOLATILE_REF_COST);
 9038   effect(KILL cr);
 9039   format %{
 9040     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9041     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9042   %}
 9043   ins_encode %{
 9044     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9045                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9046                /*weak*/ true, noreg);
 9047     __ csetw($res$$Register, Assembler::EQ);
 9048   %}
 9049   ins_pipe(pipe_slow);
 9050 %}
 9051 
 9052 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9053   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9054   ins_cost(2 * VOLATILE_REF_COST);
 9055   effect(KILL cr);
 9056   format %{
 9057     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9058     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9059   %}
 9060   ins_encode %{
 9061     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9062                Assembler::word, /*acquire*/ false, /*release*/ true,
 9063                /*weak*/ true, noreg);
 9064     __ csetw($res$$Register, Assembler::EQ);
 9065   %}
 9066   ins_pipe(pipe_slow);
 9067 %}
 9068 
 9069 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9070   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9071   ins_cost(2 * VOLATILE_REF_COST);
 9072   effect(KILL cr);
 9073   format %{
 9074     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9075     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9076   %}
 9077   ins_encode %{
 9078     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9079                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9080                /*weak*/ true, noreg);
 9081     __ csetw($res$$Register, Assembler::EQ);
 9082   %}
 9083   ins_pipe(pipe_slow);
 9084 %}
 9085 
 9086 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9087   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9088   ins_cost(2 * VOLATILE_REF_COST);
 9089   effect(KILL cr);
 9090   format %{
 9091     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9092     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9093   %}
 9094   ins_encode %{
 9095     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9096                Assembler::word, /*acquire*/ false, /*release*/ true,
 9097                /*weak*/ true, noreg);
 9098     __ csetw($res$$Register, Assembler::EQ);
 9099   %}
 9100   ins_pipe(pipe_slow);
 9101 %}
 9102 
 9103 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9104   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9105   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9106   ins_cost(2 * VOLATILE_REF_COST);
 9107   effect(KILL cr);
 9108   format %{
 9109     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9110     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9111   %}
 9112   ins_encode %{
 9113     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9114                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9115                /*weak*/ true, noreg);
 9116     __ csetw($res$$Register, Assembler::EQ);
 9117   %}
 9118   ins_pipe(pipe_slow);
 9119 %}
 9120 
 9121 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9122   predicate(needs_acquiring_load_exclusive(n));
 9123   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9124   ins_cost(VOLATILE_REF_COST);
 9125   effect(KILL cr);
 9126   format %{
 9127     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9128     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9129   %}
 9130   ins_encode %{
 9131     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9132                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9133                /*weak*/ true, noreg);
 9134     __ csetw($res$$Register, Assembler::EQ);
 9135   %}
 9136   ins_pipe(pipe_slow);
 9137 %}
 9138 
 9139 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9140   predicate(needs_acquiring_load_exclusive(n));
 9141   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9142   ins_cost(VOLATILE_REF_COST);
 9143   effect(KILL cr);
 9144   format %{
 9145     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9146     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9147   %}
 9148   ins_encode %{
 9149     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9150                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9151                /*weak*/ true, noreg);
 9152     __ csetw($res$$Register, Assembler::EQ);
 9153   %}
 9154   ins_pipe(pipe_slow);
 9155 %}
 9156 
 9157 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9158   predicate(needs_acquiring_load_exclusive(n));
 9159   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9160   ins_cost(VOLATILE_REF_COST);
 9161   effect(KILL cr);
 9162   format %{
 9163     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9164     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9165   %}
 9166   ins_encode %{
 9167     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9168                Assembler::word, /*acquire*/ true, /*release*/ true,
 9169                /*weak*/ true, noreg);
 9170     __ csetw($res$$Register, Assembler::EQ);
 9171   %}
 9172   ins_pipe(pipe_slow);
 9173 %}
 9174 
 9175 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9176   predicate(needs_acquiring_load_exclusive(n));
 9177   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9178   ins_cost(VOLATILE_REF_COST);
 9179   effect(KILL cr);
 9180   format %{
 9181     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9182     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9183   %}
 9184   ins_encode %{
 9185     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9186                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9187                /*weak*/ true, noreg);
 9188     __ csetw($res$$Register, Assembler::EQ);
 9189   %}
 9190   ins_pipe(pipe_slow);
 9191 %}
 9192 
 9193 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9194   predicate(needs_acquiring_load_exclusive(n));
 9195   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9196   ins_cost(VOLATILE_REF_COST);
 9197   effect(KILL cr);
 9198   format %{
 9199     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9200     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9201   %}
 9202   ins_encode %{
 9203     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9204                Assembler::word, /*acquire*/ true, /*release*/ true,
 9205                /*weak*/ true, noreg);
 9206     __ csetw($res$$Register, Assembler::EQ);
 9207   %}
 9208   ins_pipe(pipe_slow);
 9209 %}
 9210 
 9211 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9212   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9213   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9214   ins_cost(VOLATILE_REF_COST);
 9215   effect(KILL cr);
 9216   format %{
 9217     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9218     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9219   %}
 9220   ins_encode %{
 9221     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9222                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9223                /*weak*/ true, noreg);
 9224     __ csetw($res$$Register, Assembler::EQ);
 9225   %}
 9226   ins_pipe(pipe_slow);
 9227 %}
 9228 
 9229 // END This section of the file is automatically generated. Do not edit --------------
 9230 // ---------------------------------------------------------------------
 9231 
 9232 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9233   match(Set prev (GetAndSetI mem newv));
 9234   ins_cost(2 * VOLATILE_REF_COST);
 9235   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9236   ins_encode %{
 9237     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9238   %}
 9239   ins_pipe(pipe_serial);
 9240 %}
 9241 
 9242 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9243   match(Set prev (GetAndSetL mem newv));
 9244   ins_cost(2 * VOLATILE_REF_COST);
 9245   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9246   ins_encode %{
 9247     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9248   %}
 9249   ins_pipe(pipe_serial);
 9250 %}
 9251 
 9252 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9253   match(Set prev (GetAndSetN mem newv));
 9254   ins_cost(2 * VOLATILE_REF_COST);
 9255   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9256   ins_encode %{
 9257     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9258   %}
 9259   ins_pipe(pipe_serial);
 9260 %}
 9261 
 9262 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9263   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9264   match(Set prev (GetAndSetP mem newv));
 9265   ins_cost(2 * VOLATILE_REF_COST);
 9266   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9267   ins_encode %{
 9268     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9269   %}
 9270   ins_pipe(pipe_serial);
 9271 %}
 9272 
 9273 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9274   predicate(needs_acquiring_load_exclusive(n));
 9275   match(Set prev (GetAndSetI mem newv));
 9276   ins_cost(VOLATILE_REF_COST);
 9277   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9278   ins_encode %{
 9279     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9280   %}
 9281   ins_pipe(pipe_serial);
 9282 %}
 9283 
 9284 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9285   predicate(needs_acquiring_load_exclusive(n));
 9286   match(Set prev (GetAndSetL mem newv));
 9287   ins_cost(VOLATILE_REF_COST);
 9288   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9289   ins_encode %{
 9290     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9291   %}
 9292   ins_pipe(pipe_serial);
 9293 %}
 9294 
 9295 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9296   predicate(needs_acquiring_load_exclusive(n));
 9297   match(Set prev (GetAndSetN mem newv));
 9298   ins_cost(VOLATILE_REF_COST);
 9299   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9300   ins_encode %{
 9301     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9302   %}
 9303   ins_pipe(pipe_serial);
 9304 %}
 9305 
 9306 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9307   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9308   match(Set prev (GetAndSetP mem newv));
 9309   ins_cost(VOLATILE_REF_COST);
 9310   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9311   ins_encode %{
 9312     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9313   %}
 9314   ins_pipe(pipe_serial);
 9315 %}
 9316 
 9317 
 9318 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9319   match(Set newval (GetAndAddL mem incr));
 9320   ins_cost(2 * VOLATILE_REF_COST + 1);
 9321   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9322   ins_encode %{
 9323     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9324   %}
 9325   ins_pipe(pipe_serial);
 9326 %}
 9327 
 9328 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9329   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9330   match(Set dummy (GetAndAddL mem incr));
 9331   ins_cost(2 * VOLATILE_REF_COST);
 9332   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9333   ins_encode %{
 9334     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9335   %}
 9336   ins_pipe(pipe_serial);
 9337 %}
 9338 
 9339 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9340   match(Set newval (GetAndAddL mem incr));
 9341   ins_cost(2 * VOLATILE_REF_COST + 1);
 9342   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9343   ins_encode %{
 9344     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9345   %}
 9346   ins_pipe(pipe_serial);
 9347 %}
 9348 
 9349 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9350   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9351   match(Set dummy (GetAndAddL mem incr));
 9352   ins_cost(2 * VOLATILE_REF_COST);
 9353   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9354   ins_encode %{
 9355     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9356   %}
 9357   ins_pipe(pipe_serial);
 9358 %}
 9359 
 9360 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9361   match(Set newval (GetAndAddI mem incr));
 9362   ins_cost(2 * VOLATILE_REF_COST + 1);
 9363   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9364   ins_encode %{
 9365     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9366   %}
 9367   ins_pipe(pipe_serial);
 9368 %}
 9369 
 9370 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9371   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9372   match(Set dummy (GetAndAddI mem incr));
 9373   ins_cost(2 * VOLATILE_REF_COST);
 9374   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9375   ins_encode %{
 9376     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9377   %}
 9378   ins_pipe(pipe_serial);
 9379 %}
 9380 
 9381 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9382   match(Set newval (GetAndAddI mem incr));
 9383   ins_cost(2 * VOLATILE_REF_COST + 1);
 9384   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9385   ins_encode %{
 9386     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9387   %}
 9388   ins_pipe(pipe_serial);
 9389 %}
 9390 
 9391 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9392   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9393   match(Set dummy (GetAndAddI mem incr));
 9394   ins_cost(2 * VOLATILE_REF_COST);
 9395   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9396   ins_encode %{
 9397     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9398   %}
 9399   ins_pipe(pipe_serial);
 9400 %}
 9401 
 9402 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9403   predicate(needs_acquiring_load_exclusive(n));
 9404   match(Set newval (GetAndAddL mem incr));
 9405   ins_cost(VOLATILE_REF_COST + 1);
 9406   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9407   ins_encode %{
 9408     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9409   %}
 9410   ins_pipe(pipe_serial);
 9411 %}
 9412 
 9413 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9414   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9415   match(Set dummy (GetAndAddL mem incr));
 9416   ins_cost(VOLATILE_REF_COST);
 9417   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9418   ins_encode %{
 9419     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9420   %}
 9421   ins_pipe(pipe_serial);
 9422 %}
 9423 
 9424 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9425   predicate(needs_acquiring_load_exclusive(n));
 9426   match(Set newval (GetAndAddL mem incr));
 9427   ins_cost(VOLATILE_REF_COST + 1);
 9428   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9429   ins_encode %{
 9430     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9431   %}
 9432   ins_pipe(pipe_serial);
 9433 %}
 9434 
 9435 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9436   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9437   match(Set dummy (GetAndAddL mem incr));
 9438   ins_cost(VOLATILE_REF_COST);
 9439   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9440   ins_encode %{
 9441     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9442   %}
 9443   ins_pipe(pipe_serial);
 9444 %}
 9445 
 9446 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9447   predicate(needs_acquiring_load_exclusive(n));
 9448   match(Set newval (GetAndAddI mem incr));
 9449   ins_cost(VOLATILE_REF_COST + 1);
 9450   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9451   ins_encode %{
 9452     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9453   %}
 9454   ins_pipe(pipe_serial);
 9455 %}
 9456 
 9457 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9458   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9459   match(Set dummy (GetAndAddI mem incr));
 9460   ins_cost(VOLATILE_REF_COST);
 9461   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9462   ins_encode %{
 9463     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9464   %}
 9465   ins_pipe(pipe_serial);
 9466 %}
 9467 
 9468 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9469   predicate(needs_acquiring_load_exclusive(n));
 9470   match(Set newval (GetAndAddI mem incr));
 9471   ins_cost(VOLATILE_REF_COST + 1);
 9472   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9473   ins_encode %{
 9474     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9475   %}
 9476   ins_pipe(pipe_serial);
 9477 %}
 9478 
 9479 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9480   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9481   match(Set dummy (GetAndAddI mem incr));
 9482   ins_cost(VOLATILE_REF_COST);
 9483   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9484   ins_encode %{
 9485     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9486   %}
 9487   ins_pipe(pipe_serial);
 9488 %}
 9489 
 9490 // Manifest a CmpL result in an integer register.
 9491 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9492 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9493 %{
 9494   match(Set dst (CmpL3 src1 src2));
 9495   effect(KILL flags);
 9496 
 9497   ins_cost(INSN_COST * 6);
 9498   format %{
 9499       &quot;cmp $src1, $src2&quot;
 9500       &quot;csetw $dst, ne&quot;
 9501       &quot;cnegw $dst, lt&quot;
 9502   %}
 9503   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9504   ins_encode %{
 9505     __ cmp($src1$$Register, $src2$$Register);
 9506     __ csetw($dst$$Register, Assembler::NE);
 9507     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9508   %}
 9509 
 9510   ins_pipe(pipe_class_default);
 9511 %}
 9512 
 9513 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9514 %{
 9515   match(Set dst (CmpL3 src1 src2));
 9516   effect(KILL flags);
 9517 
 9518   ins_cost(INSN_COST * 6);
 9519   format %{
 9520       &quot;cmp $src1, $src2&quot;
 9521       &quot;csetw $dst, ne&quot;
 9522       &quot;cnegw $dst, lt&quot;
 9523   %}
 9524   ins_encode %{
 9525     int32_t con = (int32_t)$src2$$constant;
 9526      if (con &lt; 0) {
 9527       __ adds(zr, $src1$$Register, -con);
 9528     } else {
 9529       __ subs(zr, $src1$$Register, con);
 9530     }
 9531     __ csetw($dst$$Register, Assembler::NE);
 9532     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9533   %}
 9534 
 9535   ins_pipe(pipe_class_default);
 9536 %}
 9537 
 9538 // ============================================================================
 9539 // Conditional Move Instructions
 9540 
 9541 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9542 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9543 // define an op class which merged both inputs and use it to type the
 9544 // argument to a single rule. unfortunatelyt his fails because the
 9545 // opclass does not live up to the COND_INTER interface of its
 9546 // component operands. When the generic code tries to negate the
 9547 // operand it ends up running the generci Machoper::negate method
 9548 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9549 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9550 
 9551 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9552   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9553 
 9554   ins_cost(INSN_COST * 2);
 9555   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9556 
 9557   ins_encode %{
 9558     __ cselw(as_Register($dst$$reg),
 9559              as_Register($src2$$reg),
 9560              as_Register($src1$$reg),
 9561              (Assembler::Condition)$cmp$$cmpcode);
 9562   %}
 9563 
 9564   ins_pipe(icond_reg_reg);
 9565 %}
 9566 
 9567 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9568   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9569 
 9570   ins_cost(INSN_COST * 2);
 9571   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9572 
 9573   ins_encode %{
 9574     __ cselw(as_Register($dst$$reg),
 9575              as_Register($src2$$reg),
 9576              as_Register($src1$$reg),
 9577              (Assembler::Condition)$cmp$$cmpcode);
 9578   %}
 9579 
 9580   ins_pipe(icond_reg_reg);
 9581 %}
 9582 
 9583 // special cases where one arg is zero
 9584 
 9585 // n.b. this is selected in preference to the rule above because it
 9586 // avoids loading constant 0 into a source register
 9587 
 9588 // TODO
 9589 // we ought only to be able to cull one of these variants as the ideal
 9590 // transforms ought always to order the zero consistently (to left/right?)
 9591 
 9592 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9593   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9594 
 9595   ins_cost(INSN_COST * 2);
 9596   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9597 
 9598   ins_encode %{
 9599     __ cselw(as_Register($dst$$reg),
 9600              as_Register($src$$reg),
 9601              zr,
 9602              (Assembler::Condition)$cmp$$cmpcode);
 9603   %}
 9604 
 9605   ins_pipe(icond_reg);
 9606 %}
 9607 
 9608 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9609   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9610 
 9611   ins_cost(INSN_COST * 2);
 9612   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9613 
 9614   ins_encode %{
 9615     __ cselw(as_Register($dst$$reg),
 9616              as_Register($src$$reg),
 9617              zr,
 9618              (Assembler::Condition)$cmp$$cmpcode);
 9619   %}
 9620 
 9621   ins_pipe(icond_reg);
 9622 %}
 9623 
 9624 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9625   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9626 
 9627   ins_cost(INSN_COST * 2);
 9628   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9629 
 9630   ins_encode %{
 9631     __ cselw(as_Register($dst$$reg),
 9632              zr,
 9633              as_Register($src$$reg),
 9634              (Assembler::Condition)$cmp$$cmpcode);
 9635   %}
 9636 
 9637   ins_pipe(icond_reg);
 9638 %}
 9639 
 9640 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9641   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9642 
 9643   ins_cost(INSN_COST * 2);
 9644   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9645 
 9646   ins_encode %{
 9647     __ cselw(as_Register($dst$$reg),
 9648              zr,
 9649              as_Register($src$$reg),
 9650              (Assembler::Condition)$cmp$$cmpcode);
 9651   %}
 9652 
 9653   ins_pipe(icond_reg);
 9654 %}
 9655 
 9656 // special case for creating a boolean 0 or 1
 9657 
 9658 // n.b. this is selected in preference to the rule above because it
 9659 // avoids loading constants 0 and 1 into a source register
 9660 
 9661 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9662   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9663 
 9664   ins_cost(INSN_COST * 2);
 9665   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9666 
 9667   ins_encode %{
 9668     // equivalently
 9669     // cset(as_Register($dst$$reg),
 9670     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9671     __ csincw(as_Register($dst$$reg),
 9672              zr,
 9673              zr,
 9674              (Assembler::Condition)$cmp$$cmpcode);
 9675   %}
 9676 
 9677   ins_pipe(icond_none);
 9678 %}
 9679 
 9680 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9681   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9682 
 9683   ins_cost(INSN_COST * 2);
 9684   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9685 
 9686   ins_encode %{
 9687     // equivalently
 9688     // cset(as_Register($dst$$reg),
 9689     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9690     __ csincw(as_Register($dst$$reg),
 9691              zr,
 9692              zr,
 9693              (Assembler::Condition)$cmp$$cmpcode);
 9694   %}
 9695 
 9696   ins_pipe(icond_none);
 9697 %}
 9698 
 9699 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9700   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9701 
 9702   ins_cost(INSN_COST * 2);
 9703   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9704 
 9705   ins_encode %{
 9706     __ csel(as_Register($dst$$reg),
 9707             as_Register($src2$$reg),
 9708             as_Register($src1$$reg),
 9709             (Assembler::Condition)$cmp$$cmpcode);
 9710   %}
 9711 
 9712   ins_pipe(icond_reg_reg);
 9713 %}
 9714 
 9715 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9716   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9717 
 9718   ins_cost(INSN_COST * 2);
 9719   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9720 
 9721   ins_encode %{
 9722     __ csel(as_Register($dst$$reg),
 9723             as_Register($src2$$reg),
 9724             as_Register($src1$$reg),
 9725             (Assembler::Condition)$cmp$$cmpcode);
 9726   %}
 9727 
 9728   ins_pipe(icond_reg_reg);
 9729 %}
 9730 
 9731 // special cases where one arg is zero
 9732 
 9733 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9734   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9735 
 9736   ins_cost(INSN_COST * 2);
 9737   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9738 
 9739   ins_encode %{
 9740     __ csel(as_Register($dst$$reg),
 9741             zr,
 9742             as_Register($src$$reg),
 9743             (Assembler::Condition)$cmp$$cmpcode);
 9744   %}
 9745 
 9746   ins_pipe(icond_reg);
 9747 %}
 9748 
 9749 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9750   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9751 
 9752   ins_cost(INSN_COST * 2);
 9753   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9754 
 9755   ins_encode %{
 9756     __ csel(as_Register($dst$$reg),
 9757             zr,
 9758             as_Register($src$$reg),
 9759             (Assembler::Condition)$cmp$$cmpcode);
 9760   %}
 9761 
 9762   ins_pipe(icond_reg);
 9763 %}
 9764 
 9765 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9766   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9767 
 9768   ins_cost(INSN_COST * 2);
 9769   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9770 
 9771   ins_encode %{
 9772     __ csel(as_Register($dst$$reg),
 9773             as_Register($src$$reg),
 9774             zr,
 9775             (Assembler::Condition)$cmp$$cmpcode);
 9776   %}
 9777 
 9778   ins_pipe(icond_reg);
 9779 %}
 9780 
 9781 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9782   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9783 
 9784   ins_cost(INSN_COST * 2);
 9785   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9786 
 9787   ins_encode %{
 9788     __ csel(as_Register($dst$$reg),
 9789             as_Register($src$$reg),
 9790             zr,
 9791             (Assembler::Condition)$cmp$$cmpcode);
 9792   %}
 9793 
 9794   ins_pipe(icond_reg);
 9795 %}
 9796 
 9797 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9798   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9799 
 9800   ins_cost(INSN_COST * 2);
 9801   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9802 
 9803   ins_encode %{
 9804     __ csel(as_Register($dst$$reg),
 9805             as_Register($src2$$reg),
 9806             as_Register($src1$$reg),
 9807             (Assembler::Condition)$cmp$$cmpcode);
 9808   %}
 9809 
 9810   ins_pipe(icond_reg_reg);
 9811 %}
 9812 
 9813 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9814   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9815 
 9816   ins_cost(INSN_COST * 2);
 9817   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9818 
 9819   ins_encode %{
 9820     __ csel(as_Register($dst$$reg),
 9821             as_Register($src2$$reg),
 9822             as_Register($src1$$reg),
 9823             (Assembler::Condition)$cmp$$cmpcode);
 9824   %}
 9825 
 9826   ins_pipe(icond_reg_reg);
 9827 %}
 9828 
 9829 // special cases where one arg is zero
 9830 
 9831 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9832   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9833 
 9834   ins_cost(INSN_COST * 2);
 9835   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9836 
 9837   ins_encode %{
 9838     __ csel(as_Register($dst$$reg),
 9839             zr,
 9840             as_Register($src$$reg),
 9841             (Assembler::Condition)$cmp$$cmpcode);
 9842   %}
 9843 
 9844   ins_pipe(icond_reg);
 9845 %}
 9846 
 9847 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9848   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9849 
 9850   ins_cost(INSN_COST * 2);
 9851   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9852 
 9853   ins_encode %{
 9854     __ csel(as_Register($dst$$reg),
 9855             zr,
 9856             as_Register($src$$reg),
 9857             (Assembler::Condition)$cmp$$cmpcode);
 9858   %}
 9859 
 9860   ins_pipe(icond_reg);
 9861 %}
 9862 
 9863 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9864   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9865 
 9866   ins_cost(INSN_COST * 2);
 9867   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9868 
 9869   ins_encode %{
 9870     __ csel(as_Register($dst$$reg),
 9871             as_Register($src$$reg),
 9872             zr,
 9873             (Assembler::Condition)$cmp$$cmpcode);
 9874   %}
 9875 
 9876   ins_pipe(icond_reg);
 9877 %}
 9878 
 9879 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9880   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9881 
 9882   ins_cost(INSN_COST * 2);
 9883   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9884 
 9885   ins_encode %{
 9886     __ csel(as_Register($dst$$reg),
 9887             as_Register($src$$reg),
 9888             zr,
 9889             (Assembler::Condition)$cmp$$cmpcode);
 9890   %}
 9891 
 9892   ins_pipe(icond_reg);
 9893 %}
 9894 
 9895 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9896   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9897 
 9898   ins_cost(INSN_COST * 2);
 9899   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9900 
 9901   ins_encode %{
 9902     __ cselw(as_Register($dst$$reg),
 9903              as_Register($src2$$reg),
 9904              as_Register($src1$$reg),
 9905              (Assembler::Condition)$cmp$$cmpcode);
 9906   %}
 9907 
 9908   ins_pipe(icond_reg_reg);
 9909 %}
 9910 
 9911 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9912   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9913 
 9914   ins_cost(INSN_COST * 2);
 9915   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9916 
 9917   ins_encode %{
 9918     __ cselw(as_Register($dst$$reg),
 9919              as_Register($src2$$reg),
 9920              as_Register($src1$$reg),
 9921              (Assembler::Condition)$cmp$$cmpcode);
 9922   %}
 9923 
 9924   ins_pipe(icond_reg_reg);
 9925 %}
 9926 
 9927 // special cases where one arg is zero
 9928 
 9929 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9930   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9931 
 9932   ins_cost(INSN_COST * 2);
 9933   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9934 
 9935   ins_encode %{
 9936     __ cselw(as_Register($dst$$reg),
 9937              zr,
 9938              as_Register($src$$reg),
 9939              (Assembler::Condition)$cmp$$cmpcode);
 9940   %}
 9941 
 9942   ins_pipe(icond_reg);
 9943 %}
 9944 
 9945 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9946   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9947 
 9948   ins_cost(INSN_COST * 2);
 9949   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9950 
 9951   ins_encode %{
 9952     __ cselw(as_Register($dst$$reg),
 9953              zr,
 9954              as_Register($src$$reg),
 9955              (Assembler::Condition)$cmp$$cmpcode);
 9956   %}
 9957 
 9958   ins_pipe(icond_reg);
 9959 %}
 9960 
 9961 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9962   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9963 
 9964   ins_cost(INSN_COST * 2);
 9965   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
 9966 
 9967   ins_encode %{
 9968     __ cselw(as_Register($dst$$reg),
 9969              as_Register($src$$reg),
 9970              zr,
 9971              (Assembler::Condition)$cmp$$cmpcode);
 9972   %}
 9973 
 9974   ins_pipe(icond_reg);
 9975 %}
 9976 
 9977 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
 9978   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
 9979 
 9980   ins_cost(INSN_COST * 2);
 9981   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
 9982 
 9983   ins_encode %{
 9984     __ cselw(as_Register($dst$$reg),
 9985              as_Register($src$$reg),
 9986              zr,
 9987              (Assembler::Condition)$cmp$$cmpcode);
 9988   %}
 9989 
 9990   ins_pipe(icond_reg);
 9991 %}
 9992 
 9993 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
 9994 %{
 9995   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
 9996 
 9997   ins_cost(INSN_COST * 3);
 9998 
 9999   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10000   ins_encode %{
10001     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10002     __ fcsels(as_FloatRegister($dst$$reg),
10003               as_FloatRegister($src2$$reg),
10004               as_FloatRegister($src1$$reg),
10005               cond);
10006   %}
10007 
10008   ins_pipe(fp_cond_reg_reg_s);
10009 %}
10010 
10011 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10012 %{
10013   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10014 
10015   ins_cost(INSN_COST * 3);
10016 
10017   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10018   ins_encode %{
10019     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10020     __ fcsels(as_FloatRegister($dst$$reg),
10021               as_FloatRegister($src2$$reg),
10022               as_FloatRegister($src1$$reg),
10023               cond);
10024   %}
10025 
10026   ins_pipe(fp_cond_reg_reg_s);
10027 %}
10028 
10029 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10030 %{
10031   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10032 
10033   ins_cost(INSN_COST * 3);
10034 
10035   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10036   ins_encode %{
10037     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10038     __ fcseld(as_FloatRegister($dst$$reg),
10039               as_FloatRegister($src2$$reg),
10040               as_FloatRegister($src1$$reg),
10041               cond);
10042   %}
10043 
10044   ins_pipe(fp_cond_reg_reg_d);
10045 %}
10046 
10047 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10048 %{
10049   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10050 
10051   ins_cost(INSN_COST * 3);
10052 
10053   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10054   ins_encode %{
10055     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10056     __ fcseld(as_FloatRegister($dst$$reg),
10057               as_FloatRegister($src2$$reg),
10058               as_FloatRegister($src1$$reg),
10059               cond);
10060   %}
10061 
10062   ins_pipe(fp_cond_reg_reg_d);
10063 %}
10064 
10065 // ============================================================================
10066 // Arithmetic Instructions
10067 //
10068 
10069 // Integer Addition
10070 
10071 // TODO
10072 // these currently employ operations which do not set CR and hence are
10073 // not flagged as killing CR but we would like to isolate the cases
10074 // where we want to set flags from those where we don&#39;t. need to work
10075 // out how to do that.
10076 
10077 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10078   match(Set dst (AddI src1 src2));
10079 
10080   ins_cost(INSN_COST);
10081   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10082 
10083   ins_encode %{
10084     __ addw(as_Register($dst$$reg),
10085             as_Register($src1$$reg),
10086             as_Register($src2$$reg));
10087   %}
10088 
10089   ins_pipe(ialu_reg_reg);
10090 %}
10091 
10092 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10093   match(Set dst (AddI src1 src2));
10094 
10095   ins_cost(INSN_COST);
10096   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10097 
10098   // use opcode to indicate that this is an add not a sub
10099   opcode(0x0);
10100 
10101   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10102 
10103   ins_pipe(ialu_reg_imm);
10104 %}
10105 
10106 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10107   match(Set dst (AddI (ConvL2I src1) src2));
10108 
10109   ins_cost(INSN_COST);
10110   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10111 
10112   // use opcode to indicate that this is an add not a sub
10113   opcode(0x0);
10114 
10115   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10116 
10117   ins_pipe(ialu_reg_imm);
10118 %}
10119 
10120 // Pointer Addition
10121 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10122   match(Set dst (AddP src1 src2));
10123 
10124   ins_cost(INSN_COST);
10125   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10126 
10127   ins_encode %{
10128     __ add(as_Register($dst$$reg),
10129            as_Register($src1$$reg),
10130            as_Register($src2$$reg));
10131   %}
10132 
10133   ins_pipe(ialu_reg_reg);
10134 %}
10135 
10136 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10137   match(Set dst (AddP src1 (ConvI2L src2)));
10138 
10139   ins_cost(1.9 * INSN_COST);
10140   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10141 
10142   ins_encode %{
10143     __ add(as_Register($dst$$reg),
10144            as_Register($src1$$reg),
10145            as_Register($src2$$reg), ext::sxtw);
10146   %}
10147 
10148   ins_pipe(ialu_reg_reg);
10149 %}
10150 
10151 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10152   match(Set dst (AddP src1 (LShiftL src2 scale)));
10153 
10154   ins_cost(1.9 * INSN_COST);
10155   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10156 
10157   ins_encode %{
10158     __ lea(as_Register($dst$$reg),
10159            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10160                    Address::lsl($scale$$constant)));
10161   %}
10162 
10163   ins_pipe(ialu_reg_reg_shift);
10164 %}
10165 
10166 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10167   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10168 
10169   ins_cost(1.9 * INSN_COST);
10170   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10171 
10172   ins_encode %{
10173     __ lea(as_Register($dst$$reg),
10174            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10175                    Address::sxtw($scale$$constant)));
10176   %}
10177 
10178   ins_pipe(ialu_reg_reg_shift);
10179 %}
10180 
10181 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10182   match(Set dst (LShiftL (ConvI2L src) scale));
10183 
10184   ins_cost(INSN_COST);
10185   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10186 
10187   ins_encode %{
10188     __ sbfiz(as_Register($dst$$reg),
10189           as_Register($src$$reg),
10190           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10191   %}
10192 
10193   ins_pipe(ialu_reg_shift);
10194 %}
10195 
10196 // Pointer Immediate Addition
10197 // n.b. this needs to be more expensive than using an indirect memory
10198 // operand
10199 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10200   match(Set dst (AddP src1 src2));
10201 
10202   ins_cost(INSN_COST);
10203   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10204 
10205   // use opcode to indicate that this is an add not a sub
10206   opcode(0x0);
10207 
10208   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10209 
10210   ins_pipe(ialu_reg_imm);
10211 %}
10212 
10213 // Long Addition
10214 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10215 
10216   match(Set dst (AddL src1 src2));
10217 
10218   ins_cost(INSN_COST);
10219   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10220 
10221   ins_encode %{
10222     __ add(as_Register($dst$$reg),
10223            as_Register($src1$$reg),
10224            as_Register($src2$$reg));
10225   %}
10226 
10227   ins_pipe(ialu_reg_reg);
10228 %}
10229 
10230 // No constant pool entries requiredLong Immediate Addition.
10231 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10232   match(Set dst (AddL src1 src2));
10233 
10234   ins_cost(INSN_COST);
10235   format %{ &quot;add $dst, $src1, $src2&quot; %}
10236 
10237   // use opcode to indicate that this is an add not a sub
10238   opcode(0x0);
10239 
10240   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10241 
10242   ins_pipe(ialu_reg_imm);
10243 %}
10244 
10245 // Integer Subtraction
10246 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10247   match(Set dst (SubI src1 src2));
10248 
10249   ins_cost(INSN_COST);
10250   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10251 
10252   ins_encode %{
10253     __ subw(as_Register($dst$$reg),
10254             as_Register($src1$$reg),
10255             as_Register($src2$$reg));
10256   %}
10257 
10258   ins_pipe(ialu_reg_reg);
10259 %}
10260 
10261 // Immediate Subtraction
10262 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10263   match(Set dst (SubI src1 src2));
10264 
10265   ins_cost(INSN_COST);
10266   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10267 
10268   // use opcode to indicate that this is a sub not an add
10269   opcode(0x1);
10270 
10271   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10272 
10273   ins_pipe(ialu_reg_imm);
10274 %}
10275 
10276 // Long Subtraction
10277 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10278 
10279   match(Set dst (SubL src1 src2));
10280 
10281   ins_cost(INSN_COST);
10282   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10283 
10284   ins_encode %{
10285     __ sub(as_Register($dst$$reg),
10286            as_Register($src1$$reg),
10287            as_Register($src2$$reg));
10288   %}
10289 
10290   ins_pipe(ialu_reg_reg);
10291 %}
10292 
10293 // No constant pool entries requiredLong Immediate Subtraction.
10294 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10295   match(Set dst (SubL src1 src2));
10296 
10297   ins_cost(INSN_COST);
10298   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10299 
10300   // use opcode to indicate that this is a sub not an add
10301   opcode(0x1);
10302 
10303   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10304 
10305   ins_pipe(ialu_reg_imm);
10306 %}
10307 
10308 // Integer Negation (special case for sub)
10309 
10310 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10311   match(Set dst (SubI zero src));
10312 
10313   ins_cost(INSN_COST);
10314   format %{ &quot;negw $dst, $src\t# int&quot; %}
10315 
10316   ins_encode %{
10317     __ negw(as_Register($dst$$reg),
10318             as_Register($src$$reg));
10319   %}
10320 
10321   ins_pipe(ialu_reg);
10322 %}
10323 
10324 // Long Negation
10325 
10326 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10327   match(Set dst (SubL zero src));
10328 
10329   ins_cost(INSN_COST);
10330   format %{ &quot;neg $dst, $src\t# long&quot; %}
10331 
10332   ins_encode %{
10333     __ neg(as_Register($dst$$reg),
10334            as_Register($src$$reg));
10335   %}
10336 
10337   ins_pipe(ialu_reg);
10338 %}
10339 
10340 // Integer Multiply
10341 
10342 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10343   match(Set dst (MulI src1 src2));
10344 
10345   ins_cost(INSN_COST * 3);
10346   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10347 
10348   ins_encode %{
10349     __ mulw(as_Register($dst$$reg),
10350             as_Register($src1$$reg),
10351             as_Register($src2$$reg));
10352   %}
10353 
10354   ins_pipe(imul_reg_reg);
10355 %}
10356 
10357 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10358   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10359 
10360   ins_cost(INSN_COST * 3);
10361   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10362 
10363   ins_encode %{
10364     __ smull(as_Register($dst$$reg),
10365              as_Register($src1$$reg),
10366              as_Register($src2$$reg));
10367   %}
10368 
10369   ins_pipe(imul_reg_reg);
10370 %}
10371 
10372 // Long Multiply
10373 
10374 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10375   match(Set dst (MulL src1 src2));
10376 
10377   ins_cost(INSN_COST * 5);
10378   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10379 
10380   ins_encode %{
10381     __ mul(as_Register($dst$$reg),
10382            as_Register($src1$$reg),
10383            as_Register($src2$$reg));
10384   %}
10385 
10386   ins_pipe(lmul_reg_reg);
10387 %}
10388 
10389 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10390 %{
10391   match(Set dst (MulHiL src1 src2));
10392 
10393   ins_cost(INSN_COST * 7);
10394   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10395 
10396   ins_encode %{
10397     __ smulh(as_Register($dst$$reg),
10398              as_Register($src1$$reg),
10399              as_Register($src2$$reg));
10400   %}
10401 
10402   ins_pipe(lmul_reg_reg);
10403 %}
10404 
10405 // Combined Integer Multiply &amp; Add/Sub
10406 
10407 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10408   match(Set dst (AddI src3 (MulI src1 src2)));
10409 
10410   ins_cost(INSN_COST * 3);
10411   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10412 
10413   ins_encode %{
10414     __ maddw(as_Register($dst$$reg),
10415              as_Register($src1$$reg),
10416              as_Register($src2$$reg),
10417              as_Register($src3$$reg));
10418   %}
10419 
10420   ins_pipe(imac_reg_reg);
10421 %}
10422 
10423 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10424   match(Set dst (SubI src3 (MulI src1 src2)));
10425 
10426   ins_cost(INSN_COST * 3);
10427   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10428 
10429   ins_encode %{
10430     __ msubw(as_Register($dst$$reg),
10431              as_Register($src1$$reg),
10432              as_Register($src2$$reg),
10433              as_Register($src3$$reg));
10434   %}
10435 
10436   ins_pipe(imac_reg_reg);
10437 %}
10438 
10439 // Combined Integer Multiply &amp; Neg
10440 
10441 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10442   match(Set dst (MulI (SubI zero src1) src2));
10443   match(Set dst (MulI src1 (SubI zero src2)));
10444 
10445   ins_cost(INSN_COST * 3);
10446   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10447 
10448   ins_encode %{
10449     __ mnegw(as_Register($dst$$reg),
10450              as_Register($src1$$reg),
10451              as_Register($src2$$reg));
10452   %}
10453 
10454   ins_pipe(imac_reg_reg);
10455 %}
10456 
10457 // Combined Long Multiply &amp; Add/Sub
10458 
10459 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10460   match(Set dst (AddL src3 (MulL src1 src2)));
10461 
10462   ins_cost(INSN_COST * 5);
10463   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10464 
10465   ins_encode %{
10466     __ madd(as_Register($dst$$reg),
10467             as_Register($src1$$reg),
10468             as_Register($src2$$reg),
10469             as_Register($src3$$reg));
10470   %}
10471 
10472   ins_pipe(lmac_reg_reg);
10473 %}
10474 
10475 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10476   match(Set dst (SubL src3 (MulL src1 src2)));
10477 
10478   ins_cost(INSN_COST * 5);
10479   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10480 
10481   ins_encode %{
10482     __ msub(as_Register($dst$$reg),
10483             as_Register($src1$$reg),
10484             as_Register($src2$$reg),
10485             as_Register($src3$$reg));
10486   %}
10487 
10488   ins_pipe(lmac_reg_reg);
10489 %}
10490 
10491 // Combined Long Multiply &amp; Neg
10492 
10493 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10494   match(Set dst (MulL (SubL zero src1) src2));
10495   match(Set dst (MulL src1 (SubL zero src2)));
10496 
10497   ins_cost(INSN_COST * 5);
10498   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10499 
10500   ins_encode %{
10501     __ mneg(as_Register($dst$$reg),
10502             as_Register($src1$$reg),
10503             as_Register($src2$$reg));
10504   %}
10505 
10506   ins_pipe(lmac_reg_reg);
10507 %}
10508 
10509 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10510 
10511 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10512   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10513 
10514   ins_cost(INSN_COST * 3);
10515   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10516 
10517   ins_encode %{
10518     __ smaddl(as_Register($dst$$reg),
10519               as_Register($src1$$reg),
10520               as_Register($src2$$reg),
10521               as_Register($src3$$reg));
10522   %}
10523 
10524   ins_pipe(imac_reg_reg);
10525 %}
10526 
10527 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10528   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10529 
10530   ins_cost(INSN_COST * 3);
10531   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10532 
10533   ins_encode %{
10534     __ smsubl(as_Register($dst$$reg),
10535               as_Register($src1$$reg),
10536               as_Register($src2$$reg),
10537               as_Register($src3$$reg));
10538   %}
10539 
10540   ins_pipe(imac_reg_reg);
10541 %}
10542 
10543 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10544   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10545   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10546 
10547   ins_cost(INSN_COST * 3);
10548   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10549 
10550   ins_encode %{
10551     __ smnegl(as_Register($dst$$reg),
10552               as_Register($src1$$reg),
10553               as_Register($src2$$reg));
10554   %}
10555 
10556   ins_pipe(imac_reg_reg);
10557 %}
10558 
10559 // Integer Divide
10560 
10561 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10562   match(Set dst (DivI src1 src2));
10563 
10564   ins_cost(INSN_COST * 19);
10565   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10566 
10567   ins_encode(aarch64_enc_divw(dst, src1, src2));
10568   ins_pipe(idiv_reg_reg);
10569 %}
10570 
10571 instruct signExtract(iRegINoSp dst, iRegIorL2I src1, immI_31 div1, immI_31 div2) %{
10572   match(Set dst (URShiftI (RShiftI src1 div1) div2));
10573   ins_cost(INSN_COST);
10574   format %{ &quot;lsrw $dst, $src1, $div1&quot; %}
10575   ins_encode %{
10576     __ lsrw(as_Register($dst$$reg), as_Register($src1$$reg), 31);
10577   %}
10578   ins_pipe(ialu_reg_shift);
10579 %}
10580 
10581 instruct div2Round(iRegINoSp dst, iRegIorL2I src, immI_31 div1, immI_31 div2) %{
10582   match(Set dst (AddI src (URShiftI (RShiftI src div1) div2)));
10583   ins_cost(INSN_COST);
10584   format %{ &quot;addw $dst, $src, LSR $div1&quot; %}
10585 
10586   ins_encode %{
10587     __ addw(as_Register($dst$$reg),
10588               as_Register($src$$reg),
10589               as_Register($src$$reg),
10590               Assembler::LSR, 31);
10591   %}
10592   ins_pipe(ialu_reg);
10593 %}
10594 
10595 // Long Divide
10596 
10597 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10598   match(Set dst (DivL src1 src2));
10599 
10600   ins_cost(INSN_COST * 35);
10601   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10602 
10603   ins_encode(aarch64_enc_div(dst, src1, src2));
10604   ins_pipe(ldiv_reg_reg);
10605 %}
10606 
10607 instruct signExtractL(iRegLNoSp dst, iRegL src1, immI_63 div1, immI_63 div2) %{
10608   match(Set dst (URShiftL (RShiftL src1 div1) div2));
10609   ins_cost(INSN_COST);
10610   format %{ &quot;lsr $dst, $src1, $div1&quot; %}
10611   ins_encode %{
10612     __ lsr(as_Register($dst$$reg), as_Register($src1$$reg), 63);
10613   %}
10614   ins_pipe(ialu_reg_shift);
10615 %}
10616 
10617 instruct div2RoundL(iRegLNoSp dst, iRegL src, immI_63 div1, immI_63 div2) %{
10618   match(Set dst (AddL src (URShiftL (RShiftL src div1) div2)));
10619   ins_cost(INSN_COST);
10620   format %{ &quot;add $dst, $src, $div1&quot; %}
10621 
10622   ins_encode %{
10623     __ add(as_Register($dst$$reg),
10624               as_Register($src$$reg),
10625               as_Register($src$$reg),
10626               Assembler::LSR, 63);
10627   %}
10628   ins_pipe(ialu_reg);
10629 %}
10630 
10631 // Integer Remainder
10632 
10633 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10634   match(Set dst (ModI src1 src2));
10635 
10636   ins_cost(INSN_COST * 22);
10637   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10638             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10639 
10640   ins_encode(aarch64_enc_modw(dst, src1, src2));
10641   ins_pipe(idiv_reg_reg);
10642 %}
10643 
10644 // Long Remainder
10645 
10646 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10647   match(Set dst (ModL src1 src2));
10648 
10649   ins_cost(INSN_COST * 38);
10650   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10651             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10652 
10653   ins_encode(aarch64_enc_mod(dst, src1, src2));
10654   ins_pipe(ldiv_reg_reg);
10655 %}
10656 
10657 // Integer Shifts
10658 
10659 // Shift Left Register
10660 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10661   match(Set dst (LShiftI src1 src2));
10662 
10663   ins_cost(INSN_COST * 2);
10664   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10665 
10666   ins_encode %{
10667     __ lslvw(as_Register($dst$$reg),
10668              as_Register($src1$$reg),
10669              as_Register($src2$$reg));
10670   %}
10671 
10672   ins_pipe(ialu_reg_reg_vshift);
10673 %}
10674 
10675 // Shift Left Immediate
10676 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10677   match(Set dst (LShiftI src1 src2));
10678 
10679   ins_cost(INSN_COST);
10680   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10681 
10682   ins_encode %{
10683     __ lslw(as_Register($dst$$reg),
10684             as_Register($src1$$reg),
10685             $src2$$constant &amp; 0x1f);
10686   %}
10687 
10688   ins_pipe(ialu_reg_shift);
10689 %}
10690 
10691 // Shift Right Logical Register
10692 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10693   match(Set dst (URShiftI src1 src2));
10694 
10695   ins_cost(INSN_COST * 2);
10696   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10697 
10698   ins_encode %{
10699     __ lsrvw(as_Register($dst$$reg),
10700              as_Register($src1$$reg),
10701              as_Register($src2$$reg));
10702   %}
10703 
10704   ins_pipe(ialu_reg_reg_vshift);
10705 %}
10706 
10707 // Shift Right Logical Immediate
10708 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10709   match(Set dst (URShiftI src1 src2));
10710 
10711   ins_cost(INSN_COST);
10712   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10713 
10714   ins_encode %{
10715     __ lsrw(as_Register($dst$$reg),
10716             as_Register($src1$$reg),
10717             $src2$$constant &amp; 0x1f);
10718   %}
10719 
10720   ins_pipe(ialu_reg_shift);
10721 %}
10722 
10723 // Shift Right Arithmetic Register
10724 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10725   match(Set dst (RShiftI src1 src2));
10726 
10727   ins_cost(INSN_COST * 2);
10728   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10729 
10730   ins_encode %{
10731     __ asrvw(as_Register($dst$$reg),
10732              as_Register($src1$$reg),
10733              as_Register($src2$$reg));
10734   %}
10735 
10736   ins_pipe(ialu_reg_reg_vshift);
10737 %}
10738 
10739 // Shift Right Arithmetic Immediate
10740 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10741   match(Set dst (RShiftI src1 src2));
10742 
10743   ins_cost(INSN_COST);
10744   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10745 
10746   ins_encode %{
10747     __ asrw(as_Register($dst$$reg),
10748             as_Register($src1$$reg),
10749             $src2$$constant &amp; 0x1f);
10750   %}
10751 
10752   ins_pipe(ialu_reg_shift);
10753 %}
10754 
10755 // Combined Int Mask and Right Shift (using UBFM)
10756 // TODO
10757 
10758 // Long Shifts
10759 
10760 // Shift Left Register
10761 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10762   match(Set dst (LShiftL src1 src2));
10763 
10764   ins_cost(INSN_COST * 2);
10765   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10766 
10767   ins_encode %{
10768     __ lslv(as_Register($dst$$reg),
10769             as_Register($src1$$reg),
10770             as_Register($src2$$reg));
10771   %}
10772 
10773   ins_pipe(ialu_reg_reg_vshift);
10774 %}
10775 
10776 // Shift Left Immediate
10777 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10778   match(Set dst (LShiftL src1 src2));
10779 
10780   ins_cost(INSN_COST);
10781   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10782 
10783   ins_encode %{
10784     __ lsl(as_Register($dst$$reg),
10785             as_Register($src1$$reg),
10786             $src2$$constant &amp; 0x3f);
10787   %}
10788 
10789   ins_pipe(ialu_reg_shift);
10790 %}
10791 
10792 // Shift Right Logical Register
10793 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10794   match(Set dst (URShiftL src1 src2));
10795 
10796   ins_cost(INSN_COST * 2);
10797   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10798 
10799   ins_encode %{
10800     __ lsrv(as_Register($dst$$reg),
10801             as_Register($src1$$reg),
10802             as_Register($src2$$reg));
10803   %}
10804 
10805   ins_pipe(ialu_reg_reg_vshift);
10806 %}
10807 
10808 // Shift Right Logical Immediate
10809 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10810   match(Set dst (URShiftL src1 src2));
10811 
10812   ins_cost(INSN_COST);
10813   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10814 
10815   ins_encode %{
10816     __ lsr(as_Register($dst$$reg),
10817            as_Register($src1$$reg),
10818            $src2$$constant &amp; 0x3f);
10819   %}
10820 
10821   ins_pipe(ialu_reg_shift);
10822 %}
10823 
10824 // A special-case pattern for card table stores.
10825 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10826   match(Set dst (URShiftL (CastP2X src1) src2));
10827 
10828   ins_cost(INSN_COST);
10829   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10830 
10831   ins_encode %{
10832     __ lsr(as_Register($dst$$reg),
10833            as_Register($src1$$reg),
10834            $src2$$constant &amp; 0x3f);
10835   %}
10836 
10837   ins_pipe(ialu_reg_shift);
10838 %}
10839 
10840 // Shift Right Arithmetic Register
10841 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10842   match(Set dst (RShiftL src1 src2));
10843 
10844   ins_cost(INSN_COST * 2);
10845   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10846 
10847   ins_encode %{
10848     __ asrv(as_Register($dst$$reg),
10849             as_Register($src1$$reg),
10850             as_Register($src2$$reg));
10851   %}
10852 
10853   ins_pipe(ialu_reg_reg_vshift);
10854 %}
10855 
10856 // Shift Right Arithmetic Immediate
10857 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10858   match(Set dst (RShiftL src1 src2));
10859 
10860   ins_cost(INSN_COST);
10861   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10862 
10863   ins_encode %{
10864     __ asr(as_Register($dst$$reg),
10865            as_Register($src1$$reg),
10866            $src2$$constant &amp; 0x3f);
10867   %}
10868 
10869   ins_pipe(ialu_reg_shift);
10870 %}
10871 
10872 // BEGIN This section of the file is automatically generated. Do not edit --------------
10873 
10874 instruct regL_not_reg(iRegLNoSp dst,
10875                          iRegL src1, immL_M1 m1,
10876                          rFlagsReg cr) %{
10877   match(Set dst (XorL src1 m1));
10878   ins_cost(INSN_COST);
10879   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10880 
10881   ins_encode %{
10882     __ eon(as_Register($dst$$reg),
10883               as_Register($src1$$reg),
10884               zr,
10885               Assembler::LSL, 0);
10886   %}
10887 
10888   ins_pipe(ialu_reg);
10889 %}
10890 instruct regI_not_reg(iRegINoSp dst,
10891                          iRegIorL2I src1, immI_M1 m1,
10892                          rFlagsReg cr) %{
10893   match(Set dst (XorI src1 m1));
10894   ins_cost(INSN_COST);
10895   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10896 
10897   ins_encode %{
10898     __ eonw(as_Register($dst$$reg),
10899               as_Register($src1$$reg),
10900               zr,
10901               Assembler::LSL, 0);
10902   %}
10903 
10904   ins_pipe(ialu_reg);
10905 %}
10906 
10907 instruct AndI_reg_not_reg(iRegINoSp dst,
10908                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10909                          rFlagsReg cr) %{
10910   match(Set dst (AndI src1 (XorI src2 m1)));
10911   ins_cost(INSN_COST);
10912   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10913 
10914   ins_encode %{
10915     __ bicw(as_Register($dst$$reg),
10916               as_Register($src1$$reg),
10917               as_Register($src2$$reg),
10918               Assembler::LSL, 0);
10919   %}
10920 
10921   ins_pipe(ialu_reg_reg);
10922 %}
10923 
10924 instruct AndL_reg_not_reg(iRegLNoSp dst,
10925                          iRegL src1, iRegL src2, immL_M1 m1,
10926                          rFlagsReg cr) %{
10927   match(Set dst (AndL src1 (XorL src2 m1)));
10928   ins_cost(INSN_COST);
10929   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10930 
10931   ins_encode %{
10932     __ bic(as_Register($dst$$reg),
10933               as_Register($src1$$reg),
10934               as_Register($src2$$reg),
10935               Assembler::LSL, 0);
10936   %}
10937 
10938   ins_pipe(ialu_reg_reg);
10939 %}
10940 
10941 instruct OrI_reg_not_reg(iRegINoSp dst,
10942                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10943                          rFlagsReg cr) %{
10944   match(Set dst (OrI src1 (XorI src2 m1)));
10945   ins_cost(INSN_COST);
10946   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10947 
10948   ins_encode %{
10949     __ ornw(as_Register($dst$$reg),
10950               as_Register($src1$$reg),
10951               as_Register($src2$$reg),
10952               Assembler::LSL, 0);
10953   %}
10954 
10955   ins_pipe(ialu_reg_reg);
10956 %}
10957 
10958 instruct OrL_reg_not_reg(iRegLNoSp dst,
10959                          iRegL src1, iRegL src2, immL_M1 m1,
10960                          rFlagsReg cr) %{
10961   match(Set dst (OrL src1 (XorL src2 m1)));
10962   ins_cost(INSN_COST);
10963   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10964 
10965   ins_encode %{
10966     __ orn(as_Register($dst$$reg),
10967               as_Register($src1$$reg),
10968               as_Register($src2$$reg),
10969               Assembler::LSL, 0);
10970   %}
10971 
10972   ins_pipe(ialu_reg_reg);
10973 %}
10974 
10975 instruct XorI_reg_not_reg(iRegINoSp dst,
10976                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10977                          rFlagsReg cr) %{
10978   match(Set dst (XorI m1 (XorI src2 src1)));
10979   ins_cost(INSN_COST);
10980   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10981 
10982   ins_encode %{
10983     __ eonw(as_Register($dst$$reg),
10984               as_Register($src1$$reg),
10985               as_Register($src2$$reg),
10986               Assembler::LSL, 0);
10987   %}
10988 
10989   ins_pipe(ialu_reg_reg);
10990 %}
10991 
10992 instruct XorL_reg_not_reg(iRegLNoSp dst,
10993                          iRegL src1, iRegL src2, immL_M1 m1,
10994                          rFlagsReg cr) %{
10995   match(Set dst (XorL m1 (XorL src2 src1)));
10996   ins_cost(INSN_COST);
10997   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
10998 
10999   ins_encode %{
11000     __ eon(as_Register($dst$$reg),
11001               as_Register($src1$$reg),
11002               as_Register($src2$$reg),
11003               Assembler::LSL, 0);
11004   %}
11005 
11006   ins_pipe(ialu_reg_reg);
11007 %}
11008 
11009 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11010                          iRegIorL2I src1, iRegIorL2I src2,
11011                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11012   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11013   ins_cost(1.9 * INSN_COST);
11014   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11015 
11016   ins_encode %{
11017     __ bicw(as_Register($dst$$reg),
11018               as_Register($src1$$reg),
11019               as_Register($src2$$reg),
11020               Assembler::LSR,
11021               $src3$$constant &amp; 0x1f);
11022   %}
11023 
11024   ins_pipe(ialu_reg_reg_shift);
11025 %}
11026 
11027 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11028                          iRegL src1, iRegL src2,
11029                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11030   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11031   ins_cost(1.9 * INSN_COST);
11032   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11033 
11034   ins_encode %{
11035     __ bic(as_Register($dst$$reg),
11036               as_Register($src1$$reg),
11037               as_Register($src2$$reg),
11038               Assembler::LSR,
11039               $src3$$constant &amp; 0x3f);
11040   %}
11041 
11042   ins_pipe(ialu_reg_reg_shift);
11043 %}
11044 
11045 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11046                          iRegIorL2I src1, iRegIorL2I src2,
11047                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11048   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11049   ins_cost(1.9 * INSN_COST);
11050   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11051 
11052   ins_encode %{
11053     __ bicw(as_Register($dst$$reg),
11054               as_Register($src1$$reg),
11055               as_Register($src2$$reg),
11056               Assembler::ASR,
11057               $src3$$constant &amp; 0x1f);
11058   %}
11059 
11060   ins_pipe(ialu_reg_reg_shift);
11061 %}
11062 
11063 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11064                          iRegL src1, iRegL src2,
11065                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11066   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11067   ins_cost(1.9 * INSN_COST);
11068   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11069 
11070   ins_encode %{
11071     __ bic(as_Register($dst$$reg),
11072               as_Register($src1$$reg),
11073               as_Register($src2$$reg),
11074               Assembler::ASR,
11075               $src3$$constant &amp; 0x3f);
11076   %}
11077 
11078   ins_pipe(ialu_reg_reg_shift);
11079 %}
11080 
11081 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11082                          iRegIorL2I src1, iRegIorL2I src2,
11083                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11084   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11085   ins_cost(1.9 * INSN_COST);
11086   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11087 
11088   ins_encode %{
11089     __ bicw(as_Register($dst$$reg),
11090               as_Register($src1$$reg),
11091               as_Register($src2$$reg),
11092               Assembler::LSL,
11093               $src3$$constant &amp; 0x1f);
11094   %}
11095 
11096   ins_pipe(ialu_reg_reg_shift);
11097 %}
11098 
11099 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11100                          iRegL src1, iRegL src2,
11101                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11102   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11103   ins_cost(1.9 * INSN_COST);
11104   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11105 
11106   ins_encode %{
11107     __ bic(as_Register($dst$$reg),
11108               as_Register($src1$$reg),
11109               as_Register($src2$$reg),
11110               Assembler::LSL,
11111               $src3$$constant &amp; 0x3f);
11112   %}
11113 
11114   ins_pipe(ialu_reg_reg_shift);
11115 %}
11116 
11117 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11118                          iRegIorL2I src1, iRegIorL2I src2,
11119                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11120   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11121   ins_cost(1.9 * INSN_COST);
11122   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11123 
11124   ins_encode %{
11125     __ eonw(as_Register($dst$$reg),
11126               as_Register($src1$$reg),
11127               as_Register($src2$$reg),
11128               Assembler::LSR,
11129               $src3$$constant &amp; 0x1f);
11130   %}
11131 
11132   ins_pipe(ialu_reg_reg_shift);
11133 %}
11134 
11135 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11136                          iRegL src1, iRegL src2,
11137                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11138   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11139   ins_cost(1.9 * INSN_COST);
11140   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11141 
11142   ins_encode %{
11143     __ eon(as_Register($dst$$reg),
11144               as_Register($src1$$reg),
11145               as_Register($src2$$reg),
11146               Assembler::LSR,
11147               $src3$$constant &amp; 0x3f);
11148   %}
11149 
11150   ins_pipe(ialu_reg_reg_shift);
11151 %}
11152 
11153 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11154                          iRegIorL2I src1, iRegIorL2I src2,
11155                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11156   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11157   ins_cost(1.9 * INSN_COST);
11158   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11159 
11160   ins_encode %{
11161     __ eonw(as_Register($dst$$reg),
11162               as_Register($src1$$reg),
11163               as_Register($src2$$reg),
11164               Assembler::ASR,
11165               $src3$$constant &amp; 0x1f);
11166   %}
11167 
11168   ins_pipe(ialu_reg_reg_shift);
11169 %}
11170 
11171 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11172                          iRegL src1, iRegL src2,
11173                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11174   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11175   ins_cost(1.9 * INSN_COST);
11176   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11177 
11178   ins_encode %{
11179     __ eon(as_Register($dst$$reg),
11180               as_Register($src1$$reg),
11181               as_Register($src2$$reg),
11182               Assembler::ASR,
11183               $src3$$constant &amp; 0x3f);
11184   %}
11185 
11186   ins_pipe(ialu_reg_reg_shift);
11187 %}
11188 
11189 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11190                          iRegIorL2I src1, iRegIorL2I src2,
11191                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11192   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11193   ins_cost(1.9 * INSN_COST);
11194   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11195 
11196   ins_encode %{
11197     __ eonw(as_Register($dst$$reg),
11198               as_Register($src1$$reg),
11199               as_Register($src2$$reg),
11200               Assembler::LSL,
11201               $src3$$constant &amp; 0x1f);
11202   %}
11203 
11204   ins_pipe(ialu_reg_reg_shift);
11205 %}
11206 
11207 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11208                          iRegL src1, iRegL src2,
11209                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11210   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11211   ins_cost(1.9 * INSN_COST);
11212   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11213 
11214   ins_encode %{
11215     __ eon(as_Register($dst$$reg),
11216               as_Register($src1$$reg),
11217               as_Register($src2$$reg),
11218               Assembler::LSL,
11219               $src3$$constant &amp; 0x3f);
11220   %}
11221 
11222   ins_pipe(ialu_reg_reg_shift);
11223 %}
11224 
11225 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11226                          iRegIorL2I src1, iRegIorL2I src2,
11227                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11228   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11229   ins_cost(1.9 * INSN_COST);
11230   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11231 
11232   ins_encode %{
11233     __ ornw(as_Register($dst$$reg),
11234               as_Register($src1$$reg),
11235               as_Register($src2$$reg),
11236               Assembler::LSR,
11237               $src3$$constant &amp; 0x1f);
11238   %}
11239 
11240   ins_pipe(ialu_reg_reg_shift);
11241 %}
11242 
11243 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11244                          iRegL src1, iRegL src2,
11245                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11246   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11247   ins_cost(1.9 * INSN_COST);
11248   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11249 
11250   ins_encode %{
11251     __ orn(as_Register($dst$$reg),
11252               as_Register($src1$$reg),
11253               as_Register($src2$$reg),
11254               Assembler::LSR,
11255               $src3$$constant &amp; 0x3f);
11256   %}
11257 
11258   ins_pipe(ialu_reg_reg_shift);
11259 %}
11260 
11261 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11262                          iRegIorL2I src1, iRegIorL2I src2,
11263                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11264   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11265   ins_cost(1.9 * INSN_COST);
11266   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11267 
11268   ins_encode %{
11269     __ ornw(as_Register($dst$$reg),
11270               as_Register($src1$$reg),
11271               as_Register($src2$$reg),
11272               Assembler::ASR,
11273               $src3$$constant &amp; 0x1f);
11274   %}
11275 
11276   ins_pipe(ialu_reg_reg_shift);
11277 %}
11278 
11279 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11280                          iRegL src1, iRegL src2,
11281                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11282   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11283   ins_cost(1.9 * INSN_COST);
11284   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11285 
11286   ins_encode %{
11287     __ orn(as_Register($dst$$reg),
11288               as_Register($src1$$reg),
11289               as_Register($src2$$reg),
11290               Assembler::ASR,
11291               $src3$$constant &amp; 0x3f);
11292   %}
11293 
11294   ins_pipe(ialu_reg_reg_shift);
11295 %}
11296 
11297 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11298                          iRegIorL2I src1, iRegIorL2I src2,
11299                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11300   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11301   ins_cost(1.9 * INSN_COST);
11302   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11303 
11304   ins_encode %{
11305     __ ornw(as_Register($dst$$reg),
11306               as_Register($src1$$reg),
11307               as_Register($src2$$reg),
11308               Assembler::LSL,
11309               $src3$$constant &amp; 0x1f);
11310   %}
11311 
11312   ins_pipe(ialu_reg_reg_shift);
11313 %}
11314 
11315 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11316                          iRegL src1, iRegL src2,
11317                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11318   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11319   ins_cost(1.9 * INSN_COST);
11320   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11321 
11322   ins_encode %{
11323     __ orn(as_Register($dst$$reg),
11324               as_Register($src1$$reg),
11325               as_Register($src2$$reg),
11326               Assembler::LSL,
11327               $src3$$constant &amp; 0x3f);
11328   %}
11329 
11330   ins_pipe(ialu_reg_reg_shift);
11331 %}
11332 
11333 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11334                          iRegIorL2I src1, iRegIorL2I src2,
11335                          immI src3, rFlagsReg cr) %{
11336   match(Set dst (AndI src1 (URShiftI src2 src3)));
11337 
11338   ins_cost(1.9 * INSN_COST);
11339   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11340 
11341   ins_encode %{
11342     __ andw(as_Register($dst$$reg),
11343               as_Register($src1$$reg),
11344               as_Register($src2$$reg),
11345               Assembler::LSR,
11346               $src3$$constant &amp; 0x1f);
11347   %}
11348 
11349   ins_pipe(ialu_reg_reg_shift);
11350 %}
11351 
11352 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11353                          iRegL src1, iRegL src2,
11354                          immI src3, rFlagsReg cr) %{
11355   match(Set dst (AndL src1 (URShiftL src2 src3)));
11356 
11357   ins_cost(1.9 * INSN_COST);
11358   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11359 
11360   ins_encode %{
11361     __ andr(as_Register($dst$$reg),
11362               as_Register($src1$$reg),
11363               as_Register($src2$$reg),
11364               Assembler::LSR,
11365               $src3$$constant &amp; 0x3f);
11366   %}
11367 
11368   ins_pipe(ialu_reg_reg_shift);
11369 %}
11370 
11371 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11372                          iRegIorL2I src1, iRegIorL2I src2,
11373                          immI src3, rFlagsReg cr) %{
11374   match(Set dst (AndI src1 (RShiftI src2 src3)));
11375 
11376   ins_cost(1.9 * INSN_COST);
11377   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11378 
11379   ins_encode %{
11380     __ andw(as_Register($dst$$reg),
11381               as_Register($src1$$reg),
11382               as_Register($src2$$reg),
11383               Assembler::ASR,
11384               $src3$$constant &amp; 0x1f);
11385   %}
11386 
11387   ins_pipe(ialu_reg_reg_shift);
11388 %}
11389 
11390 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11391                          iRegL src1, iRegL src2,
11392                          immI src3, rFlagsReg cr) %{
11393   match(Set dst (AndL src1 (RShiftL src2 src3)));
11394 
11395   ins_cost(1.9 * INSN_COST);
11396   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11397 
11398   ins_encode %{
11399     __ andr(as_Register($dst$$reg),
11400               as_Register($src1$$reg),
11401               as_Register($src2$$reg),
11402               Assembler::ASR,
11403               $src3$$constant &amp; 0x3f);
11404   %}
11405 
11406   ins_pipe(ialu_reg_reg_shift);
11407 %}
11408 
11409 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11410                          iRegIorL2I src1, iRegIorL2I src2,
11411                          immI src3, rFlagsReg cr) %{
11412   match(Set dst (AndI src1 (LShiftI src2 src3)));
11413 
11414   ins_cost(1.9 * INSN_COST);
11415   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11416 
11417   ins_encode %{
11418     __ andw(as_Register($dst$$reg),
11419               as_Register($src1$$reg),
11420               as_Register($src2$$reg),
11421               Assembler::LSL,
11422               $src3$$constant &amp; 0x1f);
11423   %}
11424 
11425   ins_pipe(ialu_reg_reg_shift);
11426 %}
11427 
11428 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11429                          iRegL src1, iRegL src2,
11430                          immI src3, rFlagsReg cr) %{
11431   match(Set dst (AndL src1 (LShiftL src2 src3)));
11432 
11433   ins_cost(1.9 * INSN_COST);
11434   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11435 
11436   ins_encode %{
11437     __ andr(as_Register($dst$$reg),
11438               as_Register($src1$$reg),
11439               as_Register($src2$$reg),
11440               Assembler::LSL,
11441               $src3$$constant &amp; 0x3f);
11442   %}
11443 
11444   ins_pipe(ialu_reg_reg_shift);
11445 %}
11446 
11447 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11448                          iRegIorL2I src1, iRegIorL2I src2,
11449                          immI src3, rFlagsReg cr) %{
11450   match(Set dst (XorI src1 (URShiftI src2 src3)));
11451 
11452   ins_cost(1.9 * INSN_COST);
11453   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11454 
11455   ins_encode %{
11456     __ eorw(as_Register($dst$$reg),
11457               as_Register($src1$$reg),
11458               as_Register($src2$$reg),
11459               Assembler::LSR,
11460               $src3$$constant &amp; 0x1f);
11461   %}
11462 
11463   ins_pipe(ialu_reg_reg_shift);
11464 %}
11465 
11466 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11467                          iRegL src1, iRegL src2,
11468                          immI src3, rFlagsReg cr) %{
11469   match(Set dst (XorL src1 (URShiftL src2 src3)));
11470 
11471   ins_cost(1.9 * INSN_COST);
11472   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11473 
11474   ins_encode %{
11475     __ eor(as_Register($dst$$reg),
11476               as_Register($src1$$reg),
11477               as_Register($src2$$reg),
11478               Assembler::LSR,
11479               $src3$$constant &amp; 0x3f);
11480   %}
11481 
11482   ins_pipe(ialu_reg_reg_shift);
11483 %}
11484 
11485 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11486                          iRegIorL2I src1, iRegIorL2I src2,
11487                          immI src3, rFlagsReg cr) %{
11488   match(Set dst (XorI src1 (RShiftI src2 src3)));
11489 
11490   ins_cost(1.9 * INSN_COST);
11491   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11492 
11493   ins_encode %{
11494     __ eorw(as_Register($dst$$reg),
11495               as_Register($src1$$reg),
11496               as_Register($src2$$reg),
11497               Assembler::ASR,
11498               $src3$$constant &amp; 0x1f);
11499   %}
11500 
11501   ins_pipe(ialu_reg_reg_shift);
11502 %}
11503 
11504 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11505                          iRegL src1, iRegL src2,
11506                          immI src3, rFlagsReg cr) %{
11507   match(Set dst (XorL src1 (RShiftL src2 src3)));
11508 
11509   ins_cost(1.9 * INSN_COST);
11510   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11511 
11512   ins_encode %{
11513     __ eor(as_Register($dst$$reg),
11514               as_Register($src1$$reg),
11515               as_Register($src2$$reg),
11516               Assembler::ASR,
11517               $src3$$constant &amp; 0x3f);
11518   %}
11519 
11520   ins_pipe(ialu_reg_reg_shift);
11521 %}
11522 
11523 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11524                          iRegIorL2I src1, iRegIorL2I src2,
11525                          immI src3, rFlagsReg cr) %{
11526   match(Set dst (XorI src1 (LShiftI src2 src3)));
11527 
11528   ins_cost(1.9 * INSN_COST);
11529   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11530 
11531   ins_encode %{
11532     __ eorw(as_Register($dst$$reg),
11533               as_Register($src1$$reg),
11534               as_Register($src2$$reg),
11535               Assembler::LSL,
11536               $src3$$constant &amp; 0x1f);
11537   %}
11538 
11539   ins_pipe(ialu_reg_reg_shift);
11540 %}
11541 
11542 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11543                          iRegL src1, iRegL src2,
11544                          immI src3, rFlagsReg cr) %{
11545   match(Set dst (XorL src1 (LShiftL src2 src3)));
11546 
11547   ins_cost(1.9 * INSN_COST);
11548   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11549 
11550   ins_encode %{
11551     __ eor(as_Register($dst$$reg),
11552               as_Register($src1$$reg),
11553               as_Register($src2$$reg),
11554               Assembler::LSL,
11555               $src3$$constant &amp; 0x3f);
11556   %}
11557 
11558   ins_pipe(ialu_reg_reg_shift);
11559 %}
11560 
11561 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11562                          iRegIorL2I src1, iRegIorL2I src2,
11563                          immI src3, rFlagsReg cr) %{
11564   match(Set dst (OrI src1 (URShiftI src2 src3)));
11565 
11566   ins_cost(1.9 * INSN_COST);
11567   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11568 
11569   ins_encode %{
11570     __ orrw(as_Register($dst$$reg),
11571               as_Register($src1$$reg),
11572               as_Register($src2$$reg),
11573               Assembler::LSR,
11574               $src3$$constant &amp; 0x1f);
11575   %}
11576 
11577   ins_pipe(ialu_reg_reg_shift);
11578 %}
11579 
11580 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11581                          iRegL src1, iRegL src2,
11582                          immI src3, rFlagsReg cr) %{
11583   match(Set dst (OrL src1 (URShiftL src2 src3)));
11584 
11585   ins_cost(1.9 * INSN_COST);
11586   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11587 
11588   ins_encode %{
11589     __ orr(as_Register($dst$$reg),
11590               as_Register($src1$$reg),
11591               as_Register($src2$$reg),
11592               Assembler::LSR,
11593               $src3$$constant &amp; 0x3f);
11594   %}
11595 
11596   ins_pipe(ialu_reg_reg_shift);
11597 %}
11598 
11599 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11600                          iRegIorL2I src1, iRegIorL2I src2,
11601                          immI src3, rFlagsReg cr) %{
11602   match(Set dst (OrI src1 (RShiftI src2 src3)));
11603 
11604   ins_cost(1.9 * INSN_COST);
11605   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11606 
11607   ins_encode %{
11608     __ orrw(as_Register($dst$$reg),
11609               as_Register($src1$$reg),
11610               as_Register($src2$$reg),
11611               Assembler::ASR,
11612               $src3$$constant &amp; 0x1f);
11613   %}
11614 
11615   ins_pipe(ialu_reg_reg_shift);
11616 %}
11617 
11618 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11619                          iRegL src1, iRegL src2,
11620                          immI src3, rFlagsReg cr) %{
11621   match(Set dst (OrL src1 (RShiftL src2 src3)));
11622 
11623   ins_cost(1.9 * INSN_COST);
11624   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11625 
11626   ins_encode %{
11627     __ orr(as_Register($dst$$reg),
11628               as_Register($src1$$reg),
11629               as_Register($src2$$reg),
11630               Assembler::ASR,
11631               $src3$$constant &amp; 0x3f);
11632   %}
11633 
11634   ins_pipe(ialu_reg_reg_shift);
11635 %}
11636 
11637 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11638                          iRegIorL2I src1, iRegIorL2I src2,
11639                          immI src3, rFlagsReg cr) %{
11640   match(Set dst (OrI src1 (LShiftI src2 src3)));
11641 
11642   ins_cost(1.9 * INSN_COST);
11643   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11644 
11645   ins_encode %{
11646     __ orrw(as_Register($dst$$reg),
11647               as_Register($src1$$reg),
11648               as_Register($src2$$reg),
11649               Assembler::LSL,
11650               $src3$$constant &amp; 0x1f);
11651   %}
11652 
11653   ins_pipe(ialu_reg_reg_shift);
11654 %}
11655 
11656 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11657                          iRegL src1, iRegL src2,
11658                          immI src3, rFlagsReg cr) %{
11659   match(Set dst (OrL src1 (LShiftL src2 src3)));
11660 
11661   ins_cost(1.9 * INSN_COST);
11662   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11663 
11664   ins_encode %{
11665     __ orr(as_Register($dst$$reg),
11666               as_Register($src1$$reg),
11667               as_Register($src2$$reg),
11668               Assembler::LSL,
11669               $src3$$constant &amp; 0x3f);
11670   %}
11671 
11672   ins_pipe(ialu_reg_reg_shift);
11673 %}
11674 
11675 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11676                          iRegIorL2I src1, iRegIorL2I src2,
11677                          immI src3, rFlagsReg cr) %{
11678   match(Set dst (AddI src1 (URShiftI src2 src3)));
11679 
11680   ins_cost(1.9 * INSN_COST);
11681   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11682 
11683   ins_encode %{
11684     __ addw(as_Register($dst$$reg),
11685               as_Register($src1$$reg),
11686               as_Register($src2$$reg),
11687               Assembler::LSR,
11688               $src3$$constant &amp; 0x1f);
11689   %}
11690 
11691   ins_pipe(ialu_reg_reg_shift);
11692 %}
11693 
11694 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11695                          iRegL src1, iRegL src2,
11696                          immI src3, rFlagsReg cr) %{
11697   match(Set dst (AddL src1 (URShiftL src2 src3)));
11698 
11699   ins_cost(1.9 * INSN_COST);
11700   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11701 
11702   ins_encode %{
11703     __ add(as_Register($dst$$reg),
11704               as_Register($src1$$reg),
11705               as_Register($src2$$reg),
11706               Assembler::LSR,
11707               $src3$$constant &amp; 0x3f);
11708   %}
11709 
11710   ins_pipe(ialu_reg_reg_shift);
11711 %}
11712 
11713 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11714                          iRegIorL2I src1, iRegIorL2I src2,
11715                          immI src3, rFlagsReg cr) %{
11716   match(Set dst (AddI src1 (RShiftI src2 src3)));
11717 
11718   ins_cost(1.9 * INSN_COST);
11719   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11720 
11721   ins_encode %{
11722     __ addw(as_Register($dst$$reg),
11723               as_Register($src1$$reg),
11724               as_Register($src2$$reg),
11725               Assembler::ASR,
11726               $src3$$constant &amp; 0x1f);
11727   %}
11728 
11729   ins_pipe(ialu_reg_reg_shift);
11730 %}
11731 
11732 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11733                          iRegL src1, iRegL src2,
11734                          immI src3, rFlagsReg cr) %{
11735   match(Set dst (AddL src1 (RShiftL src2 src3)));
11736 
11737   ins_cost(1.9 * INSN_COST);
11738   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11739 
11740   ins_encode %{
11741     __ add(as_Register($dst$$reg),
11742               as_Register($src1$$reg),
11743               as_Register($src2$$reg),
11744               Assembler::ASR,
11745               $src3$$constant &amp; 0x3f);
11746   %}
11747 
11748   ins_pipe(ialu_reg_reg_shift);
11749 %}
11750 
11751 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11752                          iRegIorL2I src1, iRegIorL2I src2,
11753                          immI src3, rFlagsReg cr) %{
11754   match(Set dst (AddI src1 (LShiftI src2 src3)));
11755 
11756   ins_cost(1.9 * INSN_COST);
11757   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11758 
11759   ins_encode %{
11760     __ addw(as_Register($dst$$reg),
11761               as_Register($src1$$reg),
11762               as_Register($src2$$reg),
11763               Assembler::LSL,
11764               $src3$$constant &amp; 0x1f);
11765   %}
11766 
11767   ins_pipe(ialu_reg_reg_shift);
11768 %}
11769 
11770 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11771                          iRegL src1, iRegL src2,
11772                          immI src3, rFlagsReg cr) %{
11773   match(Set dst (AddL src1 (LShiftL src2 src3)));
11774 
11775   ins_cost(1.9 * INSN_COST);
11776   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11777 
11778   ins_encode %{
11779     __ add(as_Register($dst$$reg),
11780               as_Register($src1$$reg),
11781               as_Register($src2$$reg),
11782               Assembler::LSL,
11783               $src3$$constant &amp; 0x3f);
11784   %}
11785 
11786   ins_pipe(ialu_reg_reg_shift);
11787 %}
11788 
11789 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11790                          iRegIorL2I src1, iRegIorL2I src2,
11791                          immI src3, rFlagsReg cr) %{
11792   match(Set dst (SubI src1 (URShiftI src2 src3)));
11793 
11794   ins_cost(1.9 * INSN_COST);
11795   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11796 
11797   ins_encode %{
11798     __ subw(as_Register($dst$$reg),
11799               as_Register($src1$$reg),
11800               as_Register($src2$$reg),
11801               Assembler::LSR,
11802               $src3$$constant &amp; 0x1f);
11803   %}
11804 
11805   ins_pipe(ialu_reg_reg_shift);
11806 %}
11807 
11808 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11809                          iRegL src1, iRegL src2,
11810                          immI src3, rFlagsReg cr) %{
11811   match(Set dst (SubL src1 (URShiftL src2 src3)));
11812 
11813   ins_cost(1.9 * INSN_COST);
11814   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11815 
11816   ins_encode %{
11817     __ sub(as_Register($dst$$reg),
11818               as_Register($src1$$reg),
11819               as_Register($src2$$reg),
11820               Assembler::LSR,
11821               $src3$$constant &amp; 0x3f);
11822   %}
11823 
11824   ins_pipe(ialu_reg_reg_shift);
11825 %}
11826 
11827 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11828                          iRegIorL2I src1, iRegIorL2I src2,
11829                          immI src3, rFlagsReg cr) %{
11830   match(Set dst (SubI src1 (RShiftI src2 src3)));
11831 
11832   ins_cost(1.9 * INSN_COST);
11833   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11834 
11835   ins_encode %{
11836     __ subw(as_Register($dst$$reg),
11837               as_Register($src1$$reg),
11838               as_Register($src2$$reg),
11839               Assembler::ASR,
11840               $src3$$constant &amp; 0x1f);
11841   %}
11842 
11843   ins_pipe(ialu_reg_reg_shift);
11844 %}
11845 
11846 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11847                          iRegL src1, iRegL src2,
11848                          immI src3, rFlagsReg cr) %{
11849   match(Set dst (SubL src1 (RShiftL src2 src3)));
11850 
11851   ins_cost(1.9 * INSN_COST);
11852   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11853 
11854   ins_encode %{
11855     __ sub(as_Register($dst$$reg),
11856               as_Register($src1$$reg),
11857               as_Register($src2$$reg),
11858               Assembler::ASR,
11859               $src3$$constant &amp; 0x3f);
11860   %}
11861 
11862   ins_pipe(ialu_reg_reg_shift);
11863 %}
11864 
11865 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11866                          iRegIorL2I src1, iRegIorL2I src2,
11867                          immI src3, rFlagsReg cr) %{
11868   match(Set dst (SubI src1 (LShiftI src2 src3)));
11869 
11870   ins_cost(1.9 * INSN_COST);
11871   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11872 
11873   ins_encode %{
11874     __ subw(as_Register($dst$$reg),
11875               as_Register($src1$$reg),
11876               as_Register($src2$$reg),
11877               Assembler::LSL,
11878               $src3$$constant &amp; 0x1f);
11879   %}
11880 
11881   ins_pipe(ialu_reg_reg_shift);
11882 %}
11883 
11884 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11885                          iRegL src1, iRegL src2,
11886                          immI src3, rFlagsReg cr) %{
11887   match(Set dst (SubL src1 (LShiftL src2 src3)));
11888 
11889   ins_cost(1.9 * INSN_COST);
11890   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11891 
11892   ins_encode %{
11893     __ sub(as_Register($dst$$reg),
11894               as_Register($src1$$reg),
11895               as_Register($src2$$reg),
11896               Assembler::LSL,
11897               $src3$$constant &amp; 0x3f);
11898   %}
11899 
11900   ins_pipe(ialu_reg_reg_shift);
11901 %}
11902 
11903 
11904 
11905 // Shift Left followed by Shift Right.
11906 // This idiom is used by the compiler for the i2b bytecode etc.
11907 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11908 %{
11909   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11910   ins_cost(INSN_COST * 2);
11911   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11912   ins_encode %{
11913     int lshift = $lshift_count$$constant &amp; 63;
11914     int rshift = $rshift_count$$constant &amp; 63;
11915     int s = 63 - lshift;
11916     int r = (rshift - lshift) &amp; 63;
11917     __ sbfm(as_Register($dst$$reg),
11918             as_Register($src$$reg),
11919             r, s);
11920   %}
11921 
11922   ins_pipe(ialu_reg_shift);
11923 %}
11924 
11925 // Shift Left followed by Shift Right.
11926 // This idiom is used by the compiler for the i2b bytecode etc.
11927 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11928 %{
11929   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11930   ins_cost(INSN_COST * 2);
11931   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11932   ins_encode %{
11933     int lshift = $lshift_count$$constant &amp; 31;
11934     int rshift = $rshift_count$$constant &amp; 31;
11935     int s = 31 - lshift;
11936     int r = (rshift - lshift) &amp; 31;
11937     __ sbfmw(as_Register($dst$$reg),
11938             as_Register($src$$reg),
11939             r, s);
11940   %}
11941 
11942   ins_pipe(ialu_reg_shift);
11943 %}
11944 
11945 // Shift Left followed by Shift Right.
11946 // This idiom is used by the compiler for the i2b bytecode etc.
11947 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11948 %{
11949   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11950   ins_cost(INSN_COST * 2);
11951   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11952   ins_encode %{
11953     int lshift = $lshift_count$$constant &amp; 63;
11954     int rshift = $rshift_count$$constant &amp; 63;
11955     int s = 63 - lshift;
11956     int r = (rshift - lshift) &amp; 63;
11957     __ ubfm(as_Register($dst$$reg),
11958             as_Register($src$$reg),
11959             r, s);
11960   %}
11961 
11962   ins_pipe(ialu_reg_shift);
11963 %}
11964 
11965 // Shift Left followed by Shift Right.
11966 // This idiom is used by the compiler for the i2b bytecode etc.
11967 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11968 %{
11969   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11970   ins_cost(INSN_COST * 2);
11971   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11972   ins_encode %{
11973     int lshift = $lshift_count$$constant &amp; 31;
11974     int rshift = $rshift_count$$constant &amp; 31;
11975     int s = 31 - lshift;
11976     int r = (rshift - lshift) &amp; 31;
11977     __ ubfmw(as_Register($dst$$reg),
11978             as_Register($src$$reg),
11979             r, s);
11980   %}
11981 
11982   ins_pipe(ialu_reg_shift);
11983 %}
11984 // Bitfield extract with shift &amp; mask
11985 
11986 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
11987 %{
11988   match(Set dst (AndI (URShiftI src rshift) mask));
11989   // Make sure we are not going to exceed what ubfxw can do.
11990   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
11991 
11992   ins_cost(INSN_COST);
11993   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
11994   ins_encode %{
11995     int rshift = $rshift$$constant &amp; 31;
11996     long mask = $mask$$constant;
11997     int width = exact_log2(mask+1);
11998     __ ubfxw(as_Register($dst$$reg),
11999             as_Register($src$$reg), rshift, width);
12000   %}
12001   ins_pipe(ialu_reg_shift);
12002 %}
12003 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12004 %{
12005   match(Set dst (AndL (URShiftL src rshift) mask));
12006   // Make sure we are not going to exceed what ubfx can do.
12007   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12008 
12009   ins_cost(INSN_COST);
12010   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12011   ins_encode %{
12012     int rshift = $rshift$$constant &amp; 63;
12013     long mask = $mask$$constant;
12014     int width = exact_log2_long(mask+1);
12015     __ ubfx(as_Register($dst$$reg),
12016             as_Register($src$$reg), rshift, width);
12017   %}
12018   ins_pipe(ialu_reg_shift);
12019 %}
12020 
12021 // We can use ubfx when extending an And with a mask when we know mask
12022 // is positive.  We know that because immI_bitmask guarantees it.
12023 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12024 %{
12025   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12026   // Make sure we are not going to exceed what ubfxw can do.
12027   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12028 
12029   ins_cost(INSN_COST * 2);
12030   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12031   ins_encode %{
12032     int rshift = $rshift$$constant &amp; 31;
12033     long mask = $mask$$constant;
12034     int width = exact_log2(mask+1);
12035     __ ubfx(as_Register($dst$$reg),
12036             as_Register($src$$reg), rshift, width);
12037   %}
12038   ins_pipe(ialu_reg_shift);
12039 %}
12040 
12041 // We can use ubfiz when masking by a positive number and then left shifting the result.
12042 // We know that the mask is positive because immI_bitmask guarantees it.
12043 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12044 %{
12045   match(Set dst (LShiftI (AndI src mask) lshift));
12046   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12047 
12048   ins_cost(INSN_COST);
12049   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12050   ins_encode %{
12051     int lshift = $lshift$$constant &amp; 31;
12052     long mask = $mask$$constant;
12053     int width = exact_log2(mask+1);
12054     __ ubfizw(as_Register($dst$$reg),
12055           as_Register($src$$reg), lshift, width);
12056   %}
12057   ins_pipe(ialu_reg_shift);
12058 %}
12059 // We can use ubfiz when masking by a positive number and then left shifting the result.
12060 // We know that the mask is positive because immL_bitmask guarantees it.
12061 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12062 %{
12063   match(Set dst (LShiftL (AndL src mask) lshift));
12064   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12065 
12066   ins_cost(INSN_COST);
12067   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12068   ins_encode %{
12069     int lshift = $lshift$$constant &amp; 63;
12070     long mask = $mask$$constant;
12071     int width = exact_log2_long(mask+1);
12072     __ ubfiz(as_Register($dst$$reg),
12073           as_Register($src$$reg), lshift, width);
12074   %}
12075   ins_pipe(ialu_reg_shift);
12076 %}
12077 
12078 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12079 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12080 %{
12081   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12082   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12083 
12084   ins_cost(INSN_COST);
12085   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12086   ins_encode %{
12087     int lshift = $lshift$$constant &amp; 63;
12088     long mask = $mask$$constant;
12089     int width = exact_log2(mask+1);
12090     __ ubfiz(as_Register($dst$$reg),
12091              as_Register($src$$reg), lshift, width);
12092   %}
12093   ins_pipe(ialu_reg_shift);
12094 %}
12095 
12096 // Rotations
12097 
12098 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12099 %{
12100   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12101   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12102 
12103   ins_cost(INSN_COST);
12104   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12105 
12106   ins_encode %{
12107     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12108             $rshift$$constant &amp; 63);
12109   %}
12110   ins_pipe(ialu_reg_reg_extr);
12111 %}
12112 
12113 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12114 %{
12115   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12116   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12117 
12118   ins_cost(INSN_COST);
12119   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12120 
12121   ins_encode %{
12122     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12123             $rshift$$constant &amp; 31);
12124   %}
12125   ins_pipe(ialu_reg_reg_extr);
12126 %}
12127 
12128 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12129 %{
12130   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12131   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12132 
12133   ins_cost(INSN_COST);
12134   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12135 
12136   ins_encode %{
12137     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12138             $rshift$$constant &amp; 63);
12139   %}
12140   ins_pipe(ialu_reg_reg_extr);
12141 %}
12142 
12143 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12144 %{
12145   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12146   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12147 
12148   ins_cost(INSN_COST);
12149   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12150 
12151   ins_encode %{
12152     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12153             $rshift$$constant &amp; 31);
12154   %}
12155   ins_pipe(ialu_reg_reg_extr);
12156 %}
12157 
12158 
12159 // rol expander
12160 
12161 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12162 %{
12163   effect(DEF dst, USE src, USE shift);
12164 
12165   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12166   ins_cost(INSN_COST * 3);
12167   ins_encode %{
12168     __ subw(rscratch1, zr, as_Register($shift$$reg));
12169     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12170             rscratch1);
12171     %}
12172   ins_pipe(ialu_reg_reg_vshift);
12173 %}
12174 
12175 // rol expander
12176 
12177 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12178 %{
12179   effect(DEF dst, USE src, USE shift);
12180 
12181   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12182   ins_cost(INSN_COST * 3);
12183   ins_encode %{
12184     __ subw(rscratch1, zr, as_Register($shift$$reg));
12185     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12186             rscratch1);
12187     %}
12188   ins_pipe(ialu_reg_reg_vshift);
12189 %}
12190 
12191 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12192 %{
12193   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12194 
12195   expand %{
12196     rolL_rReg(dst, src, shift, cr);
12197   %}
12198 %}
12199 
12200 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12201 %{
12202   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12203 
12204   expand %{
12205     rolL_rReg(dst, src, shift, cr);
12206   %}
12207 %}
12208 
12209 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12210 %{
12211   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12212 
12213   expand %{
12214     rolI_rReg(dst, src, shift, cr);
12215   %}
12216 %}
12217 
12218 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12219 %{
12220   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12221 
12222   expand %{
12223     rolI_rReg(dst, src, shift, cr);
12224   %}
12225 %}
12226 
12227 // ror expander
12228 
12229 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12230 %{
12231   effect(DEF dst, USE src, USE shift);
12232 
12233   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12234   ins_cost(INSN_COST);
12235   ins_encode %{
12236     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12237             as_Register($shift$$reg));
12238     %}
12239   ins_pipe(ialu_reg_reg_vshift);
12240 %}
12241 
12242 // ror expander
12243 
12244 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12245 %{
12246   effect(DEF dst, USE src, USE shift);
12247 
12248   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12249   ins_cost(INSN_COST);
12250   ins_encode %{
12251     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12252             as_Register($shift$$reg));
12253     %}
12254   ins_pipe(ialu_reg_reg_vshift);
12255 %}
12256 
12257 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12258 %{
12259   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12260 
12261   expand %{
12262     rorL_rReg(dst, src, shift, cr);
12263   %}
12264 %}
12265 
12266 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12267 %{
12268   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12269 
12270   expand %{
12271     rorL_rReg(dst, src, shift, cr);
12272   %}
12273 %}
12274 
12275 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12276 %{
12277   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12278 
12279   expand %{
12280     rorI_rReg(dst, src, shift, cr);
12281   %}
12282 %}
12283 
12284 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12285 %{
12286   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12287 
12288   expand %{
12289     rorI_rReg(dst, src, shift, cr);
12290   %}
12291 %}
12292 
12293 // Add/subtract (extended)
12294 
12295 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12296 %{
12297   match(Set dst (AddL src1 (ConvI2L src2)));
12298   ins_cost(INSN_COST);
12299   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12300 
12301    ins_encode %{
12302      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12303             as_Register($src2$$reg), ext::sxtw);
12304    %}
12305   ins_pipe(ialu_reg_reg);
12306 %};
12307 
12308 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12309 %{
12310   match(Set dst (SubL src1 (ConvI2L src2)));
12311   ins_cost(INSN_COST);
12312   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12313 
12314    ins_encode %{
12315      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12316             as_Register($src2$$reg), ext::sxtw);
12317    %}
12318   ins_pipe(ialu_reg_reg);
12319 %};
12320 
12321 
12322 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12323 %{
12324   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12325   ins_cost(INSN_COST);
12326   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12327 
12328    ins_encode %{
12329      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12330             as_Register($src2$$reg), ext::sxth);
12331    %}
12332   ins_pipe(ialu_reg_reg);
12333 %}
12334 
12335 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12336 %{
12337   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12338   ins_cost(INSN_COST);
12339   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12340 
12341    ins_encode %{
12342      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12343             as_Register($src2$$reg), ext::sxtb);
12344    %}
12345   ins_pipe(ialu_reg_reg);
12346 %}
12347 
12348 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12349 %{
12350   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12351   ins_cost(INSN_COST);
12352   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12353 
12354    ins_encode %{
12355      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12356             as_Register($src2$$reg), ext::uxtb);
12357    %}
12358   ins_pipe(ialu_reg_reg);
12359 %}
12360 
12361 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12362 %{
12363   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12364   ins_cost(INSN_COST);
12365   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12366 
12367    ins_encode %{
12368      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12369             as_Register($src2$$reg), ext::sxth);
12370    %}
12371   ins_pipe(ialu_reg_reg);
12372 %}
12373 
12374 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12375 %{
12376   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12377   ins_cost(INSN_COST);
12378   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12379 
12380    ins_encode %{
12381      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12382             as_Register($src2$$reg), ext::sxtw);
12383    %}
12384   ins_pipe(ialu_reg_reg);
12385 %}
12386 
12387 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12388 %{
12389   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12390   ins_cost(INSN_COST);
12391   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12392 
12393    ins_encode %{
12394      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12395             as_Register($src2$$reg), ext::sxtb);
12396    %}
12397   ins_pipe(ialu_reg_reg);
12398 %}
12399 
12400 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12401 %{
12402   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12403   ins_cost(INSN_COST);
12404   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12405 
12406    ins_encode %{
12407      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12408             as_Register($src2$$reg), ext::uxtb);
12409    %}
12410   ins_pipe(ialu_reg_reg);
12411 %}
12412 
12413 
12414 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12415 %{
12416   match(Set dst (AddI src1 (AndI src2 mask)));
12417   ins_cost(INSN_COST);
12418   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12419 
12420    ins_encode %{
12421      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12422             as_Register($src2$$reg), ext::uxtb);
12423    %}
12424   ins_pipe(ialu_reg_reg);
12425 %}
12426 
12427 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12428 %{
12429   match(Set dst (AddI src1 (AndI src2 mask)));
12430   ins_cost(INSN_COST);
12431   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12432 
12433    ins_encode %{
12434      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12435             as_Register($src2$$reg), ext::uxth);
12436    %}
12437   ins_pipe(ialu_reg_reg);
12438 %}
12439 
12440 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12441 %{
12442   match(Set dst (AddL src1 (AndL src2 mask)));
12443   ins_cost(INSN_COST);
12444   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12445 
12446    ins_encode %{
12447      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12448             as_Register($src2$$reg), ext::uxtb);
12449    %}
12450   ins_pipe(ialu_reg_reg);
12451 %}
12452 
12453 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12454 %{
12455   match(Set dst (AddL src1 (AndL src2 mask)));
12456   ins_cost(INSN_COST);
12457   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12458 
12459    ins_encode %{
12460      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12461             as_Register($src2$$reg), ext::uxth);
12462    %}
12463   ins_pipe(ialu_reg_reg);
12464 %}
12465 
12466 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12467 %{
12468   match(Set dst (AddL src1 (AndL src2 mask)));
12469   ins_cost(INSN_COST);
12470   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12471 
12472    ins_encode %{
12473      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12474             as_Register($src2$$reg), ext::uxtw);
12475    %}
12476   ins_pipe(ialu_reg_reg);
12477 %}
12478 
12479 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12480 %{
12481   match(Set dst (SubI src1 (AndI src2 mask)));
12482   ins_cost(INSN_COST);
12483   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12484 
12485    ins_encode %{
12486      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12487             as_Register($src2$$reg), ext::uxtb);
12488    %}
12489   ins_pipe(ialu_reg_reg);
12490 %}
12491 
12492 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12493 %{
12494   match(Set dst (SubI src1 (AndI src2 mask)));
12495   ins_cost(INSN_COST);
12496   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12497 
12498    ins_encode %{
12499      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12500             as_Register($src2$$reg), ext::uxth);
12501    %}
12502   ins_pipe(ialu_reg_reg);
12503 %}
12504 
12505 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12506 %{
12507   match(Set dst (SubL src1 (AndL src2 mask)));
12508   ins_cost(INSN_COST);
12509   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12510 
12511    ins_encode %{
12512      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12513             as_Register($src2$$reg), ext::uxtb);
12514    %}
12515   ins_pipe(ialu_reg_reg);
12516 %}
12517 
12518 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12519 %{
12520   match(Set dst (SubL src1 (AndL src2 mask)));
12521   ins_cost(INSN_COST);
12522   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12523 
12524    ins_encode %{
12525      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12526             as_Register($src2$$reg), ext::uxth);
12527    %}
12528   ins_pipe(ialu_reg_reg);
12529 %}
12530 
12531 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12532 %{
12533   match(Set dst (SubL src1 (AndL src2 mask)));
12534   ins_cost(INSN_COST);
12535   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12536 
12537    ins_encode %{
12538      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12539             as_Register($src2$$reg), ext::uxtw);
12540    %}
12541   ins_pipe(ialu_reg_reg);
12542 %}
12543 
12544 
12545 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12546 %{
12547   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12548   ins_cost(1.9 * INSN_COST);
12549   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12550 
12551    ins_encode %{
12552      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12553             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12554    %}
12555   ins_pipe(ialu_reg_reg_shift);
12556 %}
12557 
12558 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12559 %{
12560   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12561   ins_cost(1.9 * INSN_COST);
12562   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12563 
12564    ins_encode %{
12565      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12566             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12567    %}
12568   ins_pipe(ialu_reg_reg_shift);
12569 %}
12570 
12571 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12572 %{
12573   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12574   ins_cost(1.9 * INSN_COST);
12575   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12576 
12577    ins_encode %{
12578      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12579             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12580    %}
12581   ins_pipe(ialu_reg_reg_shift);
12582 %}
12583 
12584 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12585 %{
12586   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12587   ins_cost(1.9 * INSN_COST);
12588   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12589 
12590    ins_encode %{
12591      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12592             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12593    %}
12594   ins_pipe(ialu_reg_reg_shift);
12595 %}
12596 
12597 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12598 %{
12599   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12600   ins_cost(1.9 * INSN_COST);
12601   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12602 
12603    ins_encode %{
12604      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12605             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12606    %}
12607   ins_pipe(ialu_reg_reg_shift);
12608 %}
12609 
12610 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12611 %{
12612   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12613   ins_cost(1.9 * INSN_COST);
12614   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12615 
12616    ins_encode %{
12617      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12618             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12619    %}
12620   ins_pipe(ialu_reg_reg_shift);
12621 %}
12622 
12623 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12624 %{
12625   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12626   ins_cost(1.9 * INSN_COST);
12627   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12628 
12629    ins_encode %{
12630      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12631             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12632    %}
12633   ins_pipe(ialu_reg_reg_shift);
12634 %}
12635 
12636 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12637 %{
12638   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12639   ins_cost(1.9 * INSN_COST);
12640   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12641 
12642    ins_encode %{
12643      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12644             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12645    %}
12646   ins_pipe(ialu_reg_reg_shift);
12647 %}
12648 
12649 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12650 %{
12651   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12652   ins_cost(1.9 * INSN_COST);
12653   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12654 
12655    ins_encode %{
12656      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12657             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12658    %}
12659   ins_pipe(ialu_reg_reg_shift);
12660 %}
12661 
12662 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12663 %{
12664   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12665   ins_cost(1.9 * INSN_COST);
12666   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12667 
12668    ins_encode %{
12669      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12670             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12671    %}
12672   ins_pipe(ialu_reg_reg_shift);
12673 %}
12674 
12675 
12676 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12677 %{
12678   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12679   ins_cost(1.9 * INSN_COST);
12680   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12681 
12682    ins_encode %{
12683      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12684             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12685    %}
12686   ins_pipe(ialu_reg_reg_shift);
12687 %};
12688 
12689 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12690 %{
12691   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12692   ins_cost(1.9 * INSN_COST);
12693   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12694 
12695    ins_encode %{
12696      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12697             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12698    %}
12699   ins_pipe(ialu_reg_reg_shift);
12700 %};
12701 
12702 
12703 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12704 %{
12705   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12706   ins_cost(1.9 * INSN_COST);
12707   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12708 
12709    ins_encode %{
12710      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12712    %}
12713   ins_pipe(ialu_reg_reg_shift);
12714 %}
12715 
12716 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12717 %{
12718   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12719   ins_cost(1.9 * INSN_COST);
12720   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12721 
12722    ins_encode %{
12723      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12724             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12725    %}
12726   ins_pipe(ialu_reg_reg_shift);
12727 %}
12728 
12729 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12730 %{
12731   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12732   ins_cost(1.9 * INSN_COST);
12733   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12734 
12735    ins_encode %{
12736      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12737             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12738    %}
12739   ins_pipe(ialu_reg_reg_shift);
12740 %}
12741 
12742 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12743 %{
12744   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12745   ins_cost(1.9 * INSN_COST);
12746   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12747 
12748    ins_encode %{
12749      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12750             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12751    %}
12752   ins_pipe(ialu_reg_reg_shift);
12753 %}
12754 
12755 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12756 %{
12757   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12758   ins_cost(1.9 * INSN_COST);
12759   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12760 
12761    ins_encode %{
12762      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12763             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12764    %}
12765   ins_pipe(ialu_reg_reg_shift);
12766 %}
12767 
12768 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12769 %{
12770   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12771   ins_cost(1.9 * INSN_COST);
12772   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12773 
12774    ins_encode %{
12775      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12776             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12777    %}
12778   ins_pipe(ialu_reg_reg_shift);
12779 %}
12780 
12781 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12782 %{
12783   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12784   ins_cost(1.9 * INSN_COST);
12785   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12786 
12787    ins_encode %{
12788      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12789             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12790    %}
12791   ins_pipe(ialu_reg_reg_shift);
12792 %}
12793 
12794 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12795 %{
12796   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12797   ins_cost(1.9 * INSN_COST);
12798   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12799 
12800    ins_encode %{
12801      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12802             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12803    %}
12804   ins_pipe(ialu_reg_reg_shift);
12805 %}
12806 
12807 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12808 %{
12809   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12810   ins_cost(1.9 * INSN_COST);
12811   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12812 
12813    ins_encode %{
12814      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12815             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12816    %}
12817   ins_pipe(ialu_reg_reg_shift);
12818 %}
12819 
12820 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12821 %{
12822   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12823   ins_cost(1.9 * INSN_COST);
12824   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12825 
12826    ins_encode %{
12827      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12828             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12829    %}
12830   ins_pipe(ialu_reg_reg_shift);
12831 %}
12832 // END This section of the file is automatically generated. Do not edit --------------
12833 
12834 // ============================================================================
12835 // Floating Point Arithmetic Instructions
12836 
12837 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12838   match(Set dst (AddF src1 src2));
12839 
12840   ins_cost(INSN_COST * 5);
12841   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12842 
12843   ins_encode %{
12844     __ fadds(as_FloatRegister($dst$$reg),
12845              as_FloatRegister($src1$$reg),
12846              as_FloatRegister($src2$$reg));
12847   %}
12848 
12849   ins_pipe(fp_dop_reg_reg_s);
12850 %}
12851 
12852 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12853   match(Set dst (AddD src1 src2));
12854 
12855   ins_cost(INSN_COST * 5);
12856   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12857 
12858   ins_encode %{
12859     __ faddd(as_FloatRegister($dst$$reg),
12860              as_FloatRegister($src1$$reg),
12861              as_FloatRegister($src2$$reg));
12862   %}
12863 
12864   ins_pipe(fp_dop_reg_reg_d);
12865 %}
12866 
12867 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12868   match(Set dst (SubF src1 src2));
12869 
12870   ins_cost(INSN_COST * 5);
12871   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12872 
12873   ins_encode %{
12874     __ fsubs(as_FloatRegister($dst$$reg),
12875              as_FloatRegister($src1$$reg),
12876              as_FloatRegister($src2$$reg));
12877   %}
12878 
12879   ins_pipe(fp_dop_reg_reg_s);
12880 %}
12881 
12882 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12883   match(Set dst (SubD src1 src2));
12884 
12885   ins_cost(INSN_COST * 5);
12886   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12887 
12888   ins_encode %{
12889     __ fsubd(as_FloatRegister($dst$$reg),
12890              as_FloatRegister($src1$$reg),
12891              as_FloatRegister($src2$$reg));
12892   %}
12893 
12894   ins_pipe(fp_dop_reg_reg_d);
12895 %}
12896 
12897 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12898   match(Set dst (MulF src1 src2));
12899 
12900   ins_cost(INSN_COST * 6);
12901   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12902 
12903   ins_encode %{
12904     __ fmuls(as_FloatRegister($dst$$reg),
12905              as_FloatRegister($src1$$reg),
12906              as_FloatRegister($src2$$reg));
12907   %}
12908 
12909   ins_pipe(fp_dop_reg_reg_s);
12910 %}
12911 
12912 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12913   match(Set dst (MulD src1 src2));
12914 
12915   ins_cost(INSN_COST * 6);
12916   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12917 
12918   ins_encode %{
12919     __ fmuld(as_FloatRegister($dst$$reg),
12920              as_FloatRegister($src1$$reg),
12921              as_FloatRegister($src2$$reg));
12922   %}
12923 
12924   ins_pipe(fp_dop_reg_reg_d);
12925 %}
12926 
12927 // src1 * src2 + src3
12928 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12929   predicate(UseFMA);
12930   match(Set dst (FmaF src3 (Binary src1 src2)));
12931 
12932   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12933 
12934   ins_encode %{
12935     __ fmadds(as_FloatRegister($dst$$reg),
12936              as_FloatRegister($src1$$reg),
12937              as_FloatRegister($src2$$reg),
12938              as_FloatRegister($src3$$reg));
12939   %}
12940 
12941   ins_pipe(pipe_class_default);
12942 %}
12943 
12944 // src1 * src2 + src3
12945 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12946   predicate(UseFMA);
12947   match(Set dst (FmaD src3 (Binary src1 src2)));
12948 
12949   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12950 
12951   ins_encode %{
12952     __ fmaddd(as_FloatRegister($dst$$reg),
12953              as_FloatRegister($src1$$reg),
12954              as_FloatRegister($src2$$reg),
12955              as_FloatRegister($src3$$reg));
12956   %}
12957 
12958   ins_pipe(pipe_class_default);
12959 %}
12960 
12961 // -src1 * src2 + src3
12962 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12963   predicate(UseFMA);
12964   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12965   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12966 
12967   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12968 
12969   ins_encode %{
12970     __ fmsubs(as_FloatRegister($dst$$reg),
12971               as_FloatRegister($src1$$reg),
12972               as_FloatRegister($src2$$reg),
12973               as_FloatRegister($src3$$reg));
12974   %}
12975 
12976   ins_pipe(pipe_class_default);
12977 %}
12978 
12979 // -src1 * src2 + src3
12980 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12981   predicate(UseFMA);
12982   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12983   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12984 
12985   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
12986 
12987   ins_encode %{
12988     __ fmsubd(as_FloatRegister($dst$$reg),
12989               as_FloatRegister($src1$$reg),
12990               as_FloatRegister($src2$$reg),
12991               as_FloatRegister($src3$$reg));
12992   %}
12993 
12994   ins_pipe(pipe_class_default);
12995 %}
12996 
12997 // -src1 * src2 - src3
12998 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12999   predicate(UseFMA);
13000   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13001   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13002 
13003   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13004 
13005   ins_encode %{
13006     __ fnmadds(as_FloatRegister($dst$$reg),
13007                as_FloatRegister($src1$$reg),
13008                as_FloatRegister($src2$$reg),
13009                as_FloatRegister($src3$$reg));
13010   %}
13011 
13012   ins_pipe(pipe_class_default);
13013 %}
13014 
13015 // -src1 * src2 - src3
13016 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13017   predicate(UseFMA);
13018   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13019   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13020 
13021   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13022 
13023   ins_encode %{
13024     __ fnmaddd(as_FloatRegister($dst$$reg),
13025                as_FloatRegister($src1$$reg),
13026                as_FloatRegister($src2$$reg),
13027                as_FloatRegister($src3$$reg));
13028   %}
13029 
13030   ins_pipe(pipe_class_default);
13031 %}
13032 
13033 // src1 * src2 - src3
13034 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13035   predicate(UseFMA);
13036   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13037 
13038   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13039 
13040   ins_encode %{
13041     __ fnmsubs(as_FloatRegister($dst$$reg),
13042                as_FloatRegister($src1$$reg),
13043                as_FloatRegister($src2$$reg),
13044                as_FloatRegister($src3$$reg));
13045   %}
13046 
13047   ins_pipe(pipe_class_default);
13048 %}
13049 
13050 // src1 * src2 - src3
13051 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13052   predicate(UseFMA);
13053   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13054 
13055   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13056 
13057   ins_encode %{
13058   // n.b. insn name should be fnmsubd
13059     __ fnmsub(as_FloatRegister($dst$$reg),
13060               as_FloatRegister($src1$$reg),
13061               as_FloatRegister($src2$$reg),
13062               as_FloatRegister($src3$$reg));
13063   %}
13064 
13065   ins_pipe(pipe_class_default);
13066 %}
13067 
13068 
13069 // Math.max(FF)F
13070 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13071   match(Set dst (MaxF src1 src2));
13072 
13073   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13074   ins_encode %{
13075     __ fmaxs(as_FloatRegister($dst$$reg),
13076              as_FloatRegister($src1$$reg),
13077              as_FloatRegister($src2$$reg));
13078   %}
13079 
13080   ins_pipe(fp_dop_reg_reg_s);
13081 %}
13082 
13083 // Math.min(FF)F
13084 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13085   match(Set dst (MinF src1 src2));
13086 
13087   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13088   ins_encode %{
13089     __ fmins(as_FloatRegister($dst$$reg),
13090              as_FloatRegister($src1$$reg),
13091              as_FloatRegister($src2$$reg));
13092   %}
13093 
13094   ins_pipe(fp_dop_reg_reg_s);
13095 %}
13096 
13097 // Math.max(DD)D
13098 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13099   match(Set dst (MaxD src1 src2));
13100 
13101   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13102   ins_encode %{
13103     __ fmaxd(as_FloatRegister($dst$$reg),
13104              as_FloatRegister($src1$$reg),
13105              as_FloatRegister($src2$$reg));
13106   %}
13107 
13108   ins_pipe(fp_dop_reg_reg_d);
13109 %}
13110 
13111 // Math.min(DD)D
13112 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13113   match(Set dst (MinD src1 src2));
13114 
13115   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13116   ins_encode %{
13117     __ fmind(as_FloatRegister($dst$$reg),
13118              as_FloatRegister($src1$$reg),
13119              as_FloatRegister($src2$$reg));
13120   %}
13121 
13122   ins_pipe(fp_dop_reg_reg_d);
13123 %}
13124 
13125 
13126 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13127   match(Set dst (DivF src1  src2));
13128 
13129   ins_cost(INSN_COST * 18);
13130   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13131 
13132   ins_encode %{
13133     __ fdivs(as_FloatRegister($dst$$reg),
13134              as_FloatRegister($src1$$reg),
13135              as_FloatRegister($src2$$reg));
13136   %}
13137 
13138   ins_pipe(fp_div_s);
13139 %}
13140 
13141 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13142   match(Set dst (DivD src1  src2));
13143 
13144   ins_cost(INSN_COST * 32);
13145   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13146 
13147   ins_encode %{
13148     __ fdivd(as_FloatRegister($dst$$reg),
13149              as_FloatRegister($src1$$reg),
13150              as_FloatRegister($src2$$reg));
13151   %}
13152 
13153   ins_pipe(fp_div_d);
13154 %}
13155 
13156 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13157   match(Set dst (NegF src));
13158 
13159   ins_cost(INSN_COST * 3);
13160   format %{ &quot;fneg   $dst, $src&quot; %}
13161 
13162   ins_encode %{
13163     __ fnegs(as_FloatRegister($dst$$reg),
13164              as_FloatRegister($src$$reg));
13165   %}
13166 
13167   ins_pipe(fp_uop_s);
13168 %}
13169 
13170 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13171   match(Set dst (NegD src));
13172 
13173   ins_cost(INSN_COST * 3);
13174   format %{ &quot;fnegd   $dst, $src&quot; %}
13175 
13176   ins_encode %{
13177     __ fnegd(as_FloatRegister($dst$$reg),
13178              as_FloatRegister($src$$reg));
13179   %}
13180 
13181   ins_pipe(fp_uop_d);
13182 %}
13183 
13184 instruct absF_reg(vRegF dst, vRegF src) %{
13185   match(Set dst (AbsF src));
13186 
13187   ins_cost(INSN_COST * 3);
13188   format %{ &quot;fabss   $dst, $src&quot; %}
13189   ins_encode %{
13190     __ fabss(as_FloatRegister($dst$$reg),
13191              as_FloatRegister($src$$reg));
13192   %}
13193 
13194   ins_pipe(fp_uop_s);
13195 %}
13196 
13197 instruct absD_reg(vRegD dst, vRegD src) %{
13198   match(Set dst (AbsD src));
13199 
13200   ins_cost(INSN_COST * 3);
13201   format %{ &quot;fabsd   $dst, $src&quot; %}
13202   ins_encode %{
13203     __ fabsd(as_FloatRegister($dst$$reg),
13204              as_FloatRegister($src$$reg));
13205   %}
13206 
13207   ins_pipe(fp_uop_d);
13208 %}
13209 
13210 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13211   match(Set dst (SqrtD src));
13212 
13213   ins_cost(INSN_COST * 50);
13214   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13215   ins_encode %{
13216     __ fsqrtd(as_FloatRegister($dst$$reg),
13217              as_FloatRegister($src$$reg));
13218   %}
13219 
13220   ins_pipe(fp_div_s);
13221 %}
13222 
13223 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13224   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
13225 
13226   ins_cost(INSN_COST * 50);
13227   format %{ &quot;fsqrts  $dst, $src&quot; %}
13228   ins_encode %{
13229     __ fsqrts(as_FloatRegister($dst$$reg),
13230              as_FloatRegister($src$$reg));
13231   %}
13232 
13233   ins_pipe(fp_div_d);
13234 %}
13235 
13236 // Math.rint, floor, ceil
13237 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13238   match(Set dst (RoundDoubleMode src rmode));
13239   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13240   ins_encode %{
13241     switch ($rmode$$constant) {
13242       case RoundDoubleModeNode::rmode_rint:
13243         __ frintnd(as_FloatRegister($dst$$reg),
13244                    as_FloatRegister($src$$reg));
13245         break;
13246       case RoundDoubleModeNode::rmode_floor:
13247         __ frintmd(as_FloatRegister($dst$$reg),
13248                    as_FloatRegister($src$$reg));
13249         break;
13250       case RoundDoubleModeNode::rmode_ceil:
13251         __ frintpd(as_FloatRegister($dst$$reg),
13252                    as_FloatRegister($src$$reg));
13253         break;
13254     }
13255   %}
13256   ins_pipe(fp_uop_d);
13257 %}
13258 
13259 // ============================================================================
13260 // Logical Instructions
13261 
13262 // Integer Logical Instructions
13263 
13264 // And Instructions
13265 
13266 
13267 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13268   match(Set dst (AndI src1 src2));
13269 
13270   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13271 
13272   ins_cost(INSN_COST);
13273   ins_encode %{
13274     __ andw(as_Register($dst$$reg),
13275             as_Register($src1$$reg),
13276             as_Register($src2$$reg));
13277   %}
13278 
13279   ins_pipe(ialu_reg_reg);
13280 %}
13281 
13282 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13283   match(Set dst (AndI src1 src2));
13284 
13285   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13286 
13287   ins_cost(INSN_COST);
13288   ins_encode %{
13289     __ andw(as_Register($dst$$reg),
13290             as_Register($src1$$reg),
13291             (unsigned long)($src2$$constant));
13292   %}
13293 
13294   ins_pipe(ialu_reg_imm);
13295 %}
13296 
13297 // Or Instructions
13298 
13299 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13300   match(Set dst (OrI src1 src2));
13301 
13302   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13303 
13304   ins_cost(INSN_COST);
13305   ins_encode %{
13306     __ orrw(as_Register($dst$$reg),
13307             as_Register($src1$$reg),
13308             as_Register($src2$$reg));
13309   %}
13310 
13311   ins_pipe(ialu_reg_reg);
13312 %}
13313 
13314 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13315   match(Set dst (OrI src1 src2));
13316 
13317   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13318 
13319   ins_cost(INSN_COST);
13320   ins_encode %{
13321     __ orrw(as_Register($dst$$reg),
13322             as_Register($src1$$reg),
13323             (unsigned long)($src2$$constant));
13324   %}
13325 
13326   ins_pipe(ialu_reg_imm);
13327 %}
13328 
13329 // Xor Instructions
13330 
13331 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13332   match(Set dst (XorI src1 src2));
13333 
13334   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13335 
13336   ins_cost(INSN_COST);
13337   ins_encode %{
13338     __ eorw(as_Register($dst$$reg),
13339             as_Register($src1$$reg),
13340             as_Register($src2$$reg));
13341   %}
13342 
13343   ins_pipe(ialu_reg_reg);
13344 %}
13345 
13346 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13347   match(Set dst (XorI src1 src2));
13348 
13349   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13350 
13351   ins_cost(INSN_COST);
13352   ins_encode %{
13353     __ eorw(as_Register($dst$$reg),
13354             as_Register($src1$$reg),
13355             (unsigned long)($src2$$constant));
13356   %}
13357 
13358   ins_pipe(ialu_reg_imm);
13359 %}
13360 
13361 // Long Logical Instructions
13362 // TODO
13363 
13364 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13365   match(Set dst (AndL src1 src2));
13366 
13367   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13368 
13369   ins_cost(INSN_COST);
13370   ins_encode %{
13371     __ andr(as_Register($dst$$reg),
13372             as_Register($src1$$reg),
13373             as_Register($src2$$reg));
13374   %}
13375 
13376   ins_pipe(ialu_reg_reg);
13377 %}
13378 
13379 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13380   match(Set dst (AndL src1 src2));
13381 
13382   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13383 
13384   ins_cost(INSN_COST);
13385   ins_encode %{
13386     __ andr(as_Register($dst$$reg),
13387             as_Register($src1$$reg),
13388             (unsigned long)($src2$$constant));
13389   %}
13390 
13391   ins_pipe(ialu_reg_imm);
13392 %}
13393 
13394 // Or Instructions
13395 
13396 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13397   match(Set dst (OrL src1 src2));
13398 
13399   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13400 
13401   ins_cost(INSN_COST);
13402   ins_encode %{
13403     __ orr(as_Register($dst$$reg),
13404            as_Register($src1$$reg),
13405            as_Register($src2$$reg));
13406   %}
13407 
13408   ins_pipe(ialu_reg_reg);
13409 %}
13410 
13411 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13412   match(Set dst (OrL src1 src2));
13413 
13414   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13415 
13416   ins_cost(INSN_COST);
13417   ins_encode %{
13418     __ orr(as_Register($dst$$reg),
13419            as_Register($src1$$reg),
13420            (unsigned long)($src2$$constant));
13421   %}
13422 
13423   ins_pipe(ialu_reg_imm);
13424 %}
13425 
13426 // Xor Instructions
13427 
13428 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13429   match(Set dst (XorL src1 src2));
13430 
13431   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13432 
13433   ins_cost(INSN_COST);
13434   ins_encode %{
13435     __ eor(as_Register($dst$$reg),
13436            as_Register($src1$$reg),
13437            as_Register($src2$$reg));
13438   %}
13439 
13440   ins_pipe(ialu_reg_reg);
13441 %}
13442 
13443 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13444   match(Set dst (XorL src1 src2));
13445 
13446   ins_cost(INSN_COST);
13447   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13448 
13449   ins_encode %{
13450     __ eor(as_Register($dst$$reg),
13451            as_Register($src1$$reg),
13452            (unsigned long)($src2$$constant));
13453   %}
13454 
13455   ins_pipe(ialu_reg_imm);
13456 %}
13457 
13458 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13459 %{
13460   match(Set dst (ConvI2L src));
13461 
13462   ins_cost(INSN_COST);
13463   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13464   ins_encode %{
13465     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13466   %}
13467   ins_pipe(ialu_reg_shift);
13468 %}
13469 
13470 // this pattern occurs in bigmath arithmetic
13471 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13472 %{
13473   match(Set dst (AndL (ConvI2L src) mask));
13474 
13475   ins_cost(INSN_COST);
13476   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13477   ins_encode %{
13478     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13479   %}
13480 
13481   ins_pipe(ialu_reg_shift);
13482 %}
13483 
13484 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13485   match(Set dst (ConvL2I src));
13486 
13487   ins_cost(INSN_COST);
13488   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13489 
13490   ins_encode %{
13491     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13492   %}
13493 
13494   ins_pipe(ialu_reg);
13495 %}
13496 
13497 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13498 %{
13499   match(Set dst (Conv2B src));
13500   effect(KILL cr);
13501 
13502   format %{
13503     &quot;cmpw $src, zr\n\t&quot;
13504     &quot;cset $dst, ne&quot;
13505   %}
13506 
13507   ins_encode %{
13508     __ cmpw(as_Register($src$$reg), zr);
13509     __ cset(as_Register($dst$$reg), Assembler::NE);
13510   %}
13511 
13512   ins_pipe(ialu_reg);
13513 %}
13514 
13515 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13516 %{
13517   match(Set dst (Conv2B src));
13518   effect(KILL cr);
13519 
13520   format %{
13521     &quot;cmp  $src, zr\n\t&quot;
13522     &quot;cset $dst, ne&quot;
13523   %}
13524 
13525   ins_encode %{
13526     __ cmp(as_Register($src$$reg), zr);
13527     __ cset(as_Register($dst$$reg), Assembler::NE);
13528   %}
13529 
13530   ins_pipe(ialu_reg);
13531 %}
13532 
13533 instruct convD2F_reg(vRegF dst, vRegD src) %{
13534   match(Set dst (ConvD2F src));
13535 
13536   ins_cost(INSN_COST * 5);
13537   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13538 
13539   ins_encode %{
13540     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13541   %}
13542 
13543   ins_pipe(fp_d2f);
13544 %}
13545 
13546 instruct convF2D_reg(vRegD dst, vRegF src) %{
13547   match(Set dst (ConvF2D src));
13548 
13549   ins_cost(INSN_COST * 5);
13550   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13551 
13552   ins_encode %{
13553     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13554   %}
13555 
13556   ins_pipe(fp_f2d);
13557 %}
13558 
13559 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13560   match(Set dst (ConvF2I src));
13561 
13562   ins_cost(INSN_COST * 5);
13563   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13564 
13565   ins_encode %{
13566     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13567   %}
13568 
13569   ins_pipe(fp_f2i);
13570 %}
13571 
13572 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13573   match(Set dst (ConvF2L src));
13574 
13575   ins_cost(INSN_COST * 5);
13576   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13577 
13578   ins_encode %{
13579     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13580   %}
13581 
13582   ins_pipe(fp_f2l);
13583 %}
13584 
13585 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13586   match(Set dst (ConvI2F src));
13587 
13588   ins_cost(INSN_COST * 5);
13589   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13590 
13591   ins_encode %{
13592     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13593   %}
13594 
13595   ins_pipe(fp_i2f);
13596 %}
13597 
13598 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13599   match(Set dst (ConvL2F src));
13600 
13601   ins_cost(INSN_COST * 5);
13602   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13603 
13604   ins_encode %{
13605     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13606   %}
13607 
13608   ins_pipe(fp_l2f);
13609 %}
13610 
13611 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13612   match(Set dst (ConvD2I src));
13613 
13614   ins_cost(INSN_COST * 5);
13615   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13616 
13617   ins_encode %{
13618     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13619   %}
13620 
13621   ins_pipe(fp_d2i);
13622 %}
13623 
13624 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13625   match(Set dst (ConvD2L src));
13626 
13627   ins_cost(INSN_COST * 5);
13628   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13629 
13630   ins_encode %{
13631     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13632   %}
13633 
13634   ins_pipe(fp_d2l);
13635 %}
13636 
13637 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13638   match(Set dst (ConvI2D src));
13639 
13640   ins_cost(INSN_COST * 5);
13641   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13642 
13643   ins_encode %{
13644     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13645   %}
13646 
13647   ins_pipe(fp_i2d);
13648 %}
13649 
13650 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13651   match(Set dst (ConvL2D src));
13652 
13653   ins_cost(INSN_COST * 5);
13654   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13655 
13656   ins_encode %{
13657     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13658   %}
13659 
13660   ins_pipe(fp_l2d);
13661 %}
13662 
13663 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13664 
13665 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13666 
13667   match(Set dst (MoveF2I src));
13668 
13669   effect(DEF dst, USE src);
13670 
13671   ins_cost(4 * INSN_COST);
13672 
13673   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13674 
13675   ins_encode %{
13676     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13677   %}
13678 
13679   ins_pipe(iload_reg_reg);
13680 
13681 %}
13682 
13683 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13684 
13685   match(Set dst (MoveI2F src));
13686 
13687   effect(DEF dst, USE src);
13688 
13689   ins_cost(4 * INSN_COST);
13690 
13691   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13692 
13693   ins_encode %{
13694     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13695   %}
13696 
13697   ins_pipe(pipe_class_memory);
13698 
13699 %}
13700 
13701 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13702 
13703   match(Set dst (MoveD2L src));
13704 
13705   effect(DEF dst, USE src);
13706 
13707   ins_cost(4 * INSN_COST);
13708 
13709   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13710 
13711   ins_encode %{
13712     __ ldr($dst$$Register, Address(sp, $src$$disp));
13713   %}
13714 
13715   ins_pipe(iload_reg_reg);
13716 
13717 %}
13718 
13719 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13720 
13721   match(Set dst (MoveL2D src));
13722 
13723   effect(DEF dst, USE src);
13724 
13725   ins_cost(4 * INSN_COST);
13726 
13727   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13728 
13729   ins_encode %{
13730     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13731   %}
13732 
13733   ins_pipe(pipe_class_memory);
13734 
13735 %}
13736 
13737 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13738 
13739   match(Set dst (MoveF2I src));
13740 
13741   effect(DEF dst, USE src);
13742 
13743   ins_cost(INSN_COST);
13744 
13745   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13746 
13747   ins_encode %{
13748     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13749   %}
13750 
13751   ins_pipe(pipe_class_memory);
13752 
13753 %}
13754 
13755 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13756 
13757   match(Set dst (MoveI2F src));
13758 
13759   effect(DEF dst, USE src);
13760 
13761   ins_cost(INSN_COST);
13762 
13763   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13764 
13765   ins_encode %{
13766     __ strw($src$$Register, Address(sp, $dst$$disp));
13767   %}
13768 
13769   ins_pipe(istore_reg_reg);
13770 
13771 %}
13772 
13773 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13774 
13775   match(Set dst (MoveD2L src));
13776 
13777   effect(DEF dst, USE src);
13778 
13779   ins_cost(INSN_COST);
13780 
13781   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13782 
13783   ins_encode %{
13784     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13785   %}
13786 
13787   ins_pipe(pipe_class_memory);
13788 
13789 %}
13790 
13791 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13792 
13793   match(Set dst (MoveL2D src));
13794 
13795   effect(DEF dst, USE src);
13796 
13797   ins_cost(INSN_COST);
13798 
13799   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13800 
13801   ins_encode %{
13802     __ str($src$$Register, Address(sp, $dst$$disp));
13803   %}
13804 
13805   ins_pipe(istore_reg_reg);
13806 
13807 %}
13808 
13809 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13810 
13811   match(Set dst (MoveF2I src));
13812 
13813   effect(DEF dst, USE src);
13814 
13815   ins_cost(INSN_COST);
13816 
13817   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13818 
13819   ins_encode %{
13820     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13821   %}
13822 
13823   ins_pipe(fp_f2i);
13824 
13825 %}
13826 
13827 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13828 
13829   match(Set dst (MoveI2F src));
13830 
13831   effect(DEF dst, USE src);
13832 
13833   ins_cost(INSN_COST);
13834 
13835   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13836 
13837   ins_encode %{
13838     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13839   %}
13840 
13841   ins_pipe(fp_i2f);
13842 
13843 %}
13844 
13845 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13846 
13847   match(Set dst (MoveD2L src));
13848 
13849   effect(DEF dst, USE src);
13850 
13851   ins_cost(INSN_COST);
13852 
13853   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13854 
13855   ins_encode %{
13856     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13857   %}
13858 
13859   ins_pipe(fp_d2l);
13860 
13861 %}
13862 
13863 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13864 
13865   match(Set dst (MoveL2D src));
13866 
13867   effect(DEF dst, USE src);
13868 
13869   ins_cost(INSN_COST);
13870 
13871   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13872 
13873   ins_encode %{
13874     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13875   %}
13876 
13877   ins_pipe(fp_l2d);
13878 
13879 %}
13880 
13881 // ============================================================================
13882 // clearing of an array
13883 
13884 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13885 %{
13886   match(Set dummy (ClearArray cnt base));
13887   effect(USE_KILL cnt, USE_KILL base);
13888 
13889   ins_cost(4 * INSN_COST);
13890   format %{ &quot;ClearArray $cnt, $base&quot; %}
13891 
13892   ins_encode %{
13893     __ zero_words($base$$Register, $cnt$$Register);
13894   %}
13895 
13896   ins_pipe(pipe_class_memory);
13897 %}
13898 
13899 instruct clearArray_imm_reg(immL cnt, iRegP_R10 base, Universe dummy, rFlagsReg cr)
13900 %{
13901   predicate((u_int64_t)n-&gt;in(2)-&gt;get_long()
13902             &lt; (u_int64_t)(BlockZeroingLowLimit &gt;&gt; LogBytesPerWord));
13903   match(Set dummy (ClearArray cnt base));
13904   effect(USE_KILL base);
13905 
13906   ins_cost(4 * INSN_COST);
13907   format %{ &quot;ClearArray $cnt, $base&quot; %}
13908 
13909   ins_encode %{
13910     __ zero_words($base$$Register, (u_int64_t)$cnt$$constant);
13911   %}
13912 
13913   ins_pipe(pipe_class_memory);
13914 %}
13915 
13916 // ============================================================================
13917 // Overflow Math Instructions
13918 
13919 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13920 %{
13921   match(Set cr (OverflowAddI op1 op2));
13922 
13923   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13924   ins_cost(INSN_COST);
13925   ins_encode %{
13926     __ cmnw($op1$$Register, $op2$$Register);
13927   %}
13928 
13929   ins_pipe(icmp_reg_reg);
13930 %}
13931 
13932 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13933 %{
13934   match(Set cr (OverflowAddI op1 op2));
13935 
13936   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13937   ins_cost(INSN_COST);
13938   ins_encode %{
13939     __ cmnw($op1$$Register, $op2$$constant);
13940   %}
13941 
13942   ins_pipe(icmp_reg_imm);
13943 %}
13944 
13945 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13946 %{
13947   match(Set cr (OverflowAddL op1 op2));
13948 
13949   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13950   ins_cost(INSN_COST);
13951   ins_encode %{
13952     __ cmn($op1$$Register, $op2$$Register);
13953   %}
13954 
13955   ins_pipe(icmp_reg_reg);
13956 %}
13957 
13958 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13959 %{
13960   match(Set cr (OverflowAddL op1 op2));
13961 
13962   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13963   ins_cost(INSN_COST);
13964   ins_encode %{
13965     __ cmn($op1$$Register, $op2$$constant);
13966   %}
13967 
13968   ins_pipe(icmp_reg_imm);
13969 %}
13970 
13971 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13972 %{
13973   match(Set cr (OverflowSubI op1 op2));
13974 
13975   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13976   ins_cost(INSN_COST);
13977   ins_encode %{
13978     __ cmpw($op1$$Register, $op2$$Register);
13979   %}
13980 
13981   ins_pipe(icmp_reg_reg);
13982 %}
13983 
13984 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13985 %{
13986   match(Set cr (OverflowSubI op1 op2));
13987 
13988   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
13989   ins_cost(INSN_COST);
13990   ins_encode %{
13991     __ cmpw($op1$$Register, $op2$$constant);
13992   %}
13993 
13994   ins_pipe(icmp_reg_imm);
13995 %}
13996 
13997 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13998 %{
13999   match(Set cr (OverflowSubL op1 op2));
14000 
14001   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14002   ins_cost(INSN_COST);
14003   ins_encode %{
14004     __ cmp($op1$$Register, $op2$$Register);
14005   %}
14006 
14007   ins_pipe(icmp_reg_reg);
14008 %}
14009 
14010 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14011 %{
14012   match(Set cr (OverflowSubL op1 op2));
14013 
14014   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14015   ins_cost(INSN_COST);
14016   ins_encode %{
14017     __ subs(zr, $op1$$Register, $op2$$constant);
14018   %}
14019 
14020   ins_pipe(icmp_reg_imm);
14021 %}
14022 
14023 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14024 %{
14025   match(Set cr (OverflowSubI zero op1));
14026 
14027   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14028   ins_cost(INSN_COST);
14029   ins_encode %{
14030     __ cmpw(zr, $op1$$Register);
14031   %}
14032 
14033   ins_pipe(icmp_reg_imm);
14034 %}
14035 
14036 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14037 %{
14038   match(Set cr (OverflowSubL zero op1));
14039 
14040   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14041   ins_cost(INSN_COST);
14042   ins_encode %{
14043     __ cmp(zr, $op1$$Register);
14044   %}
14045 
14046   ins_pipe(icmp_reg_imm);
14047 %}
14048 
14049 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14050 %{
14051   match(Set cr (OverflowMulI op1 op2));
14052 
14053   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14054             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14055             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14056             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14057             &quot;cmpw  rscratch1, #1&quot; %}
14058   ins_cost(5 * INSN_COST);
14059   ins_encode %{
14060     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14061     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14062     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14063     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14064     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14065   %}
14066 
14067   ins_pipe(pipe_slow);
14068 %}
14069 
14070 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14071 %{
14072   match(If cmp (OverflowMulI op1 op2));
14073   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14074             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14075   effect(USE labl, KILL cr);
14076 
14077   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14078             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14079             &quot;b$cmp   $labl&quot; %}
14080   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14081   ins_encode %{
14082     Label* L = $labl$$label;
14083     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14084     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14085     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14086     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14087   %}
14088 
14089   ins_pipe(pipe_serial);
14090 %}
14091 
14092 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14093 %{
14094   match(Set cr (OverflowMulL op1 op2));
14095 
14096   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14097             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14098             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14099             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14100             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14101             &quot;cmpw  rscratch1, #1&quot; %}
14102   ins_cost(6 * INSN_COST);
14103   ins_encode %{
14104     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14105     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14106     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14107     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14108     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14109     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14110   %}
14111 
14112   ins_pipe(pipe_slow);
14113 %}
14114 
14115 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14116 %{
14117   match(If cmp (OverflowMulL op1 op2));
14118   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14119             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14120   effect(USE labl, KILL cr);
14121 
14122   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14123             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14124             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14125             &quot;b$cmp $labl&quot; %}
14126   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14127   ins_encode %{
14128     Label* L = $labl$$label;
14129     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14130     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14131     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14132     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14133     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14134   %}
14135 
14136   ins_pipe(pipe_serial);
14137 %}
14138 
14139 // ============================================================================
14140 // Compare Instructions
14141 
14142 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14143 %{
14144   match(Set cr (CmpI op1 op2));
14145 
14146   effect(DEF cr, USE op1, USE op2);
14147 
14148   ins_cost(INSN_COST);
14149   format %{ &quot;cmpw  $op1, $op2&quot; %}
14150 
14151   ins_encode(aarch64_enc_cmpw(op1, op2));
14152 
14153   ins_pipe(icmp_reg_reg);
14154 %}
14155 
14156 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14157 %{
14158   match(Set cr (CmpI op1 zero));
14159 
14160   effect(DEF cr, USE op1);
14161 
14162   ins_cost(INSN_COST);
14163   format %{ &quot;cmpw $op1, 0&quot; %}
14164 
14165   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14166 
14167   ins_pipe(icmp_reg_imm);
14168 %}
14169 
14170 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14171 %{
14172   match(Set cr (CmpI op1 op2));
14173 
14174   effect(DEF cr, USE op1);
14175 
14176   ins_cost(INSN_COST);
14177   format %{ &quot;cmpw  $op1, $op2&quot; %}
14178 
14179   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14180 
14181   ins_pipe(icmp_reg_imm);
14182 %}
14183 
14184 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14185 %{
14186   match(Set cr (CmpI op1 op2));
14187 
14188   effect(DEF cr, USE op1);
14189 
14190   ins_cost(INSN_COST * 2);
14191   format %{ &quot;cmpw  $op1, $op2&quot; %}
14192 
14193   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14194 
14195   ins_pipe(icmp_reg_imm);
14196 %}
14197 
14198 // Unsigned compare Instructions; really, same as signed compare
14199 // except it should only be used to feed an If or a CMovI which takes a
14200 // cmpOpU.
14201 
14202 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14203 %{
14204   match(Set cr (CmpU op1 op2));
14205 
14206   effect(DEF cr, USE op1, USE op2);
14207 
14208   ins_cost(INSN_COST);
14209   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14210 
14211   ins_encode(aarch64_enc_cmpw(op1, op2));
14212 
14213   ins_pipe(icmp_reg_reg);
14214 %}
14215 
14216 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14217 %{
14218   match(Set cr (CmpU op1 zero));
14219 
14220   effect(DEF cr, USE op1);
14221 
14222   ins_cost(INSN_COST);
14223   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14224 
14225   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14226 
14227   ins_pipe(icmp_reg_imm);
14228 %}
14229 
14230 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14231 %{
14232   match(Set cr (CmpU op1 op2));
14233 
14234   effect(DEF cr, USE op1);
14235 
14236   ins_cost(INSN_COST);
14237   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14238 
14239   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14240 
14241   ins_pipe(icmp_reg_imm);
14242 %}
14243 
14244 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14245 %{
14246   match(Set cr (CmpU op1 op2));
14247 
14248   effect(DEF cr, USE op1);
14249 
14250   ins_cost(INSN_COST * 2);
14251   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14252 
14253   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14254 
14255   ins_pipe(icmp_reg_imm);
14256 %}
14257 
14258 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14259 %{
14260   match(Set cr (CmpL op1 op2));
14261 
14262   effect(DEF cr, USE op1, USE op2);
14263 
14264   ins_cost(INSN_COST);
14265   format %{ &quot;cmp  $op1, $op2&quot; %}
14266 
14267   ins_encode(aarch64_enc_cmp(op1, op2));
14268 
14269   ins_pipe(icmp_reg_reg);
14270 %}
14271 
14272 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14273 %{
14274   match(Set cr (CmpL op1 zero));
14275 
14276   effect(DEF cr, USE op1);
14277 
14278   ins_cost(INSN_COST);
14279   format %{ &quot;tst  $op1&quot; %}
14280 
14281   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14282 
14283   ins_pipe(icmp_reg_imm);
14284 %}
14285 
14286 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14287 %{
14288   match(Set cr (CmpL op1 op2));
14289 
14290   effect(DEF cr, USE op1);
14291 
14292   ins_cost(INSN_COST);
14293   format %{ &quot;cmp  $op1, $op2&quot; %}
14294 
14295   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14296 
14297   ins_pipe(icmp_reg_imm);
14298 %}
14299 
14300 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14301 %{
14302   match(Set cr (CmpL op1 op2));
14303 
14304   effect(DEF cr, USE op1);
14305 
14306   ins_cost(INSN_COST * 2);
14307   format %{ &quot;cmp  $op1, $op2&quot; %}
14308 
14309   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14310 
14311   ins_pipe(icmp_reg_imm);
14312 %}
14313 
14314 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14315 %{
14316   match(Set cr (CmpUL op1 op2));
14317 
14318   effect(DEF cr, USE op1, USE op2);
14319 
14320   ins_cost(INSN_COST);
14321   format %{ &quot;cmp  $op1, $op2&quot; %}
14322 
14323   ins_encode(aarch64_enc_cmp(op1, op2));
14324 
14325   ins_pipe(icmp_reg_reg);
14326 %}
14327 
14328 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14329 %{
14330   match(Set cr (CmpUL op1 zero));
14331 
14332   effect(DEF cr, USE op1);
14333 
14334   ins_cost(INSN_COST);
14335   format %{ &quot;tst  $op1&quot; %}
14336 
14337   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14338 
14339   ins_pipe(icmp_reg_imm);
14340 %}
14341 
14342 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14343 %{
14344   match(Set cr (CmpUL op1 op2));
14345 
14346   effect(DEF cr, USE op1);
14347 
14348   ins_cost(INSN_COST);
14349   format %{ &quot;cmp  $op1, $op2&quot; %}
14350 
14351   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14352 
14353   ins_pipe(icmp_reg_imm);
14354 %}
14355 
14356 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14357 %{
14358   match(Set cr (CmpUL op1 op2));
14359 
14360   effect(DEF cr, USE op1);
14361 
14362   ins_cost(INSN_COST * 2);
14363   format %{ &quot;cmp  $op1, $op2&quot; %}
14364 
14365   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14366 
14367   ins_pipe(icmp_reg_imm);
14368 %}
14369 
14370 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14371 %{
14372   match(Set cr (CmpP op1 op2));
14373 
14374   effect(DEF cr, USE op1, USE op2);
14375 
14376   ins_cost(INSN_COST);
14377   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14378 
14379   ins_encode(aarch64_enc_cmpp(op1, op2));
14380 
14381   ins_pipe(icmp_reg_reg);
14382 %}
14383 
14384 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14385 %{
14386   match(Set cr (CmpN op1 op2));
14387 
14388   effect(DEF cr, USE op1, USE op2);
14389 
14390   ins_cost(INSN_COST);
14391   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14392 
14393   ins_encode(aarch64_enc_cmpn(op1, op2));
14394 
14395   ins_pipe(icmp_reg_reg);
14396 %}
14397 
14398 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14399 %{
14400   match(Set cr (CmpP op1 zero));
14401 
14402   effect(DEF cr, USE op1, USE zero);
14403 
14404   ins_cost(INSN_COST);
14405   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14406 
14407   ins_encode(aarch64_enc_testp(op1));
14408 
14409   ins_pipe(icmp_reg_imm);
14410 %}
14411 
14412 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14413 %{
14414   match(Set cr (CmpN op1 zero));
14415 
14416   effect(DEF cr, USE op1, USE zero);
14417 
14418   ins_cost(INSN_COST);
14419   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14420 
14421   ins_encode(aarch64_enc_testn(op1));
14422 
14423   ins_pipe(icmp_reg_imm);
14424 %}
14425 
14426 // FP comparisons
14427 //
14428 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14429 // using normal cmpOp. See declaration of rFlagsReg for details.
14430 
14431 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14432 %{
14433   match(Set cr (CmpF src1 src2));
14434 
14435   ins_cost(3 * INSN_COST);
14436   format %{ &quot;fcmps $src1, $src2&quot; %}
14437 
14438   ins_encode %{
14439     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14440   %}
14441 
14442   ins_pipe(pipe_class_compare);
14443 %}
14444 
14445 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14446 %{
14447   match(Set cr (CmpF src1 src2));
14448 
14449   ins_cost(3 * INSN_COST);
14450   format %{ &quot;fcmps $src1, 0.0&quot; %}
14451 
14452   ins_encode %{
14453     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14454   %}
14455 
14456   ins_pipe(pipe_class_compare);
14457 %}
14458 // FROM HERE
14459 
14460 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14461 %{
14462   match(Set cr (CmpD src1 src2));
14463 
14464   ins_cost(3 * INSN_COST);
14465   format %{ &quot;fcmpd $src1, $src2&quot; %}
14466 
14467   ins_encode %{
14468     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14469   %}
14470 
14471   ins_pipe(pipe_class_compare);
14472 %}
14473 
14474 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14475 %{
14476   match(Set cr (CmpD src1 src2));
14477 
14478   ins_cost(3 * INSN_COST);
14479   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14480 
14481   ins_encode %{
14482     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14483   %}
14484 
14485   ins_pipe(pipe_class_compare);
14486 %}
14487 
14488 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14489 %{
14490   match(Set dst (CmpF3 src1 src2));
14491   effect(KILL cr);
14492 
14493   ins_cost(5 * INSN_COST);
14494   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14495             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14496             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14497   %}
14498 
14499   ins_encode %{
14500     Label done;
14501     FloatRegister s1 = as_FloatRegister($src1$$reg);
14502     FloatRegister s2 = as_FloatRegister($src2$$reg);
14503     Register d = as_Register($dst$$reg);
14504     __ fcmps(s1, s2);
14505     // installs 0 if EQ else -1
14506     __ csinvw(d, zr, zr, Assembler::EQ);
14507     // keeps -1 if less or unordered else installs 1
14508     __ csnegw(d, d, d, Assembler::LT);
14509     __ bind(done);
14510   %}
14511 
14512   ins_pipe(pipe_class_default);
14513 
14514 %}
14515 
14516 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14517 %{
14518   match(Set dst (CmpD3 src1 src2));
14519   effect(KILL cr);
14520 
14521   ins_cost(5 * INSN_COST);
14522   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14523             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14524             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14525   %}
14526 
14527   ins_encode %{
14528     Label done;
14529     FloatRegister s1 = as_FloatRegister($src1$$reg);
14530     FloatRegister s2 = as_FloatRegister($src2$$reg);
14531     Register d = as_Register($dst$$reg);
14532     __ fcmpd(s1, s2);
14533     // installs 0 if EQ else -1
14534     __ csinvw(d, zr, zr, Assembler::EQ);
14535     // keeps -1 if less or unordered else installs 1
14536     __ csnegw(d, d, d, Assembler::LT);
14537     __ bind(done);
14538   %}
14539   ins_pipe(pipe_class_default);
14540 
14541 %}
14542 
14543 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14544 %{
14545   match(Set dst (CmpF3 src1 zero));
14546   effect(KILL cr);
14547 
14548   ins_cost(5 * INSN_COST);
14549   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14550             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14551             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14552   %}
14553 
14554   ins_encode %{
14555     Label done;
14556     FloatRegister s1 = as_FloatRegister($src1$$reg);
14557     Register d = as_Register($dst$$reg);
14558     __ fcmps(s1, 0.0);
14559     // installs 0 if EQ else -1
14560     __ csinvw(d, zr, zr, Assembler::EQ);
14561     // keeps -1 if less or unordered else installs 1
14562     __ csnegw(d, d, d, Assembler::LT);
14563     __ bind(done);
14564   %}
14565 
14566   ins_pipe(pipe_class_default);
14567 
14568 %}
14569 
14570 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14571 %{
14572   match(Set dst (CmpD3 src1 zero));
14573   effect(KILL cr);
14574 
14575   ins_cost(5 * INSN_COST);
14576   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14577             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14578             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14579   %}
14580 
14581   ins_encode %{
14582     Label done;
14583     FloatRegister s1 = as_FloatRegister($src1$$reg);
14584     Register d = as_Register($dst$$reg);
14585     __ fcmpd(s1, 0.0);
14586     // installs 0 if EQ else -1
14587     __ csinvw(d, zr, zr, Assembler::EQ);
14588     // keeps -1 if less or unordered else installs 1
14589     __ csnegw(d, d, d, Assembler::LT);
14590     __ bind(done);
14591   %}
14592   ins_pipe(pipe_class_default);
14593 
14594 %}
14595 
14596 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14597 %{
14598   match(Set dst (CmpLTMask p q));
14599   effect(KILL cr);
14600 
14601   ins_cost(3 * INSN_COST);
14602 
14603   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14604             &quot;csetw $dst, lt\n\t&quot;
14605             &quot;subw $dst, zr, $dst&quot;
14606   %}
14607 
14608   ins_encode %{
14609     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14610     __ csetw(as_Register($dst$$reg), Assembler::LT);
14611     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14612   %}
14613 
14614   ins_pipe(ialu_reg_reg);
14615 %}
14616 
14617 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14618 %{
14619   match(Set dst (CmpLTMask src zero));
14620   effect(KILL cr);
14621 
14622   ins_cost(INSN_COST);
14623 
14624   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14625 
14626   ins_encode %{
14627     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14628   %}
14629 
14630   ins_pipe(ialu_reg_shift);
14631 %}
14632 
14633 // ============================================================================
14634 // Max and Min
14635 
14636 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14637 %{
14638   effect( DEF dst, USE src1, USE src2, USE cr );
14639 
14640   ins_cost(INSN_COST * 2);
14641   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14642 
14643   ins_encode %{
14644     __ cselw(as_Register($dst$$reg),
14645              as_Register($src1$$reg),
14646              as_Register($src2$$reg),
14647              Assembler::LT);
14648   %}
14649 
14650   ins_pipe(icond_reg_reg);
14651 %}
14652 
14653 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14654 %{
14655   match(Set dst (MinI src1 src2));
14656   ins_cost(INSN_COST * 3);
14657 
14658   expand %{
14659     rFlagsReg cr;
14660     compI_reg_reg(cr, src1, src2);
14661     cmovI_reg_reg_lt(dst, src1, src2, cr);
14662   %}
14663 
14664 %}
14665 // FROM HERE
14666 
14667 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14668 %{
14669   effect( DEF dst, USE src1, USE src2, USE cr );
14670 
14671   ins_cost(INSN_COST * 2);
14672   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14673 
14674   ins_encode %{
14675     __ cselw(as_Register($dst$$reg),
14676              as_Register($src1$$reg),
14677              as_Register($src2$$reg),
14678              Assembler::GT);
14679   %}
14680 
14681   ins_pipe(icond_reg_reg);
14682 %}
14683 
14684 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14685 %{
14686   match(Set dst (MaxI src1 src2));
14687   ins_cost(INSN_COST * 3);
14688   expand %{
14689     rFlagsReg cr;
14690     compI_reg_reg(cr, src1, src2);
14691     cmovI_reg_reg_gt(dst, src1, src2, cr);
14692   %}
14693 %}
14694 
14695 // ============================================================================
14696 // Branch Instructions
14697 
14698 // Direct Branch.
14699 instruct branch(label lbl)
14700 %{
14701   match(Goto);
14702 
14703   effect(USE lbl);
14704 
14705   ins_cost(BRANCH_COST);
14706   format %{ &quot;b  $lbl&quot; %}
14707 
14708   ins_encode(aarch64_enc_b(lbl));
14709 
14710   ins_pipe(pipe_branch);
14711 %}
14712 
14713 // Conditional Near Branch
14714 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14715 %{
14716   // Same match rule as `branchConFar&#39;.
14717   match(If cmp cr);
14718 
14719   effect(USE lbl);
14720 
14721   ins_cost(BRANCH_COST);
14722   // If set to 1 this indicates that the current instruction is a
14723   // short variant of a long branch. This avoids using this
14724   // instruction in first-pass matching. It will then only be used in
14725   // the `Shorten_branches&#39; pass.
14726   // ins_short_branch(1);
14727   format %{ &quot;b$cmp  $lbl&quot; %}
14728 
14729   ins_encode(aarch64_enc_br_con(cmp, lbl));
14730 
14731   ins_pipe(pipe_branch_cond);
14732 %}
14733 
14734 // Conditional Near Branch Unsigned
14735 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14736 %{
14737   // Same match rule as `branchConFar&#39;.
14738   match(If cmp cr);
14739 
14740   effect(USE lbl);
14741 
14742   ins_cost(BRANCH_COST);
14743   // If set to 1 this indicates that the current instruction is a
14744   // short variant of a long branch. This avoids using this
14745   // instruction in first-pass matching. It will then only be used in
14746   // the `Shorten_branches&#39; pass.
14747   // ins_short_branch(1);
14748   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14749 
14750   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14751 
14752   ins_pipe(pipe_branch_cond);
14753 %}
14754 
14755 // Make use of CBZ and CBNZ.  These instructions, as well as being
14756 // shorter than (cmp; branch), have the additional benefit of not
14757 // killing the flags.
14758 
14759 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14760   match(If cmp (CmpI op1 op2));
14761   effect(USE labl);
14762 
14763   ins_cost(BRANCH_COST);
14764   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14765   ins_encode %{
14766     Label* L = $labl$$label;
14767     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14768     if (cond == Assembler::EQ)
14769       __ cbzw($op1$$Register, *L);
14770     else
14771       __ cbnzw($op1$$Register, *L);
14772   %}
14773   ins_pipe(pipe_cmp_branch);
14774 %}
14775 
14776 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14777   match(If cmp (CmpL op1 op2));
14778   effect(USE labl);
14779 
14780   ins_cost(BRANCH_COST);
14781   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14782   ins_encode %{
14783     Label* L = $labl$$label;
14784     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14785     if (cond == Assembler::EQ)
14786       __ cbz($op1$$Register, *L);
14787     else
14788       __ cbnz($op1$$Register, *L);
14789   %}
14790   ins_pipe(pipe_cmp_branch);
14791 %}
14792 
14793 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14794   match(If cmp (CmpP op1 op2));
14795   effect(USE labl);
14796 
14797   ins_cost(BRANCH_COST);
14798   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14799   ins_encode %{
14800     Label* L = $labl$$label;
14801     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14802     if (cond == Assembler::EQ)
14803       __ cbz($op1$$Register, *L);
14804     else
14805       __ cbnz($op1$$Register, *L);
14806   %}
14807   ins_pipe(pipe_cmp_branch);
14808 %}
14809 
14810 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14811   match(If cmp (CmpN op1 op2));
14812   effect(USE labl);
14813 
14814   ins_cost(BRANCH_COST);
14815   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14816   ins_encode %{
14817     Label* L = $labl$$label;
14818     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14819     if (cond == Assembler::EQ)
14820       __ cbzw($op1$$Register, *L);
14821     else
14822       __ cbnzw($op1$$Register, *L);
14823   %}
14824   ins_pipe(pipe_cmp_branch);
14825 %}
14826 
14827 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14828   match(If cmp (CmpP (DecodeN oop) zero));
14829   effect(USE labl);
14830 
14831   ins_cost(BRANCH_COST);
14832   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14833   ins_encode %{
14834     Label* L = $labl$$label;
14835     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14836     if (cond == Assembler::EQ)
14837       __ cbzw($oop$$Register, *L);
14838     else
14839       __ cbnzw($oop$$Register, *L);
14840   %}
14841   ins_pipe(pipe_cmp_branch);
14842 %}
14843 
14844 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14845   match(If cmp (CmpU op1 op2));
14846   effect(USE labl);
14847 
14848   ins_cost(BRANCH_COST);
14849   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14850   ins_encode %{
14851     Label* L = $labl$$label;
14852     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14853     if (cond == Assembler::EQ || cond == Assembler::LS)
14854       __ cbzw($op1$$Register, *L);
14855     else
14856       __ cbnzw($op1$$Register, *L);
14857   %}
14858   ins_pipe(pipe_cmp_branch);
14859 %}
14860 
14861 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14862   match(If cmp (CmpUL op1 op2));
14863   effect(USE labl);
14864 
14865   ins_cost(BRANCH_COST);
14866   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14867   ins_encode %{
14868     Label* L = $labl$$label;
14869     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14870     if (cond == Assembler::EQ || cond == Assembler::LS)
14871       __ cbz($op1$$Register, *L);
14872     else
14873       __ cbnz($op1$$Register, *L);
14874   %}
14875   ins_pipe(pipe_cmp_branch);
14876 %}
14877 
14878 // Test bit and Branch
14879 
14880 // Patterns for short (&lt; 32KiB) variants
14881 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14882   match(If cmp (CmpL op1 op2));
14883   effect(USE labl);
14884 
14885   ins_cost(BRANCH_COST);
14886   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14887   ins_encode %{
14888     Label* L = $labl$$label;
14889     Assembler::Condition cond =
14890       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14891     __ tbr(cond, $op1$$Register, 63, *L);
14892   %}
14893   ins_pipe(pipe_cmp_branch);
14894   ins_short_branch(1);
14895 %}
14896 
14897 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14898   match(If cmp (CmpI op1 op2));
14899   effect(USE labl);
14900 
14901   ins_cost(BRANCH_COST);
14902   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14903   ins_encode %{
14904     Label* L = $labl$$label;
14905     Assembler::Condition cond =
14906       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14907     __ tbr(cond, $op1$$Register, 31, *L);
14908   %}
14909   ins_pipe(pipe_cmp_branch);
14910   ins_short_branch(1);
14911 %}
14912 
14913 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14914   match(If cmp (CmpL (AndL op1 op2) op3));
14915   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14916   effect(USE labl);
14917 
14918   ins_cost(BRANCH_COST);
14919   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14920   ins_encode %{
14921     Label* L = $labl$$label;
14922     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14923     int bit = exact_log2($op2$$constant);
14924     __ tbr(cond, $op1$$Register, bit, *L);
14925   %}
14926   ins_pipe(pipe_cmp_branch);
14927   ins_short_branch(1);
14928 %}
14929 
14930 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14931   match(If cmp (CmpI (AndI op1 op2) op3));
14932   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14933   effect(USE labl);
14934 
14935   ins_cost(BRANCH_COST);
14936   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14937   ins_encode %{
14938     Label* L = $labl$$label;
14939     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14940     int bit = exact_log2($op2$$constant);
14941     __ tbr(cond, $op1$$Register, bit, *L);
14942   %}
14943   ins_pipe(pipe_cmp_branch);
14944   ins_short_branch(1);
14945 %}
14946 
14947 // And far variants
14948 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14949   match(If cmp (CmpL op1 op2));
14950   effect(USE labl);
14951 
14952   ins_cost(BRANCH_COST);
14953   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14954   ins_encode %{
14955     Label* L = $labl$$label;
14956     Assembler::Condition cond =
14957       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14958     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14959   %}
14960   ins_pipe(pipe_cmp_branch);
14961 %}
14962 
14963 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14964   match(If cmp (CmpI op1 op2));
14965   effect(USE labl);
14966 
14967   ins_cost(BRANCH_COST);
14968   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14969   ins_encode %{
14970     Label* L = $labl$$label;
14971     Assembler::Condition cond =
14972       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14973     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
14974   %}
14975   ins_pipe(pipe_cmp_branch);
14976 %}
14977 
14978 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14979   match(If cmp (CmpL (AndL op1 op2) op3));
14980   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14981   effect(USE labl);
14982 
14983   ins_cost(BRANCH_COST);
14984   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14985   ins_encode %{
14986     Label* L = $labl$$label;
14987     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14988     int bit = exact_log2($op2$$constant);
14989     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
14990   %}
14991   ins_pipe(pipe_cmp_branch);
14992 %}
14993 
14994 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14995   match(If cmp (CmpI (AndI op1 op2) op3));
14996   predicate(is_power_of_2(n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14997   effect(USE labl);
14998 
14999   ins_cost(BRANCH_COST);
15000   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15001   ins_encode %{
15002     Label* L = $labl$$label;
15003     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15004     int bit = exact_log2($op2$$constant);
15005     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15006   %}
15007   ins_pipe(pipe_cmp_branch);
15008 %}
15009 
15010 // Test bits
15011 
15012 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15013   match(Set cr (CmpL (AndL op1 op2) op3));
15014   predicate(Assembler::operand_valid_for_logical_immediate
15015             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15016 
15017   ins_cost(INSN_COST);
15018   format %{ &quot;tst $op1, $op2 # long&quot; %}
15019   ins_encode %{
15020     __ tst($op1$$Register, $op2$$constant);
15021   %}
15022   ins_pipe(ialu_reg_reg);
15023 %}
15024 
15025 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15026   match(Set cr (CmpI (AndI op1 op2) op3));
15027   predicate(Assembler::operand_valid_for_logical_immediate
15028             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15029 
15030   ins_cost(INSN_COST);
15031   format %{ &quot;tst $op1, $op2 # int&quot; %}
15032   ins_encode %{
15033     __ tstw($op1$$Register, $op2$$constant);
15034   %}
15035   ins_pipe(ialu_reg_reg);
15036 %}
15037 
15038 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15039   match(Set cr (CmpL (AndL op1 op2) op3));
15040 
15041   ins_cost(INSN_COST);
15042   format %{ &quot;tst $op1, $op2 # long&quot; %}
15043   ins_encode %{
15044     __ tst($op1$$Register, $op2$$Register);
15045   %}
15046   ins_pipe(ialu_reg_reg);
15047 %}
15048 
15049 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15050   match(Set cr (CmpI (AndI op1 op2) op3));
15051 
15052   ins_cost(INSN_COST);
15053   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15054   ins_encode %{
15055     __ tstw($op1$$Register, $op2$$Register);
15056   %}
15057   ins_pipe(ialu_reg_reg);
15058 %}
15059 
15060 
15061 // Conditional Far Branch
15062 // Conditional Far Branch Unsigned
15063 // TODO: fixme
15064 
15065 // counted loop end branch near
15066 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15067 %{
15068   match(CountedLoopEnd cmp cr);
15069 
15070   effect(USE lbl);
15071 
15072   ins_cost(BRANCH_COST);
15073   // short variant.
15074   // ins_short_branch(1);
15075   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15076 
15077   ins_encode(aarch64_enc_br_con(cmp, lbl));
15078 
15079   ins_pipe(pipe_branch);
15080 %}
15081 
15082 // counted loop end branch near Unsigned
15083 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15084 %{
15085   match(CountedLoopEnd cmp cr);
15086 
15087   effect(USE lbl);
15088 
15089   ins_cost(BRANCH_COST);
15090   // short variant.
15091   // ins_short_branch(1);
15092   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15093 
15094   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15095 
15096   ins_pipe(pipe_branch);
15097 %}
15098 
15099 // counted loop end branch far
15100 // counted loop end branch far unsigned
15101 // TODO: fixme
15102 
15103 // ============================================================================
15104 // inlined locking and unlocking
15105 
15106 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15107 %{
15108   match(Set cr (FastLock object box));
15109   effect(TEMP tmp, TEMP tmp2);
15110 
15111   // TODO
15112   // identify correct cost
15113   ins_cost(5 * INSN_COST);
15114   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15115 
15116   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15117 
15118   ins_pipe(pipe_serial);
15119 %}
15120 
15121 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15122 %{
15123   match(Set cr (FastUnlock object box));
15124   effect(TEMP tmp, TEMP tmp2);
15125 
15126   ins_cost(5 * INSN_COST);
15127   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15128 
15129   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15130 
15131   ins_pipe(pipe_serial);
15132 %}
15133 
15134 
15135 // ============================================================================
15136 // Safepoint Instructions
15137 
15138 // TODO
15139 // provide a near and far version of this code
15140 
15141 instruct safePoint(rFlagsReg cr, iRegP poll)
15142 %{
15143   match(SafePoint poll);
15144   effect(KILL cr);
15145 
15146   format %{
15147     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15148   %}
15149   ins_encode %{
15150     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15151   %}
15152   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15153 %}
15154 
15155 
15156 // ============================================================================
15157 // Procedure Call/Return Instructions
15158 
15159 // Call Java Static Instruction
15160 
15161 instruct CallStaticJavaDirect(method meth)
15162 %{
15163   match(CallStaticJava);
15164 
15165   effect(USE meth);
15166 
15167   ins_cost(CALL_COST);
15168 
15169   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15170 
15171   ins_encode( aarch64_enc_java_static_call(meth),
15172               aarch64_enc_call_epilog );
15173 
15174   ins_pipe(pipe_class_call);
15175 %}
15176 
15177 // TO HERE
15178 
15179 // Call Java Dynamic Instruction
15180 instruct CallDynamicJavaDirect(method meth)
15181 %{
15182   match(CallDynamicJava);
15183 
15184   effect(USE meth);
15185 
15186   ins_cost(CALL_COST);
15187 
15188   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15189 
15190   ins_encode( aarch64_enc_java_dynamic_call(meth),
15191                aarch64_enc_call_epilog );
15192 
15193   ins_pipe(pipe_class_call);
15194 %}
15195 
15196 // Call Runtime Instruction
15197 
15198 instruct CallRuntimeDirect(method meth)
15199 %{
15200   match(CallRuntime);
15201 
15202   effect(USE meth);
15203 
15204   ins_cost(CALL_COST);
15205 
15206   format %{ &quot;CALL, runtime $meth&quot; %}
15207 
15208   ins_encode( aarch64_enc_java_to_runtime(meth) );
15209 
15210   ins_pipe(pipe_class_call);
15211 %}
15212 
15213 // Call Runtime Instruction
15214 
15215 instruct CallLeafDirect(method meth)
15216 %{
15217   match(CallLeaf);
15218 
15219   effect(USE meth);
15220 
15221   ins_cost(CALL_COST);
15222 
15223   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15224 
15225   ins_encode( aarch64_enc_java_to_runtime(meth) );
15226 
15227   ins_pipe(pipe_class_call);
15228 %}
15229 
15230 // Call Runtime Instruction
15231 
15232 instruct CallLeafNoFPDirect(method meth)
15233 %{
15234   match(CallLeafNoFP);
15235 
15236   effect(USE meth);
15237 
15238   ins_cost(CALL_COST);
15239 
15240   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15241 
15242   ins_encode( aarch64_enc_java_to_runtime(meth) );
15243 
15244   ins_pipe(pipe_class_call);
15245 %}
15246 
15247 // Tail Call; Jump from runtime stub to Java code.
15248 // Also known as an &#39;interprocedural jump&#39;.
15249 // Target of jump will eventually return to caller.
15250 // TailJump below removes the return address.
15251 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15252 %{
15253   match(TailCall jump_target method_oop);
15254 
15255   ins_cost(CALL_COST);
15256 
15257   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15258 
15259   ins_encode(aarch64_enc_tail_call(jump_target));
15260 
15261   ins_pipe(pipe_class_call);
15262 %}
15263 
15264 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15265 %{
15266   match(TailJump jump_target ex_oop);
15267 
15268   ins_cost(CALL_COST);
15269 
15270   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15271 
15272   ins_encode(aarch64_enc_tail_jmp(jump_target));
15273 
15274   ins_pipe(pipe_class_call);
15275 %}
15276 
15277 // Create exception oop: created by stack-crawling runtime code.
15278 // Created exception is now available to this handler, and is setup
15279 // just prior to jumping to this handler. No code emitted.
15280 // TODO check
15281 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15282 instruct CreateException(iRegP_R0 ex_oop)
15283 %{
15284   match(Set ex_oop (CreateEx));
15285 
15286   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15287 
15288   size(0);
15289 
15290   ins_encode( /*empty*/ );
15291 
15292   ins_pipe(pipe_class_empty);
15293 %}
15294 
15295 // Rethrow exception: The exception oop will come in the first
15296 // argument position. Then JUMP (not call) to the rethrow stub code.
15297 instruct RethrowException() %{
15298   match(Rethrow);
15299   ins_cost(CALL_COST);
15300 
15301   format %{ &quot;b rethrow_stub&quot; %}
15302 
15303   ins_encode( aarch64_enc_rethrow() );
15304 
15305   ins_pipe(pipe_class_call);
15306 %}
15307 
15308 
15309 // Return Instruction
15310 // epilog node loads ret address into lr as part of frame pop
15311 instruct Ret()
15312 %{
15313   match(Return);
15314 
15315   format %{ &quot;ret\t// return register&quot; %}
15316 
15317   ins_encode( aarch64_enc_ret() );
15318 
15319   ins_pipe(pipe_branch);
15320 %}
15321 
15322 // Die now.
15323 instruct ShouldNotReachHere() %{
15324   match(Halt);
15325 
15326   ins_cost(CALL_COST);
15327   format %{ &quot;ShouldNotReachHere&quot; %}
15328 
15329   ins_encode %{
15330     // +1 so NativeInstruction::is_sigill_zombie_not_entrant() doesn&#39;t
15331     // return true
15332     __ dpcs1(0xdead + 1);
15333   %}
15334 
15335   ins_pipe(pipe_class_default);
15336 %}
15337 
15338 // ============================================================================
15339 // Partial Subtype Check
15340 //
15341 // superklass array for an instance of the superklass.  Set a hidden
15342 // internal cache on a hit (cache is checked with exposed code in
15343 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15344 // encoding ALSO sets flags.
15345 
15346 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15347 %{
15348   match(Set result (PartialSubtypeCheck sub super));
15349   effect(KILL cr, KILL temp);
15350 
15351   ins_cost(1100);  // slightly larger than the next version
15352   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15353 
15354   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15355 
15356   opcode(0x1); // Force zero of result reg on hit
15357 
15358   ins_pipe(pipe_class_memory);
15359 %}
15360 
15361 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15362 %{
15363   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15364   effect(KILL temp, KILL result);
15365 
15366   ins_cost(1100);  // slightly larger than the next version
15367   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15368 
15369   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15370 
15371   opcode(0x0); // Don&#39;t zero result reg on hit
15372 
15373   ins_pipe(pipe_class_memory);
15374 %}
15375 
15376 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15377                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15378 %{
15379   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15380   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15381   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15382 
15383   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15384   ins_encode %{
15385     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15386     __ string_compare($str1$$Register, $str2$$Register,
15387                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15388                       $tmp1$$Register, $tmp2$$Register,
15389                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15390   %}
15391   ins_pipe(pipe_class_memory);
15392 %}
15393 
15394 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15395                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15396 %{
15397   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15398   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15399   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15400 
15401   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15402   ins_encode %{
15403     __ string_compare($str1$$Register, $str2$$Register,
15404                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15405                       $tmp1$$Register, $tmp2$$Register,
15406                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15407   %}
15408   ins_pipe(pipe_class_memory);
15409 %}
15410 
15411 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15412                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15413                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15414 %{
15415   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15416   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15417   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15418          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15419 
15420   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15421   ins_encode %{
15422     __ string_compare($str1$$Register, $str2$$Register,
15423                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15424                       $tmp1$$Register, $tmp2$$Register,
15425                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15426                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15427   %}
15428   ins_pipe(pipe_class_memory);
15429 %}
15430 
15431 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15432                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15433                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15434 %{
15435   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15436   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15437   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15438          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15439 
15440   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15441   ins_encode %{
15442     __ string_compare($str1$$Register, $str2$$Register,
15443                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15444                       $tmp1$$Register, $tmp2$$Register,
15445                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15446                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15447   %}
15448   ins_pipe(pipe_class_memory);
15449 %}
15450 
15451 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15452        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15453        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15454 %{
15455   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15456   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15457   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15458          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15459   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15460 
15461   ins_encode %{
15462     __ string_indexof($str1$$Register, $str2$$Register,
15463                       $cnt1$$Register, $cnt2$$Register,
15464                       $tmp1$$Register, $tmp2$$Register,
15465                       $tmp3$$Register, $tmp4$$Register,
15466                       $tmp5$$Register, $tmp6$$Register,
15467                       -1, $result$$Register, StrIntrinsicNode::UU);
15468   %}
15469   ins_pipe(pipe_class_memory);
15470 %}
15471 
15472 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15473        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15474        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15475 %{
15476   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15477   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15478   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15479          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15480   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15481 
15482   ins_encode %{
15483     __ string_indexof($str1$$Register, $str2$$Register,
15484                       $cnt1$$Register, $cnt2$$Register,
15485                       $tmp1$$Register, $tmp2$$Register,
15486                       $tmp3$$Register, $tmp4$$Register,
15487                       $tmp5$$Register, $tmp6$$Register,
15488                       -1, $result$$Register, StrIntrinsicNode::LL);
15489   %}
15490   ins_pipe(pipe_class_memory);
15491 %}
15492 
15493 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15494        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15495        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15496 %{
15497   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15498   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15499   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15500          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15501   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15502 
15503   ins_encode %{
15504     __ string_indexof($str1$$Register, $str2$$Register,
15505                       $cnt1$$Register, $cnt2$$Register,
15506                       $tmp1$$Register, $tmp2$$Register,
15507                       $tmp3$$Register, $tmp4$$Register,
15508                       $tmp5$$Register, $tmp6$$Register,
15509                       -1, $result$$Register, StrIntrinsicNode::UL);
15510   %}
15511   ins_pipe(pipe_class_memory);
15512 %}
15513 
15514 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15515                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15516                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15517 %{
15518   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15519   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15520   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15521          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15522   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15523 
15524   ins_encode %{
15525     int icnt2 = (int)$int_cnt2$$constant;
15526     __ string_indexof($str1$$Register, $str2$$Register,
15527                       $cnt1$$Register, zr,
15528                       $tmp1$$Register, $tmp2$$Register,
15529                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15530                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15531   %}
15532   ins_pipe(pipe_class_memory);
15533 %}
15534 
15535 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15536                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15537                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15538 %{
15539   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15540   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15541   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15542          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15543   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15544 
15545   ins_encode %{
15546     int icnt2 = (int)$int_cnt2$$constant;
15547     __ string_indexof($str1$$Register, $str2$$Register,
15548                       $cnt1$$Register, zr,
15549                       $tmp1$$Register, $tmp2$$Register,
15550                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15551                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15552   %}
15553   ins_pipe(pipe_class_memory);
15554 %}
15555 
15556 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15557                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15558                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15559 %{
15560   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15561   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15562   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15563          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15564   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15565 
15566   ins_encode %{
15567     int icnt2 = (int)$int_cnt2$$constant;
15568     __ string_indexof($str1$$Register, $str2$$Register,
15569                       $cnt1$$Register, zr,
15570                       $tmp1$$Register, $tmp2$$Register,
15571                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15572                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15573   %}
15574   ins_pipe(pipe_class_memory);
15575 %}
15576 
15577 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15578                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15579                               iRegINoSp tmp3, rFlagsReg cr)
15580 %{
15581   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15582   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15583          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15584 
15585   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15586 
15587   ins_encode %{
15588     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15589                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15590                            $tmp3$$Register);
15591   %}
15592   ins_pipe(pipe_class_memory);
15593 %}
15594 
15595 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15596                         iRegI_R0 result, rFlagsReg cr)
15597 %{
15598   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15599   match(Set result (StrEquals (Binary str1 str2) cnt));
15600   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15601 
15602   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15603   ins_encode %{
15604     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15605     __ string_equals($str1$$Register, $str2$$Register,
15606                      $result$$Register, $cnt$$Register, 1);
15607   %}
15608   ins_pipe(pipe_class_memory);
15609 %}
15610 
15611 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15612                         iRegI_R0 result, rFlagsReg cr)
15613 %{
15614   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15615   match(Set result (StrEquals (Binary str1 str2) cnt));
15616   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15617 
15618   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15619   ins_encode %{
15620     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15621     __ string_equals($str1$$Register, $str2$$Register,
15622                      $result$$Register, $cnt$$Register, 2);
15623   %}
15624   ins_pipe(pipe_class_memory);
15625 %}
15626 
15627 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15628                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15629                        iRegP_R10 tmp, rFlagsReg cr)
15630 %{
15631   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15632   match(Set result (AryEq ary1 ary2));
15633   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15634 
15635   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15636   ins_encode %{
15637     __ arrays_equals($ary1$$Register, $ary2$$Register,
15638                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15639                      $result$$Register, $tmp$$Register, 1);
15640     %}
15641   ins_pipe(pipe_class_memory);
15642 %}
15643 
15644 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15645                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15646                        iRegP_R10 tmp, rFlagsReg cr)
15647 %{
15648   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15649   match(Set result (AryEq ary1 ary2));
15650   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15651 
15652   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15653   ins_encode %{
15654     __ arrays_equals($ary1$$Register, $ary2$$Register,
15655                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15656                      $result$$Register, $tmp$$Register, 2);
15657   %}
15658   ins_pipe(pipe_class_memory);
15659 %}
15660 
15661 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15662 %{
15663   match(Set result (HasNegatives ary1 len));
15664   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15665   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15666   ins_encode %{
15667     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15668   %}
15669   ins_pipe( pipe_slow );
15670 %}
15671 
15672 // fast char[] to byte[] compression
15673 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15674                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15675                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15676                          iRegI_R0 result, rFlagsReg cr)
15677 %{
15678   match(Set result (StrCompressedCopy src (Binary dst len)));
15679   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15680 
15681   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15682   ins_encode %{
15683     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15684                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15685                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15686                            $result$$Register);
15687   %}
15688   ins_pipe( pipe_slow );
15689 %}
15690 
15691 // fast byte[] to char[] inflation
15692 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15693                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15694 %{
15695   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15696   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15697 
15698   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15699   ins_encode %{
15700     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15701                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15702   %}
15703   ins_pipe(pipe_class_memory);
15704 %}
15705 
15706 // encode char[] to byte[] in ISO_8859_1
15707 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15708                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15709                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15710                           iRegI_R0 result, rFlagsReg cr)
15711 %{
15712   match(Set result (EncodeISOArray src (Binary dst len)));
15713   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15714          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15715 
15716   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15717   ins_encode %{
15718     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15719          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15720          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15721   %}
15722   ins_pipe( pipe_class_memory );
15723 %}
15724 
15725 // ============================================================================
15726 // This name is KNOWN by the ADLC and cannot be changed.
15727 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15728 // for this guy.
15729 instruct tlsLoadP(thread_RegP dst)
15730 %{
15731   match(Set dst (ThreadLocal));
15732 
15733   ins_cost(0);
15734 
15735   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15736 
15737   size(0);
15738 
15739   ins_encode( /*empty*/ );
15740 
15741   ins_pipe(pipe_class_empty);
15742 %}
15743 
15744 // ====================VECTOR INSTRUCTIONS=====================================
15745 
15746 // Load vector (32 bits)
15747 instruct loadV4(vecD dst, vmem4 mem)
15748 %{
15749   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15750   match(Set dst (LoadVector mem));
15751   ins_cost(4 * INSN_COST);
15752   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15753   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15754   ins_pipe(vload_reg_mem64);
15755 %}
15756 
15757 // Load vector (64 bits)
15758 instruct loadV8(vecD dst, vmem8 mem)
15759 %{
15760   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15761   match(Set dst (LoadVector mem));
15762   ins_cost(4 * INSN_COST);
15763   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15764   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15765   ins_pipe(vload_reg_mem64);
15766 %}
15767 
15768 // Load Vector (128 bits)
15769 instruct loadV16(vecX dst, vmem16 mem)
15770 %{
15771   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15772   match(Set dst (LoadVector mem));
15773   ins_cost(4 * INSN_COST);
15774   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15775   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15776   ins_pipe(vload_reg_mem128);
15777 %}
15778 
15779 // Store Vector (32 bits)
15780 instruct storeV4(vecD src, vmem4 mem)
15781 %{
15782   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15783   match(Set mem (StoreVector mem src));
15784   ins_cost(4 * INSN_COST);
15785   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15786   ins_encode( aarch64_enc_strvS(src, mem) );
15787   ins_pipe(vstore_reg_mem64);
15788 %}
15789 
15790 // Store Vector (64 bits)
15791 instruct storeV8(vecD src, vmem8 mem)
15792 %{
15793   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15794   match(Set mem (StoreVector mem src));
15795   ins_cost(4 * INSN_COST);
15796   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15797   ins_encode( aarch64_enc_strvD(src, mem) );
15798   ins_pipe(vstore_reg_mem64);
15799 %}
15800 
15801 // Store Vector (128 bits)
15802 instruct storeV16(vecX src, vmem16 mem)
15803 %{
15804   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15805   match(Set mem (StoreVector mem src));
15806   ins_cost(4 * INSN_COST);
15807   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15808   ins_encode( aarch64_enc_strvQ(src, mem) );
15809   ins_pipe(vstore_reg_mem128);
15810 %}
15811 
15812 instruct replicate8B(vecD dst, iRegIorL2I src)
15813 %{
15814   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15815             n-&gt;as_Vector()-&gt;length() == 8);
15816   match(Set dst (ReplicateB src));
15817   ins_cost(INSN_COST);
15818   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15819   ins_encode %{
15820     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15821   %}
15822   ins_pipe(vdup_reg_reg64);
15823 %}
15824 
15825 instruct replicate16B(vecX dst, iRegIorL2I src)
15826 %{
15827   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15828   match(Set dst (ReplicateB src));
15829   ins_cost(INSN_COST);
15830   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15831   ins_encode %{
15832     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15833   %}
15834   ins_pipe(vdup_reg_reg128);
15835 %}
15836 
15837 instruct replicate8B_imm(vecD dst, immI con)
15838 %{
15839   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15840             n-&gt;as_Vector()-&gt;length() == 8);
15841   match(Set dst (ReplicateB con));
15842   ins_cost(INSN_COST);
15843   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15844   ins_encode %{
15845     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15846   %}
15847   ins_pipe(vmovi_reg_imm64);
15848 %}
15849 
15850 instruct replicate16B_imm(vecX dst, immI con)
15851 %{
15852   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15853   match(Set dst (ReplicateB con));
15854   ins_cost(INSN_COST);
15855   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15856   ins_encode %{
15857     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15858   %}
15859   ins_pipe(vmovi_reg_imm128);
15860 %}
15861 
15862 instruct replicate4S(vecD dst, iRegIorL2I src)
15863 %{
15864   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15865             n-&gt;as_Vector()-&gt;length() == 4);
15866   match(Set dst (ReplicateS src));
15867   ins_cost(INSN_COST);
15868   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15869   ins_encode %{
15870     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15871   %}
15872   ins_pipe(vdup_reg_reg64);
15873 %}
15874 
15875 instruct replicate8S(vecX dst, iRegIorL2I src)
15876 %{
15877   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15878   match(Set dst (ReplicateS src));
15879   ins_cost(INSN_COST);
15880   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15881   ins_encode %{
15882     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15883   %}
15884   ins_pipe(vdup_reg_reg128);
15885 %}
15886 
15887 instruct replicate4S_imm(vecD dst, immI con)
15888 %{
15889   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15890             n-&gt;as_Vector()-&gt;length() == 4);
15891   match(Set dst (ReplicateS con));
15892   ins_cost(INSN_COST);
15893   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15894   ins_encode %{
15895     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15896   %}
15897   ins_pipe(vmovi_reg_imm64);
15898 %}
15899 
15900 instruct replicate8S_imm(vecX dst, immI con)
15901 %{
15902   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15903   match(Set dst (ReplicateS con));
15904   ins_cost(INSN_COST);
15905   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15906   ins_encode %{
15907     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15908   %}
15909   ins_pipe(vmovi_reg_imm128);
15910 %}
15911 
15912 instruct replicate2I(vecD dst, iRegIorL2I src)
15913 %{
15914   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15915   match(Set dst (ReplicateI src));
15916   ins_cost(INSN_COST);
15917   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15918   ins_encode %{
15919     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15920   %}
15921   ins_pipe(vdup_reg_reg64);
15922 %}
15923 
15924 instruct replicate4I(vecX dst, iRegIorL2I src)
15925 %{
15926   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15927   match(Set dst (ReplicateI src));
15928   ins_cost(INSN_COST);
15929   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15930   ins_encode %{
15931     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15932   %}
15933   ins_pipe(vdup_reg_reg128);
15934 %}
15935 
15936 instruct replicate2I_imm(vecD dst, immI con)
15937 %{
15938   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15939   match(Set dst (ReplicateI con));
15940   ins_cost(INSN_COST);
15941   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15942   ins_encode %{
15943     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15944   %}
15945   ins_pipe(vmovi_reg_imm64);
15946 %}
15947 
15948 instruct replicate4I_imm(vecX dst, immI con)
15949 %{
15950   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15951   match(Set dst (ReplicateI con));
15952   ins_cost(INSN_COST);
15953   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15954   ins_encode %{
15955     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15956   %}
15957   ins_pipe(vmovi_reg_imm128);
15958 %}
15959 
15960 instruct replicate2L(vecX dst, iRegL src)
15961 %{
15962   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15963   match(Set dst (ReplicateL src));
15964   ins_cost(INSN_COST);
15965   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15966   ins_encode %{
15967     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15968   %}
15969   ins_pipe(vdup_reg_reg128);
15970 %}
15971 
15972 instruct replicate2L_zero(vecX dst, immI0 zero)
15973 %{
15974   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15975   match(Set dst (ReplicateI zero));
15976   ins_cost(INSN_COST);
15977   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
15978   ins_encode %{
15979     __ eor(as_FloatRegister($dst$$reg), __ T16B,
15980            as_FloatRegister($dst$$reg),
15981            as_FloatRegister($dst$$reg));
15982   %}
15983   ins_pipe(vmovi_reg_imm128);
15984 %}
15985 
15986 instruct replicate2F(vecD dst, vRegF src)
15987 %{
15988   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15989   match(Set dst (ReplicateF src));
15990   ins_cost(INSN_COST);
15991   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
15992   ins_encode %{
15993     __ dup(as_FloatRegister($dst$$reg), __ T2S,
15994            as_FloatRegister($src$$reg));
15995   %}
15996   ins_pipe(vdup_reg_freg64);
15997 %}
15998 
15999 instruct replicate4F(vecX dst, vRegF src)
16000 %{
16001   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16002   match(Set dst (ReplicateF src));
16003   ins_cost(INSN_COST);
16004   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16005   ins_encode %{
16006     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16007            as_FloatRegister($src$$reg));
16008   %}
16009   ins_pipe(vdup_reg_freg128);
16010 %}
16011 
16012 instruct replicate2D(vecX dst, vRegD src)
16013 %{
16014   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16015   match(Set dst (ReplicateD src));
16016   ins_cost(INSN_COST);
16017   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16018   ins_encode %{
16019     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16020            as_FloatRegister($src$$reg));
16021   %}
16022   ins_pipe(vdup_reg_dreg128);
16023 %}
16024 
16025 // ====================REDUCTION ARITHMETIC====================================
16026 
16027 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp, iRegINoSp tmp2)
16028 %{
16029   match(Set dst (AddReductionVI src1 src2));
16030   ins_cost(INSN_COST);
16031   effect(TEMP tmp, TEMP tmp2);
16032   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16033             &quot;umov  $tmp2, $src2, S, 1\n\t&quot;
16034             &quot;addw  $dst, $src1, $tmp\n\t&quot;
16035             &quot;addw  $dst, $dst, $tmp2\t add reduction2i&quot;
16036   %}
16037   ins_encode %{
16038     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16039     __ umov($tmp2$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16040     __ addw($dst$$Register, $src1$$Register, $tmp$$Register);
16041     __ addw($dst$$Register, $dst$$Register, $tmp2$$Register);
16042   %}
16043   ins_pipe(pipe_class_default);
16044 %}
16045 
16046 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16047 %{
16048   match(Set dst (AddReductionVI src1 src2));
16049   ins_cost(INSN_COST);
16050   effect(TEMP tmp, TEMP tmp2);
16051   format %{ &quot;addv  $tmp, T4S, $src2\n\t&quot;
16052             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16053             &quot;addw  $dst, $tmp2, $src1\t add reduction4i&quot;
16054   %}
16055   ins_encode %{
16056     __ addv(as_FloatRegister($tmp$$reg), __ T4S,
16057             as_FloatRegister($src2$$reg));
16058     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16059     __ addw($dst$$Register, $tmp2$$Register, $src1$$Register);
16060   %}
16061   ins_pipe(pipe_class_default);
16062 %}
16063 
16064 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I src1, vecD src2, iRegINoSp tmp)
16065 %{
16066   match(Set dst (MulReductionVI src1 src2));
16067   ins_cost(INSN_COST);
16068   effect(TEMP tmp, TEMP dst);
16069   format %{ &quot;umov  $tmp, $src2, S, 0\n\t&quot;
16070             &quot;mul   $dst, $tmp, $src1\n\t&quot;
16071             &quot;umov  $tmp, $src2, S, 1\n\t&quot;
16072             &quot;mul   $dst, $tmp, $dst\t mul reduction2i\n\t&quot;
16073   %}
16074   ins_encode %{
16075     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 0);
16076     __ mul($dst$$Register, $tmp$$Register, $src1$$Register);
16077     __ umov($tmp$$Register, as_FloatRegister($src2$$reg), __ S, 1);
16078     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16079   %}
16080   ins_pipe(pipe_class_default);
16081 %}
16082 
16083 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I src1, vecX src2, vecX tmp, iRegINoSp tmp2)
16084 %{
16085   match(Set dst (MulReductionVI src1 src2));
16086   ins_cost(INSN_COST);
16087   effect(TEMP tmp, TEMP tmp2, TEMP dst);
16088   format %{ &quot;ins   $tmp, $src2, 0, 1\n\t&quot;
16089             &quot;mul   $tmp, $tmp, $src2\n\t&quot;
16090             &quot;umov  $tmp2, $tmp, S, 0\n\t&quot;
16091             &quot;mul   $dst, $tmp2, $src1\n\t&quot;
16092             &quot;umov  $tmp2, $tmp, S, 1\n\t&quot;
16093             &quot;mul   $dst, $tmp2, $dst\t mul reduction4i\n\t&quot;
16094   %}
16095   ins_encode %{
16096     __ ins(as_FloatRegister($tmp$$reg), __ D,
16097            as_FloatRegister($src2$$reg), 0, 1);
16098     __ mulv(as_FloatRegister($tmp$$reg), __ T2S,
16099            as_FloatRegister($tmp$$reg), as_FloatRegister($src2$$reg));
16100     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 0);
16101     __ mul($dst$$Register, $tmp2$$Register, $src1$$Register);
16102     __ umov($tmp2$$Register, as_FloatRegister($tmp$$reg), __ S, 1);
16103     __ mul($dst$$Register, $tmp2$$Register, $dst$$Register);
16104   %}
16105   ins_pipe(pipe_class_default);
16106 %}
16107 
16108 instruct reduce_add2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16109 %{
16110   match(Set dst (AddReductionVF src1 src2));
16111   ins_cost(INSN_COST);
16112   effect(TEMP tmp, TEMP dst);
16113   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16114             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16115             &quot;fadds $dst, $dst, $tmp\t add reduction2f&quot;
16116   %}
16117   ins_encode %{
16118     __ fadds(as_FloatRegister($dst$$reg),
16119              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16120     __ ins(as_FloatRegister($tmp$$reg), __ S,
16121            as_FloatRegister($src2$$reg), 0, 1);
16122     __ fadds(as_FloatRegister($dst$$reg),
16123              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16124   %}
16125   ins_pipe(pipe_class_default);
16126 %}
16127 
16128 instruct reduce_add4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16129 %{
16130   match(Set dst (AddReductionVF src1 src2));
16131   ins_cost(INSN_COST);
16132   effect(TEMP tmp, TEMP dst);
16133   format %{ &quot;fadds $dst, $src1, $src2\n\t&quot;
16134             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16135             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16136             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16137             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16138             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16139             &quot;fadds $dst, $dst, $tmp\t add reduction4f&quot;
16140   %}
16141   ins_encode %{
16142     __ fadds(as_FloatRegister($dst$$reg),
16143              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16144     __ ins(as_FloatRegister($tmp$$reg), __ S,
16145            as_FloatRegister($src2$$reg), 0, 1);
16146     __ fadds(as_FloatRegister($dst$$reg),
16147              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16148     __ ins(as_FloatRegister($tmp$$reg), __ S,
16149            as_FloatRegister($src2$$reg), 0, 2);
16150     __ fadds(as_FloatRegister($dst$$reg),
16151              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16152     __ ins(as_FloatRegister($tmp$$reg), __ S,
16153            as_FloatRegister($src2$$reg), 0, 3);
16154     __ fadds(as_FloatRegister($dst$$reg),
16155              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16156   %}
16157   ins_pipe(pipe_class_default);
16158 %}
16159 
16160 instruct reduce_mul2F(vRegF dst, vRegF src1, vecD src2, vecD tmp)
16161 %{
16162   match(Set dst (MulReductionVF src1 src2));
16163   ins_cost(INSN_COST);
16164   effect(TEMP tmp, TEMP dst);
16165   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16166             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16167             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16168   %}
16169   ins_encode %{
16170     __ fmuls(as_FloatRegister($dst$$reg),
16171              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16172     __ ins(as_FloatRegister($tmp$$reg), __ S,
16173            as_FloatRegister($src2$$reg), 0, 1);
16174     __ fmuls(as_FloatRegister($dst$$reg),
16175              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16176   %}
16177   ins_pipe(pipe_class_default);
16178 %}
16179 
16180 instruct reduce_mul4F(vRegF dst, vRegF src1, vecX src2, vecX tmp)
16181 %{
16182   match(Set dst (MulReductionVF src1 src2));
16183   ins_cost(INSN_COST);
16184   effect(TEMP tmp, TEMP dst);
16185   format %{ &quot;fmuls $dst, $src1, $src2\n\t&quot;
16186             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16187             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16188             &quot;ins   $tmp, S, $src2, 0, 2\n\t&quot;
16189             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16190             &quot;ins   $tmp, S, $src2, 0, 3\n\t&quot;
16191             &quot;fmuls $dst, $dst, $tmp\t add reduction4f&quot;
16192   %}
16193   ins_encode %{
16194     __ fmuls(as_FloatRegister($dst$$reg),
16195              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16196     __ ins(as_FloatRegister($tmp$$reg), __ S,
16197            as_FloatRegister($src2$$reg), 0, 1);
16198     __ fmuls(as_FloatRegister($dst$$reg),
16199              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16200     __ ins(as_FloatRegister($tmp$$reg), __ S,
16201            as_FloatRegister($src2$$reg), 0, 2);
16202     __ fmuls(as_FloatRegister($dst$$reg),
16203              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16204     __ ins(as_FloatRegister($tmp$$reg), __ S,
16205            as_FloatRegister($src2$$reg), 0, 3);
16206     __ fmuls(as_FloatRegister($dst$$reg),
16207              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16208   %}
16209   ins_pipe(pipe_class_default);
16210 %}
16211 
16212 instruct reduce_add2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16213 %{
16214   match(Set dst (AddReductionVD src1 src2));
16215   ins_cost(INSN_COST);
16216   effect(TEMP tmp, TEMP dst);
16217   format %{ &quot;faddd $dst, $src1, $src2\n\t&quot;
16218             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16219             &quot;faddd $dst, $dst, $tmp\t add reduction2d&quot;
16220   %}
16221   ins_encode %{
16222     __ faddd(as_FloatRegister($dst$$reg),
16223              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16224     __ ins(as_FloatRegister($tmp$$reg), __ D,
16225            as_FloatRegister($src2$$reg), 0, 1);
16226     __ faddd(as_FloatRegister($dst$$reg),
16227              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16228   %}
16229   ins_pipe(pipe_class_default);
16230 %}
16231 
16232 instruct reduce_mul2D(vRegD dst, vRegD src1, vecX src2, vecX tmp)
16233 %{
16234   match(Set dst (MulReductionVD src1 src2));
16235   ins_cost(INSN_COST);
16236   effect(TEMP tmp, TEMP dst);
16237   format %{ &quot;fmuld $dst, $src1, $src2\n\t&quot;
16238             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16239             &quot;fmuld $dst, $dst, $tmp\t add reduction2d&quot;
16240   %}
16241   ins_encode %{
16242     __ fmuld(as_FloatRegister($dst$$reg),
16243              as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16244     __ ins(as_FloatRegister($tmp$$reg), __ D,
16245            as_FloatRegister($src2$$reg), 0, 1);
16246     __ fmuld(as_FloatRegister($dst$$reg),
16247              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16248   %}
16249   ins_pipe(pipe_class_default);
16250 %}
16251 
16252 instruct reduce_max2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16253   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16254   match(Set dst (MaxReductionV src1 src2));
16255   ins_cost(INSN_COST);
16256   effect(TEMP_DEF dst, TEMP tmp);
16257   format %{ &quot;fmaxs $dst, $src1, $src2\n\t&quot;
16258             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16259             &quot;fmaxs $dst, $dst, $tmp\t max reduction2F&quot; %}
16260   ins_encode %{
16261     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16262     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16263     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16264   %}
16265   ins_pipe(pipe_class_default);
16266 %}
16267 
16268 instruct reduce_max4F(vRegF dst, vRegF src1, vecX src2) %{
16269   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16270   match(Set dst (MaxReductionV src1 src2));
16271   ins_cost(INSN_COST);
16272   effect(TEMP_DEF dst);
16273   format %{ &quot;fmaxv $dst, T4S, $src2\n\t&quot;
16274             &quot;fmaxs $dst, $dst, $src1\t max reduction4F&quot; %}
16275   ins_encode %{
16276     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16277     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16278   %}
16279   ins_pipe(pipe_class_default);
16280 %}
16281 
16282 instruct reduce_max2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16283   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16284   match(Set dst (MaxReductionV src1 src2));
16285   ins_cost(INSN_COST);
16286   effect(TEMP_DEF dst, TEMP tmp);
16287   format %{ &quot;fmaxd $dst, $src1, $src2\n\t&quot;
16288             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16289             &quot;fmaxd $dst, $dst, $tmp\t max reduction2D&quot; %}
16290   ins_encode %{
16291     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16292     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16293     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16294   %}
16295   ins_pipe(pipe_class_default);
16296 %}
16297 
16298 instruct reduce_min2F(vRegF dst, vRegF src1, vecD src2, vecD tmp) %{
16299   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16300   match(Set dst (MinReductionV src1 src2));
16301   ins_cost(INSN_COST);
16302   effect(TEMP_DEF dst, TEMP tmp);
16303   format %{ &quot;fmins $dst, $src1, $src2\n\t&quot;
16304             &quot;ins   $tmp, S, $src2, 0, 1\n\t&quot;
16305             &quot;fmins $dst, $dst, $tmp\t min reduction2F&quot; %}
16306   ins_encode %{
16307     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16308     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($src2$$reg), 0, 1);
16309     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16310   %}
16311   ins_pipe(pipe_class_default);
16312 %}
16313 
16314 instruct reduce_min4F(vRegF dst, vRegF src1, vecX src2) %{
16315   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16316   match(Set dst (MinReductionV src1 src2));
16317   ins_cost(INSN_COST);
16318   effect(TEMP_DEF dst);
16319   format %{ &quot;fminv $dst, T4S, $src2\n\t&quot;
16320             &quot;fmins $dst, $dst, $src1\t min reduction4F&quot; %}
16321   ins_encode %{
16322     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src2$$reg));
16323     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));
16324   %}
16325   ins_pipe(pipe_class_default);
16326 %}
16327 
16328 instruct reduce_min2D(vRegD dst, vRegD src1, vecX src2, vecX tmp) %{
16329   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16330   match(Set dst (MinReductionV src1 src2));
16331   ins_cost(INSN_COST);
16332   effect(TEMP_DEF dst, TEMP tmp);
16333   format %{ &quot;fmind $dst, $src1, $src2\n\t&quot;
16334             &quot;ins   $tmp, D, $src2, 0, 1\n\t&quot;
16335             &quot;fmind $dst, $dst, $tmp\t min reduction2D&quot; %}
16336   ins_encode %{
16337     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
16338     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($src2$$reg), 0, 1);
16339     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16340   %}
16341   ins_pipe(pipe_class_default);
16342 %}
16343 
16344 // ====================VECTOR ARITHMETIC=======================================
16345 
16346 // --------------------------------- ADD --------------------------------------
16347 
16348 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16349 %{
16350   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16351             n-&gt;as_Vector()-&gt;length() == 8);
16352   match(Set dst (AddVB src1 src2));
16353   ins_cost(INSN_COST);
16354   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16355   ins_encode %{
16356     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16357             as_FloatRegister($src1$$reg),
16358             as_FloatRegister($src2$$reg));
16359   %}
16360   ins_pipe(vdop64);
16361 %}
16362 
16363 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16364 %{
16365   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16366   match(Set dst (AddVB src1 src2));
16367   ins_cost(INSN_COST);
16368   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16369   ins_encode %{
16370     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16371             as_FloatRegister($src1$$reg),
16372             as_FloatRegister($src2$$reg));
16373   %}
16374   ins_pipe(vdop128);
16375 %}
16376 
16377 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16378 %{
16379   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16380             n-&gt;as_Vector()-&gt;length() == 4);
16381   match(Set dst (AddVS src1 src2));
16382   ins_cost(INSN_COST);
16383   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16384   ins_encode %{
16385     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16386             as_FloatRegister($src1$$reg),
16387             as_FloatRegister($src2$$reg));
16388   %}
16389   ins_pipe(vdop64);
16390 %}
16391 
16392 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16393 %{
16394   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16395   match(Set dst (AddVS src1 src2));
16396   ins_cost(INSN_COST);
16397   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16398   ins_encode %{
16399     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16400             as_FloatRegister($src1$$reg),
16401             as_FloatRegister($src2$$reg));
16402   %}
16403   ins_pipe(vdop128);
16404 %}
16405 
16406 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16407 %{
16408   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16409   match(Set dst (AddVI src1 src2));
16410   ins_cost(INSN_COST);
16411   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16412   ins_encode %{
16413     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16414             as_FloatRegister($src1$$reg),
16415             as_FloatRegister($src2$$reg));
16416   %}
16417   ins_pipe(vdop64);
16418 %}
16419 
16420 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16421 %{
16422   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16423   match(Set dst (AddVI src1 src2));
16424   ins_cost(INSN_COST);
16425   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16426   ins_encode %{
16427     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16428             as_FloatRegister($src1$$reg),
16429             as_FloatRegister($src2$$reg));
16430   %}
16431   ins_pipe(vdop128);
16432 %}
16433 
16434 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16435 %{
16436   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16437   match(Set dst (AddVL src1 src2));
16438   ins_cost(INSN_COST);
16439   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16440   ins_encode %{
16441     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16442             as_FloatRegister($src1$$reg),
16443             as_FloatRegister($src2$$reg));
16444   %}
16445   ins_pipe(vdop128);
16446 %}
16447 
16448 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16449 %{
16450   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16451   match(Set dst (AddVF src1 src2));
16452   ins_cost(INSN_COST);
16453   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16454   ins_encode %{
16455     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16456             as_FloatRegister($src1$$reg),
16457             as_FloatRegister($src2$$reg));
16458   %}
16459   ins_pipe(vdop_fp64);
16460 %}
16461 
16462 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16463 %{
16464   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16465   match(Set dst (AddVF src1 src2));
16466   ins_cost(INSN_COST);
16467   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16468   ins_encode %{
16469     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16470             as_FloatRegister($src1$$reg),
16471             as_FloatRegister($src2$$reg));
16472   %}
16473   ins_pipe(vdop_fp128);
16474 %}
16475 
16476 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16477 %{
16478   match(Set dst (AddVD src1 src2));
16479   ins_cost(INSN_COST);
16480   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16481   ins_encode %{
16482     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16483             as_FloatRegister($src1$$reg),
16484             as_FloatRegister($src2$$reg));
16485   %}
16486   ins_pipe(vdop_fp128);
16487 %}
16488 
16489 // --------------------------------- SUB --------------------------------------
16490 
16491 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16492 %{
16493   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16494             n-&gt;as_Vector()-&gt;length() == 8);
16495   match(Set dst (SubVB src1 src2));
16496   ins_cost(INSN_COST);
16497   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16498   ins_encode %{
16499     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16500             as_FloatRegister($src1$$reg),
16501             as_FloatRegister($src2$$reg));
16502   %}
16503   ins_pipe(vdop64);
16504 %}
16505 
16506 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16507 %{
16508   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16509   match(Set dst (SubVB src1 src2));
16510   ins_cost(INSN_COST);
16511   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16512   ins_encode %{
16513     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16514             as_FloatRegister($src1$$reg),
16515             as_FloatRegister($src2$$reg));
16516   %}
16517   ins_pipe(vdop128);
16518 %}
16519 
16520 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16521 %{
16522   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16523             n-&gt;as_Vector()-&gt;length() == 4);
16524   match(Set dst (SubVS src1 src2));
16525   ins_cost(INSN_COST);
16526   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16527   ins_encode %{
16528     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16529             as_FloatRegister($src1$$reg),
16530             as_FloatRegister($src2$$reg));
16531   %}
16532   ins_pipe(vdop64);
16533 %}
16534 
16535 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16536 %{
16537   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16538   match(Set dst (SubVS src1 src2));
16539   ins_cost(INSN_COST);
16540   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16541   ins_encode %{
16542     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16543             as_FloatRegister($src1$$reg),
16544             as_FloatRegister($src2$$reg));
16545   %}
16546   ins_pipe(vdop128);
16547 %}
16548 
16549 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16550 %{
16551   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16552   match(Set dst (SubVI src1 src2));
16553   ins_cost(INSN_COST);
16554   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16555   ins_encode %{
16556     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16557             as_FloatRegister($src1$$reg),
16558             as_FloatRegister($src2$$reg));
16559   %}
16560   ins_pipe(vdop64);
16561 %}
16562 
16563 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16564 %{
16565   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16566   match(Set dst (SubVI src1 src2));
16567   ins_cost(INSN_COST);
16568   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16569   ins_encode %{
16570     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16571             as_FloatRegister($src1$$reg),
16572             as_FloatRegister($src2$$reg));
16573   %}
16574   ins_pipe(vdop128);
16575 %}
16576 
16577 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16578 %{
16579   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16580   match(Set dst (SubVL src1 src2));
16581   ins_cost(INSN_COST);
16582   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16583   ins_encode %{
16584     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16585             as_FloatRegister($src1$$reg),
16586             as_FloatRegister($src2$$reg));
16587   %}
16588   ins_pipe(vdop128);
16589 %}
16590 
16591 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16592 %{
16593   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16594   match(Set dst (SubVF src1 src2));
16595   ins_cost(INSN_COST);
16596   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16597   ins_encode %{
16598     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16599             as_FloatRegister($src1$$reg),
16600             as_FloatRegister($src2$$reg));
16601   %}
16602   ins_pipe(vdop_fp64);
16603 %}
16604 
16605 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16606 %{
16607   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16608   match(Set dst (SubVF src1 src2));
16609   ins_cost(INSN_COST);
16610   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16611   ins_encode %{
16612     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16613             as_FloatRegister($src1$$reg),
16614             as_FloatRegister($src2$$reg));
16615   %}
16616   ins_pipe(vdop_fp128);
16617 %}
16618 
16619 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16620 %{
16621   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16622   match(Set dst (SubVD src1 src2));
16623   ins_cost(INSN_COST);
16624   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16625   ins_encode %{
16626     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16627             as_FloatRegister($src1$$reg),
16628             as_FloatRegister($src2$$reg));
16629   %}
16630   ins_pipe(vdop_fp128);
16631 %}
16632 
16633 // --------------------------------- MUL --------------------------------------
16634 
16635 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16636 %{
16637   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16638             n-&gt;as_Vector()-&gt;length() == 4);
16639   match(Set dst (MulVS src1 src2));
16640   ins_cost(INSN_COST);
16641   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16642   ins_encode %{
16643     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16644             as_FloatRegister($src1$$reg),
16645             as_FloatRegister($src2$$reg));
16646   %}
16647   ins_pipe(vmul64);
16648 %}
16649 
16650 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16651 %{
16652   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16653   match(Set dst (MulVS src1 src2));
16654   ins_cost(INSN_COST);
16655   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16656   ins_encode %{
16657     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16658             as_FloatRegister($src1$$reg),
16659             as_FloatRegister($src2$$reg));
16660   %}
16661   ins_pipe(vmul128);
16662 %}
16663 
16664 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16665 %{
16666   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16667   match(Set dst (MulVI src1 src2));
16668   ins_cost(INSN_COST);
16669   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16670   ins_encode %{
16671     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16672             as_FloatRegister($src1$$reg),
16673             as_FloatRegister($src2$$reg));
16674   %}
16675   ins_pipe(vmul64);
16676 %}
16677 
16678 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16679 %{
16680   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16681   match(Set dst (MulVI src1 src2));
16682   ins_cost(INSN_COST);
16683   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16684   ins_encode %{
16685     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16686             as_FloatRegister($src1$$reg),
16687             as_FloatRegister($src2$$reg));
16688   %}
16689   ins_pipe(vmul128);
16690 %}
16691 
16692 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16693 %{
16694   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16695   match(Set dst (MulVF src1 src2));
16696   ins_cost(INSN_COST);
16697   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16698   ins_encode %{
16699     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16700             as_FloatRegister($src1$$reg),
16701             as_FloatRegister($src2$$reg));
16702   %}
16703   ins_pipe(vmuldiv_fp64);
16704 %}
16705 
16706 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16707 %{
16708   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16709   match(Set dst (MulVF src1 src2));
16710   ins_cost(INSN_COST);
16711   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16712   ins_encode %{
16713     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16714             as_FloatRegister($src1$$reg),
16715             as_FloatRegister($src2$$reg));
16716   %}
16717   ins_pipe(vmuldiv_fp128);
16718 %}
16719 
16720 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16721 %{
16722   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16723   match(Set dst (MulVD src1 src2));
16724   ins_cost(INSN_COST);
16725   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16726   ins_encode %{
16727     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16728             as_FloatRegister($src1$$reg),
16729             as_FloatRegister($src2$$reg));
16730   %}
16731   ins_pipe(vmuldiv_fp128);
16732 %}
16733 
16734 // --------------------------------- MLA --------------------------------------
16735 
16736 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16737 %{
16738   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16739             n-&gt;as_Vector()-&gt;length() == 4);
16740   match(Set dst (AddVS dst (MulVS src1 src2)));
16741   ins_cost(INSN_COST);
16742   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16743   ins_encode %{
16744     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16745             as_FloatRegister($src1$$reg),
16746             as_FloatRegister($src2$$reg));
16747   %}
16748   ins_pipe(vmla64);
16749 %}
16750 
16751 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16752 %{
16753   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16754   match(Set dst (AddVS dst (MulVS src1 src2)));
16755   ins_cost(INSN_COST);
16756   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16757   ins_encode %{
16758     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16759             as_FloatRegister($src1$$reg),
16760             as_FloatRegister($src2$$reg));
16761   %}
16762   ins_pipe(vmla128);
16763 %}
16764 
16765 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16766 %{
16767   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16768   match(Set dst (AddVI dst (MulVI src1 src2)));
16769   ins_cost(INSN_COST);
16770   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16771   ins_encode %{
16772     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16773             as_FloatRegister($src1$$reg),
16774             as_FloatRegister($src2$$reg));
16775   %}
16776   ins_pipe(vmla64);
16777 %}
16778 
16779 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16780 %{
16781   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16782   match(Set dst (AddVI dst (MulVI src1 src2)));
16783   ins_cost(INSN_COST);
16784   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16785   ins_encode %{
16786     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16787             as_FloatRegister($src1$$reg),
16788             as_FloatRegister($src2$$reg));
16789   %}
16790   ins_pipe(vmla128);
16791 %}
16792 
16793 // dst + src1 * src2
16794 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16795   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16796   match(Set dst (FmaVF  dst (Binary src1 src2)));
16797   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16798   ins_cost(INSN_COST);
16799   ins_encode %{
16800     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16801             as_FloatRegister($src1$$reg),
16802             as_FloatRegister($src2$$reg));
16803   %}
16804   ins_pipe(vmuldiv_fp64);
16805 %}
16806 
16807 // dst + src1 * src2
16808 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16809   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16810   match(Set dst (FmaVF  dst (Binary src1 src2)));
16811   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16812   ins_cost(INSN_COST);
16813   ins_encode %{
16814     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16815             as_FloatRegister($src1$$reg),
16816             as_FloatRegister($src2$$reg));
16817   %}
16818   ins_pipe(vmuldiv_fp128);
16819 %}
16820 
16821 // dst + src1 * src2
16822 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16823   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16824   match(Set dst (FmaVD  dst (Binary src1 src2)));
16825   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16826   ins_cost(INSN_COST);
16827   ins_encode %{
16828     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16829             as_FloatRegister($src1$$reg),
16830             as_FloatRegister($src2$$reg));
16831   %}
16832   ins_pipe(vmuldiv_fp128);
16833 %}
16834 
16835 // --------------------------------- MLS --------------------------------------
16836 
16837 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16838 %{
16839   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16840             n-&gt;as_Vector()-&gt;length() == 4);
16841   match(Set dst (SubVS dst (MulVS src1 src2)));
16842   ins_cost(INSN_COST);
16843   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16844   ins_encode %{
16845     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16846             as_FloatRegister($src1$$reg),
16847             as_FloatRegister($src2$$reg));
16848   %}
16849   ins_pipe(vmla64);
16850 %}
16851 
16852 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16853 %{
16854   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16855   match(Set dst (SubVS dst (MulVS src1 src2)));
16856   ins_cost(INSN_COST);
16857   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16858   ins_encode %{
16859     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16860             as_FloatRegister($src1$$reg),
16861             as_FloatRegister($src2$$reg));
16862   %}
16863   ins_pipe(vmla128);
16864 %}
16865 
16866 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16867 %{
16868   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16869   match(Set dst (SubVI dst (MulVI src1 src2)));
16870   ins_cost(INSN_COST);
16871   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16872   ins_encode %{
16873     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16874             as_FloatRegister($src1$$reg),
16875             as_FloatRegister($src2$$reg));
16876   %}
16877   ins_pipe(vmla64);
16878 %}
16879 
16880 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16881 %{
16882   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16883   match(Set dst (SubVI dst (MulVI src1 src2)));
16884   ins_cost(INSN_COST);
16885   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16886   ins_encode %{
16887     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16888             as_FloatRegister($src1$$reg),
16889             as_FloatRegister($src2$$reg));
16890   %}
16891   ins_pipe(vmla128);
16892 %}
16893 
16894 // dst - src1 * src2
16895 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16896   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16897   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16898   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16899   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16900   ins_cost(INSN_COST);
16901   ins_encode %{
16902     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16903             as_FloatRegister($src1$$reg),
16904             as_FloatRegister($src2$$reg));
16905   %}
16906   ins_pipe(vmuldiv_fp64);
16907 %}
16908 
16909 // dst - src1 * src2
16910 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16911   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16912   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16913   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16914   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16915   ins_cost(INSN_COST);
16916   ins_encode %{
16917     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16918             as_FloatRegister($src1$$reg),
16919             as_FloatRegister($src2$$reg));
16920   %}
16921   ins_pipe(vmuldiv_fp128);
16922 %}
16923 
16924 // dst - src1 * src2
16925 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16926   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16927   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16928   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16929   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16930   ins_cost(INSN_COST);
16931   ins_encode %{
16932     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16933             as_FloatRegister($src1$$reg),
16934             as_FloatRegister($src2$$reg));
16935   %}
16936   ins_pipe(vmuldiv_fp128);
16937 %}
16938 
16939 // --------------------------------- DIV --------------------------------------
16940 
16941 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
16942 %{
16943   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16944   match(Set dst (DivVF src1 src2));
16945   ins_cost(INSN_COST);
16946   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16947   ins_encode %{
16948     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
16949             as_FloatRegister($src1$$reg),
16950             as_FloatRegister($src2$$reg));
16951   %}
16952   ins_pipe(vmuldiv_fp64);
16953 %}
16954 
16955 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
16956 %{
16957   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16958   match(Set dst (DivVF src1 src2));
16959   ins_cost(INSN_COST);
16960   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16961   ins_encode %{
16962     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
16963             as_FloatRegister($src1$$reg),
16964             as_FloatRegister($src2$$reg));
16965   %}
16966   ins_pipe(vmuldiv_fp128);
16967 %}
16968 
16969 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
16970 %{
16971   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16972   match(Set dst (DivVD src1 src2));
16973   ins_cost(INSN_COST);
16974   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
16975   ins_encode %{
16976     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
16977             as_FloatRegister($src1$$reg),
16978             as_FloatRegister($src2$$reg));
16979   %}
16980   ins_pipe(vmuldiv_fp128);
16981 %}
16982 
16983 // --------------------------------- SQRT -------------------------------------
16984 
16985 instruct vsqrt2D(vecX dst, vecX src)
16986 %{
16987   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16988   match(Set dst (SqrtVD src));
16989   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
16990   ins_encode %{
16991     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
16992              as_FloatRegister($src$$reg));
16993   %}
16994   ins_pipe(vsqrt_fp128);
16995 %}
16996 
16997 // --------------------------------- ABS --------------------------------------
16998 
16999 instruct vabs2F(vecD dst, vecD src)
17000 %{
17001   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17002   match(Set dst (AbsVF src));
17003   ins_cost(INSN_COST * 3);
17004   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17005   ins_encode %{
17006     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17007             as_FloatRegister($src$$reg));
17008   %}
17009   ins_pipe(vunop_fp64);
17010 %}
17011 
17012 instruct vabs4F(vecX dst, vecX src)
17013 %{
17014   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17015   match(Set dst (AbsVF src));
17016   ins_cost(INSN_COST * 3);
17017   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17018   ins_encode %{
17019     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17020             as_FloatRegister($src$$reg));
17021   %}
17022   ins_pipe(vunop_fp128);
17023 %}
17024 
17025 instruct vabs2D(vecX dst, vecX src)
17026 %{
17027   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17028   match(Set dst (AbsVD src));
17029   ins_cost(INSN_COST * 3);
17030   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17031   ins_encode %{
17032     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17033             as_FloatRegister($src$$reg));
17034   %}
17035   ins_pipe(vunop_fp128);
17036 %}
17037 
17038 // --------------------------------- NEG --------------------------------------
17039 
17040 instruct vneg2F(vecD dst, vecD src)
17041 %{
17042   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17043   match(Set dst (NegVF src));
17044   ins_cost(INSN_COST * 3);
17045   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17046   ins_encode %{
17047     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17048             as_FloatRegister($src$$reg));
17049   %}
17050   ins_pipe(vunop_fp64);
17051 %}
17052 
17053 instruct vneg4F(vecX dst, vecX src)
17054 %{
17055   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17056   match(Set dst (NegVF src));
17057   ins_cost(INSN_COST * 3);
17058   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17059   ins_encode %{
17060     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17061             as_FloatRegister($src$$reg));
17062   %}
17063   ins_pipe(vunop_fp128);
17064 %}
17065 
17066 instruct vneg2D(vecX dst, vecX src)
17067 %{
17068   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17069   match(Set dst (NegVD src));
17070   ins_cost(INSN_COST * 3);
17071   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17072   ins_encode %{
17073     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17074             as_FloatRegister($src$$reg));
17075   %}
17076   ins_pipe(vunop_fp128);
17077 %}
17078 
17079 // --------------------------------- AND --------------------------------------
17080 
17081 instruct vand8B(vecD dst, vecD src1, vecD src2)
17082 %{
17083   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17084             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17085   match(Set dst (AndV src1 src2));
17086   ins_cost(INSN_COST);
17087   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17088   ins_encode %{
17089     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17090             as_FloatRegister($src1$$reg),
17091             as_FloatRegister($src2$$reg));
17092   %}
17093   ins_pipe(vlogical64);
17094 %}
17095 
17096 instruct vand16B(vecX dst, vecX src1, vecX src2)
17097 %{
17098   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17099   match(Set dst (AndV src1 src2));
17100   ins_cost(INSN_COST);
17101   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17102   ins_encode %{
17103     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17104             as_FloatRegister($src1$$reg),
17105             as_FloatRegister($src2$$reg));
17106   %}
17107   ins_pipe(vlogical128);
17108 %}
17109 
17110 // --------------------------------- OR ---------------------------------------
17111 
17112 instruct vor8B(vecD dst, vecD src1, vecD src2)
17113 %{
17114   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17115             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17116   match(Set dst (OrV src1 src2));
17117   ins_cost(INSN_COST);
17118   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17119   ins_encode %{
17120     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17121             as_FloatRegister($src1$$reg),
17122             as_FloatRegister($src2$$reg));
17123   %}
17124   ins_pipe(vlogical64);
17125 %}
17126 
17127 instruct vor16B(vecX dst, vecX src1, vecX src2)
17128 %{
17129   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17130   match(Set dst (OrV src1 src2));
17131   ins_cost(INSN_COST);
17132   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17133   ins_encode %{
17134     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17135             as_FloatRegister($src1$$reg),
17136             as_FloatRegister($src2$$reg));
17137   %}
17138   ins_pipe(vlogical128);
17139 %}
17140 
17141 // --------------------------------- XOR --------------------------------------
17142 
17143 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17144 %{
17145   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17146             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17147   match(Set dst (XorV src1 src2));
17148   ins_cost(INSN_COST);
17149   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17150   ins_encode %{
17151     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17152             as_FloatRegister($src1$$reg),
17153             as_FloatRegister($src2$$reg));
17154   %}
17155   ins_pipe(vlogical64);
17156 %}
17157 
17158 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17159 %{
17160   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17161   match(Set dst (XorV src1 src2));
17162   ins_cost(INSN_COST);
17163   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17164   ins_encode %{
17165     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17166             as_FloatRegister($src1$$reg),
17167             as_FloatRegister($src2$$reg));
17168   %}
17169   ins_pipe(vlogical128);
17170 %}
17171 
17172 // ------------------------------ Shift ---------------------------------------
17173 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17174   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17175   match(Set dst (LShiftCntV cnt));
17176   match(Set dst (RShiftCntV cnt));
17177   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17178   ins_encode %{
17179     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17180   %}
17181   ins_pipe(vdup_reg_reg64);
17182 %}
17183 
17184 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17185   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17186   match(Set dst (LShiftCntV cnt));
17187   match(Set dst (RShiftCntV cnt));
17188   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17189   ins_encode %{
17190     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17191   %}
17192   ins_pipe(vdup_reg_reg128);
17193 %}
17194 
17195 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17196   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17197             n-&gt;as_Vector()-&gt;length() == 8);
17198   match(Set dst (LShiftVB src shift));
17199   ins_cost(INSN_COST);
17200   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17201   ins_encode %{
17202     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17203             as_FloatRegister($src$$reg),
17204             as_FloatRegister($shift$$reg));
17205   %}
17206   ins_pipe(vshift64);
17207 %}
17208 
17209 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17210   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17211   match(Set dst (LShiftVB src shift));
17212   ins_cost(INSN_COST);
17213   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17214   ins_encode %{
17215     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17216             as_FloatRegister($src$$reg),
17217             as_FloatRegister($shift$$reg));
17218   %}
17219   ins_pipe(vshift128);
17220 %}
17221 
17222 // Right shifts with vector shift count on aarch64 SIMD are implemented
17223 // as left shift by negative shift count.
17224 // There are two cases for vector shift count.
17225 //
17226 // Case 1: The vector shift count is from replication.
17227 //        |            |
17228 //    LoadVector  RShiftCntV
17229 //        |       /
17230 //     RShiftVI
17231 // Note: In inner loop, multiple neg instructions are used, which can be
17232 // moved to outer loop and merge into one neg instruction.
17233 //
17234 // Case 2: The vector shift count is from loading.
17235 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17236 // panama/vectorIntrinsics(JEP 338: Vector API).
17237 //        |            |
17238 //    LoadVector  LoadVector
17239 //        |       /
17240 //     RShiftVI
17241 //
17242 
17243 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17244   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17245             n-&gt;as_Vector()-&gt;length() == 8);
17246   match(Set dst (RShiftVB src shift));
17247   ins_cost(INSN_COST);
17248   effect(TEMP tmp);
17249   format %{ &quot;negr  $tmp,$shift\t&quot;
17250             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17251   ins_encode %{
17252     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17253             as_FloatRegister($shift$$reg));
17254     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17255             as_FloatRegister($src$$reg),
17256             as_FloatRegister($tmp$$reg));
17257   %}
17258   ins_pipe(vshift64);
17259 %}
17260 
17261 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17262   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17263   match(Set dst (RShiftVB src shift));
17264   ins_cost(INSN_COST);
17265   effect(TEMP tmp);
17266   format %{ &quot;negr  $tmp,$shift\t&quot;
17267             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17268   ins_encode %{
17269     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17270             as_FloatRegister($shift$$reg));
17271     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17272             as_FloatRegister($src$$reg),
17273             as_FloatRegister($tmp$$reg));
17274   %}
17275   ins_pipe(vshift128);
17276 %}
17277 
17278 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17279   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17280             n-&gt;as_Vector()-&gt;length() == 8);
17281   match(Set dst (URShiftVB src shift));
17282   ins_cost(INSN_COST);
17283   effect(TEMP tmp);
17284   format %{ &quot;negr  $tmp,$shift\t&quot;
17285             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17286   ins_encode %{
17287     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17288             as_FloatRegister($shift$$reg));
17289     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17290             as_FloatRegister($src$$reg),
17291             as_FloatRegister($tmp$$reg));
17292   %}
17293   ins_pipe(vshift64);
17294 %}
17295 
17296 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17297   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17298   match(Set dst (URShiftVB src shift));
17299   ins_cost(INSN_COST);
17300   effect(TEMP tmp);
17301   format %{ &quot;negr  $tmp,$shift\t&quot;
17302             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17303   ins_encode %{
17304     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17305             as_FloatRegister($shift$$reg));
17306     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17307             as_FloatRegister($src$$reg),
17308             as_FloatRegister($tmp$$reg));
17309   %}
17310   ins_pipe(vshift128);
17311 %}
17312 
17313 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17314   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17315             n-&gt;as_Vector()-&gt;length() == 8);
17316   match(Set dst (LShiftVB src shift));
17317   ins_cost(INSN_COST);
17318   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17319   ins_encode %{
17320     int sh = (int)$shift$$constant;
17321     if (sh &gt;= 8) {
17322       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17323              as_FloatRegister($src$$reg),
17324              as_FloatRegister($src$$reg));
17325     } else {
17326       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17327              as_FloatRegister($src$$reg), sh);
17328     }
17329   %}
17330   ins_pipe(vshift64_imm);
17331 %}
17332 
17333 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17334   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17335   match(Set dst (LShiftVB src shift));
17336   ins_cost(INSN_COST);
17337   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17338   ins_encode %{
17339     int sh = (int)$shift$$constant;
17340     if (sh &gt;= 8) {
17341       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17342              as_FloatRegister($src$$reg),
17343              as_FloatRegister($src$$reg));
17344     } else {
17345       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17346              as_FloatRegister($src$$reg), sh);
17347     }
17348   %}
17349   ins_pipe(vshift128_imm);
17350 %}
17351 
17352 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17353   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17354             n-&gt;as_Vector()-&gt;length() == 8);
17355   match(Set dst (RShiftVB src shift));
17356   ins_cost(INSN_COST);
17357   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17358   ins_encode %{
17359     int sh = (int)$shift$$constant;
17360     if (sh &gt;= 8) sh = 7;
17361     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17362            as_FloatRegister($src$$reg), sh);
17363   %}
17364   ins_pipe(vshift64_imm);
17365 %}
17366 
17367 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17368   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17369   match(Set dst (RShiftVB src shift));
17370   ins_cost(INSN_COST);
17371   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17372   ins_encode %{
17373     int sh = (int)$shift$$constant;
17374     if (sh &gt;= 8) sh = 7;
17375     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17376            as_FloatRegister($src$$reg), sh);
17377   %}
17378   ins_pipe(vshift128_imm);
17379 %}
17380 
17381 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17382   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17383             n-&gt;as_Vector()-&gt;length() == 8);
17384   match(Set dst (URShiftVB src shift));
17385   ins_cost(INSN_COST);
17386   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17387   ins_encode %{
17388     int sh = (int)$shift$$constant;
17389     if (sh &gt;= 8) {
17390       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17391              as_FloatRegister($src$$reg),
17392              as_FloatRegister($src$$reg));
17393     } else {
17394       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17395              as_FloatRegister($src$$reg), sh);
17396     }
17397   %}
17398   ins_pipe(vshift64_imm);
17399 %}
17400 
17401 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17402   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17403   match(Set dst (URShiftVB src shift));
17404   ins_cost(INSN_COST);
17405   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17406   ins_encode %{
17407     int sh = (int)$shift$$constant;
17408     if (sh &gt;= 8) {
17409       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17410              as_FloatRegister($src$$reg),
17411              as_FloatRegister($src$$reg));
17412     } else {
17413       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17414              as_FloatRegister($src$$reg), sh);
17415     }
17416   %}
17417   ins_pipe(vshift128_imm);
17418 %}
17419 
17420 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17421   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17422             n-&gt;as_Vector()-&gt;length() == 4);
17423   match(Set dst (LShiftVS src shift));
17424   ins_cost(INSN_COST);
17425   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17426   ins_encode %{
17427     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17428             as_FloatRegister($src$$reg),
17429             as_FloatRegister($shift$$reg));
17430   %}
17431   ins_pipe(vshift64);
17432 %}
17433 
17434 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17435   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17436   match(Set dst (LShiftVS src shift));
17437   ins_cost(INSN_COST);
17438   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17439   ins_encode %{
17440     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17441             as_FloatRegister($src$$reg),
17442             as_FloatRegister($shift$$reg));
17443   %}
17444   ins_pipe(vshift128);
17445 %}
17446 
17447 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17448   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17449             n-&gt;as_Vector()-&gt;length() == 4);
17450   match(Set dst (RShiftVS src shift));
17451   ins_cost(INSN_COST);
17452   effect(TEMP tmp);
17453   format %{ &quot;negr  $tmp,$shift\t&quot;
17454             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17455   ins_encode %{
17456     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17457             as_FloatRegister($shift$$reg));
17458     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17459             as_FloatRegister($src$$reg),
17460             as_FloatRegister($tmp$$reg));
17461   %}
17462   ins_pipe(vshift64);
17463 %}
17464 
17465 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17466   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17467   match(Set dst (RShiftVS src shift));
17468   ins_cost(INSN_COST);
17469   effect(TEMP tmp);
17470   format %{ &quot;negr  $tmp,$shift\t&quot;
17471             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17472   ins_encode %{
17473     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17474             as_FloatRegister($shift$$reg));
17475     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17476             as_FloatRegister($src$$reg),
17477             as_FloatRegister($tmp$$reg));
17478   %}
17479   ins_pipe(vshift128);
17480 %}
17481 
17482 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17483   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17484             n-&gt;as_Vector()-&gt;length() == 4);
17485   match(Set dst (URShiftVS src shift));
17486   ins_cost(INSN_COST);
17487   effect(TEMP tmp);
17488   format %{ &quot;negr  $tmp,$shift\t&quot;
17489             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17490   ins_encode %{
17491     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17492             as_FloatRegister($shift$$reg));
17493     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17494             as_FloatRegister($src$$reg),
17495             as_FloatRegister($tmp$$reg));
17496   %}
17497   ins_pipe(vshift64);
17498 %}
17499 
17500 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17501   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17502   match(Set dst (URShiftVS src shift));
17503   ins_cost(INSN_COST);
17504   effect(TEMP tmp);
17505   format %{ &quot;negr  $tmp,$shift\t&quot;
17506             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17507   ins_encode %{
17508     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17509             as_FloatRegister($shift$$reg));
17510     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17511             as_FloatRegister($src$$reg),
17512             as_FloatRegister($tmp$$reg));
17513   %}
17514   ins_pipe(vshift128);
17515 %}
17516 
17517 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17518   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17519             n-&gt;as_Vector()-&gt;length() == 4);
17520   match(Set dst (LShiftVS src shift));
17521   ins_cost(INSN_COST);
17522   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17523   ins_encode %{
17524     int sh = (int)$shift$$constant;
17525     if (sh &gt;= 16) {
17526       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17527              as_FloatRegister($src$$reg),
17528              as_FloatRegister($src$$reg));
17529     } else {
17530       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17531              as_FloatRegister($src$$reg), sh);
17532     }
17533   %}
17534   ins_pipe(vshift64_imm);
17535 %}
17536 
17537 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17538   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17539   match(Set dst (LShiftVS src shift));
17540   ins_cost(INSN_COST);
17541   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17542   ins_encode %{
17543     int sh = (int)$shift$$constant;
17544     if (sh &gt;= 16) {
17545       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17546              as_FloatRegister($src$$reg),
17547              as_FloatRegister($src$$reg));
17548     } else {
17549       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17550              as_FloatRegister($src$$reg), sh);
17551     }
17552   %}
17553   ins_pipe(vshift128_imm);
17554 %}
17555 
17556 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17557   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17558             n-&gt;as_Vector()-&gt;length() == 4);
17559   match(Set dst (RShiftVS src shift));
17560   ins_cost(INSN_COST);
17561   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17562   ins_encode %{
17563     int sh = (int)$shift$$constant;
17564     if (sh &gt;= 16) sh = 15;
17565     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17566            as_FloatRegister($src$$reg), sh);
17567   %}
17568   ins_pipe(vshift64_imm);
17569 %}
17570 
17571 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17572   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17573   match(Set dst (RShiftVS src shift));
17574   ins_cost(INSN_COST);
17575   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17576   ins_encode %{
17577     int sh = (int)$shift$$constant;
17578     if (sh &gt;= 16) sh = 15;
17579     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17580            as_FloatRegister($src$$reg), sh);
17581   %}
17582   ins_pipe(vshift128_imm);
17583 %}
17584 
17585 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17586   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17587             n-&gt;as_Vector()-&gt;length() == 4);
17588   match(Set dst (URShiftVS src shift));
17589   ins_cost(INSN_COST);
17590   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17591   ins_encode %{
17592     int sh = (int)$shift$$constant;
17593     if (sh &gt;= 16) {
17594       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17595              as_FloatRegister($src$$reg),
17596              as_FloatRegister($src$$reg));
17597     } else {
17598       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17599              as_FloatRegister($src$$reg), sh);
17600     }
17601   %}
17602   ins_pipe(vshift64_imm);
17603 %}
17604 
17605 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17606   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17607   match(Set dst (URShiftVS src shift));
17608   ins_cost(INSN_COST);
17609   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17610   ins_encode %{
17611     int sh = (int)$shift$$constant;
17612     if (sh &gt;= 16) {
17613       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17614              as_FloatRegister($src$$reg),
17615              as_FloatRegister($src$$reg));
17616     } else {
17617       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17618              as_FloatRegister($src$$reg), sh);
17619     }
17620   %}
17621   ins_pipe(vshift128_imm);
17622 %}
17623 
17624 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17625   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17626   match(Set dst (LShiftVI src shift));
17627   ins_cost(INSN_COST);
17628   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17629   ins_encode %{
17630     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17631             as_FloatRegister($src$$reg),
17632             as_FloatRegister($shift$$reg));
17633   %}
17634   ins_pipe(vshift64);
17635 %}
17636 
17637 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17638   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17639   match(Set dst (LShiftVI src shift));
17640   ins_cost(INSN_COST);
17641   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17642   ins_encode %{
17643     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17644             as_FloatRegister($src$$reg),
17645             as_FloatRegister($shift$$reg));
17646   %}
17647   ins_pipe(vshift128);
17648 %}
17649 
17650 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17651   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17652   match(Set dst (RShiftVI src shift));
17653   ins_cost(INSN_COST);
17654   effect(TEMP tmp);
17655   format %{ &quot;negr  $tmp,$shift\t&quot;
17656             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17657   ins_encode %{
17658     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17659             as_FloatRegister($shift$$reg));
17660     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17661             as_FloatRegister($src$$reg),
17662             as_FloatRegister($tmp$$reg));
17663   %}
17664   ins_pipe(vshift64);
17665 %}
17666 
17667 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17668   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17669   match(Set dst (RShiftVI src shift));
17670   ins_cost(INSN_COST);
17671   effect(TEMP tmp);
17672   format %{ &quot;negr  $tmp,$shift\t&quot;
17673             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17674   ins_encode %{
17675     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17676             as_FloatRegister($shift$$reg));
17677     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17678             as_FloatRegister($src$$reg),
17679             as_FloatRegister($tmp$$reg));
17680   %}
17681   ins_pipe(vshift128);
17682 %}
17683 
17684 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17685   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17686   match(Set dst (URShiftVI src shift));
17687   ins_cost(INSN_COST);
17688   effect(TEMP tmp);
17689   format %{ &quot;negr  $tmp,$shift\t&quot;
17690             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17691   ins_encode %{
17692     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17693             as_FloatRegister($shift$$reg));
17694     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17695             as_FloatRegister($src$$reg),
17696             as_FloatRegister($tmp$$reg));
17697   %}
17698   ins_pipe(vshift64);
17699 %}
17700 
17701 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17702   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17703   match(Set dst (URShiftVI src shift));
17704   ins_cost(INSN_COST);
17705   effect(TEMP tmp);
17706   format %{ &quot;negr  $tmp,$shift\t&quot;
17707             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17708   ins_encode %{
17709     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17710             as_FloatRegister($shift$$reg));
17711     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17712             as_FloatRegister($src$$reg),
17713             as_FloatRegister($tmp$$reg));
17714   %}
17715   ins_pipe(vshift128);
17716 %}
17717 
17718 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17719   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17720   match(Set dst (LShiftVI src shift));
17721   ins_cost(INSN_COST);
17722   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17723   ins_encode %{
17724     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17725            as_FloatRegister($src$$reg),
17726            (int)$shift$$constant);
17727   %}
17728   ins_pipe(vshift64_imm);
17729 %}
17730 
17731 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17732   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17733   match(Set dst (LShiftVI src shift));
17734   ins_cost(INSN_COST);
17735   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17736   ins_encode %{
17737     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17738            as_FloatRegister($src$$reg),
17739            (int)$shift$$constant);
17740   %}
17741   ins_pipe(vshift128_imm);
17742 %}
17743 
17744 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17745   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17746   match(Set dst (RShiftVI src shift));
17747   ins_cost(INSN_COST);
17748   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17749   ins_encode %{
17750     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17751             as_FloatRegister($src$$reg),
17752             (int)$shift$$constant);
17753   %}
17754   ins_pipe(vshift64_imm);
17755 %}
17756 
17757 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17758   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17759   match(Set dst (RShiftVI src shift));
17760   ins_cost(INSN_COST);
17761   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17762   ins_encode %{
17763     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17764             as_FloatRegister($src$$reg),
17765             (int)$shift$$constant);
17766   %}
17767   ins_pipe(vshift128_imm);
17768 %}
17769 
17770 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17771   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17772   match(Set dst (URShiftVI src shift));
17773   ins_cost(INSN_COST);
17774   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17775   ins_encode %{
17776     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17777             as_FloatRegister($src$$reg),
17778             (int)$shift$$constant);
17779   %}
17780   ins_pipe(vshift64_imm);
17781 %}
17782 
17783 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17784   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17785   match(Set dst (URShiftVI src shift));
17786   ins_cost(INSN_COST);
17787   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17788   ins_encode %{
17789     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17790             as_FloatRegister($src$$reg),
17791             (int)$shift$$constant);
17792   %}
17793   ins_pipe(vshift128_imm);
17794 %}
17795 
17796 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17797   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17798   match(Set dst (LShiftVL src shift));
17799   ins_cost(INSN_COST);
17800   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17801   ins_encode %{
17802     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17803             as_FloatRegister($src$$reg),
17804             as_FloatRegister($shift$$reg));
17805   %}
17806   ins_pipe(vshift128);
17807 %}
17808 
17809 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17810   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17811   match(Set dst (RShiftVL src shift));
17812   ins_cost(INSN_COST);
17813   effect(TEMP tmp);
17814   format %{ &quot;negr  $tmp,$shift\t&quot;
17815             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17816   ins_encode %{
17817     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17818             as_FloatRegister($shift$$reg));
17819     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17820             as_FloatRegister($src$$reg),
17821             as_FloatRegister($tmp$$reg));
17822   %}
17823   ins_pipe(vshift128);
17824 %}
17825 
17826 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
17827   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17828   match(Set dst (URShiftVL src shift));
17829   ins_cost(INSN_COST);
17830   effect(TEMP tmp);
17831   format %{ &quot;negr  $tmp,$shift\t&quot;
17832             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
17833   ins_encode %{
17834     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17835             as_FloatRegister($shift$$reg));
17836     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
17837             as_FloatRegister($src$$reg),
17838             as_FloatRegister($tmp$$reg));
17839   %}
17840   ins_pipe(vshift128);
17841 %}
17842 
17843 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
17844   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17845   match(Set dst (LShiftVL src shift));
17846   ins_cost(INSN_COST);
17847   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
17848   ins_encode %{
17849     __ shl(as_FloatRegister($dst$$reg), __ T2D,
17850            as_FloatRegister($src$$reg),
17851            (int)$shift$$constant);
17852   %}
17853   ins_pipe(vshift128_imm);
17854 %}
17855 
17856 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
17857   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17858   match(Set dst (RShiftVL src shift));
17859   ins_cost(INSN_COST);
17860   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
17861   ins_encode %{
17862     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
17863             as_FloatRegister($src$$reg),
17864             (int)$shift$$constant);
17865   %}
17866   ins_pipe(vshift128_imm);
17867 %}
17868 
17869 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
17870   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17871   match(Set dst (URShiftVL src shift));
17872   ins_cost(INSN_COST);
17873   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
17874   ins_encode %{
17875     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
17876             as_FloatRegister($src$$reg),
17877             (int)$shift$$constant);
17878   %}
17879   ins_pipe(vshift128_imm);
17880 %}
17881 
17882 instruct vmax2F(vecD dst, vecD src1, vecD src2)
17883 %{
17884   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17885   match(Set dst (MaxV src1 src2));
17886   ins_cost(INSN_COST);
17887   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
17888   ins_encode %{
17889     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
17890             as_FloatRegister($src1$$reg),
17891             as_FloatRegister($src2$$reg));
17892   %}
17893   ins_pipe(vdop_fp64);
17894 %}
17895 
17896 instruct vmax4F(vecX dst, vecX src1, vecX src2)
17897 %{
17898   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17899   match(Set dst (MaxV src1 src2));
17900   ins_cost(INSN_COST);
17901   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
17902   ins_encode %{
17903     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
17904             as_FloatRegister($src1$$reg),
17905             as_FloatRegister($src2$$reg));
17906   %}
17907   ins_pipe(vdop_fp128);
17908 %}
17909 
17910 instruct vmax2D(vecX dst, vecX src1, vecX src2)
17911 %{
17912   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17913   match(Set dst (MaxV src1 src2));
17914   ins_cost(INSN_COST);
17915   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
17916   ins_encode %{
17917     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
17918             as_FloatRegister($src1$$reg),
17919             as_FloatRegister($src2$$reg));
17920   %}
17921   ins_pipe(vdop_fp128);
17922 %}
17923 
17924 instruct vmin2F(vecD dst, vecD src1, vecD src2)
17925 %{
17926   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17927   match(Set dst (MinV src1 src2));
17928   ins_cost(INSN_COST);
17929   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
17930   ins_encode %{
17931     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
17932             as_FloatRegister($src1$$reg),
17933             as_FloatRegister($src2$$reg));
17934   %}
17935   ins_pipe(vdop_fp64);
17936 %}
17937 
17938 instruct vmin4F(vecX dst, vecX src1, vecX src2)
17939 %{
17940   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
17941   match(Set dst (MinV src1 src2));
17942   ins_cost(INSN_COST);
17943   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
17944   ins_encode %{
17945     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
17946             as_FloatRegister($src1$$reg),
17947             as_FloatRegister($src2$$reg));
17948   %}
17949   ins_pipe(vdop_fp128);
17950 %}
17951 
17952 instruct vmin2D(vecX dst, vecX src1, vecX src2)
17953 %{
17954   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17955   match(Set dst (MinV src1 src2));
17956   ins_cost(INSN_COST);
17957   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
17958   ins_encode %{
17959     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
17960             as_FloatRegister($src1$$reg),
17961             as_FloatRegister($src2$$reg));
17962   %}
17963   ins_pipe(vdop_fp128);
17964 %}
17965 
17966 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
17967   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
17968   match(Set dst (RoundDoubleModeV src rmode));
17969   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
17970   ins_encode %{
17971     switch ($rmode$$constant) {
17972       case RoundDoubleModeNode::rmode_rint:
17973         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
17974                   as_FloatRegister($src$$reg));
17975         break;
17976       case RoundDoubleModeNode::rmode_floor:
17977         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
17978                   as_FloatRegister($src$$reg));
17979         break;
17980       case RoundDoubleModeNode::rmode_ceil:
17981         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
17982                   as_FloatRegister($src$$reg));
17983         break;
17984     }
17985   %}
17986   ins_pipe(vdop_fp128);
17987 %}
17988 
17989 //----------PEEPHOLE RULES-----------------------------------------------------
17990 // These must follow all instruction definitions as they use the names
17991 // defined in the instructions definitions.
17992 //
17993 // peepmatch ( root_instr_name [preceding_instruction]* );
17994 //
17995 // peepconstraint %{
17996 // (instruction_number.operand_name relational_op instruction_number.operand_name
17997 //  [, ...] );
17998 // // instruction numbers are zero-based using left to right order in peepmatch
17999 //
18000 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18001 // // provide an instruction_number.operand_name for each operand that appears
18002 // // in the replacement instruction&#39;s match rule
18003 //
18004 // ---------VM FLAGS---------------------------------------------------------
18005 //
18006 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18007 //
18008 // Each peephole rule is given an identifying number starting with zero and
18009 // increasing by one in the order seen by the parser.  An individual peephole
18010 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18011 // on the command-line.
18012 //
18013 // ---------CURRENT LIMITATIONS----------------------------------------------
18014 //
18015 // Only match adjacent instructions in same basic block
18016 // Only equality constraints
18017 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18018 // Only one replacement instruction
18019 //
18020 // ---------EXAMPLE----------------------------------------------------------
18021 //
18022 // // pertinent parts of existing instructions in architecture description
18023 // instruct movI(iRegINoSp dst, iRegI src)
18024 // %{
18025 //   match(Set dst (CopyI src));
18026 // %}
18027 //
18028 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18029 // %{
18030 //   match(Set dst (AddI dst src));
18031 //   effect(KILL cr);
18032 // %}
18033 //
18034 // // Change (inc mov) to lea
18035 // peephole %{
18036 //   // increment preceeded by register-register move
18037 //   peepmatch ( incI_iReg movI );
18038 //   // require that the destination register of the increment
18039 //   // match the destination register of the move
18040 //   peepconstraint ( 0.dst == 1.dst );
18041 //   // construct a replacement instruction that sets
18042 //   // the destination to ( move&#39;s source register + one )
18043 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18044 // %}
18045 //
18046 
18047 // Implementation no longer uses movX instructions since
18048 // machine-independent system no longer uses CopyX nodes.
18049 //
18050 // peephole
18051 // %{
18052 //   peepmatch (incI_iReg movI);
18053 //   peepconstraint (0.dst == 1.dst);
18054 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18055 // %}
18056 
18057 // peephole
18058 // %{
18059 //   peepmatch (decI_iReg movI);
18060 //   peepconstraint (0.dst == 1.dst);
18061 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18062 // %}
18063 
18064 // peephole
18065 // %{
18066 //   peepmatch (addI_iReg_imm movI);
18067 //   peepconstraint (0.dst == 1.dst);
18068 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18069 // %}
18070 
18071 // peephole
18072 // %{
18073 //   peepmatch (incL_iReg movL);
18074 //   peepconstraint (0.dst == 1.dst);
18075 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18076 // %}
18077 
18078 // peephole
18079 // %{
18080 //   peepmatch (decL_iReg movL);
18081 //   peepconstraint (0.dst == 1.dst);
18082 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18083 // %}
18084 
18085 // peephole
18086 // %{
18087 //   peepmatch (addL_iReg_imm movL);
18088 //   peepconstraint (0.dst == 1.dst);
18089 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18090 // %}
18091 
18092 // peephole
18093 // %{
18094 //   peepmatch (addP_iReg_imm movP);
18095 //   peepconstraint (0.dst == 1.dst);
18096 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18097 // %}
18098 
18099 // // Change load of spilled value to only a spill
18100 // instruct storeI(memory mem, iRegI src)
18101 // %{
18102 //   match(Set mem (StoreI mem src));
18103 // %}
18104 //
18105 // instruct loadI(iRegINoSp dst, memory mem)
18106 // %{
18107 //   match(Set dst (LoadI mem));
18108 // %}
18109 //
18110 
18111 //----------SMARTSPILL RULES---------------------------------------------------
18112 // These must follow all instruction definitions as they use the names
18113 // defined in the instructions definitions.
18114 
18115 // Local Variables:
18116 // mode: c++
18117 // End:
    </pre>
  </body>
</html>