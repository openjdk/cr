<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/vm_version_aarch64.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright (c) 2015, 2020, Red Hat Inc. All rights reserved.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #include &quot;precompiled.hpp&quot;
 27 #include &quot;asm/macroAssembler.hpp&quot;
 28 #include &quot;asm/macroAssembler.inline.hpp&quot;
 29 #include &quot;memory/resourceArea.hpp&quot;
 30 #include &quot;runtime/java.hpp&quot;
 31 #include &quot;runtime/os.hpp&quot;
 32 #include &quot;runtime/stubCodeGenerator.hpp&quot;
 33 #include &quot;runtime/vm_version.hpp&quot;
 34 #include &quot;utilities/macros.hpp&quot;
 35 
 36 #include OS_HEADER_INLINE(os)
 37 
 38 #include &lt;sys/auxv.h&gt;
 39 #include &lt;asm/hwcap.h&gt;
 40 
 41 #ifndef HWCAP_AES
 42 #define HWCAP_AES   (1&lt;&lt;3)
 43 #endif
 44 
 45 #ifndef HWCAP_PMULL
 46 #define HWCAP_PMULL (1&lt;&lt;4)
 47 #endif
 48 
 49 #ifndef HWCAP_SHA1
 50 #define HWCAP_SHA1  (1&lt;&lt;5)
 51 #endif
 52 
 53 #ifndef HWCAP_SHA2
 54 #define HWCAP_SHA2  (1&lt;&lt;6)
 55 #endif
 56 
 57 #ifndef HWCAP_CRC32
 58 #define HWCAP_CRC32 (1&lt;&lt;7)
 59 #endif
 60 
 61 #ifndef HWCAP_ATOMICS
 62 #define HWCAP_ATOMICS (1&lt;&lt;8)
 63 #endif
 64 
 65 int VM_Version::_cpu;
 66 int VM_Version::_model;
 67 int VM_Version::_model2;
 68 int VM_Version::_variant;
 69 int VM_Version::_revision;
 70 int VM_Version::_stepping;
 71 bool VM_Version::_dcpop;
 72 VM_Version::PsrInfo VM_Version::_psr_info   = { 0, };
 73 
 74 static BufferBlob* stub_blob;
 75 static const int stub_size = 550;
 76 
 77 extern &quot;C&quot; {
 78   typedef void (*getPsrInfo_stub_t)(void*);
 79 }
 80 static getPsrInfo_stub_t getPsrInfo_stub = NULL;
 81 
 82 
 83 class VM_Version_StubGenerator: public StubCodeGenerator {
 84  public:
 85 
 86   VM_Version_StubGenerator(CodeBuffer *c) : StubCodeGenerator(c) {}
 87 
 88   address generate_getPsrInfo() {
 89     StubCodeMark mark(this, &quot;VM_Version&quot;, &quot;getPsrInfo_stub&quot;);
 90 #   define __ _masm-&gt;
 91     address start = __ pc();
 92 
 93     // void getPsrInfo(VM_Version::PsrInfo* psr_info);
 94 
 95     address entry = __ pc();
 96 
 97     __ enter();
 98 
 99     __ get_dczid_el0(rscratch1);
100     __ strw(rscratch1, Address(c_rarg0, in_bytes(VM_Version::dczid_el0_offset())));
101 
102     __ get_ctr_el0(rscratch1);
103     __ strw(rscratch1, Address(c_rarg0, in_bytes(VM_Version::ctr_el0_offset())));
104 
105     __ leave();
106     __ ret(lr);
107 
108 #   undef __
109 
110     return start;
111   }
112 };
113 
114 
115 void VM_Version::get_processor_features() {
116   _supports_cx8 = true;
117   _supports_atomic_getset4 = true;
118   _supports_atomic_getadd4 = true;
119   _supports_atomic_getset8 = true;
120   _supports_atomic_getadd8 = true;
121 
122   getPsrInfo_stub(&amp;_psr_info);
123 
124   int dcache_line = VM_Version::dcache_line_size();
125 
126   // Limit AllocatePrefetchDistance so that it does not exceed the
127   // constraint in AllocatePrefetchDistanceConstraintFunc.
128   if (FLAG_IS_DEFAULT(AllocatePrefetchDistance))
129     FLAG_SET_DEFAULT(AllocatePrefetchDistance, MIN2(512, 3*dcache_line));
130 
131   if (FLAG_IS_DEFAULT(AllocatePrefetchStepSize))
132     FLAG_SET_DEFAULT(AllocatePrefetchStepSize, dcache_line);
133   if (FLAG_IS_DEFAULT(PrefetchScanIntervalInBytes))
134     FLAG_SET_DEFAULT(PrefetchScanIntervalInBytes, 3*dcache_line);
135   if (FLAG_IS_DEFAULT(PrefetchCopyIntervalInBytes))
136     FLAG_SET_DEFAULT(PrefetchCopyIntervalInBytes, 3*dcache_line);
137   if (FLAG_IS_DEFAULT(SoftwarePrefetchHintDistance))
138     FLAG_SET_DEFAULT(SoftwarePrefetchHintDistance, 3*dcache_line);
139 
140   if (PrefetchCopyIntervalInBytes != -1 &amp;&amp;
141        ((PrefetchCopyIntervalInBytes &amp; 7) || (PrefetchCopyIntervalInBytes &gt;= 32768))) {
142     warning(&quot;PrefetchCopyIntervalInBytes must be -1, or a multiple of 8 and &lt; 32768&quot;);
143     PrefetchCopyIntervalInBytes &amp;= ~7;
144     if (PrefetchCopyIntervalInBytes &gt;= 32768)
145       PrefetchCopyIntervalInBytes = 32760;
146   }
147 
148   if (AllocatePrefetchDistance !=-1 &amp;&amp; (AllocatePrefetchDistance &amp; 7)) {
149     warning(&quot;AllocatePrefetchDistance must be multiple of 8&quot;);
150     AllocatePrefetchDistance &amp;= ~7;
151   }
152 
153   if (AllocatePrefetchStepSize &amp; 7) {
154     warning(&quot;AllocatePrefetchStepSize must be multiple of 8&quot;);
155     AllocatePrefetchStepSize &amp;= ~7;
156   }
157 
158   if (SoftwarePrefetchHintDistance != -1 &amp;&amp;
159        (SoftwarePrefetchHintDistance &amp; 7)) {
160     warning(&quot;SoftwarePrefetchHintDistance must be -1, or a multiple of 8&quot;);
161     SoftwarePrefetchHintDistance &amp;= ~7;
162   }
163 
164   unsigned long auxv = getauxval(AT_HWCAP);
165 
166   char buf[512];
167 
168   _features = auxv;
169 
170   int cpu_lines = 0;
171   if (FILE *f = fopen(&quot;/proc/cpuinfo&quot;, &quot;r&quot;)) {
172     // need a large buffer as the flags line may include lots of text
173     char buf[1024], *p;
174     while (fgets(buf, sizeof (buf), f) != NULL) {
175       if ((p = strchr(buf, &#39;:&#39;)) != NULL) {
176         long v = strtol(p+1, NULL, 0);
177         if (strncmp(buf, &quot;CPU implementer&quot;, sizeof &quot;CPU implementer&quot; - 1) == 0) {
178           _cpu = v;
179           cpu_lines++;
180         } else if (strncmp(buf, &quot;CPU variant&quot;, sizeof &quot;CPU variant&quot; - 1) == 0) {
181           _variant = v;
182         } else if (strncmp(buf, &quot;CPU part&quot;, sizeof &quot;CPU part&quot; - 1) == 0) {
183           if (_model != v)  _model2 = _model;
184           _model = v;
185         } else if (strncmp(buf, &quot;CPU revision&quot;, sizeof &quot;CPU revision&quot; - 1) == 0) {
186           _revision = v;
187         } else if (strncmp(buf, &quot;flags&quot;, sizeof(&quot;flags&quot;) - 1) == 0) {
188           if (strstr(p+1, &quot;dcpop&quot;)) {
189             _dcpop = true;
190           }
191         }
192       }
193     }
194     fclose(f);
195   }
196 
197   if (os::supports_map_sync()) {
198     // if dcpop is available publish data cache line flush size via
199     // generic field, otherwise let if default to zero thereby
200     // disabling writeback
201     if (_dcpop) {
202       _data_cache_line_flush_size = dcache_line;
203     }
204   }
205 
206   // Enable vendor specific features
207 
208   // Ampere eMAG
209   if (_cpu == CPU_AMCC &amp;&amp; (_model == 0) &amp;&amp; (_variant == 0x3)) {
210     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
211       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
212     }
213     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
214       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, true);
215     }
216     if (FLAG_IS_DEFAULT(UseSIMDForArrayEquals)) {
217       FLAG_SET_DEFAULT(UseSIMDForArrayEquals, !(_revision == 1 || _revision == 2));
218     }
219   }
220 
221   // ThunderX
222   if (_cpu == CPU_CAVIUM &amp;&amp; (_model == 0xA1)) {
223     if (_variant == 0) _features |= CPU_DMB_ATOMICS;
224     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
225       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
226     }
227     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
228       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, (_variant &gt; 0));
229     }
230     if (FLAG_IS_DEFAULT(UseSIMDForArrayEquals)) {
231       FLAG_SET_DEFAULT(UseSIMDForArrayEquals, false);
232     }
233   }
234 
235   // ThunderX2
236   if ((_cpu == CPU_CAVIUM &amp;&amp; (_model == 0xAF)) ||
237       (_cpu == CPU_BROADCOM &amp;&amp; (_model == 0x516))) {
238     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
239       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
240     }
241     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
242       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, true);
243     }
244   }
245 
246   // HiSilicon TSV110
247   if (_cpu == CPU_HISILICON &amp;&amp; _model == 0xd01) {
248     if (FLAG_IS_DEFAULT(AvoidUnalignedAccesses)) {
249       FLAG_SET_DEFAULT(AvoidUnalignedAccesses, true);
250     }
251     if (FLAG_IS_DEFAULT(UseSIMDForMemoryOps)) {
252       FLAG_SET_DEFAULT(UseSIMDForMemoryOps, true);
253     }
254   }
255 
256   // Cortex A53
257   if (_cpu == CPU_ARM &amp;&amp; (_model == 0xd03 || _model2 == 0xd03)) {
258     _features |= CPU_A53MAC;
259     if (FLAG_IS_DEFAULT(UseSIMDForArrayEquals)) {
260       FLAG_SET_DEFAULT(UseSIMDForArrayEquals, false);
261     }
262   }
263 
264   // Cortex A73
265   if (_cpu == CPU_ARM &amp;&amp; (_model == 0xd09 || _model2 == 0xd09)) {
266     if (FLAG_IS_DEFAULT(SoftwarePrefetchHintDistance)) {
267       FLAG_SET_DEFAULT(SoftwarePrefetchHintDistance, -1);
268     }
269     // A73 is faster with short-and-easy-for-speculative-execution-loop
270     if (FLAG_IS_DEFAULT(UseSimpleArrayEquals)) {
271       FLAG_SET_DEFAULT(UseSimpleArrayEquals, true);
272     }
273   }
274 
275   if (_cpu == CPU_ARM &amp;&amp; (_model == 0xd07 || _model2 == 0xd07)) _features |= CPU_STXR_PREFETCH;
276   // If an olde style /proc/cpuinfo (cpu_lines == 1) then if _model is an A57 (0xd07)
277   // we assume the worst and assume we could be on a big little system and have
278   // undisclosed A53 cores which we could be swapped to at any stage
279   if (_cpu == CPU_ARM &amp;&amp; cpu_lines == 1 &amp;&amp; _model == 0xd07) _features |= CPU_A53MAC;
280 
281   sprintf(buf, &quot;0x%02x:0x%x:0x%03x:%d&quot;, _cpu, _variant, _model, _revision);
282   if (_model2) sprintf(buf+strlen(buf), &quot;(0x%03x)&quot;, _model2);
283   if (auxv &amp; HWCAP_ASIMD) strcat(buf, &quot;, simd&quot;);
284   if (auxv &amp; HWCAP_CRC32) strcat(buf, &quot;, crc&quot;);
285   if (auxv &amp; HWCAP_AES)   strcat(buf, &quot;, aes&quot;);
286   if (auxv &amp; HWCAP_SHA1)  strcat(buf, &quot;, sha1&quot;);
287   if (auxv &amp; HWCAP_SHA2)  strcat(buf, &quot;, sha256&quot;);
288   if (auxv &amp; HWCAP_ATOMICS) strcat(buf, &quot;, lse&quot;);
289 
290   _features_string = os::strdup(buf);
291 
292   if (FLAG_IS_DEFAULT(UseCRC32)) {
293     UseCRC32 = (auxv &amp; HWCAP_CRC32) != 0;
294   }
295 
296   if (UseCRC32 &amp;&amp; (auxv &amp; HWCAP_CRC32) == 0) {
297     warning(&quot;UseCRC32 specified, but not supported on this CPU&quot;);
298     FLAG_SET_DEFAULT(UseCRC32, false);
299   }
300 
301   if (FLAG_IS_DEFAULT(UseAdler32Intrinsics)) {
302     FLAG_SET_DEFAULT(UseAdler32Intrinsics, true);
303   }
304 
305   if (UseVectorizedMismatchIntrinsic) {
306     warning(&quot;UseVectorizedMismatchIntrinsic specified, but not available on this CPU.&quot;);
307     FLAG_SET_DEFAULT(UseVectorizedMismatchIntrinsic, false);
308   }
309 
310   if (auxv &amp; HWCAP_ATOMICS) {
311     if (FLAG_IS_DEFAULT(UseLSE))
312       FLAG_SET_DEFAULT(UseLSE, true);
313   } else {
314     if (UseLSE) {
315       warning(&quot;UseLSE specified, but not supported on this CPU&quot;);
316       FLAG_SET_DEFAULT(UseLSE, false);
317     }
318   }
319 
320   if (auxv &amp; HWCAP_AES) {
321     UseAES = UseAES || FLAG_IS_DEFAULT(UseAES);
322     UseAESIntrinsics =
323         UseAESIntrinsics || (UseAES &amp;&amp; FLAG_IS_DEFAULT(UseAESIntrinsics));
324     if (UseAESIntrinsics &amp;&amp; !UseAES) {
325       warning(&quot;UseAESIntrinsics enabled, but UseAES not, enabling&quot;);
326       UseAES = true;
327     }
328   } else {
329     if (UseAES) {
330       warning(&quot;UseAES specified, but not supported on this CPU&quot;);
331       FLAG_SET_DEFAULT(UseAES, false);
332     }
333     if (UseAESIntrinsics) {
334       warning(&quot;UseAESIntrinsics specified, but not supported on this CPU&quot;);
335       FLAG_SET_DEFAULT(UseAESIntrinsics, false);
336     }
337   }
338 
339   if (UseAESCTRIntrinsics) {
340     warning(&quot;AES/CTR intrinsics are not available on this CPU&quot;);
341     FLAG_SET_DEFAULT(UseAESCTRIntrinsics, false);
342   }
343 
344   if (FLAG_IS_DEFAULT(UseCRC32Intrinsics)) {
345     UseCRC32Intrinsics = true;
346   }
347 
348   if (auxv &amp; HWCAP_CRC32) {
349     if (FLAG_IS_DEFAULT(UseCRC32CIntrinsics)) {
350       FLAG_SET_DEFAULT(UseCRC32CIntrinsics, true);
351     }
352   } else if (UseCRC32CIntrinsics) {
353     warning(&quot;CRC32C is not available on the CPU&quot;);
354     FLAG_SET_DEFAULT(UseCRC32CIntrinsics, false);
355   }
356 
357   if (FLAG_IS_DEFAULT(UseFMA)) {
358     FLAG_SET_DEFAULT(UseFMA, true);
359   }
360 
361   if (auxv &amp; (HWCAP_SHA1 | HWCAP_SHA2)) {
362     if (FLAG_IS_DEFAULT(UseSHA)) {
363       FLAG_SET_DEFAULT(UseSHA, true);
364     }
365   } else if (UseSHA) {
366     warning(&quot;SHA instructions are not available on this CPU&quot;);
367     FLAG_SET_DEFAULT(UseSHA, false);
368   }
369 
370   if (UseSHA &amp;&amp; (auxv &amp; HWCAP_SHA1)) {
371     if (FLAG_IS_DEFAULT(UseSHA1Intrinsics)) {
372       FLAG_SET_DEFAULT(UseSHA1Intrinsics, true);
373     }
374   } else if (UseSHA1Intrinsics) {
375     warning(&quot;Intrinsics for SHA-1 crypto hash functions not available on this CPU.&quot;);
376     FLAG_SET_DEFAULT(UseSHA1Intrinsics, false);
377   }
378 
379   if (UseSHA &amp;&amp; (auxv &amp; HWCAP_SHA2)) {
380     if (FLAG_IS_DEFAULT(UseSHA256Intrinsics)) {
381       FLAG_SET_DEFAULT(UseSHA256Intrinsics, true);
382     }
383   } else if (UseSHA256Intrinsics) {
384     warning(&quot;Intrinsics for SHA-224 and SHA-256 crypto hash functions not available on this CPU.&quot;);
385     FLAG_SET_DEFAULT(UseSHA256Intrinsics, false);
386   }
387 
388   if (UseSHA512Intrinsics) {
389     warning(&quot;Intrinsics for SHA-384 and SHA-512 crypto hash functions not available on this CPU.&quot;);
390     FLAG_SET_DEFAULT(UseSHA512Intrinsics, false);
391   }
392 
393   if (!(UseSHA1Intrinsics || UseSHA256Intrinsics || UseSHA512Intrinsics)) {
394     FLAG_SET_DEFAULT(UseSHA, false);
395   }
396 
397   if (auxv &amp; HWCAP_PMULL) {
398     if (FLAG_IS_DEFAULT(UseGHASHIntrinsics)) {
399       FLAG_SET_DEFAULT(UseGHASHIntrinsics, true);
400     }
401   } else if (UseGHASHIntrinsics) {
402     warning(&quot;GHASH intrinsics are not available on this CPU&quot;);
403     FLAG_SET_DEFAULT(UseGHASHIntrinsics, false);
404   }
405 
406   if (is_zva_enabled()) {
407     if (FLAG_IS_DEFAULT(UseBlockZeroing)) {
408       FLAG_SET_DEFAULT(UseBlockZeroing, true);
409     }
410     if (FLAG_IS_DEFAULT(BlockZeroingLowLimit)) {
411       FLAG_SET_DEFAULT(BlockZeroingLowLimit, 4 * VM_Version::zva_length());
412     }
413   } else if (UseBlockZeroing) {
414     warning(&quot;DC ZVA is not available on this CPU&quot;);
415     FLAG_SET_DEFAULT(UseBlockZeroing, false);
416   }
417 
418   // This machine allows unaligned memory accesses
419   if (FLAG_IS_DEFAULT(UseUnalignedAccesses)) {
420     FLAG_SET_DEFAULT(UseUnalignedAccesses, true);
421   }
422 
423   if (FLAG_IS_DEFAULT(UseBarriersForVolatile)) {
424     UseBarriersForVolatile = (_features &amp; CPU_DMB_ATOMICS) != 0;
425   }
426 
427   if (FLAG_IS_DEFAULT(UsePopCountInstruction)) {
428     UsePopCountInstruction = true;
429   }
430 
431 #ifdef COMPILER2
432   if (FLAG_IS_DEFAULT(UseMultiplyToLenIntrinsic)) {
433     UseMultiplyToLenIntrinsic = true;
434   }
435 
436   if (FLAG_IS_DEFAULT(UseSquareToLenIntrinsic)) {
437     UseSquareToLenIntrinsic = true;
438   }
439 
440   if (FLAG_IS_DEFAULT(UseMulAddIntrinsic)) {
441     UseMulAddIntrinsic = true;
442   }
443 
444   if (FLAG_IS_DEFAULT(UseMontgomeryMultiplyIntrinsic)) {
445     UseMontgomeryMultiplyIntrinsic = true;
446   }
447   if (FLAG_IS_DEFAULT(UseMontgomerySquareIntrinsic)) {
448     UseMontgomerySquareIntrinsic = true;
449   }
450 
451   if (FLAG_IS_DEFAULT(OptoScheduling)) {
452     OptoScheduling = true;
453   }
454 
455   if (FLAG_IS_DEFAULT(AlignVector)) {
456     AlignVector = AvoidUnalignedAccesses;
457   }
458 #endif
459 }
460 
461 void VM_Version::initialize() {
462   ResourceMark rm;
463 
464   stub_blob = BufferBlob::create(&quot;getPsrInfo_stub&quot;, stub_size);
465   if (stub_blob == NULL) {
466     vm_exit_during_initialization(&quot;Unable to allocate getPsrInfo_stub&quot;);
467   }
468 
469   CodeBuffer c(stub_blob);
470   VM_Version_StubGenerator g(&amp;c);
471   getPsrInfo_stub = CAST_TO_FN_PTR(getPsrInfo_stub_t,
472                                    g.generate_getPsrInfo());
473 
474   get_processor_features();
475 
476   UNSUPPORTED_OPTION(CriticalJNINatives);
477 }
    </pre>
  </body>
</html>