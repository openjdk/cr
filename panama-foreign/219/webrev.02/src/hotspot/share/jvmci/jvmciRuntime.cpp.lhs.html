<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/share/jvmci/jvmciRuntime.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (c) 2012, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  */
  23 
  24 #include &quot;precompiled.hpp&quot;
  25 #include &quot;classfile/javaClasses.inline.hpp&quot;
  26 #include &quot;classfile/symbolTable.hpp&quot;
  27 #include &quot;compiler/compileBroker.hpp&quot;
  28 #include &quot;jvmci/jniAccessMark.inline.hpp&quot;
  29 #include &quot;jvmci/jvmciCompilerToVM.hpp&quot;
  30 #include &quot;jvmci/jvmciRuntime.hpp&quot;
  31 #include &quot;logging/log.hpp&quot;
  32 #include &quot;memory/oopFactory.hpp&quot;
  33 #include &quot;memory/universe.hpp&quot;
  34 #include &quot;oops/constantPool.inline.hpp&quot;
  35 #include &quot;oops/method.inline.hpp&quot;
  36 #include &quot;oops/objArrayKlass.hpp&quot;
  37 #include &quot;oops/oop.inline.hpp&quot;
  38 #include &quot;runtime/atomic.hpp&quot;
  39 #include &quot;runtime/biasedLocking.hpp&quot;
  40 #include &quot;runtime/deoptimization.hpp&quot;
  41 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  42 #include &quot;runtime/frame.inline.hpp&quot;
  43 #include &quot;runtime/sharedRuntime.hpp&quot;
  44 #if INCLUDE_G1GC
  45 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
  46 #endif // INCLUDE_G1GC
  47 
  48 // Simple helper to see if the caller of a runtime stub which
  49 // entered the VM has been deoptimized
  50 
  51 static bool caller_is_deopted() {
  52   JavaThread* thread = JavaThread::current();
  53   RegisterMap reg_map(thread, false);
  54   frame runtime_frame = thread-&gt;last_frame();
  55   frame caller_frame = runtime_frame.sender(&amp;reg_map);
  56   assert(caller_frame.is_compiled_frame(), &quot;must be compiled&quot;);
  57   return caller_frame.is_deoptimized_frame();
  58 }
  59 
  60 // Stress deoptimization
  61 static void deopt_caller() {
  62   if ( !caller_is_deopted()) {
  63     JavaThread* thread = JavaThread::current();
  64     RegisterMap reg_map(thread, false);
  65     frame runtime_frame = thread-&gt;last_frame();
  66     frame caller_frame = runtime_frame.sender(&amp;reg_map);
  67     Deoptimization::deoptimize_frame(thread, caller_frame.id(), Deoptimization::Reason_constraint);
  68     assert(caller_is_deopted(), &quot;Must be deoptimized&quot;);
  69   }
  70 }
  71 
  72 // Manages a scope for a JVMCI runtime call that attempts a heap allocation.
  73 // If there is a pending exception upon closing the scope and the runtime
  74 // call is of the variety where allocation failure returns NULL without an
  75 // exception, the following action is taken:
  76 //   1. The pending exception is cleared
  77 //   2. NULL is written to JavaThread::_vm_result
  78 //   3. Checks that an OutOfMemoryError is Universe::out_of_memory_error_retry().
  79 class RetryableAllocationMark: public StackObj {
  80  private:
  81   JavaThread* _thread;
  82  public:
  83   RetryableAllocationMark(JavaThread* thread, bool activate) {
  84     if (activate) {
  85       assert(!thread-&gt;in_retryable_allocation(), &quot;retryable allocation scope is non-reentrant&quot;);
  86       _thread = thread;
  87       _thread-&gt;set_in_retryable_allocation(true);
  88     } else {
  89       _thread = NULL;
  90     }
  91   }
  92   ~RetryableAllocationMark() {
  93     if (_thread != NULL) {
  94       _thread-&gt;set_in_retryable_allocation(false);
  95       JavaThread* THREAD = _thread;
  96       if (HAS_PENDING_EXCEPTION) {
  97         oop ex = PENDING_EXCEPTION;
  98         CLEAR_PENDING_EXCEPTION;
  99         oop retry_oome = Universe::out_of_memory_error_retry();
 100         if (ex-&gt;is_a(retry_oome-&gt;klass()) &amp;&amp; retry_oome != ex) {
 101           ResourceMark rm;
 102           fatal(&quot;Unexpected exception in scope of retryable allocation: &quot; INTPTR_FORMAT &quot; of type %s&quot;, p2i(ex), ex-&gt;klass()-&gt;external_name());
 103         }
 104         _thread-&gt;set_vm_result(NULL);
 105       }
 106     }
 107   }
 108 };
 109 
 110 JRT_BLOCK_ENTRY(void, JVMCIRuntime::new_instance_common(JavaThread* thread, Klass* klass, bool null_on_fail))
 111   JRT_BLOCK;
 112   assert(klass-&gt;is_klass(), &quot;not a class&quot;);
 113   Handle holder(THREAD, klass-&gt;klass_holder()); // keep the klass alive
 114   InstanceKlass* h = InstanceKlass::cast(klass);
 115   {
 116     RetryableAllocationMark ram(thread, null_on_fail);
 117     h-&gt;check_valid_for_instantiation(true, CHECK);
 118     oop obj;
 119     if (null_on_fail) {
 120       if (!h-&gt;is_initialized()) {
 121         // Cannot re-execute class initialization without side effects
 122         // so return without attempting the initialization
 123         return;
 124       }
 125     } else {
 126       // make sure klass is initialized
 127       h-&gt;initialize(CHECK);
 128     }
 129     // allocate instance and return via TLS
 130     obj = h-&gt;allocate_instance(CHECK);
 131     thread-&gt;set_vm_result(obj);
 132   }
 133   JRT_BLOCK_END;
 134   SharedRuntime::on_slowpath_allocation_exit(thread);
 135 JRT_END
 136 
 137 JRT_BLOCK_ENTRY(void, JVMCIRuntime::new_array_common(JavaThread* thread, Klass* array_klass, jint length, bool null_on_fail))
 138   JRT_BLOCK;
 139   // Note: no handle for klass needed since they are not used
 140   //       anymore after new_objArray() and no GC can happen before.
 141   //       (This may have to change if this code changes!)
 142   assert(array_klass-&gt;is_klass(), &quot;not a class&quot;);
 143   oop obj;
 144   if (array_klass-&gt;is_typeArray_klass()) {
 145     BasicType elt_type = TypeArrayKlass::cast(array_klass)-&gt;element_type();
 146     RetryableAllocationMark ram(thread, null_on_fail);
 147     obj = oopFactory::new_typeArray(elt_type, length, CHECK);
 148   } else {
 149     Handle holder(THREAD, array_klass-&gt;klass_holder()); // keep the klass alive
 150     Klass* elem_klass = ObjArrayKlass::cast(array_klass)-&gt;element_klass();
 151     RetryableAllocationMark ram(thread, null_on_fail);
 152     obj = oopFactory::new_objArray(elem_klass, length, CHECK);
 153   }
 154   thread-&gt;set_vm_result(obj);
 155   // This is pretty rare but this runtime patch is stressful to deoptimization
 156   // if we deoptimize here so force a deopt to stress the path.
 157   if (DeoptimizeALot) {
 158     static int deopts = 0;
 159     // Alternate between deoptimizing and raising an error (which will also cause a deopt)
 160     if (deopts++ % 2 == 0) {
 161       if (null_on_fail) {
 162         return;
 163       } else {
 164         ResourceMark rm(THREAD);
 165         THROW(vmSymbols::java_lang_OutOfMemoryError());
 166       }
 167     } else {
 168       deopt_caller();
 169     }
 170   }
 171   JRT_BLOCK_END;
 172   SharedRuntime::on_slowpath_allocation_exit(thread);
 173 JRT_END
 174 
 175 JRT_ENTRY(void, JVMCIRuntime::new_multi_array_common(JavaThread* thread, Klass* klass, int rank, jint* dims, bool null_on_fail))
 176   assert(klass-&gt;is_klass(), &quot;not a class&quot;);
 177   assert(rank &gt;= 1, &quot;rank must be nonzero&quot;);
 178   Handle holder(THREAD, klass-&gt;klass_holder()); // keep the klass alive
 179   RetryableAllocationMark ram(thread, null_on_fail);
 180   oop obj = ArrayKlass::cast(klass)-&gt;multi_allocate(rank, dims, CHECK);
 181   thread-&gt;set_vm_result(obj);
 182 JRT_END
 183 
 184 JRT_ENTRY(void, JVMCIRuntime::dynamic_new_array_common(JavaThread* thread, oopDesc* element_mirror, jint length, bool null_on_fail))
 185   RetryableAllocationMark ram(thread, null_on_fail);
 186   oop obj = Reflection::reflect_new_array(element_mirror, length, CHECK);
 187   thread-&gt;set_vm_result(obj);
 188 JRT_END
 189 
 190 JRT_ENTRY(void, JVMCIRuntime::dynamic_new_instance_common(JavaThread* thread, oopDesc* type_mirror, bool null_on_fail))
 191   InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(type_mirror));
 192 
 193   if (klass == NULL) {
 194     ResourceMark rm(THREAD);
 195     THROW(vmSymbols::java_lang_InstantiationException());
 196   }
 197   RetryableAllocationMark ram(thread, null_on_fail);
 198 
 199   // Create new instance (the receiver)
 200   klass-&gt;check_valid_for_instantiation(false, CHECK);
 201 
 202   if (null_on_fail) {
 203     if (!klass-&gt;is_initialized()) {
 204       // Cannot re-execute class initialization without side effects
 205       // so return without attempting the initialization
 206       return;
 207     }
 208   } else {
 209     // Make sure klass gets initialized
 210     klass-&gt;initialize(CHECK);
 211   }
 212 
 213   oop obj = klass-&gt;allocate_instance(CHECK);
 214   thread-&gt;set_vm_result(obj);
 215 JRT_END
 216 
 217 extern void vm_exit(int code);
 218 
 219 // Enter this method from compiled code handler below. This is where we transition
 220 // to VM mode. This is done as a helper routine so that the method called directly
 221 // from compiled code does not have to transition to VM. This allows the entry
 222 // method to see if the nmethod that we have just looked up a handler for has
 223 // been deoptimized while we were in the vm. This simplifies the assembly code
 224 // cpu directories.
 225 //
 226 // We are entering here from exception stub (via the entry method below)
 227 // If there is a compiled exception handler in this method, we will continue there;
 228 // otherwise we will unwind the stack and continue at the caller of top frame method
 229 // Note: we enter in Java using a special JRT wrapper. This wrapper allows us to
 230 // control the area where we can allow a safepoint. After we exit the safepoint area we can
 231 // check to see if the handler we are going to return is now in a nmethod that has
 232 // been deoptimized. If that is the case we return the deopt blob
 233 // unpack_with_exception entry instead. This makes life for the exception blob easier
 234 // because making that same check and diverting is painful from assembly language.
 235 JRT_ENTRY_NO_ASYNC(static address, exception_handler_for_pc_helper(JavaThread* thread, oopDesc* ex, address pc, CompiledMethod*&amp; cm))
 236   // Reset method handle flag.
 237   thread-&gt;set_is_method_handle_return(false);
 238 
 239   Handle exception(thread, ex);
 240   cm = CodeCache::find_compiled(pc);
 241   assert(cm != NULL, &quot;this is not a compiled method&quot;);
 242   // Adjust the pc as needed/
 243   if (cm-&gt;is_deopt_pc(pc)) {
 244     RegisterMap map(thread, false);
 245     frame exception_frame = thread-&gt;last_frame().sender(&amp;map);
 246     // if the frame isn&#39;t deopted then pc must not correspond to the caller of last_frame
 247     assert(exception_frame.is_deoptimized_frame(), &quot;must be deopted&quot;);
 248     pc = exception_frame.pc();
 249   }
 250 #ifdef ASSERT
 251   assert(exception.not_null(), &quot;NULL exceptions should be handled by throw_exception&quot;);
 252   assert(oopDesc::is_oop(exception()), &quot;just checking&quot;);
 253   // Check that exception is a subclass of Throwable, otherwise we have a VerifyError
 254   if (!(exception-&gt;is_a(SystemDictionary::Throwable_klass()))) {
 255     if (ExitVMOnVerifyError) vm_exit(-1);
 256     ShouldNotReachHere();
 257   }
 258 #endif
 259 
 260   // Check the stack guard pages and reenable them if necessary and there is
 261   // enough space on the stack to do so.  Use fast exceptions only if the guard
 262   // pages are enabled.
 263   bool guard_pages_enabled = thread-&gt;stack_guards_enabled();
 264   if (!guard_pages_enabled) guard_pages_enabled = thread-&gt;reguard_stack();
 265 
 266   if (JvmtiExport::can_post_on_exceptions()) {
 267     // To ensure correct notification of exception catches and throws
 268     // we have to deoptimize here.  If we attempted to notify the
 269     // catches and throws during this exception lookup it&#39;s possible
 270     // we could deoptimize on the way out of the VM and end back in
 271     // the interpreter at the throw site.  This would result in double
 272     // notifications since the interpreter would also notify about
 273     // these same catches and throws as it unwound the frame.
 274 
 275     RegisterMap reg_map(thread);
 276     frame stub_frame = thread-&gt;last_frame();
 277     frame caller_frame = stub_frame.sender(&amp;reg_map);
 278 
 279     // We don&#39;t really want to deoptimize the nmethod itself since we
 280     // can actually continue in the exception handler ourselves but I
 281     // don&#39;t see an easy way to have the desired effect.
 282     Deoptimization::deoptimize_frame(thread, caller_frame.id(), Deoptimization::Reason_constraint);
 283     assert(caller_is_deopted(), &quot;Must be deoptimized&quot;);
 284 
 285     return SharedRuntime::deopt_blob()-&gt;unpack_with_exception_in_tls();
 286   }
 287 
 288   // ExceptionCache is used only for exceptions at call sites and not for implicit exceptions
 289   if (guard_pages_enabled) {
 290     address fast_continuation = cm-&gt;handler_for_exception_and_pc(exception, pc);
 291     if (fast_continuation != NULL) {
 292       // Set flag if return address is a method handle call site.
 293       thread-&gt;set_is_method_handle_return(cm-&gt;is_method_handle_return(pc));
 294       return fast_continuation;
 295     }
 296   }
 297 
 298   // If the stack guard pages are enabled, check whether there is a handler in
 299   // the current method.  Otherwise (guard pages disabled), force an unwind and
 300   // skip the exception cache update (i.e., just leave continuation==NULL).
 301   address continuation = NULL;
 302   if (guard_pages_enabled) {
 303 
 304     // New exception handling mechanism can support inlined methods
 305     // with exception handlers since the mappings are from PC to PC
 306 
 307     // debugging support
 308     // tracing
 309     if (log_is_enabled(Info, exceptions)) {
 310       ResourceMark rm;
 311       stringStream tempst;
 312       assert(cm-&gt;method() != NULL, &quot;Unexpected null method()&quot;);
 313       tempst.print(&quot;compiled method &lt;%s&gt;\n&quot;
 314                    &quot; at PC&quot; INTPTR_FORMAT &quot; for thread &quot; INTPTR_FORMAT,
 315                    cm-&gt;method()-&gt;print_value_string(), p2i(pc), p2i(thread));
 316       Exceptions::log_exception(exception, tempst.as_string());
 317     }
 318     // for AbortVMOnException flag
 319     NOT_PRODUCT(Exceptions::debug_check_abort(exception));
 320 
 321     // Clear out the exception oop and pc since looking up an
 322     // exception handler can cause class loading, which might throw an
 323     // exception and those fields are expected to be clear during
 324     // normal bytecode execution.
 325     thread-&gt;clear_exception_oop_and_pc();
 326 
 327     bool recursive_exception = false;
 328     continuation = SharedRuntime::compute_compiled_exc_handler(cm, pc, exception, false, false, recursive_exception);
 329     // If an exception was thrown during exception dispatch, the exception oop may have changed
 330     thread-&gt;set_exception_oop(exception());
 331     thread-&gt;set_exception_pc(pc);
 332 
 333     // The exception cache is used only for non-implicit exceptions
 334     // Update the exception cache only when another exception did
 335     // occur during the computation of the compiled exception handler
 336     // (e.g., when loading the class of the catch type).
 337     // Checking for exception oop equality is not
 338     // sufficient because some exceptions are pre-allocated and reused.
 339     if (continuation != NULL &amp;&amp; !recursive_exception &amp;&amp; !SharedRuntime::deopt_blob()-&gt;contains(continuation)) {
 340       cm-&gt;add_handler_for_exception_and_pc(exception, pc, continuation);
 341     }
 342   }
 343 
 344   // Set flag if return address is a method handle call site.
 345   thread-&gt;set_is_method_handle_return(cm-&gt;is_method_handle_return(pc));
 346 
 347   if (log_is_enabled(Info, exceptions)) {
 348     ResourceMark rm;
 349     log_info(exceptions)(&quot;Thread &quot; PTR_FORMAT &quot; continuing at PC &quot; PTR_FORMAT
 350                          &quot; for exception thrown at PC &quot; PTR_FORMAT,
 351                          p2i(thread), p2i(continuation), p2i(pc));
 352   }
 353 
 354   return continuation;
 355 JRT_END
 356 
 357 // Enter this method from compiled code only if there is a Java exception handler
 358 // in the method handling the exception.
 359 // We are entering here from exception stub. We don&#39;t do a normal VM transition here.
 360 // We do it in a helper. This is so we can check to see if the nmethod we have just
 361 // searched for an exception handler has been deoptimized in the meantime.
 362 address JVMCIRuntime::exception_handler_for_pc(JavaThread* thread) {
 363   oop exception = thread-&gt;exception_oop();
 364   address pc = thread-&gt;exception_pc();
 365   // Still in Java mode
 366   DEBUG_ONLY(ResetNoHandleMark rnhm);
 367   CompiledMethod* cm = NULL;
 368   address continuation = NULL;
 369   {
 370     // Enter VM mode by calling the helper
 371     ResetNoHandleMark rnhm;
 372     continuation = exception_handler_for_pc_helper(thread, exception, pc, cm);
 373   }
 374   // Back in JAVA, use no oops DON&#39;T safepoint
 375 
 376   // Now check to see if the compiled method we were called from is now deoptimized.
 377   // If so we must return to the deopt blob and deoptimize the nmethod
 378   if (cm != NULL &amp;&amp; caller_is_deopted()) {
 379     continuation = SharedRuntime::deopt_blob()-&gt;unpack_with_exception_in_tls();
 380   }
 381 
 382   assert(continuation != NULL, &quot;no handler found&quot;);
 383   return continuation;
 384 }
 385 
 386 JRT_BLOCK_ENTRY(void, JVMCIRuntime::monitorenter(JavaThread* thread, oopDesc* obj, BasicLock* lock))
 387   SharedRuntime::monitor_enter_helper(obj, lock, thread);
 388 JRT_END
 389 
 390 JRT_LEAF(void, JVMCIRuntime::monitorexit(JavaThread* thread, oopDesc* obj, BasicLock* lock))
 391   assert(thread-&gt;last_Java_sp(), &quot;last_Java_sp must be set&quot;);
 392   assert(oopDesc::is_oop(obj), &quot;invalid lock object pointer dected&quot;);
 393   SharedRuntime::monitor_exit_helper(obj, lock, thread);
 394 JRT_END
 395 
 396 // Object.notify() fast path, caller does slow path
 397 JRT_LEAF(jboolean, JVMCIRuntime::object_notify(JavaThread *thread, oopDesc* obj))
 398 
 399   // Very few notify/notifyAll operations find any threads on the waitset, so
 400   // the dominant fast-path is to simply return.
 401   // Relatedly, it&#39;s critical that notify/notifyAll be fast in order to
 402   // reduce lock hold times.
 403   if (!SafepointSynchronize::is_synchronizing()) {
 404     if (ObjectSynchronizer::quick_notify(obj, thread, false)) {
 405       return true;
 406     }
 407   }
 408   return false; // caller must perform slow path
 409 
 410 JRT_END
 411 
 412 // Object.notifyAll() fast path, caller does slow path
 413 JRT_LEAF(jboolean, JVMCIRuntime::object_notifyAll(JavaThread *thread, oopDesc* obj))
 414 
 415   if (!SafepointSynchronize::is_synchronizing() ) {
 416     if (ObjectSynchronizer::quick_notify(obj, thread, true)) {
 417       return true;
 418     }
 419   }
 420   return false; // caller must perform slow path
 421 
 422 JRT_END
 423 
 424 JRT_BLOCK_ENTRY(int, JVMCIRuntime::throw_and_post_jvmti_exception(JavaThread* thread, const char* exception, const char* message))
 425   JRT_BLOCK;
 426   TempNewSymbol symbol = SymbolTable::new_symbol(exception);
 427   SharedRuntime::throw_and_post_jvmti_exception(thread, symbol, message);
 428   JRT_BLOCK_END;
 429   return caller_is_deopted();
 430 JRT_END
 431 
 432 JRT_BLOCK_ENTRY(int, JVMCIRuntime::throw_klass_external_name_exception(JavaThread* thread, const char* exception, Klass* klass))
 433   JRT_BLOCK;
 434   ResourceMark rm(thread);
 435   TempNewSymbol symbol = SymbolTable::new_symbol(exception);
 436   SharedRuntime::throw_and_post_jvmti_exception(thread, symbol, klass-&gt;external_name());
 437   JRT_BLOCK_END;
 438   return caller_is_deopted();
 439 JRT_END
 440 
 441 JRT_BLOCK_ENTRY(int, JVMCIRuntime::throw_class_cast_exception(JavaThread* thread, const char* exception, Klass* caster_klass, Klass* target_klass))
 442   JRT_BLOCK;
 443   ResourceMark rm(thread);
 444   const char* message = SharedRuntime::generate_class_cast_message(caster_klass, target_klass);
 445   TempNewSymbol symbol = SymbolTable::new_symbol(exception);
 446   SharedRuntime::throw_and_post_jvmti_exception(thread, symbol, message);
 447   JRT_BLOCK_END;
 448   return caller_is_deopted();
 449 JRT_END
 450 
 451 JRT_LEAF(void, JVMCIRuntime::log_object(JavaThread* thread, oopDesc* obj, bool as_string, bool newline))
 452   ttyLocker ttyl;
 453 
 454   if (obj == NULL) {
 455     tty-&gt;print(&quot;NULL&quot;);
 456   } else if (oopDesc::is_oop_or_null(obj, true) &amp;&amp; (!as_string || !java_lang_String::is_instance(obj))) {
 457     if (oopDesc::is_oop_or_null(obj, true)) {
 458       char buf[O_BUFLEN];
 459       tty-&gt;print(&quot;%s@&quot; INTPTR_FORMAT, obj-&gt;klass()-&gt;name()-&gt;as_C_string(buf, O_BUFLEN), p2i(obj));
 460     } else {
 461       tty-&gt;print(INTPTR_FORMAT, p2i(obj));
 462     }
 463   } else {
 464     ResourceMark rm;
 465     assert(obj != NULL &amp;&amp; java_lang_String::is_instance(obj), &quot;must be&quot;);
 466     char *buf = java_lang_String::as_utf8_string(obj);
 467     tty-&gt;print_raw(buf);
 468   }
 469   if (newline) {
 470     tty-&gt;cr();
 471   }
 472 JRT_END
 473 
 474 #if INCLUDE_G1GC
 475 
 476 JRT_LEAF(void, JVMCIRuntime::write_barrier_pre(JavaThread* thread, oopDesc* obj))
 477   G1ThreadLocalData::satb_mark_queue(thread).enqueue(obj);
 478 JRT_END
 479 
 480 JRT_LEAF(void, JVMCIRuntime::write_barrier_post(JavaThread* thread, void* card_addr))
 481   G1ThreadLocalData::dirty_card_queue(thread).enqueue(card_addr);
 482 JRT_END
 483 
 484 #endif // INCLUDE_G1GC
 485 
 486 JRT_LEAF(jboolean, JVMCIRuntime::validate_object(JavaThread* thread, oopDesc* parent, oopDesc* child))
 487   bool ret = true;
 488   if(!Universe::heap()-&gt;is_in(parent)) {
 489     tty-&gt;print_cr(&quot;Parent Object &quot; INTPTR_FORMAT &quot; not in heap&quot;, p2i(parent));
 490     parent-&gt;print();
 491     ret=false;
 492   }
 493   if(!Universe::heap()-&gt;is_in(child)) {
 494     tty-&gt;print_cr(&quot;Child Object &quot; INTPTR_FORMAT &quot; not in heap&quot;, p2i(child));
 495     child-&gt;print();
 496     ret=false;
 497   }
 498   return (jint)ret;
 499 JRT_END
 500 
 501 JRT_ENTRY(void, JVMCIRuntime::vm_error(JavaThread* thread, jlong where, jlong format, jlong value))
 502   ResourceMark rm;
 503   const char *error_msg = where == 0L ? &quot;&lt;internal JVMCI error&gt;&quot; : (char*) (address) where;
 504   char *detail_msg = NULL;
 505   if (format != 0L) {
 506     const char* buf = (char*) (address) format;
 507     size_t detail_msg_length = strlen(buf) * 2;
 508     detail_msg = (char *) NEW_RESOURCE_ARRAY(u_char, detail_msg_length);
 509     jio_snprintf(detail_msg, detail_msg_length, buf, value);
 510   }
 511   report_vm_error(__FILE__, __LINE__, error_msg, &quot;%s&quot;, detail_msg);
 512 JRT_END
 513 
 514 JRT_LEAF(oopDesc*, JVMCIRuntime::load_and_clear_exception(JavaThread* thread))
 515   oop exception = thread-&gt;exception_oop();
 516   assert(exception != NULL, &quot;npe&quot;);
 517   thread-&gt;set_exception_oop(NULL);
 518   thread-&gt;set_exception_pc(0);
 519   return exception;
 520 JRT_END
 521 
 522 PRAGMA_DIAG_PUSH
 523 PRAGMA_FORMAT_NONLITERAL_IGNORED
 524 JRT_LEAF(void, JVMCIRuntime::log_printf(JavaThread* thread, const char* format, jlong v1, jlong v2, jlong v3))
 525   ResourceMark rm;
 526   tty-&gt;print(format, v1, v2, v3);
 527 JRT_END
 528 PRAGMA_DIAG_POP
 529 
 530 static void decipher(jlong v, bool ignoreZero) {
 531   if (v != 0 || !ignoreZero) {
 532     void* p = (void *)(address) v;
 533     CodeBlob* cb = CodeCache::find_blob(p);
 534     if (cb) {
 535       if (cb-&gt;is_nmethod()) {
 536         char buf[O_BUFLEN];
 537         tty-&gt;print(&quot;%s [&quot; INTPTR_FORMAT &quot;+&quot; JLONG_FORMAT &quot;]&quot;, cb-&gt;as_nmethod_or_null()-&gt;method()-&gt;name_and_sig_as_C_string(buf, O_BUFLEN), p2i(cb-&gt;code_begin()), (jlong)((address)v - cb-&gt;code_begin()));
 538         return;
 539       }
 540       cb-&gt;print_value_on(tty);
 541       return;
 542     }
 543     if (Universe::heap()-&gt;is_in(p)) {
 544       oop obj = oop(p);
 545       obj-&gt;print_value_on(tty);
 546       return;
 547     }
 548     tty-&gt;print(INTPTR_FORMAT &quot; [long: &quot; JLONG_FORMAT &quot;, double %lf, char %c]&quot;,p2i((void *)v), (jlong)v, (jdouble)v, (char)v);
 549   }
 550 }
 551 
 552 PRAGMA_DIAG_PUSH
 553 PRAGMA_FORMAT_NONLITERAL_IGNORED
 554 JRT_LEAF(void, JVMCIRuntime::vm_message(jboolean vmError, jlong format, jlong v1, jlong v2, jlong v3))
 555   ResourceMark rm;
 556   const char *buf = (const char*) (address) format;
 557   if (vmError) {
 558     if (buf != NULL) {
 559       fatal(buf, v1, v2, v3);
 560     } else {
 561       fatal(&quot;&lt;anonymous error&gt;&quot;);
 562     }
 563   } else if (buf != NULL) {
 564     tty-&gt;print(buf, v1, v2, v3);
 565   } else {
 566     assert(v2 == 0, &quot;v2 != 0&quot;);
 567     assert(v3 == 0, &quot;v3 != 0&quot;);
 568     decipher(v1, false);
 569   }
 570 JRT_END
 571 PRAGMA_DIAG_POP
 572 
 573 JRT_LEAF(void, JVMCIRuntime::log_primitive(JavaThread* thread, jchar typeChar, jlong value, jboolean newline))
 574   union {
 575       jlong l;
 576       jdouble d;
 577       jfloat f;
 578   } uu;
 579   uu.l = value;
 580   switch (typeChar) {
 581     case &#39;Z&#39;: tty-&gt;print(value == 0 ? &quot;false&quot; : &quot;true&quot;); break;
 582     case &#39;B&#39;: tty-&gt;print(&quot;%d&quot;, (jbyte) value); break;
 583     case &#39;C&#39;: tty-&gt;print(&quot;%c&quot;, (jchar) value); break;
 584     case &#39;S&#39;: tty-&gt;print(&quot;%d&quot;, (jshort) value); break;
 585     case &#39;I&#39;: tty-&gt;print(&quot;%d&quot;, (jint) value); break;
 586     case &#39;F&#39;: tty-&gt;print(&quot;%f&quot;, uu.f); break;
 587     case &#39;J&#39;: tty-&gt;print(JLONG_FORMAT, value); break;
 588     case &#39;D&#39;: tty-&gt;print(&quot;%lf&quot;, uu.d); break;
 589     default: assert(false, &quot;unknown typeChar&quot;); break;
 590   }
 591   if (newline) {
 592     tty-&gt;cr();
 593   }
 594 JRT_END
 595 
 596 JRT_ENTRY(jint, JVMCIRuntime::identity_hash_code(JavaThread* thread, oopDesc* obj))
 597   return (jint) obj-&gt;identity_hash();
 598 JRT_END
 599 
 600 JRT_ENTRY(jint, JVMCIRuntime::test_deoptimize_call_int(JavaThread* thread, int value))
 601   deopt_caller();
 602   return (jint) value;
 603 JRT_END
 604 
 605 
 606 // private static JVMCIRuntime JVMCI.initializeRuntime()
 607 JVM_ENTRY_NO_ENV(jobject, JVM_GetJVMCIRuntime(JNIEnv *env, jclass c))
 608   JNI_JVMCIENV(thread, env);
 609   if (!EnableJVMCI) {
 610     JVMCI_THROW_MSG_NULL(InternalError, &quot;JVMCI is not enabled&quot;);
 611   }
 612   JVMCIENV-&gt;runtime()-&gt;initialize_HotSpotJVMCIRuntime(JVMCI_CHECK_NULL);
 613   JVMCIObject runtime = JVMCIENV-&gt;runtime()-&gt;get_HotSpotJVMCIRuntime(JVMCI_CHECK_NULL);
 614   return JVMCIENV-&gt;get_jobject(runtime);
 615 JVM_END
 616 
 617 void JVMCIRuntime::call_getCompiler(TRAPS) {
 618   THREAD_JVMCIENV(JavaThread::current());
 619   JVMCIObject jvmciRuntime = JVMCIRuntime::get_HotSpotJVMCIRuntime(JVMCI_CHECK);
 620   initialize(JVMCIENV);
 621   JVMCIENV-&gt;call_HotSpotJVMCIRuntime_getCompiler(jvmciRuntime, JVMCI_CHECK);
 622 }
 623 
 624 void JVMCINMethodData::initialize(
 625   int nmethod_mirror_index,
 626   const char* name,
 627   FailedSpeculation** failed_speculations)
 628 {
 629   _failed_speculations = failed_speculations;
 630   _nmethod_mirror_index = nmethod_mirror_index;
 631   if (name != NULL) {
 632     _has_name = true;
 633     char* dest = (char*) this-&gt;name();
 634     strcpy(dest, name);
 635   } else {
 636     _has_name = false;
 637   }
 638 }
 639 
 640 void JVMCINMethodData::add_failed_speculation(nmethod* nm, jlong speculation) {
 641   uint index = (speculation &gt;&gt; 32) &amp; 0xFFFFFFFF;
 642   int length = (int) speculation;
 643   if (index + length &gt; (uint) nm-&gt;speculations_size()) {
 644     fatal(INTPTR_FORMAT &quot;[index: %d, length: %d] out of bounds wrt encoded speculations of length %u&quot;, speculation, index, length, nm-&gt;speculations_size());
 645   }
 646   address data = nm-&gt;speculations_begin() + index;
 647   FailedSpeculation::add_failed_speculation(nm, _failed_speculations, data, length);
 648 }
 649 
 650 oop JVMCINMethodData::get_nmethod_mirror(nmethod* nm, bool phantom_ref) {
 651   if (_nmethod_mirror_index == -1) {
 652     return NULL;
 653   }
 654   if (phantom_ref) {
 655     return nm-&gt;oop_at_phantom(_nmethod_mirror_index);
 656   } else {
 657     return nm-&gt;oop_at(_nmethod_mirror_index);
 658   }
 659 }
 660 
 661 void JVMCINMethodData::set_nmethod_mirror(nmethod* nm, oop new_mirror) {
 662   assert(_nmethod_mirror_index != -1, &quot;cannot set JVMCI mirror for nmethod&quot;);
 663   oop* addr = nm-&gt;oop_addr_at(_nmethod_mirror_index);
 664   assert(new_mirror != NULL, &quot;use clear_nmethod_mirror to clear the mirror&quot;);
 665   assert(*addr == NULL, &quot;cannot overwrite non-null mirror&quot;);
 666 
 667   *addr = new_mirror;
 668 
 669   // Since we&#39;ve patched some oops in the nmethod,
 670   // (re)register it with the heap.
 671   Universe::heap()-&gt;register_nmethod(nm);
 672 }
 673 
 674 void JVMCINMethodData::clear_nmethod_mirror(nmethod* nm) {
 675   if (_nmethod_mirror_index != -1) {
 676     oop* addr = nm-&gt;oop_addr_at(_nmethod_mirror_index);
 677     *addr = NULL;
 678   }
 679 }
 680 
 681 void JVMCINMethodData::invalidate_nmethod_mirror(nmethod* nm) {
 682   oop nmethod_mirror = get_nmethod_mirror(nm, /* phantom_ref */ false);
 683   if (nmethod_mirror == NULL) {
 684     return;
 685   }
 686 
 687   // Update the values in the mirror if it still refers to nm.
 688   // We cannot use JVMCIObject to wrap the mirror as this is called
 689   // during GC, forbidding the creation of JNIHandles.
 690   JVMCIEnv* jvmciEnv = NULL;
 691   nmethod* current = (nmethod*) HotSpotJVMCI::InstalledCode::address(jvmciEnv, nmethod_mirror);
 692   if (nm == current) {
 693     if (!nm-&gt;is_alive()) {
 694       // Break the link from the mirror to nm such that
 695       // future invocations via the mirror will result in
 696       // an InvalidInstalledCodeException.
 697       HotSpotJVMCI::InstalledCode::set_address(jvmciEnv, nmethod_mirror, 0);
 698       HotSpotJVMCI::InstalledCode::set_entryPoint(jvmciEnv, nmethod_mirror, 0);
 699     } else if (nm-&gt;is_not_entrant()) {
 700       // Zero the entry point so any new invocation will fail but keep
 701       // the address link around that so that existing activations can
 702       // be deoptimized via the mirror (i.e. JVMCIEnv::invalidate_installed_code).
 703       HotSpotJVMCI::InstalledCode::set_entryPoint(jvmciEnv, nmethod_mirror, 0);
 704     }
 705   }
 706 }
 707 
 708 void JVMCIRuntime::initialize_HotSpotJVMCIRuntime(JVMCI_TRAPS) {
 709   if (is_HotSpotJVMCIRuntime_initialized()) {
 710     if (JVMCIENV-&gt;is_hotspot() &amp;&amp; UseJVMCINativeLibrary) {
 711       JVMCI_THROW_MSG(InternalError, &quot;JVMCI has already been enabled in the JVMCI shared library&quot;);
 712     }
 713   }
 714 
 715   initialize(JVMCIENV);
 716 
 717   // This should only be called in the context of the JVMCI class being initialized
 718   JVMCIObject result = JVMCIENV-&gt;call_HotSpotJVMCIRuntime_runtime(JVMCI_CHECK);
 719 
 720   _HotSpotJVMCIRuntime_instance = JVMCIENV-&gt;make_global(result);
 721 }
 722 
 723 void JVMCIRuntime::initialize(JVMCIEnv* JVMCIENV) {
 724   assert(this != NULL, &quot;sanity&quot;);
 725   // Check first without JVMCI_lock
 726   if (_initialized) {
 727     return;
 728   }
 729 
 730   MutexLocker locker(JVMCI_lock);
 731   // Check again under JVMCI_lock
 732   if (_initialized) {
 733     return;
 734   }
 735 
 736   while (_being_initialized) {
 737     JVMCI_lock-&gt;wait();
 738     if (_initialized) {
 739       return;
 740     }
 741   }
 742 
 743   _being_initialized = true;
 744 
 745   {
 746     MutexUnlocker unlock(JVMCI_lock);
 747 
 748     HandleMark hm;
 749     ResourceMark rm;
 750     JavaThread* THREAD = JavaThread::current();
 751     if (JVMCIENV-&gt;is_hotspot()) {
 752       HotSpotJVMCI::compute_offsets(CHECK_EXIT);
 753     } else {
 754       JNIAccessMark jni(JVMCIENV);
 755 
 756       JNIJVMCI::initialize_ids(jni.env());
 757       if (jni()-&gt;ExceptionCheck()) {
 758         jni()-&gt;ExceptionDescribe();
 759         fatal(&quot;JNI exception during init&quot;);
 760       }
 761     }
 762     create_jvmci_primitive_type(T_BOOLEAN, JVMCI_CHECK_EXIT_((void)0));
 763     create_jvmci_primitive_type(T_BYTE, JVMCI_CHECK_EXIT_((void)0));
 764     create_jvmci_primitive_type(T_CHAR, JVMCI_CHECK_EXIT_((void)0));
 765     create_jvmci_primitive_type(T_SHORT, JVMCI_CHECK_EXIT_((void)0));
 766     create_jvmci_primitive_type(T_INT, JVMCI_CHECK_EXIT_((void)0));
 767     create_jvmci_primitive_type(T_LONG, JVMCI_CHECK_EXIT_((void)0));
 768     create_jvmci_primitive_type(T_FLOAT, JVMCI_CHECK_EXIT_((void)0));
 769     create_jvmci_primitive_type(T_DOUBLE, JVMCI_CHECK_EXIT_((void)0));
 770     create_jvmci_primitive_type(T_VOID, JVMCI_CHECK_EXIT_((void)0));
 771 
 772     if (!JVMCIENV-&gt;is_hotspot()) {
 773       JVMCIENV-&gt;copy_saved_properties();
 774     }
 775   }
 776 
 777   _initialized = true;
 778   _being_initialized = false;
 779   JVMCI_lock-&gt;notify_all();
 780 }
 781 
 782 JVMCIObject JVMCIRuntime::create_jvmci_primitive_type(BasicType type, JVMCI_TRAPS) {
 783   Thread* THREAD = Thread::current();
 784   // These primitive types are long lived and are created before the runtime is fully set up
 785   // so skip registering them for scanning.
 786   JVMCIObject mirror = JVMCIENV-&gt;get_object_constant(java_lang_Class::primitive_mirror(type), false, true);
 787   if (JVMCIENV-&gt;is_hotspot()) {
 788     JavaValue result(T_OBJECT);
 789     JavaCallArguments args;
 790     args.push_oop(Handle(THREAD, HotSpotJVMCI::resolve(mirror)));
 791     args.push_int(type2char(type));
 792     JavaCalls::call_static(&amp;result, HotSpotJVMCI::HotSpotResolvedPrimitiveType::klass(), vmSymbols::fromMetaspace_name(), vmSymbols::primitive_fromMetaspace_signature(), &amp;args, CHECK_(JVMCIObject()));
 793 
 794     return JVMCIENV-&gt;wrap(JNIHandles::make_local((oop)result.get_jobject()));
 795   } else {
 796     JNIAccessMark jni(JVMCIENV);
 797     jobject result = jni()-&gt;CallStaticObjectMethod(JNIJVMCI::HotSpotResolvedPrimitiveType::clazz(),
 798                                            JNIJVMCI::HotSpotResolvedPrimitiveType_fromMetaspace_method(),
 799                                            mirror.as_jobject(), type2char(type));
 800     if (jni()-&gt;ExceptionCheck()) {
 801       return JVMCIObject();
 802     }
 803     return JVMCIENV-&gt;wrap(result);
 804   }
 805 }
 806 
 807 void JVMCIRuntime::initialize_JVMCI(JVMCI_TRAPS) {
 808   if (!is_HotSpotJVMCIRuntime_initialized()) {
 809     initialize(JVMCI_CHECK);
 810     JVMCIENV-&gt;call_JVMCI_getRuntime(JVMCI_CHECK);
 811   }
 812 }
 813 
 814 JVMCIObject JVMCIRuntime::get_HotSpotJVMCIRuntime(JVMCI_TRAPS) {
 815   initialize(JVMCIENV);
 816   initialize_JVMCI(JVMCI_CHECK_(JVMCIObject()));
 817   return _HotSpotJVMCIRuntime_instance;
 818 }
 819 
 820 
 821 // private void CompilerToVM.registerNatives()
 822 JVM_ENTRY_NO_ENV(void, JVM_RegisterJVMCINatives(JNIEnv *env, jclass c2vmClass))
 823   JNI_JVMCIENV(thread, env);
 824 
 825   if (!EnableJVMCI) {
 826     JVMCI_THROW_MSG(InternalError, &quot;JVMCI is not enabled&quot;);
 827   }
 828 
 829   JVMCIENV-&gt;runtime()-&gt;initialize(JVMCIENV);
 830 
 831   {
 832     ResourceMark rm;
 833     HandleMark hm(thread);
 834     ThreadToNativeFromVM trans(thread);
 835 
 836     // Ensure _non_oop_bits is initialized
 837     Universe::non_oop_word();
 838 
 839     if (JNI_OK != env-&gt;RegisterNatives(c2vmClass, CompilerToVM::methods, CompilerToVM::methods_count())) {
 840       if (!env-&gt;ExceptionCheck()) {
 841         for (int i = 0; i &lt; CompilerToVM::methods_count(); i++) {
 842           if (JNI_OK != env-&gt;RegisterNatives(c2vmClass, CompilerToVM::methods + i, 1)) {
 843             guarantee(false, &quot;Error registering JNI method %s%s&quot;, CompilerToVM::methods[i].name, CompilerToVM::methods[i].signature);
 844             break;
 845           }
 846         }
 847       } else {
 848         env-&gt;ExceptionDescribe();
 849       }
 850       guarantee(false, &quot;Failed registering CompilerToVM native methods&quot;);
 851     }
 852   }
 853 JVM_END
 854 
 855 
 856 void JVMCIRuntime::shutdown() {
 857   if (is_HotSpotJVMCIRuntime_initialized()) {
 858     _shutdown_called = true;
 859 
 860     THREAD_JVMCIENV(JavaThread::current());
 861     JVMCIENV-&gt;call_HotSpotJVMCIRuntime_shutdown(_HotSpotJVMCIRuntime_instance);
 862   }
 863 }
 864 
 865 void JVMCIRuntime::bootstrap_finished(TRAPS) {
 866   if (is_HotSpotJVMCIRuntime_initialized()) {
 867     THREAD_JVMCIENV(JavaThread::current());
 868     JVMCIENV-&gt;call_HotSpotJVMCIRuntime_bootstrapFinished(_HotSpotJVMCIRuntime_instance, JVMCIENV);
 869   }
 870 }
 871 
 872 void JVMCIRuntime::describe_pending_hotspot_exception(JavaThread* THREAD, bool clear) {
 873   if (HAS_PENDING_EXCEPTION) {
 874     Handle exception(THREAD, PENDING_EXCEPTION);
 875     const char* exception_file = THREAD-&gt;exception_file();
 876     int exception_line = THREAD-&gt;exception_line();
 877     CLEAR_PENDING_EXCEPTION;
 878     if (exception-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
 879       // Don&#39;t print anything if we are being killed.
 880     } else {
 881       java_lang_Throwable::print_stack_trace(exception, tty);
 882 
 883       // Clear and ignore any exceptions raised during printing
 884       CLEAR_PENDING_EXCEPTION;
 885     }
 886     if (!clear) {
 887       THREAD-&gt;set_pending_exception(exception(), exception_file, exception_line);
 888     }
 889   }
 890 }
 891 
 892 
 893 void JVMCIRuntime::exit_on_pending_exception(JVMCIEnv* JVMCIENV, const char* message) {
 894   JavaThread* THREAD = JavaThread::current();
 895 
 896   static volatile int report_error = 0;
 897   if (!report_error &amp;&amp; Atomic::cmpxchg(&amp;report_error, 0, 1) == 0) {
 898     // Only report an error once
 899     tty-&gt;print_raw_cr(message);
 900     if (JVMCIENV != NULL) {
 901       JVMCIENV-&gt;describe_pending_exception(true);
 902     } else {
 903       describe_pending_hotspot_exception(THREAD, true);
 904     }
 905   } else {
 906     // Allow error reporting thread to print the stack trace.
 907     THREAD-&gt;sleep(200);
 908   }
 909 
 910   before_exit(THREAD);
 911   vm_exit(-1);
 912 }
 913 
 914 // ------------------------------------------------------------------
 915 // Note: the logic of this method should mirror the logic of
 916 // constantPoolOopDesc::verify_constant_pool_resolve.
 917 bool JVMCIRuntime::check_klass_accessibility(Klass* accessing_klass, Klass* resolved_klass) {
 918   if (accessing_klass-&gt;is_objArray_klass()) {
 919     accessing_klass = ObjArrayKlass::cast(accessing_klass)-&gt;bottom_klass();
 920   }
 921   if (!accessing_klass-&gt;is_instance_klass()) {
 922     return true;
 923   }
 924 
 925   if (resolved_klass-&gt;is_objArray_klass()) {
 926     // Find the element klass, if this is an array.
 927     resolved_klass = ObjArrayKlass::cast(resolved_klass)-&gt;bottom_klass();
 928   }
 929   if (resolved_klass-&gt;is_instance_klass()) {
 930     Reflection::VerifyClassAccessResults result =
 931       Reflection::verify_class_access(accessing_klass, InstanceKlass::cast(resolved_klass), true);
 932     return result == Reflection::ACCESS_OK;
 933   }
 934   return true;
 935 }
 936 
 937 // ------------------------------------------------------------------
 938 Klass* JVMCIRuntime::get_klass_by_name_impl(Klass*&amp; accessing_klass,
 939                                           const constantPoolHandle&amp; cpool,
 940                                           Symbol* sym,
 941                                           bool require_local) {
 942   JVMCI_EXCEPTION_CONTEXT;
 943 
 944   // Now we need to check the SystemDictionary
 945   if (sym-&gt;char_at(0) == JVM_SIGNATURE_CLASS &amp;&amp;
 946       sym-&gt;char_at(sym-&gt;utf8_length()-1) == JVM_SIGNATURE_ENDCLASS) {
 947     // This is a name from a signature.  Strip off the trimmings.
 948     // Call recursive to keep scope of strippedsym.
 949     TempNewSymbol strippedsym = SymbolTable::new_symbol(sym-&gt;as_utf8()+1,
 950                                                         sym-&gt;utf8_length()-2);
 951     return get_klass_by_name_impl(accessing_klass, cpool, strippedsym, require_local);
 952   }
 953 
 954   Handle loader(THREAD, (oop)NULL);
 955   Handle domain(THREAD, (oop)NULL);
 956   if (accessing_klass != NULL) {
 957     loader = Handle(THREAD, accessing_klass-&gt;class_loader());
 958     domain = Handle(THREAD, accessing_klass-&gt;protection_domain());
 959   }
 960 
 961   Klass* found_klass;
 962   {
 963     ttyUnlocker ttyul;  // release tty lock to avoid ordering problems
 964     MutexLocker ml(Compile_lock);
 965     if (!require_local) {
 966       found_klass = SystemDictionary::find_constrained_instance_or_array_klass(sym, loader, CHECK_NULL);
 967     } else {
 968       found_klass = SystemDictionary::find_instance_or_array_klass(sym, loader, domain, CHECK_NULL);
 969     }
 970   }
 971 
 972   // If we fail to find an array klass, look again for its element type.
 973   // The element type may be available either locally or via constraints.
 974   // In either case, if we can find the element type in the system dictionary,
 975   // we must build an array type around it.  The CI requires array klasses
 976   // to be loaded if their element klasses are loaded, except when memory
 977   // is exhausted.
 978   if (sym-&gt;char_at(0) == JVM_SIGNATURE_ARRAY &amp;&amp;
 979       (sym-&gt;char_at(1) == JVM_SIGNATURE_ARRAY || sym-&gt;char_at(1) == JVM_SIGNATURE_CLASS)) {
 980     // We have an unloaded array.
 981     // Build it on the fly if the element class exists.
 982     TempNewSymbol elem_sym = SymbolTable::new_symbol(sym-&gt;as_utf8()+1,
 983                                                      sym-&gt;utf8_length()-1);
 984 
 985     // Get element Klass recursively.
 986     Klass* elem_klass =
 987       get_klass_by_name_impl(accessing_klass,
 988                              cpool,
 989                              elem_sym,
 990                              require_local);
 991     if (elem_klass != NULL) {
 992       // Now make an array for it
 993       return elem_klass-&gt;array_klass(THREAD);
 994     }
 995   }
 996 
 997   if (found_klass == NULL &amp;&amp; !cpool.is_null() &amp;&amp; cpool-&gt;has_preresolution()) {
 998     // Look inside the constant pool for pre-resolved class entries.
 999     for (int i = cpool-&gt;length() - 1; i &gt;= 1; i--) {
1000       if (cpool-&gt;tag_at(i).is_klass()) {
1001         Klass*  kls = cpool-&gt;resolved_klass_at(i);
1002         if (kls-&gt;name() == sym) {
1003           return kls;
1004         }
1005       }
1006     }
1007   }
1008 
1009   return found_klass;
1010 }
1011 
1012 // ------------------------------------------------------------------
1013 Klass* JVMCIRuntime::get_klass_by_name(Klass* accessing_klass,
1014                                   Symbol* klass_name,
1015                                   bool require_local) {
1016   ResourceMark rm;
1017   constantPoolHandle cpool;
1018   return get_klass_by_name_impl(accessing_klass,
1019                                                  cpool,
1020                                                  klass_name,
1021                                                  require_local);
1022 }
1023 
1024 // ------------------------------------------------------------------
1025 // Implementation of get_klass_by_index.
1026 Klass* JVMCIRuntime::get_klass_by_index_impl(const constantPoolHandle&amp; cpool,
1027                                         int index,
1028                                         bool&amp; is_accessible,
1029                                         Klass* accessor) {
1030   JVMCI_EXCEPTION_CONTEXT;
1031   Klass* klass = ConstantPool::klass_at_if_loaded(cpool, index);
1032   Symbol* klass_name = NULL;
1033   if (klass == NULL) {
1034     klass_name = cpool-&gt;klass_name_at(index);
1035   }
1036 
1037   if (klass == NULL) {
1038     // Not found in constant pool.  Use the name to do the lookup.
1039     Klass* k = get_klass_by_name_impl(accessor,
1040                                         cpool,
1041                                         klass_name,
1042                                         false);
1043     // Calculate accessibility the hard way.
1044     if (k == NULL) {
1045       is_accessible = false;
1046     } else if (k-&gt;class_loader() != accessor-&gt;class_loader() &amp;&amp;
1047                get_klass_by_name_impl(accessor, cpool, k-&gt;name(), true) == NULL) {
1048       // Loaded only remotely.  Not linked yet.
1049       is_accessible = false;
1050     } else {
1051       // Linked locally, and we must also check public/private, etc.
1052       is_accessible = check_klass_accessibility(accessor, k);
1053     }
1054     if (!is_accessible) {
1055       return NULL;
1056     }
1057     return k;
1058   }
1059 
1060   // It is known to be accessible, since it was found in the constant pool.
1061   is_accessible = true;
1062   return klass;
1063 }
1064 
1065 // ------------------------------------------------------------------
1066 // Get a klass from the constant pool.
1067 Klass* JVMCIRuntime::get_klass_by_index(const constantPoolHandle&amp; cpool,
1068                                    int index,
1069                                    bool&amp; is_accessible,
1070                                    Klass* accessor) {
1071   ResourceMark rm;
1072   Klass* result = get_klass_by_index_impl(cpool, index, is_accessible, accessor);
1073   return result;
1074 }
1075 
1076 // ------------------------------------------------------------------
1077 // Implementation of get_field_by_index.
1078 //
1079 // Implementation note: the results of field lookups are cached
1080 // in the accessor klass.
1081 void JVMCIRuntime::get_field_by_index_impl(InstanceKlass* klass, fieldDescriptor&amp; field_desc,
1082                                         int index) {
1083   JVMCI_EXCEPTION_CONTEXT;
1084 
1085   assert(klass-&gt;is_linked(), &quot;must be linked before using its constant-pool&quot;);
1086 
1087   constantPoolHandle cpool(thread, klass-&gt;constants());
1088 
1089   // Get the field&#39;s name, signature, and type.
1090   Symbol* name  = cpool-&gt;name_ref_at(index);
1091 
1092   int nt_index = cpool-&gt;name_and_type_ref_index_at(index);
1093   int sig_index = cpool-&gt;signature_ref_index_at(nt_index);
1094   Symbol* signature = cpool-&gt;symbol_at(sig_index);
1095 
1096   // Get the field&#39;s declared holder.
1097   int holder_index = cpool-&gt;klass_ref_index_at(index);
1098   bool holder_is_accessible;
1099   Klass* declared_holder = get_klass_by_index(cpool, holder_index,
1100                                                holder_is_accessible,
1101                                                klass);
1102 
1103   // The declared holder of this field may not have been loaded.
1104   // Bail out with partial field information.
1105   if (!holder_is_accessible) {
1106     return;
1107   }
1108 
1109 
1110   // Perform the field lookup.
1111   Klass*  canonical_holder =
1112     InstanceKlass::cast(declared_holder)-&gt;find_field(name, signature, &amp;field_desc);
1113   if (canonical_holder == NULL) {
1114     return;
1115   }
1116 
1117   assert(canonical_holder == field_desc.field_holder(), &quot;just checking&quot;);
1118 }
1119 
1120 // ------------------------------------------------------------------
1121 // Get a field by index from a klass&#39;s constant pool.
1122 void JVMCIRuntime::get_field_by_index(InstanceKlass* accessor, fieldDescriptor&amp; fd, int index) {
1123   ResourceMark rm;
1124   return get_field_by_index_impl(accessor, fd, index);
1125 }
1126 
1127 // ------------------------------------------------------------------
1128 // Perform an appropriate method lookup based on accessor, holder,
1129 // name, signature, and bytecode.
1130 Method* JVMCIRuntime::lookup_method(InstanceKlass* accessor,
1131                                     Klass*        holder,
1132                                     Symbol*       name,
1133                                     Symbol*       sig,
1134                                     Bytecodes::Code bc,
1135                                     constantTag   tag) {
1136   // Accessibility checks are performed in JVMCIEnv::get_method_by_index_impl().
1137   assert(check_klass_accessibility(accessor, holder), &quot;holder not accessible&quot;);
1138 
1139   Method* dest_method;
1140   LinkInfo link_info(holder, name, sig, accessor, LinkInfo::needs_access_check, tag);
1141   switch (bc) {
1142   case Bytecodes::_invokestatic:
1143     dest_method =
1144       LinkResolver::resolve_static_call_or_null(link_info);
1145     break;
1146   case Bytecodes::_invokespecial:
1147     dest_method =
1148       LinkResolver::resolve_special_call_or_null(link_info);
1149     break;
1150   case Bytecodes::_invokeinterface:
1151     dest_method =
1152       LinkResolver::linktime_resolve_interface_method_or_null(link_info);
1153     break;
1154   case Bytecodes::_invokevirtual:
1155     dest_method =
1156       LinkResolver::linktime_resolve_virtual_method_or_null(link_info);
1157     break;
1158   default: ShouldNotReachHere();
1159   }
1160 
1161   return dest_method;
1162 }
1163 
1164 
1165 // ------------------------------------------------------------------
1166 Method* JVMCIRuntime::get_method_by_index_impl(const constantPoolHandle&amp; cpool,
1167                                                int index, Bytecodes::Code bc,
1168                                                InstanceKlass* accessor) {
1169   if (bc == Bytecodes::_invokedynamic) {
1170     ConstantPoolCacheEntry* cpce = cpool-&gt;invokedynamic_cp_cache_entry_at(index);
1171     bool is_resolved = !cpce-&gt;is_f1_null();
1172     if (is_resolved) {
1173       // Get the invoker Method* from the constant pool.
1174       // (The appendix argument, if any, will be noted in the method&#39;s signature.)
1175       Method* adapter = cpce-&gt;f1_as_method();
1176       return adapter;
1177     }
1178 
1179     return NULL;
1180   }
1181 
1182   int holder_index = cpool-&gt;klass_ref_index_at(index);
1183   bool holder_is_accessible;
1184   Klass* holder = get_klass_by_index_impl(cpool, holder_index, holder_is_accessible, accessor);
1185 
1186   // Get the method&#39;s name and signature.
1187   Symbol* name_sym = cpool-&gt;name_ref_at(index);
1188   Symbol* sig_sym  = cpool-&gt;signature_ref_at(index);
1189 
1190   if (cpool-&gt;has_preresolution()
1191       || ((holder == SystemDictionary::MethodHandle_klass() || holder == SystemDictionary::VarHandle_klass()) &amp;&amp;
1192           MethodHandles::is_signature_polymorphic_name(holder, name_sym))) {
1193     // Short-circuit lookups for JSR 292-related call sites.
1194     // That is, do not rely only on name-based lookups, because they may fail
1195     // if the names are not resolvable in the boot class loader (7056328).
1196     switch (bc) {
1197     case Bytecodes::_invokevirtual:
1198     case Bytecodes::_invokeinterface:
1199     case Bytecodes::_invokespecial:
1200     case Bytecodes::_invokestatic:
1201       {
1202         Method* m = ConstantPool::method_at_if_loaded(cpool, index);
1203         if (m != NULL) {
1204           return m;
1205         }
1206       }
1207       break;
1208     default:
1209       break;
1210     }
1211   }
1212 
1213   if (holder_is_accessible) { // Our declared holder is loaded.
1214     constantTag tag = cpool-&gt;tag_ref_at(index);
1215     Method* m = lookup_method(accessor, holder, name_sym, sig_sym, bc, tag);
1216     if (m != NULL) {
1217       // We found the method.
1218       return m;
1219     }
1220   }
1221 
1222   // Either the declared holder was not loaded, or the method could
1223   // not be found.
1224 
1225   return NULL;
1226 }
1227 
1228 // ------------------------------------------------------------------
1229 InstanceKlass* JVMCIRuntime::get_instance_klass_for_declared_method_holder(Klass* method_holder) {
1230   // For the case of &lt;array&gt;.clone(), the method holder can be an ArrayKlass*
1231   // instead of an InstanceKlass*.  For that case simply pretend that the
1232   // declared holder is Object.clone since that&#39;s where the call will bottom out.
1233   if (method_holder-&gt;is_instance_klass()) {
1234     return InstanceKlass::cast(method_holder);
1235   } else if (method_holder-&gt;is_array_klass()) {
1236     return SystemDictionary::Object_klass();
1237   } else {
1238     ShouldNotReachHere();
1239   }
1240   return NULL;
1241 }
1242 
1243 
1244 // ------------------------------------------------------------------
1245 Method* JVMCIRuntime::get_method_by_index(const constantPoolHandle&amp; cpool,
1246                                      int index, Bytecodes::Code bc,
1247                                      InstanceKlass* accessor) {
1248   ResourceMark rm;
1249   return get_method_by_index_impl(cpool, index, bc, accessor);
1250 }
1251 
1252 // ------------------------------------------------------------------
1253 // Check for changes to the system dictionary during compilation
1254 // class loads, evolution, breakpoints
1255 JVMCI::CodeInstallResult JVMCIRuntime::validate_compile_task_dependencies(Dependencies* dependencies, JVMCICompileState* compile_state, char** failure_detail) {
1256   // If JVMTI capabilities were enabled during compile, the compilation is invalidated.
1257   if (compile_state != NULL &amp;&amp; compile_state-&gt;jvmti_state_changed()) {
1258     *failure_detail = (char*) &quot;Jvmti state change during compilation invalidated dependencies&quot;;
1259     return JVMCI::dependencies_failed;
1260   }
1261 
1262   CompileTask* task = compile_state == NULL ? NULL : compile_state-&gt;task();
1263   Dependencies::DepType result = dependencies-&gt;validate_dependencies(task, failure_detail);
1264   if (result == Dependencies::end_marker) {
1265     return JVMCI::ok;
1266   }
1267 
1268   return JVMCI::dependencies_failed;
1269 }
1270 
1271 // Reports a pending exception and exits the VM.
1272 static void fatal_exception_in_compile(JVMCIEnv* JVMCIENV, JavaThread* thread, const char* msg) {
1273   // Only report a fatal JVMCI compilation exception once
1274   static volatile int report_init_failure = 0;
1275   if (!report_init_failure &amp;&amp; Atomic::cmpxchg(&amp;report_init_failure, 0, 1) == 0) {
1276       tty-&gt;print_cr(&quot;%s:&quot;, msg);
1277       JVMCIENV-&gt;describe_pending_exception(true);
1278   }
1279   JVMCIENV-&gt;clear_pending_exception();
1280   before_exit(thread);
1281   vm_exit(-1);
1282 }
1283 
1284 void JVMCIRuntime::compile_method(JVMCIEnv* JVMCIENV, JVMCICompiler* compiler, const methodHandle&amp; method, int entry_bci) {
1285   JVMCI_EXCEPTION_CONTEXT
1286 
1287   JVMCICompileState* compile_state = JVMCIENV-&gt;compile_state();
1288 
1289   bool is_osr = entry_bci != InvocationEntryBci;
1290   if (compiler-&gt;is_bootstrapping() &amp;&amp; is_osr) {
1291     // no OSR compilations during bootstrap - the compiler is just too slow at this point,
1292     // and we know that there are no endless loops
1293     compile_state-&gt;set_failure(true, &quot;No OSR during boostrap&quot;);
1294     return;
1295   }
1296   if (JVMCI::shutdown_called()) {
1297     compile_state-&gt;set_failure(false, &quot;Avoiding compilation during shutdown&quot;);
1298     return;
1299   }
1300 
1301   HandleMark hm;
1302   JVMCIObject receiver = get_HotSpotJVMCIRuntime(JVMCIENV);
1303   if (JVMCIENV-&gt;has_pending_exception()) {
1304     fatal_exception_in_compile(JVMCIENV, thread, &quot;Exception during HotSpotJVMCIRuntime initialization&quot;);
1305   }
1306   JVMCIObject jvmci_method = JVMCIENV-&gt;get_jvmci_method(method, JVMCIENV);
1307   if (JVMCIENV-&gt;has_pending_exception()) {
1308     JVMCIENV-&gt;describe_pending_exception(true);
1309     compile_state-&gt;set_failure(false, &quot;exception getting JVMCI wrapper method&quot;);
1310     return;
1311   }
1312 
1313   JVMCIObject result_object = JVMCIENV-&gt;call_HotSpotJVMCIRuntime_compileMethod(receiver, jvmci_method, entry_bci,
1314                                                                      (jlong) compile_state, compile_state-&gt;task()-&gt;compile_id());
1315   if (!JVMCIENV-&gt;has_pending_exception()) {
1316     if (result_object.is_non_null()) {
1317       JVMCIObject failure_message = JVMCIENV-&gt;get_HotSpotCompilationRequestResult_failureMessage(result_object);
1318       if (failure_message.is_non_null()) {
1319         // Copy failure reason into resource memory first ...
1320         const char* failure_reason = JVMCIENV-&gt;as_utf8_string(failure_message);
1321         // ... and then into the C heap.
1322         failure_reason = os::strdup(failure_reason, mtJVMCI);
1323         bool retryable = JVMCIENV-&gt;get_HotSpotCompilationRequestResult_retry(result_object) != 0;
1324         compile_state-&gt;set_failure(retryable, failure_reason, true);
1325       } else {
1326         if (compile_state-&gt;task()-&gt;code() == NULL) {
1327           compile_state-&gt;set_failure(true, &quot;no nmethod produced&quot;);
1328         } else {
1329           compile_state-&gt;task()-&gt;set_num_inlined_bytecodes(JVMCIENV-&gt;get_HotSpotCompilationRequestResult_inlinedBytecodes(result_object));
1330           compiler-&gt;inc_methods_compiled();
1331         }
1332       }
1333     } else {
1334       assert(false, &quot;JVMCICompiler.compileMethod should always return non-null&quot;);
1335     }
1336   } else {
1337     // An uncaught exception here implies failure during compiler initialization.
1338     // The only sensible thing to do here is to exit the VM.
1339     fatal_exception_in_compile(JVMCIENV, thread, &quot;Exception during JVMCI compiler initialization&quot;);
1340   }
1341   if (compiler-&gt;is_bootstrapping()) {
1342     compiler-&gt;set_bootstrap_compilation_request_handled();
1343   }
1344 }
1345 
1346 
1347 // ------------------------------------------------------------------
1348 JVMCI::CodeInstallResult JVMCIRuntime::register_method(JVMCIEnv* JVMCIENV,
1349                                 const methodHandle&amp; method,
1350                                 nmethod*&amp; nm,
1351                                 int entry_bci,
1352                                 CodeOffsets* offsets,
1353                                 int orig_pc_offset,
1354                                 CodeBuffer* code_buffer,
1355                                 int frame_words,
1356                                 OopMapSet* oop_map_set,
1357                                 ExceptionHandlerTable* handler_table,
1358                                 ImplicitExceptionTable* implicit_exception_table,
1359                                 AbstractCompiler* compiler,
1360                                 DebugInformationRecorder* debug_info,
1361                                 Dependencies* dependencies,
1362                                 int compile_id,
1363                                 bool has_unsafe_access,
1364                                 bool has_wide_vector,
1365                                 JVMCIObject compiled_code,
1366                                 JVMCIObject nmethod_mirror,
1367                                 FailedSpeculation** failed_speculations,
1368                                 char* speculations,
1369                                 int speculations_len) {
1370   JVMCI_EXCEPTION_CONTEXT;
1371   nm = NULL;
1372   int comp_level = CompLevel_full_optimization;
1373   char* failure_detail = NULL;
1374 
1375   bool install_default = JVMCIENV-&gt;get_HotSpotNmethod_isDefault(nmethod_mirror) != 0;
1376   assert(JVMCIENV-&gt;isa_HotSpotNmethod(nmethod_mirror), &quot;must be&quot;);
1377   JVMCIObject name = JVMCIENV-&gt;get_InstalledCode_name(nmethod_mirror);
1378   const char* nmethod_mirror_name = name.is_null() ? NULL : JVMCIENV-&gt;as_utf8_string(name);
1379   int nmethod_mirror_index;
1380   if (!install_default) {
1381     // Reserve or initialize mirror slot in the oops table.
1382     OopRecorder* oop_recorder = debug_info-&gt;oop_recorder();
1383     nmethod_mirror_index = oop_recorder-&gt;allocate_oop_index(nmethod_mirror.is_hotspot() ? nmethod_mirror.as_jobject() : NULL);
1384   } else {
1385     // A default HotSpotNmethod mirror is never tracked by the nmethod
1386     nmethod_mirror_index = -1;
1387   }
1388 
1389   JVMCI::CodeInstallResult result;
1390   {
1391     // To prevent compile queue updates.
1392     MutexLocker locker(THREAD, MethodCompileQueue_lock);
1393 
1394     // Prevent SystemDictionary::add_to_hierarchy from running
1395     // and invalidating our dependencies until we install this method.
1396     MutexLocker ml(Compile_lock);
1397 
1398     // Encode the dependencies now, so we can check them right away.
1399     dependencies-&gt;encode_content_bytes();
1400 
1401     // Record the dependencies for the current compile in the log
1402     if (LogCompilation) {
1403       for (Dependencies::DepStream deps(dependencies); deps.next(); ) {
1404         deps.log_dependency();
1405       }
1406     }
1407 
1408     // Check for {class loads, evolution, breakpoints} during compilation
1409     result = validate_compile_task_dependencies(dependencies, JVMCIENV-&gt;compile_state(), &amp;failure_detail);
1410     if (result != JVMCI::ok) {
1411       // While not a true deoptimization, it is a preemptive decompile.
1412       MethodData* mdp = method()-&gt;method_data();
1413       if (mdp != NULL) {
1414         mdp-&gt;inc_decompile_count();
1415 #ifdef ASSERT
1416         if (mdp-&gt;decompile_count() &gt; (uint)PerMethodRecompilationCutoff) {
1417           ResourceMark m;
1418           tty-&gt;print_cr(&quot;WARN: endless recompilation of %s. Method was set to not compilable.&quot;, method()-&gt;name_and_sig_as_C_string());
1419         }
1420 #endif
1421       }
1422 
1423       // All buffers in the CodeBuffer are allocated in the CodeCache.
1424       // If the code buffer is created on each compile attempt
1425       // as in C2, then it must be freed.
1426       //code_buffer-&gt;free_blob();
1427     } else {
1428       nm =  nmethod::new_nmethod(method,
1429                                  compile_id,
1430                                  entry_bci,
1431                                  offsets,
1432                                  orig_pc_offset,
1433                                  debug_info, dependencies, code_buffer,
1434                                  frame_words, oop_map_set,
1435                                  handler_table, implicit_exception_table,
<a name="1" id="anc1"></a><span class="line-modified">1436                                  compiler, comp_level,</span>
1437                                  speculations, speculations_len,
1438                                  nmethod_mirror_index, nmethod_mirror_name, failed_speculations);
1439 
1440 
1441       // Free codeBlobs
1442       if (nm == NULL) {
1443         // The CodeCache is full.  Print out warning and disable compilation.
1444         {
1445           MutexUnlocker ml(Compile_lock);
1446           MutexUnlocker locker(MethodCompileQueue_lock);
1447           CompileBroker::handle_full_code_cache(CodeCache::get_code_blob_type(comp_level));
1448         }
1449       } else {
1450         nm-&gt;set_has_unsafe_access(has_unsafe_access);
1451         nm-&gt;set_has_wide_vectors(has_wide_vector);
1452 
1453         // Record successful registration.
1454         // (Put nm into the task handle *before* publishing to the Java heap.)
1455         if (JVMCIENV-&gt;compile_state() != NULL) {
1456           JVMCIENV-&gt;compile_state()-&gt;task()-&gt;set_code(nm);
1457         }
1458 
1459         JVMCINMethodData* data = nm-&gt;jvmci_nmethod_data();
1460         assert(data != NULL, &quot;must be&quot;);
1461         if (install_default) {
1462           assert(!nmethod_mirror.is_hotspot() || data-&gt;get_nmethod_mirror(nm, /* phantom_ref */ false) == NULL, &quot;must be&quot;);
1463           if (entry_bci == InvocationEntryBci) {
1464             if (TieredCompilation) {
1465               // If there is an old version we&#39;re done with it
1466               CompiledMethod* old = method-&gt;code();
1467               if (TraceMethodReplacement &amp;&amp; old != NULL) {
1468                 ResourceMark rm;
1469                 char *method_name = method-&gt;name_and_sig_as_C_string();
1470                 tty-&gt;print_cr(&quot;Replacing method %s&quot;, method_name);
1471               }
1472               if (old != NULL ) {
1473                 old-&gt;make_not_entrant();
1474               }
1475             }
1476 
1477             LogTarget(Info, nmethod, install) lt;
1478             if (lt.is_enabled()) {
1479               ResourceMark rm;
1480               char *method_name = method-&gt;name_and_sig_as_C_string();
1481               lt.print(&quot;Installing method (%d) %s [entry point: %p]&quot;,
1482                         comp_level, method_name, nm-&gt;entry_point());
1483             }
1484             // Allow the code to be executed
1485             MutexLocker ml(CompiledMethod_lock, Mutex::_no_safepoint_check_flag);
1486             if (nm-&gt;make_in_use()) {
1487               method-&gt;set_code(method, nm);
1488             }
1489           } else {
1490             LogTarget(Info, nmethod, install) lt;
1491             if (lt.is_enabled()) {
1492               ResourceMark rm;
1493               char *method_name = method-&gt;name_and_sig_as_C_string();
1494               lt.print(&quot;Installing osr method (%d) %s @ %d&quot;,
1495                         comp_level, method_name, entry_bci);
1496             }
1497             MutexLocker ml(CompiledMethod_lock, Mutex::_no_safepoint_check_flag);
1498             if (nm-&gt;make_in_use()) {
1499               InstanceKlass::cast(method-&gt;method_holder())-&gt;add_osr_nmethod(nm);
1500             }
1501           }
1502         } else {
1503           assert(!nmethod_mirror.is_hotspot() || data-&gt;get_nmethod_mirror(nm, /* phantom_ref */ false) == HotSpotJVMCI::resolve(nmethod_mirror), &quot;must be&quot;);
1504         }
1505       }
1506       result = nm != NULL ? JVMCI::ok :JVMCI::cache_full;
1507     }
1508   }
1509 
1510   // String creation must be done outside lock
1511   if (failure_detail != NULL) {
1512     // A failure to allocate the string is silently ignored.
1513     JVMCIObject message = JVMCIENV-&gt;create_string(failure_detail, JVMCIENV);
1514     JVMCIENV-&gt;set_HotSpotCompiledNmethod_installationFailureMessage(compiled_code, message);
1515   }
1516 
1517   // JVMTI -- compiled method notification (must be done outside lock)
1518   if (nm != NULL) {
1519     nm-&gt;post_compiled_method_load_event();
1520   }
1521 
1522   return result;
1523 }
<a name="2" id="anc2"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="2" type="hidden" />
</body>
</html>