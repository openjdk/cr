<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New src/hotspot/share/gc/shenandoah/c2/shenandoahSupport.cpp</title>
    <link rel="stylesheet" href="../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 2015, 2019, Red Hat, Inc. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 
  27 #include &quot;gc/shenandoah/c2/shenandoahSupport.hpp&quot;
  28 #include &quot;gc/shenandoah/c2/shenandoahBarrierSetC2.hpp&quot;
  29 #include &quot;gc/shenandoah/shenandoahBarrierSetAssembler.hpp&quot;
  30 #include &quot;gc/shenandoah/shenandoahForwarding.hpp&quot;
  31 #include &quot;gc/shenandoah/shenandoahHeap.hpp&quot;
  32 #include &quot;gc/shenandoah/shenandoahHeapRegion.hpp&quot;
  33 #include &quot;gc/shenandoah/shenandoahRuntime.hpp&quot;
  34 #include &quot;gc/shenandoah/shenandoahThreadLocalData.hpp&quot;
  35 #include &quot;opto/arraycopynode.hpp&quot;
  36 #include &quot;opto/block.hpp&quot;
  37 #include &quot;opto/callnode.hpp&quot;
  38 #include &quot;opto/castnode.hpp&quot;
  39 #include &quot;opto/movenode.hpp&quot;
  40 #include &quot;opto/phaseX.hpp&quot;
  41 #include &quot;opto/rootnode.hpp&quot;
  42 #include &quot;opto/runtime.hpp&quot;
  43 #include &quot;opto/subnode.hpp&quot;
  44 
  45 bool ShenandoahBarrierC2Support::expand(Compile* C, PhaseIterGVN&amp; igvn) {
  46   ShenandoahBarrierSetC2State* state = ShenandoahBarrierSetC2::bsc2()-&gt;state();
  47   if ((state-&gt;enqueue_barriers_count() +
  48        state-&gt;load_reference_barriers_count()) &gt; 0) {
  49     bool attempt_more_loopopts = ShenandoahLoopOptsAfterExpansion;
  50     C-&gt;clear_major_progress();
  51     PhaseIdealLoop ideal_loop(igvn, LoopOptsShenandoahExpand);
  52     if (C-&gt;failing()) return false;
  53     PhaseIdealLoop::verify(igvn);
  54     DEBUG_ONLY(verify_raw_mem(C-&gt;root());)
  55     if (attempt_more_loopopts) {
  56       C-&gt;set_major_progress();
  57       if (!C-&gt;optimize_loops(igvn, LoopOptsShenandoahPostExpand)) {
  58         return false;
  59       }
  60       C-&gt;clear_major_progress();
  61       if (C-&gt;range_check_cast_count() &gt; 0) {
  62         // No more loop optimizations. Remove all range check dependent CastIINodes.
  63         C-&gt;remove_range_check_casts(igvn);
  64         igvn.optimize();
  65       }
  66     }
  67   }
  68   return true;
  69 }
  70 
  71 bool ShenandoahBarrierC2Support::is_gc_state_test(Node* iff, int mask) {
  72   if (!UseShenandoahGC) {
  73     return false;
  74   }
  75   assert(iff-&gt;is_If(), &quot;bad input&quot;);
  76   if (iff-&gt;Opcode() != Op_If) {
  77     return false;
  78   }
  79   Node* bol = iff-&gt;in(1);
  80   if (!bol-&gt;is_Bool() || bol-&gt;as_Bool()-&gt;_test._test != BoolTest::ne) {
  81     return false;
  82   }
  83   Node* cmp = bol-&gt;in(1);
  84   if (cmp-&gt;Opcode() != Op_CmpI) {
  85     return false;
  86   }
  87   Node* in1 = cmp-&gt;in(1);
  88   Node* in2 = cmp-&gt;in(2);
  89   if (in2-&gt;find_int_con(-1) != 0) {
  90     return false;
  91   }
  92   if (in1-&gt;Opcode() != Op_AndI) {
  93     return false;
  94   }
  95   in2 = in1-&gt;in(2);
  96   if (in2-&gt;find_int_con(-1) != mask) {
  97     return false;
  98   }
  99   in1 = in1-&gt;in(1);
 100 
 101   return is_gc_state_load(in1);
 102 }
 103 
 104 bool ShenandoahBarrierC2Support::is_heap_stable_test(Node* iff) {
 105   return is_gc_state_test(iff, ShenandoahHeap::HAS_FORWARDED);
 106 }
 107 
 108 bool ShenandoahBarrierC2Support::is_gc_state_load(Node *n) {
 109   if (!UseShenandoahGC) {
 110     return false;
 111   }
 112   if (n-&gt;Opcode() != Op_LoadB &amp;&amp; n-&gt;Opcode() != Op_LoadUB) {
 113     return false;
 114   }
 115   Node* addp = n-&gt;in(MemNode::Address);
 116   if (!addp-&gt;is_AddP()) {
 117     return false;
 118   }
 119   Node* base = addp-&gt;in(AddPNode::Address);
 120   Node* off = addp-&gt;in(AddPNode::Offset);
 121   if (base-&gt;Opcode() != Op_ThreadLocal) {
 122     return false;
 123   }
 124   if (off-&gt;find_intptr_t_con(-1) != in_bytes(ShenandoahThreadLocalData::gc_state_offset())) {
 125     return false;
 126   }
 127   return true;
 128 }
 129 
 130 bool ShenandoahBarrierC2Support::has_safepoint_between(Node* start, Node* stop, PhaseIdealLoop *phase) {
 131   assert(phase-&gt;is_dominator(stop, start), &quot;bad inputs&quot;);
 132   ResourceMark rm;
 133   Unique_Node_List wq;
 134   wq.push(start);
 135   for (uint next = 0; next &lt; wq.size(); next++) {
 136     Node *m = wq.at(next);
 137     if (m == stop) {
 138       continue;
 139     }
 140     if (m-&gt;is_SafePoint() &amp;&amp; !m-&gt;is_CallLeaf()) {
 141       return true;
 142     }
 143     if (m-&gt;is_Region()) {
 144       for (uint i = 1; i &lt; m-&gt;req(); i++) {
 145         wq.push(m-&gt;in(i));
 146       }
 147     } else {
 148       wq.push(m-&gt;in(0));
 149     }
 150   }
 151   return false;
 152 }
 153 
 154 #ifdef ASSERT
 155 bool ShenandoahBarrierC2Support::verify_helper(Node* in, Node_Stack&amp; phis, VectorSet&amp; visited, verify_type t, bool trace, Unique_Node_List&amp; barriers_used) {
 156   assert(phis.size() == 0, &quot;&quot;);
 157 
 158   while (true) {
 159     if (in-&gt;bottom_type() == TypePtr::NULL_PTR) {
 160       if (trace) {tty-&gt;print_cr(&quot;NULL&quot;);}
 161     } else if (!in-&gt;bottom_type()-&gt;make_ptr()-&gt;make_oopptr()) {
 162       if (trace) {tty-&gt;print_cr(&quot;Non oop&quot;);}
 163     } else {
 164       if (in-&gt;is_ConstraintCast()) {
 165         in = in-&gt;in(1);
 166         continue;
 167       } else if (in-&gt;is_AddP()) {
 168         assert(!in-&gt;in(AddPNode::Address)-&gt;is_top(), &quot;no raw memory access&quot;);
 169         in = in-&gt;in(AddPNode::Address);
 170         continue;
 171       } else if (in-&gt;is_Con()) {
 172         if (trace) {
 173           tty-&gt;print(&quot;Found constant&quot;);
 174           in-&gt;dump();
 175         }
 176       } else if (in-&gt;Opcode() == Op_Parm) {
 177         if (trace) {
 178           tty-&gt;print(&quot;Found argument&quot;);
 179         }
 180       } else if (in-&gt;Opcode() == Op_CreateEx) {
 181         if (trace) {
 182           tty-&gt;print(&quot;Found create-exception&quot;);
 183         }
 184       } else if (in-&gt;Opcode() == Op_LoadP &amp;&amp; in-&gt;adr_type() == TypeRawPtr::BOTTOM) {
 185         if (trace) {
 186           tty-&gt;print(&quot;Found raw LoadP (OSR argument?)&quot;);
 187         }
 188       } else if (in-&gt;Opcode() == Op_ShenandoahLoadReferenceBarrier) {
 189         if (t == ShenandoahOopStore) {
 190           uint i = 0;
 191           for (; i &lt; phis.size(); i++) {
 192             Node* n = phis.node_at(i);
 193             if (n-&gt;Opcode() == Op_ShenandoahEnqueueBarrier) {
 194               break;
 195             }
 196           }
 197           if (i == phis.size()) {
 198             return false;
 199           }
 200         }
 201         barriers_used.push(in);
 202         if (trace) {tty-&gt;print(&quot;Found barrier&quot;); in-&gt;dump();}
 203       } else if (in-&gt;Opcode() == Op_ShenandoahEnqueueBarrier) {
 204         if (t != ShenandoahOopStore) {
 205           in = in-&gt;in(1);
 206           continue;
 207         }
 208         if (trace) {tty-&gt;print(&quot;Found enqueue barrier&quot;); in-&gt;dump();}
 209         phis.push(in, in-&gt;req());
 210         in = in-&gt;in(1);
 211         continue;
 212       } else if (in-&gt;is_Proj() &amp;&amp; in-&gt;in(0)-&gt;is_Allocate()) {
 213         if (trace) {
 214           tty-&gt;print(&quot;Found alloc&quot;);
 215           in-&gt;in(0)-&gt;dump();
 216         }
 217       } else if (in-&gt;is_Proj() &amp;&amp; (in-&gt;in(0)-&gt;Opcode() == Op_CallStaticJava || in-&gt;in(0)-&gt;Opcode() == Op_CallDynamicJava)) {
 218         if (trace) {
 219           tty-&gt;print(&quot;Found Java call&quot;);
 220         }
 221       } else if (in-&gt;is_Phi()) {
 222         if (!visited.test_set(in-&gt;_idx)) {
 223           if (trace) {tty-&gt;print(&quot;Pushed phi:&quot;); in-&gt;dump();}
 224           phis.push(in, 2);
 225           in = in-&gt;in(1);
 226           continue;
 227         }
 228         if (trace) {tty-&gt;print(&quot;Already seen phi:&quot;); in-&gt;dump();}
 229       } else if (in-&gt;Opcode() == Op_CMoveP || in-&gt;Opcode() == Op_CMoveN) {
 230         if (!visited.test_set(in-&gt;_idx)) {
 231           if (trace) {tty-&gt;print(&quot;Pushed cmovep:&quot;); in-&gt;dump();}
 232           phis.push(in, CMoveNode::IfTrue);
 233           in = in-&gt;in(CMoveNode::IfFalse);
 234           continue;
 235         }
 236         if (trace) {tty-&gt;print(&quot;Already seen cmovep:&quot;); in-&gt;dump();}
 237       } else if (in-&gt;Opcode() == Op_EncodeP || in-&gt;Opcode() == Op_DecodeN) {
 238         in = in-&gt;in(1);
 239         continue;
 240       } else {
 241         return false;
 242       }
 243     }
 244     bool cont = false;
 245     while (phis.is_nonempty()) {
 246       uint idx = phis.index();
 247       Node* phi = phis.node();
 248       if (idx &gt;= phi-&gt;req()) {
 249         if (trace) {tty-&gt;print(&quot;Popped phi:&quot;); phi-&gt;dump();}
 250         phis.pop();
 251         continue;
 252       }
 253       if (trace) {tty-&gt;print(&quot;Next entry(%d) for phi:&quot;, idx); phi-&gt;dump();}
 254       in = phi-&gt;in(idx);
 255       phis.set_index(idx+1);
 256       cont = true;
 257       break;
 258     }
 259     if (!cont) {
 260       break;
 261     }
 262   }
 263   return true;
 264 }
 265 
 266 void ShenandoahBarrierC2Support::report_verify_failure(const char* msg, Node* n1, Node* n2) {
 267   if (n1 != NULL) {
 268     n1-&gt;dump(+10);
 269   }
 270   if (n2 != NULL) {
 271     n2-&gt;dump(+10);
 272   }
 273   fatal(&quot;%s&quot;, msg);
 274 }
 275 
 276 void ShenandoahBarrierC2Support::verify(RootNode* root) {
 277   ResourceMark rm;
 278   Unique_Node_List wq;
 279   GrowableArray&lt;Node*&gt; barriers;
 280   Unique_Node_List barriers_used;
 281   Node_Stack phis(0);
 282   VectorSet visited(Thread::current()-&gt;resource_area());
 283   const bool trace = false;
 284   const bool verify_no_useless_barrier = false;
 285 
 286   wq.push(root);
 287   for (uint next = 0; next &lt; wq.size(); next++) {
 288     Node *n = wq.at(next);
 289     if (n-&gt;is_Load()) {
 290       const bool trace = false;
 291       if (trace) {tty-&gt;print(&quot;Verifying&quot;); n-&gt;dump();}
 292       if (n-&gt;Opcode() == Op_LoadRange || n-&gt;Opcode() == Op_LoadKlass || n-&gt;Opcode() == Op_LoadNKlass) {
 293         if (trace) {tty-&gt;print_cr(&quot;Load range/klass&quot;);}
 294       } else {
 295         const TypePtr* adr_type = n-&gt;as_Load()-&gt;adr_type();
 296 
 297         if (adr_type-&gt;isa_oopptr() &amp;&amp; adr_type-&gt;is_oopptr()-&gt;offset() == oopDesc::mark_offset_in_bytes()) {
 298           if (trace) {tty-&gt;print_cr(&quot;Mark load&quot;);}
 299         } else if (adr_type-&gt;isa_instptr() &amp;&amp;
 300                    adr_type-&gt;is_instptr()-&gt;klass()-&gt;is_subtype_of(Compile::current()-&gt;env()-&gt;Reference_klass()) &amp;&amp;
 301                    adr_type-&gt;is_instptr()-&gt;offset() == java_lang_ref_Reference::referent_offset()) {
 302           if (trace) {tty-&gt;print_cr(&quot;Reference.get()&quot;);}
 303         } else if (!verify_helper(n-&gt;in(MemNode::Address), phis, visited, ShenandoahLoad, trace, barriers_used)) {
 304           report_verify_failure(&quot;Shenandoah verification: Load should have barriers&quot;, n);
 305         }
 306       }
 307     } else if (n-&gt;is_Store()) {
 308       const bool trace = false;
 309 
 310       if (trace) {tty-&gt;print(&quot;Verifying&quot;); n-&gt;dump();}
 311       if (n-&gt;in(MemNode::ValueIn)-&gt;bottom_type()-&gt;make_oopptr()) {
 312         Node* adr = n-&gt;in(MemNode::Address);
 313         bool verify = true;
 314 
 315         if (adr-&gt;is_AddP() &amp;&amp; adr-&gt;in(AddPNode::Base)-&gt;is_top()) {
 316           adr = adr-&gt;in(AddPNode::Address);
 317           if (adr-&gt;is_AddP()) {
 318             assert(adr-&gt;in(AddPNode::Base)-&gt;is_top(), &quot;&quot;);
 319             adr = adr-&gt;in(AddPNode::Address);
 320             if (adr-&gt;Opcode() == Op_LoadP &amp;&amp;
 321                 adr-&gt;in(MemNode::Address)-&gt;in(AddPNode::Base)-&gt;is_top() &amp;&amp;
 322                 adr-&gt;in(MemNode::Address)-&gt;in(AddPNode::Address)-&gt;Opcode() == Op_ThreadLocal &amp;&amp;
 323                 adr-&gt;in(MemNode::Address)-&gt;in(AddPNode::Offset)-&gt;find_intptr_t_con(-1) == in_bytes(ShenandoahThreadLocalData::satb_mark_queue_buffer_offset())) {
 324               if (trace) {tty-&gt;print_cr(&quot;SATB prebarrier&quot;);}
 325               verify = false;
 326             }
 327           }
 328         }
 329 
 330         if (verify &amp;&amp; !verify_helper(n-&gt;in(MemNode::ValueIn), phis, visited, ShenandoahStoreValEnqueueBarrier ? ShenandoahOopStore : ShenandoahValue, trace, barriers_used)) {
 331           report_verify_failure(&quot;Shenandoah verification: Store should have barriers&quot;, n);
 332         }
 333       }
 334       if (!verify_helper(n-&gt;in(MemNode::Address), phis, visited, ShenandoahStore, trace, barriers_used)) {
 335         report_verify_failure(&quot;Shenandoah verification: Store (address) should have barriers&quot;, n);
 336       }
 337     } else if (n-&gt;Opcode() == Op_CmpP) {
 338       const bool trace = false;
 339 
 340       Node* in1 = n-&gt;in(1);
 341       Node* in2 = n-&gt;in(2);
 342       if (in1-&gt;bottom_type()-&gt;isa_oopptr()) {
 343         if (trace) {tty-&gt;print(&quot;Verifying&quot;); n-&gt;dump();}
 344 
 345         bool mark_inputs = false;
 346         if (in1-&gt;bottom_type() == TypePtr::NULL_PTR || in2-&gt;bottom_type() == TypePtr::NULL_PTR ||
 347             (in1-&gt;is_Con() || in2-&gt;is_Con())) {
 348           if (trace) {tty-&gt;print_cr(&quot;Comparison against a constant&quot;);}
 349           mark_inputs = true;
 350         } else if ((in1-&gt;is_CheckCastPP() &amp;&amp; in1-&gt;in(1)-&gt;is_Proj() &amp;&amp; in1-&gt;in(1)-&gt;in(0)-&gt;is_Allocate()) ||
 351                    (in2-&gt;is_CheckCastPP() &amp;&amp; in2-&gt;in(1)-&gt;is_Proj() &amp;&amp; in2-&gt;in(1)-&gt;in(0)-&gt;is_Allocate())) {
 352           if (trace) {tty-&gt;print_cr(&quot;Comparison with newly alloc&#39;ed object&quot;);}
 353           mark_inputs = true;
 354         } else {
 355           assert(in2-&gt;bottom_type()-&gt;isa_oopptr(), &quot;&quot;);
 356 
 357           if (!verify_helper(in1, phis, visited, ShenandoahStore, trace, barriers_used) ||
 358               !verify_helper(in2, phis, visited, ShenandoahStore, trace, barriers_used)) {
 359             report_verify_failure(&quot;Shenandoah verification: Cmp should have barriers&quot;, n);
 360           }
 361         }
 362         if (verify_no_useless_barrier &amp;&amp;
 363             mark_inputs &amp;&amp;
 364             (!verify_helper(in1, phis, visited, ShenandoahValue, trace, barriers_used) ||
 365              !verify_helper(in2, phis, visited, ShenandoahValue, trace, barriers_used))) {
 366           phis.clear();
 367           visited.reset();
 368         }
 369       }
 370     } else if (n-&gt;is_LoadStore()) {
 371       if (n-&gt;in(MemNode::ValueIn)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 372           !verify_helper(n-&gt;in(MemNode::ValueIn), phis, visited, ShenandoahStoreValEnqueueBarrier ? ShenandoahOopStore : ShenandoahValue, trace, barriers_used)) {
 373         report_verify_failure(&quot;Shenandoah verification: LoadStore (value) should have barriers&quot;, n);
 374       }
 375 
 376       if (n-&gt;in(MemNode::Address)-&gt;bottom_type()-&gt;make_oopptr() &amp;&amp; !verify_helper(n-&gt;in(MemNode::Address), phis, visited, ShenandoahStore, trace, barriers_used)) {
 377         report_verify_failure(&quot;Shenandoah verification: LoadStore (address) should have barriers&quot;, n);
 378       }
 379     } else if (n-&gt;Opcode() == Op_CallLeafNoFP || n-&gt;Opcode() == Op_CallLeaf) {
 380       CallNode* call = n-&gt;as_Call();
 381 
 382       static struct {
 383         const char* name;
 384         struct {
 385           int pos;
 386           verify_type t;
 387         } args[6];
 388       } calls[] = {
 389         &quot;aescrypt_encryptBlock&quot;,
 390         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 391           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 392         &quot;aescrypt_decryptBlock&quot;,
 393         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 394           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 395         &quot;multiplyToLen&quot;,
 396         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },   { TypeFunc::Parms+4, ShenandoahStore },
 397           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 398         &quot;squareToLen&quot;,
 399         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },   { -1,  ShenandoahNone},
 400           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 401         &quot;montgomery_multiply&quot;,
 402         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },
 403           { TypeFunc::Parms+6, ShenandoahStore }, { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 404         &quot;montgomery_square&quot;,
 405         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahLoad },   { TypeFunc::Parms+5, ShenandoahStore },
 406           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 407         &quot;mulAdd&quot;,
 408         { { TypeFunc::Parms, ShenandoahStore },  { TypeFunc::Parms+1, ShenandoahLoad },   { -1,  ShenandoahNone},
 409           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 410         &quot;vectorizedMismatch&quot;,
 411         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahLoad },   { -1,  ShenandoahNone},
 412           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 413         &quot;updateBytesCRC32&quot;,
 414         { { TypeFunc::Parms+1, ShenandoahLoad }, { -1,  ShenandoahNone},                  { -1,  ShenandoahNone},
 415           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 416         &quot;updateBytesAdler32&quot;,
 417         { { TypeFunc::Parms+1, ShenandoahLoad }, { -1,  ShenandoahNone},                  { -1,  ShenandoahNone},
 418           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 419         &quot;updateBytesCRC32C&quot;,
 420         { { TypeFunc::Parms+1, ShenandoahLoad }, { TypeFunc::Parms+3, ShenandoahLoad},    { -1,  ShenandoahNone},
 421           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 422         &quot;counterMode_AESCrypt&quot;,
 423         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 424           { TypeFunc::Parms+3, ShenandoahStore }, { TypeFunc::Parms+5, ShenandoahStore }, { TypeFunc::Parms+6, ShenandoahStore } },
 425         &quot;cipherBlockChaining_encryptAESCrypt&quot;,
 426         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 427           { TypeFunc::Parms+3, ShenandoahLoad },  { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 428         &quot;cipherBlockChaining_decryptAESCrypt&quot;,
 429         { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },
 430           { TypeFunc::Parms+3, ShenandoahLoad },  { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 431         &quot;shenandoah_clone_barrier&quot;,
 432         { { TypeFunc::Parms, ShenandoahLoad },   { -1,  ShenandoahNone},                  { -1,  ShenandoahNone},
 433           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 434         &quot;ghash_processBlocks&quot;,
 435         { { TypeFunc::Parms, ShenandoahStore },  { TypeFunc::Parms+1, ShenandoahLoad },   { TypeFunc::Parms+2, ShenandoahLoad },
 436           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 437         &quot;sha1_implCompress&quot;,
 438         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 439           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 440         &quot;sha256_implCompress&quot;,
 441         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 442           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 443         &quot;sha512_implCompress&quot;,
 444         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 445           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 446         &quot;sha1_implCompressMB&quot;,
 447         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 448           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 449         &quot;sha256_implCompressMB&quot;,
 450         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 451           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 452         &quot;sha512_implCompressMB&quot;,
 453         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+1, ShenandoahStore },   { -1, ShenandoahNone },
 454           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 455         &quot;encodeBlock&quot;,
 456         { { TypeFunc::Parms, ShenandoahLoad },  { TypeFunc::Parms+3, ShenandoahStore },   { -1, ShenandoahNone },
 457           { -1,  ShenandoahNone},                 { -1,  ShenandoahNone},                 { -1,  ShenandoahNone} },
 458       };
 459 
 460       if (call-&gt;is_call_to_arraycopystub()) {
 461         Node* dest = NULL;
 462         const TypeTuple* args = n-&gt;as_Call()-&gt;_tf-&gt;domain_sig();
 463         for (uint i = TypeFunc::Parms, j = 0; i &lt; args-&gt;cnt(); i++) {
 464           if (args-&gt;field_at(i)-&gt;isa_ptr()) {
 465             j++;
 466             if (j == 2) {
 467               dest = n-&gt;in(i);
 468               break;
 469             }
 470           }
 471         }
 472         if (!verify_helper(n-&gt;in(TypeFunc::Parms), phis, visited, ShenandoahLoad, trace, barriers_used) ||
 473             !verify_helper(dest, phis, visited, ShenandoahStore, trace, barriers_used)) {
 474           report_verify_failure(&quot;Shenandoah verification: ArrayCopy should have barriers&quot;, n);
 475         }
 476       } else if (strlen(call-&gt;_name) &gt; 5 &amp;&amp;
 477                  !strcmp(call-&gt;_name + strlen(call-&gt;_name) - 5, &quot;_fill&quot;)) {
 478         if (!verify_helper(n-&gt;in(TypeFunc::Parms), phis, visited, ShenandoahStore, trace, barriers_used)) {
 479           report_verify_failure(&quot;Shenandoah verification: _fill should have barriers&quot;, n);
 480         }
 481       } else if (!strcmp(call-&gt;_name, &quot;shenandoah_wb_pre&quot;)) {
 482         // skip
 483       } else {
 484         const int calls_len = sizeof(calls) / sizeof(calls[0]);
 485         int i = 0;
 486         for (; i &lt; calls_len; i++) {
 487           if (!strcmp(calls[i].name, call-&gt;_name)) {
 488             break;
 489           }
 490         }
 491         if (i != calls_len) {
 492           const uint args_len = sizeof(calls[0].args) / sizeof(calls[0].args[0]);
 493           for (uint j = 0; j &lt; args_len; j++) {
 494             int pos = calls[i].args[j].pos;
 495             if (pos == -1) {
 496               break;
 497             }
 498             if (!verify_helper(call-&gt;in(pos), phis, visited, calls[i].args[j].t, trace, barriers_used)) {
 499               report_verify_failure(&quot;Shenandoah verification: intrinsic calls should have barriers&quot;, n);
 500             }
 501           }
 502           for (uint j = TypeFunc::Parms; j &lt; call-&gt;req(); j++) {
 503             if (call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 504                 call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;isa_oopptr()) {
 505               uint k = 0;
 506               for (; k &lt; args_len &amp;&amp; calls[i].args[k].pos != (int)j; k++);
 507               if (k == args_len) {
 508                 fatal(&quot;arg %d for call %s not covered&quot;, j, call-&gt;_name);
 509               }
 510             }
 511           }
 512         } else {
 513           for (uint j = TypeFunc::Parms; j &lt; call-&gt;req(); j++) {
 514             if (call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 515                 call-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;isa_oopptr()) {
 516               fatal(&quot;%s not covered&quot;, call-&gt;_name);
 517             }
 518           }
 519         }
 520       }
 521     } else if (n-&gt;Opcode() == Op_ShenandoahEnqueueBarrier || n-&gt;Opcode() == Op_ShenandoahLoadReferenceBarrier) {
 522       // skip
 523     } else if (n-&gt;is_AddP()
 524                || n-&gt;is_Phi()
 525                || n-&gt;is_ConstraintCast()
 526                || n-&gt;Opcode() == Op_Return
 527                || n-&gt;Opcode() == Op_CMoveP
 528                || n-&gt;Opcode() == Op_CMoveN
 529                || n-&gt;Opcode() == Op_Rethrow
 530                || n-&gt;is_MemBar()
 531                || n-&gt;Opcode() == Op_Conv2B
 532                || n-&gt;Opcode() == Op_SafePoint
 533                || n-&gt;is_CallJava()
 534                || n-&gt;Opcode() == Op_Unlock
 535                || n-&gt;Opcode() == Op_EncodeP
 536                || n-&gt;Opcode() == Op_DecodeN) {
 537       // nothing to do
 538     } else {
 539       static struct {
 540         int opcode;
 541         struct {
 542           int pos;
 543           verify_type t;
 544         } inputs[2];
 545       } others[] = {
 546         Op_FastLock,
 547         { { 1, ShenandoahLoad },                  { -1, ShenandoahNone} },
 548         Op_Lock,
 549         { { TypeFunc::Parms, ShenandoahLoad },    { -1, ShenandoahNone} },
 550         Op_ArrayCopy,
 551         { { ArrayCopyNode::Src, ShenandoahLoad }, { ArrayCopyNode::Dest, ShenandoahStore } },
 552         Op_StrCompressedCopy,
 553         { { 2, ShenandoahLoad },                  { 3, ShenandoahStore } },
 554         Op_StrInflatedCopy,
 555         { { 2, ShenandoahLoad },                  { 3, ShenandoahStore } },
 556         Op_AryEq,
 557         { { 2, ShenandoahLoad },                  { 3, ShenandoahLoad } },
 558         Op_StrIndexOf,
 559         { { 2, ShenandoahLoad },                  { 4, ShenandoahLoad } },
 560         Op_StrComp,
 561         { { 2, ShenandoahLoad },                  { 4, ShenandoahLoad } },
 562         Op_StrEquals,
 563         { { 2, ShenandoahLoad },                  { 3, ShenandoahLoad } },
 564         Op_EncodeISOArray,
 565         { { 2, ShenandoahLoad },                  { 3, ShenandoahStore } },
 566         Op_HasNegatives,
 567         { { 2, ShenandoahLoad },                  { -1, ShenandoahNone} },
 568         Op_CastP2X,
 569         { { 1, ShenandoahLoad },                  { -1, ShenandoahNone} },
 570         Op_StrIndexOfChar,
 571         { { 2, ShenandoahLoad },                  { -1, ShenandoahNone } },
 572       };
 573 
 574       const int others_len = sizeof(others) / sizeof(others[0]);
 575       int i = 0;
 576       for (; i &lt; others_len; i++) {
 577         if (others[i].opcode == n-&gt;Opcode()) {
 578           break;
 579         }
 580       }
 581       uint stop = n-&gt;is_Call() ? n-&gt;as_Call()-&gt;tf()-&gt;domain_sig()-&gt;cnt() : n-&gt;req();
 582       if (i != others_len) {
 583         const uint inputs_len = sizeof(others[0].inputs) / sizeof(others[0].inputs[0]);
 584         for (uint j = 0; j &lt; inputs_len; j++) {
 585           int pos = others[i].inputs[j].pos;
 586           if (pos == -1) {
 587             break;
 588           }
 589           if (!verify_helper(n-&gt;in(pos), phis, visited, others[i].inputs[j].t, trace, barriers_used)) {
 590             report_verify_failure(&quot;Shenandoah verification: intrinsic calls should have barriers&quot;, n);
 591           }
 592         }
 593         for (uint j = 1; j &lt; stop; j++) {
 594           if (n-&gt;in(j) != NULL &amp;&amp; n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 595               n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;make_oopptr()) {
 596             uint k = 0;
 597             for (; k &lt; inputs_len &amp;&amp; others[i].inputs[k].pos != (int)j; k++);
 598             if (k == inputs_len) {
 599               fatal(&quot;arg %d for node %s not covered&quot;, j, n-&gt;Name());
 600             }
 601           }
 602         }
 603       } else {
 604         for (uint j = 1; j &lt; stop; j++) {
 605           if (n-&gt;in(j) != NULL &amp;&amp; n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr() &amp;&amp;
 606               n-&gt;in(j)-&gt;bottom_type()-&gt;make_ptr()-&gt;make_oopptr()) {
 607             fatal(&quot;%s not covered&quot;, n-&gt;Name());
 608           }
 609         }
 610       }
 611     }
 612 
 613     if (n-&gt;is_SafePoint()) {
 614       SafePointNode* sfpt = n-&gt;as_SafePoint();
 615       if (verify_no_useless_barrier &amp;&amp; sfpt-&gt;jvms() != NULL) {
 616         for (uint i = sfpt-&gt;jvms()-&gt;scloff(); i &lt; sfpt-&gt;jvms()-&gt;endoff(); i++) {
 617           if (!verify_helper(sfpt-&gt;in(i), phis, visited, ShenandoahLoad, trace, barriers_used)) {
 618             phis.clear();
 619             visited.reset();
 620           }
 621         }
 622       }
 623     }
 624   }
 625 
 626   if (verify_no_useless_barrier) {
 627     for (int i = 0; i &lt; barriers.length(); i++) {
 628       Node* n = barriers.at(i);
 629       if (!barriers_used.member(n)) {
 630         tty-&gt;print(&quot;XXX useless barrier&quot;); n-&gt;dump(-2);
 631         ShouldNotReachHere();
 632       }
 633     }
 634   }
 635 }
 636 #endif
 637 
 638 bool ShenandoahBarrierC2Support::is_dominator_same_ctrl(Node* c, Node* d, Node* n, PhaseIdealLoop* phase) {
 639   // That both nodes have the same control is not sufficient to prove
 640   // domination, verify that there&#39;s no path from d to n
 641   ResourceMark rm;
 642   Unique_Node_List wq;
 643   wq.push(d);
 644   for (uint next = 0; next &lt; wq.size(); next++) {
 645     Node *m = wq.at(next);
 646     if (m == n) {
 647       return false;
 648     }
 649     if (m-&gt;is_Phi() &amp;&amp; m-&gt;in(0)-&gt;is_Loop()) {
 650       assert(phase-&gt;ctrl_or_self(m-&gt;in(LoopNode::EntryControl)) != c, &quot;following loop entry should lead to new control&quot;);
 651     } else {
 652       if (m-&gt;is_Store() || m-&gt;is_LoadStore()) {
 653         // Take anti-dependencies into account
 654         Node* mem = m-&gt;in(MemNode::Memory);
 655         for (DUIterator_Fast imax, i = mem-&gt;fast_outs(imax); i &lt; imax; i++) {
 656           Node* u = mem-&gt;fast_out(i);
 657           if (u-&gt;is_Load() &amp;&amp; phase-&gt;C-&gt;can_alias(m-&gt;adr_type(), phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type())) &amp;&amp;
 658               phase-&gt;ctrl_or_self(u) == c) {
 659             wq.push(u);
 660           }
 661         }
 662       }
 663       for (uint i = 0; i &lt; m-&gt;req(); i++) {
 664         if (m-&gt;in(i) != NULL &amp;&amp; phase-&gt;ctrl_or_self(m-&gt;in(i)) == c) {
 665           wq.push(m-&gt;in(i));
 666         }
 667       }
 668     }
 669   }
 670   return true;
 671 }
 672 
 673 bool ShenandoahBarrierC2Support::is_dominator(Node* d_c, Node* n_c, Node* d, Node* n, PhaseIdealLoop* phase) {
 674   if (d_c != n_c) {
 675     return phase-&gt;is_dominator(d_c, n_c);
 676   }
 677   return is_dominator_same_ctrl(d_c, d, n, phase);
 678 }
 679 
 680 Node* next_mem(Node* mem, int alias) {
 681   Node* res = NULL;
 682   if (mem-&gt;is_Proj()) {
 683     res = mem-&gt;in(0);
 684   } else if (mem-&gt;is_SafePoint() || mem-&gt;is_MemBar()) {
 685     res = mem-&gt;in(TypeFunc::Memory);
 686   } else if (mem-&gt;is_Phi()) {
 687     res = mem-&gt;in(1);
 688   } else if (mem-&gt;is_MergeMem()) {
 689     res = mem-&gt;as_MergeMem()-&gt;memory_at(alias);
 690   } else if (mem-&gt;is_Store() || mem-&gt;is_LoadStore() || mem-&gt;is_ClearArray()) {
 691     assert(alias = Compile::AliasIdxRaw, &quot;following raw memory can&#39;t lead to a barrier&quot;);
 692     res = mem-&gt;in(MemNode::Memory);
 693   } else {
 694 #ifdef ASSERT
 695     mem-&gt;dump();
 696 #endif
 697     ShouldNotReachHere();
 698   }
 699   return res;
 700 }
 701 
 702 Node* ShenandoahBarrierC2Support::no_branches(Node* c, Node* dom, bool allow_one_proj, PhaseIdealLoop* phase) {
 703   Node* iffproj = NULL;
 704   while (c != dom) {
 705     Node* next = phase-&gt;idom(c);
 706     assert(next-&gt;unique_ctrl_out() == c || c-&gt;is_Proj() || c-&gt;is_Region(), &quot;multiple control flow out but no proj or region?&quot;);
 707     if (c-&gt;is_Region()) {
 708       ResourceMark rm;
 709       Unique_Node_List wq;
 710       wq.push(c);
 711       for (uint i = 0; i &lt; wq.size(); i++) {
 712         Node *n = wq.at(i);
 713         if (n == next) {
 714           continue;
 715         }
 716         if (n-&gt;is_Region()) {
 717           for (uint j = 1; j &lt; n-&gt;req(); j++) {
 718             wq.push(n-&gt;in(j));
 719           }
 720         } else {
 721           wq.push(n-&gt;in(0));
 722         }
 723       }
 724       for (uint i = 0; i &lt; wq.size(); i++) {
 725         Node *n = wq.at(i);
 726         assert(n-&gt;is_CFG(), &quot;&quot;);
 727         if (n-&gt;is_Multi()) {
 728           for (DUIterator_Fast jmax, j = n-&gt;fast_outs(jmax); j &lt; jmax; j++) {
 729             Node* u = n-&gt;fast_out(j);
 730             if (u-&gt;is_CFG()) {
 731               if (!wq.member(u) &amp;&amp; !u-&gt;as_Proj()-&gt;is_uncommon_trap_proj(Deoptimization::Reason_none)) {
 732                 return NodeSentinel;
 733               }
 734             }
 735           }
 736         }
 737       }
 738     } else  if (c-&gt;is_Proj()) {
 739       if (c-&gt;is_IfProj()) {
 740         if (c-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) != NULL) {
 741           // continue;
 742         } else {
 743           if (!allow_one_proj) {
 744             return NodeSentinel;
 745           }
 746           if (iffproj == NULL) {
 747             iffproj = c;
 748           } else {
 749             return NodeSentinel;
 750           }
 751         }
 752       } else if (c-&gt;Opcode() == Op_JumpProj) {
 753         return NodeSentinel; // unsupported
 754       } else if (c-&gt;Opcode() == Op_CatchProj) {
 755         return NodeSentinel; // unsupported
 756       } else if (c-&gt;Opcode() == Op_CProj &amp;&amp; next-&gt;Opcode() == Op_NeverBranch) {
 757         return NodeSentinel; // unsupported
 758       } else {
 759         assert(next-&gt;unique_ctrl_out() == c, &quot;unsupported branch pattern&quot;);
 760       }
 761     }
 762     c = next;
 763   }
 764   return iffproj;
 765 }
 766 
 767 Node* ShenandoahBarrierC2Support::dom_mem(Node* mem, Node* ctrl, int alias, Node*&amp; mem_ctrl, PhaseIdealLoop* phase) {
 768   ResourceMark rm;
 769   VectorSet wq(Thread::current()-&gt;resource_area());
 770   wq.set(mem-&gt;_idx);
 771   mem_ctrl = phase-&gt;ctrl_or_self(mem);
 772   while (!phase-&gt;is_dominator(mem_ctrl, ctrl) || mem_ctrl == ctrl) {
 773     mem = next_mem(mem, alias);
 774     if (wq.test_set(mem-&gt;_idx)) {
 775       return NULL;
 776     }
 777     mem_ctrl = phase-&gt;ctrl_or_self(mem);
 778   }
 779   if (mem-&gt;is_MergeMem()) {
 780     mem = mem-&gt;as_MergeMem()-&gt;memory_at(alias);
 781     mem_ctrl = phase-&gt;ctrl_or_self(mem);
 782   }
 783   return mem;
 784 }
 785 
 786 Node* ShenandoahBarrierC2Support::find_bottom_mem(Node* ctrl, PhaseIdealLoop* phase) {
 787   Node* mem = NULL;
 788   Node* c = ctrl;
 789   do {
 790     if (c-&gt;is_Region()) {
 791       for (DUIterator_Fast imax, i = c-&gt;fast_outs(imax); i &lt; imax &amp;&amp; mem == NULL; i++) {
 792         Node* u = c-&gt;fast_out(i);
 793         if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY) {
 794           if (u-&gt;adr_type() == TypePtr::BOTTOM) {
 795             mem = u;
 796           }
 797         }
 798       }
 799     } else {
 800       if (c-&gt;is_Call() &amp;&amp; c-&gt;as_Call()-&gt;adr_type() != NULL) {
 801         CallProjections* projs = c-&gt;as_Call()-&gt;extract_projections(true, false);
 802         if (projs-&gt;fallthrough_memproj != NULL) {
 803           if (projs-&gt;fallthrough_memproj-&gt;adr_type() == TypePtr::BOTTOM) {
 804             if (projs-&gt;catchall_memproj == NULL) {
 805               mem = projs-&gt;fallthrough_memproj;
 806             } else {
 807               if (phase-&gt;is_dominator(projs-&gt;fallthrough_catchproj, ctrl)) {
 808                 mem = projs-&gt;fallthrough_memproj;
 809               } else {
 810                 assert(phase-&gt;is_dominator(projs-&gt;catchall_catchproj, ctrl), &quot;one proj must dominate barrier&quot;);
 811                 mem = projs-&gt;catchall_memproj;
 812               }
 813             }
 814           }
 815         } else {
 816           Node* proj = c-&gt;as_Call()-&gt;proj_out(TypeFunc::Memory);
 817           if (proj != NULL &amp;&amp;
 818               proj-&gt;adr_type() == TypePtr::BOTTOM) {
 819             mem = proj;
 820           }
 821         }
 822       } else {
 823         for (DUIterator_Fast imax, i = c-&gt;fast_outs(imax); i &lt; imax; i++) {
 824           Node* u = c-&gt;fast_out(i);
 825           if (u-&gt;is_Proj() &amp;&amp;
 826               u-&gt;bottom_type() == Type::MEMORY &amp;&amp;
 827               u-&gt;adr_type() == TypePtr::BOTTOM) {
 828               assert(c-&gt;is_SafePoint() || c-&gt;is_MemBar() || c-&gt;is_Start(), &quot;&quot;);
 829               assert(mem == NULL, &quot;only one proj&quot;);
 830               mem = u;
 831           }
 832         }
 833         assert(!c-&gt;is_Call() || c-&gt;as_Call()-&gt;adr_type() != NULL || mem == NULL, &quot;no mem projection expected&quot;);
 834       }
 835     }
 836     c = phase-&gt;idom(c);
 837   } while (mem == NULL);
 838   return mem;
 839 }
 840 
 841 void ShenandoahBarrierC2Support::follow_barrier_uses(Node* n, Node* ctrl, Unique_Node_List&amp; uses, PhaseIdealLoop* phase) {
 842   for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
 843     Node* u = n-&gt;fast_out(i);
 844     if (!u-&gt;is_CFG() &amp;&amp; phase-&gt;get_ctrl(u) == ctrl &amp;&amp; (!u-&gt;is_Phi() || !u-&gt;in(0)-&gt;is_Loop() || u-&gt;in(LoopNode::LoopBackControl) != n)) {
 845       uses.push(u);
 846     }
 847   }
 848 }
 849 
 850 static void hide_strip_mined_loop(OuterStripMinedLoopNode* outer, CountedLoopNode* inner, PhaseIdealLoop* phase) {
 851   OuterStripMinedLoopEndNode* le = inner-&gt;outer_loop_end();
 852   Node* new_outer = new LoopNode(outer-&gt;in(LoopNode::EntryControl), outer-&gt;in(LoopNode::LoopBackControl));
 853   phase-&gt;register_control(new_outer, phase-&gt;get_loop(outer), outer-&gt;in(LoopNode::EntryControl));
 854   Node* new_le = new IfNode(le-&gt;in(0), le-&gt;in(1), le-&gt;_prob, le-&gt;_fcnt);
 855   phase-&gt;register_control(new_le, phase-&gt;get_loop(le), le-&gt;in(0));
 856   phase-&gt;lazy_replace(outer, new_outer);
 857   phase-&gt;lazy_replace(le, new_le);
 858   inner-&gt;clear_strip_mined();
 859 }
 860 
 861 void ShenandoahBarrierC2Support::test_gc_state(Node*&amp; ctrl, Node* raw_mem, Node*&amp; test_fail_ctrl,
 862                                                PhaseIdealLoop* phase, int flags) {
 863   PhaseIterGVN&amp; igvn = phase-&gt;igvn();
 864   Node* old_ctrl = ctrl;
 865 
 866   Node* thread          = new ThreadLocalNode();
 867   Node* gc_state_offset = igvn.MakeConX(in_bytes(ShenandoahThreadLocalData::gc_state_offset()));
 868   Node* gc_state_addr   = new AddPNode(phase-&gt;C-&gt;top(), thread, gc_state_offset);
 869   Node* gc_state        = new LoadBNode(old_ctrl, raw_mem, gc_state_addr,
 870                                         DEBUG_ONLY(phase-&gt;C-&gt;get_adr_type(Compile::AliasIdxRaw)) NOT_DEBUG(NULL),
 871                                         TypeInt::BYTE, MemNode::unordered);
 872   Node* gc_state_and    = new AndINode(gc_state, igvn.intcon(flags));
 873   Node* gc_state_cmp    = new CmpINode(gc_state_and, igvn.zerocon(T_INT));
 874   Node* gc_state_bool   = new BoolNode(gc_state_cmp, BoolTest::ne);
 875 
 876   IfNode* gc_state_iff  = new IfNode(old_ctrl, gc_state_bool, PROB_UNLIKELY(0.999), COUNT_UNKNOWN);
 877   ctrl                  = new IfTrueNode(gc_state_iff);
 878   test_fail_ctrl        = new IfFalseNode(gc_state_iff);
 879 
 880   IdealLoopTree* loop = phase-&gt;get_loop(old_ctrl);
 881   phase-&gt;register_control(gc_state_iff,   loop, old_ctrl);
 882   phase-&gt;register_control(ctrl,           loop, gc_state_iff);
 883   phase-&gt;register_control(test_fail_ctrl, loop, gc_state_iff);
 884 
 885   phase-&gt;register_new_node(thread,        old_ctrl);
 886   phase-&gt;register_new_node(gc_state_addr, old_ctrl);
 887   phase-&gt;register_new_node(gc_state,      old_ctrl);
 888   phase-&gt;register_new_node(gc_state_and,  old_ctrl);
 889   phase-&gt;register_new_node(gc_state_cmp,  old_ctrl);
 890   phase-&gt;register_new_node(gc_state_bool, old_ctrl);
 891 
 892   phase-&gt;set_ctrl(gc_state_offset, phase-&gt;C-&gt;root());
 893 
 894   assert(is_gc_state_test(gc_state_iff, flags), &quot;Should match the shape&quot;);
 895 }
 896 
 897 void ShenandoahBarrierC2Support::test_null(Node*&amp; ctrl, Node* val, Node*&amp; null_ctrl, PhaseIdealLoop* phase) {
 898   Node* old_ctrl = ctrl;
 899   PhaseIterGVN&amp; igvn = phase-&gt;igvn();
 900 
 901   const Type* val_t = igvn.type(val);
 902   if (val_t-&gt;meet(TypePtr::NULL_PTR) == val_t) {
 903     Node* null_cmp   = new CmpPNode(val, igvn.zerocon(T_OBJECT));
 904     Node* null_test  = new BoolNode(null_cmp, BoolTest::ne);
 905 
 906     IfNode* null_iff = new IfNode(old_ctrl, null_test, PROB_LIKELY(0.999), COUNT_UNKNOWN);
 907     ctrl             = new IfTrueNode(null_iff);
 908     null_ctrl        = new IfFalseNode(null_iff);
 909 
 910     IdealLoopTree* loop = phase-&gt;get_loop(old_ctrl);
 911     phase-&gt;register_control(null_iff,  loop, old_ctrl);
 912     phase-&gt;register_control(ctrl,      loop, null_iff);
 913     phase-&gt;register_control(null_ctrl, loop, null_iff);
 914 
 915     phase-&gt;register_new_node(null_cmp,  old_ctrl);
 916     phase-&gt;register_new_node(null_test, old_ctrl);
 917   }
 918 }
 919 
 920 void ShenandoahBarrierC2Support::test_in_cset(Node*&amp; ctrl, Node*&amp; not_cset_ctrl, Node* val, Node* raw_mem, PhaseIdealLoop* phase) {
 921   Node* old_ctrl = ctrl;
 922   PhaseIterGVN&amp; igvn = phase-&gt;igvn();
 923 
 924   Node* raw_val        = new CastP2XNode(old_ctrl, val);
 925   Node* cset_idx       = new URShiftXNode(raw_val, igvn.intcon(ShenandoahHeapRegion::region_size_bytes_shift_jint()));
 926 
 927   // Figure out the target cset address with raw pointer math.
 928   // This avoids matching AddP+LoadB that would emit inefficient code.
 929   // See JDK-8245465.
 930   Node* cset_addr_ptr  = igvn.makecon(TypeRawPtr::make(ShenandoahHeap::in_cset_fast_test_addr()));
 931   Node* cset_addr      = new CastP2XNode(old_ctrl, cset_addr_ptr);
 932   Node* cset_load_addr = new AddXNode(cset_addr, cset_idx);
 933   Node* cset_load_ptr  = new CastX2PNode(cset_load_addr);
 934 
 935   Node* cset_load      = new LoadBNode(old_ctrl, raw_mem, cset_load_ptr,
 936                                        DEBUG_ONLY(phase-&gt;C-&gt;get_adr_type(Compile::AliasIdxRaw)) NOT_DEBUG(NULL),
 937                                        TypeInt::BYTE, MemNode::unordered);
 938   Node* cset_cmp       = new CmpINode(cset_load, igvn.zerocon(T_INT));
 939   Node* cset_bool      = new BoolNode(cset_cmp, BoolTest::ne);
 940 
 941   IfNode* cset_iff     = new IfNode(old_ctrl, cset_bool, PROB_UNLIKELY(0.999), COUNT_UNKNOWN);
 942   ctrl                 = new IfTrueNode(cset_iff);
 943   not_cset_ctrl        = new IfFalseNode(cset_iff);
 944 
 945   IdealLoopTree *loop = phase-&gt;get_loop(old_ctrl);
 946   phase-&gt;register_control(cset_iff,      loop, old_ctrl);
 947   phase-&gt;register_control(ctrl,          loop, cset_iff);
 948   phase-&gt;register_control(not_cset_ctrl, loop, cset_iff);
 949 
 950   phase-&gt;set_ctrl(cset_addr_ptr, phase-&gt;C-&gt;root());
 951 
 952   phase-&gt;register_new_node(raw_val,        old_ctrl);
 953   phase-&gt;register_new_node(cset_idx,       old_ctrl);
 954   phase-&gt;register_new_node(cset_addr,      old_ctrl);
 955   phase-&gt;register_new_node(cset_load_addr, old_ctrl);
 956   phase-&gt;register_new_node(cset_load_ptr,  old_ctrl);
 957   phase-&gt;register_new_node(cset_load,      old_ctrl);
 958   phase-&gt;register_new_node(cset_cmp,       old_ctrl);
 959   phase-&gt;register_new_node(cset_bool,      old_ctrl);
 960 }
 961 
 962 void ShenandoahBarrierC2Support::call_lrb_stub(Node*&amp; ctrl, Node*&amp; val, Node* load_addr, Node*&amp; result_mem, Node* raw_mem, bool is_native, PhaseIdealLoop* phase) {
 963   IdealLoopTree*loop = phase-&gt;get_loop(ctrl);
 964   const TypePtr* obj_type = phase-&gt;igvn().type(val)-&gt;is_oopptr();
 965 
 966   // The slow path stub consumes and produces raw memory in addition
 967   // to the existing memory edges
 968   Node* base = find_bottom_mem(ctrl, phase);
 969   MergeMemNode* mm = MergeMemNode::make(base);
 970   mm-&gt;set_memory_at(Compile::AliasIdxRaw, raw_mem);
 971   phase-&gt;register_new_node(mm, ctrl);
 972 
 973   address target = LP64_ONLY(UseCompressedOops) NOT_LP64(false) ?
 974           CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_narrow) :
 975           CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier);
 976 
 977   address calladdr = is_native ? CAST_FROM_FN_PTR(address, ShenandoahRuntime::load_reference_barrier_native)
 978                                : target;
 979   const char* name = is_native ? &quot;load_reference_barrier_native&quot; : &quot;load_reference_barrier&quot;;
 980   Node* call = new CallLeafNode(ShenandoahBarrierSetC2::shenandoah_load_reference_barrier_Type(), calladdr, name, TypeRawPtr::BOTTOM);
 981 
 982   call-&gt;init_req(TypeFunc::Control, ctrl);
 983   call-&gt;init_req(TypeFunc::I_O, phase-&gt;C-&gt;top());
 984   call-&gt;init_req(TypeFunc::Memory, mm);
 985   call-&gt;init_req(TypeFunc::FramePtr, phase-&gt;C-&gt;top());
 986   call-&gt;init_req(TypeFunc::ReturnAdr, phase-&gt;C-&gt;top());
 987   call-&gt;init_req(TypeFunc::Parms, val);
 988   call-&gt;init_req(TypeFunc::Parms+1, load_addr);
 989   phase-&gt;register_control(call, loop, ctrl);
 990   ctrl = new ProjNode(call, TypeFunc::Control);
 991   phase-&gt;register_control(ctrl, loop, call);
 992   result_mem = new ProjNode(call, TypeFunc::Memory);
 993   phase-&gt;register_new_node(result_mem, call);
 994   val = new ProjNode(call, TypeFunc::Parms);
 995   phase-&gt;register_new_node(val, call);
 996   val = new CheckCastPPNode(ctrl, val, obj_type);
 997   phase-&gt;register_new_node(val, ctrl);
 998 }
 999 
1000 void ShenandoahBarrierC2Support::fix_ctrl(Node* barrier, Node* region, const MemoryGraphFixer&amp; fixer, Unique_Node_List&amp; uses, Unique_Node_List&amp; uses_to_ignore, uint last, PhaseIdealLoop* phase) {
1001   Node* ctrl = phase-&gt;get_ctrl(barrier);
1002   Node* init_raw_mem = fixer.find_mem(ctrl, barrier);
1003 
1004   // Update the control of all nodes that should be after the
1005   // barrier control flow
1006   uses.clear();
1007   // Every node that is control dependent on the barrier&#39;s input
1008   // control will be after the expanded barrier. The raw memory (if
1009   // its memory is control dependent on the barrier&#39;s input control)
1010   // must stay above the barrier.
1011   uses_to_ignore.clear();
1012   if (phase-&gt;has_ctrl(init_raw_mem) &amp;&amp; phase-&gt;get_ctrl(init_raw_mem) == ctrl &amp;&amp; !init_raw_mem-&gt;is_Phi()) {
1013     uses_to_ignore.push(init_raw_mem);
1014   }
1015   for (uint next = 0; next &lt; uses_to_ignore.size(); next++) {
1016     Node *n = uses_to_ignore.at(next);
1017     for (uint i = 0; i &lt; n-&gt;req(); i++) {
1018       Node* in = n-&gt;in(i);
1019       if (in != NULL &amp;&amp; phase-&gt;has_ctrl(in) &amp;&amp; phase-&gt;get_ctrl(in) == ctrl) {
1020         uses_to_ignore.push(in);
1021       }
1022     }
1023   }
1024   for (DUIterator_Fast imax, i = ctrl-&gt;fast_outs(imax); i &lt; imax; i++) {
1025     Node* u = ctrl-&gt;fast_out(i);
1026     if (u-&gt;_idx &lt; last &amp;&amp;
1027         u != barrier &amp;&amp;
1028         !uses_to_ignore.member(u) &amp;&amp;
1029         (u-&gt;in(0) != ctrl || (!u-&gt;is_Region() &amp;&amp; !u-&gt;is_Phi())) &amp;&amp;
1030         (ctrl-&gt;Opcode() != Op_CatchProj || u-&gt;Opcode() != Op_CreateEx)) {
1031       Node* old_c = phase-&gt;ctrl_or_self(u);
1032       Node* c = old_c;
1033       if (c != ctrl ||
1034           is_dominator_same_ctrl(old_c, barrier, u, phase) ||
1035           ShenandoahBarrierSetC2::is_shenandoah_state_load(u)) {
1036         phase-&gt;igvn().rehash_node_delayed(u);
1037         int nb = u-&gt;replace_edge(ctrl, region);
1038         if (u-&gt;is_CFG()) {
1039           if (phase-&gt;idom(u) == ctrl) {
1040             phase-&gt;set_idom(u, region, phase-&gt;dom_depth(region));
1041           }
1042         } else if (phase-&gt;get_ctrl(u) == ctrl) {
1043           assert(u != init_raw_mem, &quot;should leave input raw mem above the barrier&quot;);
1044           uses.push(u);
1045         }
1046         assert(nb == 1, &quot;more than 1 ctrl input?&quot;);
1047         --i, imax -= nb;
1048       }
1049     }
1050   }
1051 }
1052 
1053 static Node* create_phis_on_call_return(Node* ctrl, Node* c, Node* n, Node* n_clone, const CallProjections* projs, PhaseIdealLoop* phase) {
1054   Node* region = NULL;
1055   while (c != ctrl) {
1056     if (c-&gt;is_Region()) {
1057       region = c;
1058     }
1059     c = phase-&gt;idom(c);
1060   }
1061   assert(region != NULL, &quot;&quot;);
1062   Node* phi = new PhiNode(region, n-&gt;bottom_type());
1063   for (uint j = 1; j &lt; region-&gt;req(); j++) {
1064     Node* in = region-&gt;in(j);
1065     if (phase-&gt;is_dominator(projs-&gt;fallthrough_catchproj, in)) {
1066       phi-&gt;init_req(j, n);
1067     } else if (phase-&gt;is_dominator(projs-&gt;catchall_catchproj, in)) {
1068       phi-&gt;init_req(j, n_clone);
1069     } else {
1070       phi-&gt;init_req(j, create_phis_on_call_return(ctrl, in, n, n_clone, projs, phase));
1071     }
1072   }
1073   phase-&gt;register_new_node(phi, region);
1074   return phi;
1075 }
1076 
1077 void ShenandoahBarrierC2Support::pin_and_expand(PhaseIdealLoop* phase) {
1078   ShenandoahBarrierSetC2State* state = ShenandoahBarrierSetC2::bsc2()-&gt;state();
1079 
1080   Unique_Node_List uses;
1081   for (int i = 0; i &lt; state-&gt;enqueue_barriers_count(); i++) {
1082     Node* barrier = state-&gt;enqueue_barrier(i);
1083     Node* ctrl = phase-&gt;get_ctrl(barrier);
1084     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1085     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1086       // Expanding a barrier here will break loop strip mining
1087       // verification. Transform the loop so the loop nest doesn&#39;t
1088       // appear as strip mined.
1089       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1090       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1091     }
1092   }
1093 
1094   Node_Stack stack(0);
1095   Node_List clones;
1096   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1097     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
1098 
1099     Node* ctrl = phase-&gt;get_ctrl(lrb);
1100     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1101 
1102     CallStaticJavaNode* unc = NULL;
1103     Node* unc_ctrl = NULL;
1104     Node* uncasted_val = val;
1105 
1106     for (DUIterator_Fast imax, i = lrb-&gt;fast_outs(imax); i &lt; imax; i++) {
1107       Node* u = lrb-&gt;fast_out(i);
1108       if (u-&gt;Opcode() == Op_CastPP &amp;&amp;
1109           u-&gt;in(0) != NULL &amp;&amp;
1110           phase-&gt;is_dominator(u-&gt;in(0), ctrl)) {
1111         const Type* u_t = phase-&gt;igvn().type(u);
1112 
1113         if (u_t-&gt;meet(TypePtr::NULL_PTR) != u_t &amp;&amp;
1114             u-&gt;in(0)-&gt;Opcode() == Op_IfTrue &amp;&amp;
1115             u-&gt;in(0)-&gt;as_Proj()-&gt;is_uncommon_trap_if_pattern(Deoptimization::Reason_none) &amp;&amp;
1116             u-&gt;in(0)-&gt;in(0)-&gt;is_If() &amp;&amp;
1117             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;Opcode() == Op_Bool &amp;&amp;
1118             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::ne &amp;&amp;
1119             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;Opcode() == Op_CmpP &amp;&amp;
1120             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(1) == val &amp;&amp;
1121             u-&gt;in(0)-&gt;in(0)-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;bottom_type() == TypePtr::NULL_PTR) {
1122           IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1123           IdealLoopTree* unc_loop = phase-&gt;get_loop(u-&gt;in(0));
1124 
1125           if (!unc_loop-&gt;is_member(loop)) {
1126             continue;
1127           }
1128 
1129           Node* branch = no_branches(ctrl, u-&gt;in(0), false, phase);
1130           assert(branch == NULL || branch == NodeSentinel, &quot;was not looking for a branch&quot;);
1131           if (branch == NodeSentinel) {
1132             continue;
1133           }
1134 
1135           Node* iff = u-&gt;in(0)-&gt;in(0);
1136           Node* bol = iff-&gt;in(1)-&gt;clone();
1137           Node* cmp = bol-&gt;in(1)-&gt;clone();
1138           cmp-&gt;set_req(1, lrb);
1139           bol-&gt;set_req(1, cmp);
1140           phase-&gt;igvn().replace_input_of(iff, 1, bol);
1141           phase-&gt;set_ctrl(lrb, iff-&gt;in(0));
1142           phase-&gt;register_new_node(cmp, iff-&gt;in(0));
1143           phase-&gt;register_new_node(bol, iff-&gt;in(0));
1144           break;
1145         }
1146       }
1147     }
1148     if ((ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_CallJava()) || ctrl-&gt;is_CallJava()) {
1149       CallNode* call = ctrl-&gt;is_Proj() ? ctrl-&gt;in(0)-&gt;as_CallJava() : ctrl-&gt;as_CallJava();
1150       if (call-&gt;entry_point() == OptoRuntime::rethrow_stub()) {
1151         // The rethrow call may have too many projections to be
1152         // properly handled here. Given there&#39;s no reason for a
1153         // barrier to depend on the call, move it above the call
1154         stack.push(lrb, 0);
1155         do {
1156           Node* n = stack.node();
1157           uint idx = stack.index();
1158           if (idx &lt; n-&gt;req()) {
1159             Node* in = n-&gt;in(idx);
1160             stack.set_index(idx+1);
1161             if (in != NULL) {
1162               if (phase-&gt;has_ctrl(in)) {
1163                 if (phase-&gt;is_dominator(call, phase-&gt;get_ctrl(in))) {
1164 #ifdef ASSERT
1165                   for (uint i = 0; i &lt; stack.size(); i++) {
1166                     assert(stack.node_at(i) != in, &quot;node shouldn&#39;t have been seen yet&quot;);
1167                   }
1168 #endif
1169                   stack.push(in, 0);
1170                 }
1171               } else {
1172                 assert(phase-&gt;is_dominator(in, call-&gt;in(0)), &quot;no dependency on the call&quot;);
1173               }
1174             }
1175           } else {
1176             phase-&gt;set_ctrl(n, call-&gt;in(0));
1177             stack.pop();
1178           }
1179         } while(stack.size() &gt; 0);
1180         continue;
1181       }
1182       CallProjections* projs = call-&gt;extract_projections(false, false);
1183 #ifdef ASSERT
1184       VectorSet cloned(Thread::current()-&gt;resource_area());
1185 #endif
1186       Node* lrb_clone = lrb-&gt;clone();
1187       phase-&gt;register_new_node(lrb_clone, projs-&gt;catchall_catchproj);
1188       phase-&gt;set_ctrl(lrb, projs-&gt;fallthrough_catchproj);
1189 
1190       stack.push(lrb, 0);
1191       clones.push(lrb_clone);
1192 
1193       do {
1194         assert(stack.size() == clones.size(), &quot;&quot;);
1195         Node* n = stack.node();
1196 #ifdef ASSERT
1197         if (n-&gt;is_Load()) {
1198           Node* mem = n-&gt;in(MemNode::Memory);
1199           for (DUIterator_Fast jmax, j = mem-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1200             Node* u = mem-&gt;fast_out(j);
1201             assert(!u-&gt;is_Store() || !u-&gt;is_LoadStore() || phase-&gt;get_ctrl(u) != ctrl, &quot;anti dependent store?&quot;);
1202           }
1203         }
1204 #endif
1205         uint idx = stack.index();
1206         Node* n_clone = clones.at(clones.size()-1);
1207         if (idx &lt; n-&gt;outcnt()) {
1208           Node* u = n-&gt;raw_out(idx);
1209           Node* c = phase-&gt;ctrl_or_self(u);
1210           if (phase-&gt;is_dominator(call, c) &amp;&amp; phase-&gt;is_dominator(c, projs-&gt;fallthrough_proj)) {
1211             stack.set_index(idx+1);
1212             assert(!u-&gt;is_CFG(), &quot;&quot;);
1213             stack.push(u, 0);
1214             assert(!cloned.test_set(u-&gt;_idx), &quot;only one clone&quot;);
1215             Node* u_clone = u-&gt;clone();
1216             int nb = u_clone-&gt;replace_edge(n, n_clone);
1217             assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1218             phase-&gt;register_new_node(u_clone, projs-&gt;catchall_catchproj);
1219             clones.push(u_clone);
1220             phase-&gt;set_ctrl(u, projs-&gt;fallthrough_catchproj);
1221           } else {
1222             bool replaced = false;
1223             if (u-&gt;is_Phi()) {
1224               for (uint k = 1; k &lt; u-&gt;req(); k++) {
1225                 if (u-&gt;in(k) == n) {
1226                   if (phase-&gt;is_dominator(projs-&gt;catchall_catchproj, u-&gt;in(0)-&gt;in(k))) {
1227                     phase-&gt;igvn().replace_input_of(u, k, n_clone);
1228                     replaced = true;
1229                   } else if (!phase-&gt;is_dominator(projs-&gt;fallthrough_catchproj, u-&gt;in(0)-&gt;in(k))) {
1230                     phase-&gt;igvn().replace_input_of(u, k, create_phis_on_call_return(ctrl, u-&gt;in(0)-&gt;in(k), n, n_clone, projs, phase));
1231                     replaced = true;
1232                   }
1233                 }
1234               }
1235             } else {
1236               if (phase-&gt;is_dominator(projs-&gt;catchall_catchproj, c)) {
1237                 phase-&gt;igvn().rehash_node_delayed(u);
1238                 int nb = u-&gt;replace_edge(n, n_clone);
1239                 assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1240                 replaced = true;
1241               } else if (!phase-&gt;is_dominator(projs-&gt;fallthrough_catchproj, c)) {
1242                 if (u-&gt;is_If()) {
1243                   // Can&#39;t break If/Bool/Cmp chain
1244                   assert(n-&gt;is_Bool(), &quot;unexpected If shape&quot;);
1245                   assert(stack.node_at(stack.size()-2)-&gt;is_Cmp(), &quot;unexpected If shape&quot;);
1246                   assert(n_clone-&gt;is_Bool(), &quot;unexpected clone&quot;);
1247                   assert(clones.at(clones.size()-2)-&gt;is_Cmp(), &quot;unexpected clone&quot;);
1248                   Node* bol_clone = n-&gt;clone();
1249                   Node* cmp_clone = stack.node_at(stack.size()-2)-&gt;clone();
1250                   bol_clone-&gt;set_req(1, cmp_clone);
1251 
1252                   Node* nn = stack.node_at(stack.size()-3);
1253                   Node* nn_clone = clones.at(clones.size()-3);
1254                   assert(nn-&gt;Opcode() == nn_clone-&gt;Opcode(), &quot;mismatch&quot;);
1255 
1256                   int nb = cmp_clone-&gt;replace_edge(nn, create_phis_on_call_return(ctrl, c, nn, nn_clone, projs, phase));
1257                   assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1258 
1259                   phase-&gt;register_new_node(bol_clone, u-&gt;in(0));
1260                   phase-&gt;register_new_node(cmp_clone, u-&gt;in(0));
1261 
1262                   phase-&gt;igvn().replace_input_of(u, 1, bol_clone);
1263 
1264                 } else {
1265                   phase-&gt;igvn().rehash_node_delayed(u);
1266                   int nb = u-&gt;replace_edge(n, create_phis_on_call_return(ctrl, c, n, n_clone, projs, phase));
1267                   assert(nb &gt; 0, &quot;should have replaced some uses&quot;);
1268                 }
1269                 replaced = true;
1270               }
1271             }
1272             if (!replaced) {
1273               stack.set_index(idx+1);
1274             }
1275           }
1276         } else {
1277           stack.pop();
1278           clones.pop();
1279         }
1280       } while (stack.size() &gt; 0);
1281       assert(stack.size() == 0 &amp;&amp; clones.size() == 0, &quot;&quot;);
1282     }
1283   }
1284 
1285   for (int i = 0; i &lt; state-&gt;load_reference_barriers_count(); i++) {
1286     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
1287     Node* ctrl = phase-&gt;get_ctrl(lrb);
1288     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1289     if (loop-&gt;_head-&gt;is_OuterStripMinedLoop()) {
1290       // Expanding a barrier here will break loop strip mining
1291       // verification. Transform the loop so the loop nest doesn&#39;t
1292       // appear as strip mined.
1293       OuterStripMinedLoopNode* outer = loop-&gt;_head-&gt;as_OuterStripMinedLoop();
1294       hide_strip_mined_loop(outer, outer-&gt;unique_ctrl_out()-&gt;as_CountedLoop(), phase);
1295     }
1296   }
1297 
1298   // Expand load-reference-barriers
1299   MemoryGraphFixer fixer(Compile::AliasIdxRaw, true, phase);
1300   Unique_Node_List uses_to_ignore;
1301   for (int i = state-&gt;load_reference_barriers_count() - 1; i &gt;= 0; i--) {
1302     ShenandoahLoadReferenceBarrierNode* lrb = state-&gt;load_reference_barrier(i);
1303     uint last = phase-&gt;C-&gt;unique();
1304     Node* ctrl = phase-&gt;get_ctrl(lrb);
1305     Node* val = lrb-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn);
1306 
1307 
1308     Node* orig_ctrl = ctrl;
1309 
1310     Node* raw_mem = fixer.find_mem(ctrl, lrb);
1311     Node* init_raw_mem = raw_mem;
1312     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
1313 
1314     IdealLoopTree *loop = phase-&gt;get_loop(ctrl);
1315 
1316     Node* heap_stable_ctrl = NULL;
1317     Node* null_ctrl = NULL;
1318 
1319     assert(val-&gt;bottom_type()-&gt;make_oopptr(), &quot;need oop&quot;);
1320     assert(val-&gt;bottom_type()-&gt;make_oopptr()-&gt;const_oop() == NULL, &quot;expect non-constant&quot;);
1321 
1322     enum { _heap_stable = 1, _not_cset, _evac_path, PATH_LIMIT };
1323     Node* region = new RegionNode(PATH_LIMIT);
1324     Node* val_phi = new PhiNode(region, val-&gt;bottom_type()-&gt;is_oopptr());
1325     Node* raw_mem_phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
1326 
1327     // Stable path.
1328     test_gc_state(ctrl, raw_mem, heap_stable_ctrl, phase, ShenandoahHeap::HAS_FORWARDED);
1329     IfNode* heap_stable_iff = heap_stable_ctrl-&gt;in(0)-&gt;as_If();
1330 
1331     // Heap stable case
1332     region-&gt;init_req(_heap_stable, heap_stable_ctrl);
1333     val_phi-&gt;init_req(_heap_stable, val);
1334     raw_mem_phi-&gt;init_req(_heap_stable, raw_mem);
1335 
1336     // Test for in-cset.
1337     // Wires !in_cset(obj) to slot 2 of region and phis
1338     Node* not_cset_ctrl = NULL;
1339     test_in_cset(ctrl, not_cset_ctrl, val, raw_mem, phase);
1340     if (not_cset_ctrl != NULL) {
1341       region-&gt;init_req(_not_cset, not_cset_ctrl);
1342       val_phi-&gt;init_req(_not_cset, val);
1343       raw_mem_phi-&gt;init_req(_not_cset, raw_mem);
1344     }
1345 
1346     // Resolve object when orig-value is in cset.
1347     // Make the unconditional resolve for fwdptr.
1348 
1349     // Call lrb-stub and wire up that path in slots 4
1350     Node* result_mem = NULL;
1351 
1352     Node* addr;
1353     if (ShenandoahSelfFixing) {
1354       VectorSet visited(Thread::current()-&gt;resource_area());
1355       addr = get_load_addr(phase, visited, lrb);
1356     } else {
1357       addr = phase-&gt;igvn().zerocon(T_OBJECT);
1358     }
1359     if (addr-&gt;Opcode() == Op_AddP) {
1360       Node* orig_base = addr-&gt;in(AddPNode::Base);
1361       Node* base = new CheckCastPPNode(ctrl, orig_base, orig_base-&gt;bottom_type(), true);
1362       phase-&gt;register_new_node(base, ctrl);
1363       if (addr-&gt;in(AddPNode::Base) == addr-&gt;in((AddPNode::Address))) {
1364         // Field access
1365         addr = addr-&gt;clone();
1366         addr-&gt;set_req(AddPNode::Base, base);
1367         addr-&gt;set_req(AddPNode::Address, base);
1368         phase-&gt;register_new_node(addr, ctrl);
1369       } else {
1370         Node* addr2 = addr-&gt;in(AddPNode::Address);
1371         if (addr2-&gt;Opcode() == Op_AddP &amp;&amp; addr2-&gt;in(AddPNode::Base) == addr2-&gt;in(AddPNode::Address) &amp;&amp;
1372               addr2-&gt;in(AddPNode::Base) == orig_base) {
1373           addr2 = addr2-&gt;clone();
1374           addr2-&gt;set_req(AddPNode::Base, base);
1375           addr2-&gt;set_req(AddPNode::Address, base);
1376           phase-&gt;register_new_node(addr2, ctrl);
1377           addr = addr-&gt;clone();
1378           addr-&gt;set_req(AddPNode::Base, base);
1379           addr-&gt;set_req(AddPNode::Address, addr2);
1380           phase-&gt;register_new_node(addr, ctrl);
1381         }
1382       }
1383     }
1384     call_lrb_stub(ctrl, val, addr, result_mem, raw_mem, lrb-&gt;is_native(), phase);
1385     region-&gt;init_req(_evac_path, ctrl);
1386     val_phi-&gt;init_req(_evac_path, val);
1387     raw_mem_phi-&gt;init_req(_evac_path, result_mem);
1388 
1389     phase-&gt;register_control(region, loop, heap_stable_iff);
1390     Node* out_val = val_phi;
1391     phase-&gt;register_new_node(val_phi, region);
1392     phase-&gt;register_new_node(raw_mem_phi, region);
1393 
1394     fix_ctrl(lrb, region, fixer, uses, uses_to_ignore, last, phase);
1395 
1396     ctrl = orig_ctrl;
1397 
1398     phase-&gt;igvn().replace_node(lrb, out_val);
1399 
1400     follow_barrier_uses(out_val, ctrl, uses, phase);
1401 
1402     for(uint next = 0; next &lt; uses.size(); next++ ) {
1403       Node *n = uses.at(next);
1404       assert(phase-&gt;get_ctrl(n) == ctrl, &quot;bad control&quot;);
1405       assert(n != init_raw_mem, &quot;should leave input raw mem above the barrier&quot;);
1406       phase-&gt;set_ctrl(n, region);
1407       follow_barrier_uses(n, ctrl, uses, phase);
1408     }
1409 
1410     // The slow path call produces memory: hook the raw memory phi
1411     // from the expanded load reference barrier with the rest of the graph
1412     // which may require adding memory phis at every post dominated
1413     // region and at enclosing loop heads. Use the memory state
1414     // collected in memory_nodes to fix the memory graph. Update that
1415     // memory state as we go.
1416     fixer.fix_mem(ctrl, region, init_raw_mem, raw_mem_for_ctrl, raw_mem_phi, uses);
1417   }
1418   // Done expanding load-reference-barriers.
1419   assert(ShenandoahBarrierSetC2::bsc2()-&gt;state()-&gt;load_reference_barriers_count() == 0, &quot;all load reference barrier nodes should have been replaced&quot;);
1420 
1421   for (int i = state-&gt;enqueue_barriers_count() - 1; i &gt;= 0; i--) {
1422     Node* barrier = state-&gt;enqueue_barrier(i);
1423     Node* pre_val = barrier-&gt;in(1);
1424 
1425     if (phase-&gt;igvn().type(pre_val)-&gt;higher_equal(TypePtr::NULL_PTR)) {
1426       ShouldNotReachHere();
1427       continue;
1428     }
1429 
1430     Node* ctrl = phase-&gt;get_ctrl(barrier);
1431 
1432     if (ctrl-&gt;is_Proj() &amp;&amp; ctrl-&gt;in(0)-&gt;is_CallJava()) {
1433       assert(is_dominator(phase-&gt;get_ctrl(pre_val), ctrl-&gt;in(0)-&gt;in(0), pre_val, ctrl-&gt;in(0), phase), &quot;can&#39;t move&quot;);
1434       ctrl = ctrl-&gt;in(0)-&gt;in(0);
1435       phase-&gt;set_ctrl(barrier, ctrl);
1436     } else if (ctrl-&gt;is_CallRuntime()) {
1437       assert(is_dominator(phase-&gt;get_ctrl(pre_val), ctrl-&gt;in(0), pre_val, ctrl, phase), &quot;can&#39;t move&quot;);
1438       ctrl = ctrl-&gt;in(0);
1439       phase-&gt;set_ctrl(barrier, ctrl);
1440     }
1441 
1442     Node* init_ctrl = ctrl;
1443     IdealLoopTree* loop = phase-&gt;get_loop(ctrl);
1444     Node* raw_mem = fixer.find_mem(ctrl, barrier);
1445     Node* init_raw_mem = raw_mem;
1446     Node* raw_mem_for_ctrl = fixer.find_mem(ctrl, NULL);
1447     Node* heap_stable_ctrl = NULL;
1448     Node* null_ctrl = NULL;
1449     uint last = phase-&gt;C-&gt;unique();
1450 
1451     enum { _heap_stable = 1, _heap_unstable, PATH_LIMIT };
1452     Node* region = new RegionNode(PATH_LIMIT);
1453     Node* phi = PhiNode::make(region, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
1454 
1455     enum { _fast_path = 1, _slow_path, _null_path, PATH_LIMIT2 };
1456     Node* region2 = new RegionNode(PATH_LIMIT2);
1457     Node* phi2 = PhiNode::make(region2, raw_mem, Type::MEMORY, TypeRawPtr::BOTTOM);
1458 
1459     // Stable path.
1460     test_gc_state(ctrl, raw_mem, heap_stable_ctrl, phase, ShenandoahHeap::MARKING);
1461     region-&gt;init_req(_heap_stable, heap_stable_ctrl);
1462     phi-&gt;init_req(_heap_stable, raw_mem);
1463 
1464     // Null path
1465     Node* reg2_ctrl = NULL;
1466     test_null(ctrl, pre_val, null_ctrl, phase);
1467     if (null_ctrl != NULL) {
1468       reg2_ctrl = null_ctrl-&gt;in(0);
1469       region2-&gt;init_req(_null_path, null_ctrl);
1470       phi2-&gt;init_req(_null_path, raw_mem);
1471     } else {
1472       region2-&gt;del_req(_null_path);
1473       phi2-&gt;del_req(_null_path);
1474     }
1475 
1476     const int index_offset = in_bytes(ShenandoahThreadLocalData::satb_mark_queue_index_offset());
1477     const int buffer_offset = in_bytes(ShenandoahThreadLocalData::satb_mark_queue_buffer_offset());
1478     Node* thread = new ThreadLocalNode();
1479     phase-&gt;register_new_node(thread, ctrl);
1480     Node* buffer_adr = new AddPNode(phase-&gt;C-&gt;top(), thread, phase-&gt;igvn().MakeConX(buffer_offset));
1481     phase-&gt;register_new_node(buffer_adr, ctrl);
1482     Node* index_adr = new AddPNode(phase-&gt;C-&gt;top(), thread, phase-&gt;igvn().MakeConX(index_offset));
1483     phase-&gt;register_new_node(index_adr, ctrl);
1484 
1485     BasicType index_bt = TypeX_X-&gt;basic_type();
1486     assert(sizeof(size_t) == type2aelembytes(index_bt), &quot;Loading G1 SATBMarkQueue::_index with wrong size.&quot;);
1487     const TypePtr* adr_type = TypeRawPtr::BOTTOM;
1488     Node* index = new LoadXNode(ctrl, raw_mem, index_adr, adr_type, TypeX_X, MemNode::unordered);
1489     phase-&gt;register_new_node(index, ctrl);
1490     Node* index_cmp = new CmpXNode(index, phase-&gt;igvn().MakeConX(0));
1491     phase-&gt;register_new_node(index_cmp, ctrl);
1492     Node* index_test = new BoolNode(index_cmp, BoolTest::ne);
1493     phase-&gt;register_new_node(index_test, ctrl);
1494     IfNode* queue_full_iff = new IfNode(ctrl, index_test, PROB_LIKELY(0.999), COUNT_UNKNOWN);
1495     if (reg2_ctrl == NULL) reg2_ctrl = queue_full_iff;
1496     phase-&gt;register_control(queue_full_iff, loop, ctrl);
1497     Node* not_full = new IfTrueNode(queue_full_iff);
1498     phase-&gt;register_control(not_full, loop, queue_full_iff);
1499     Node* full = new IfFalseNode(queue_full_iff);
1500     phase-&gt;register_control(full, loop, queue_full_iff);
1501 
1502     ctrl = not_full;
1503 
1504     Node* next_index = new SubXNode(index, phase-&gt;igvn().MakeConX(sizeof(intptr_t)));
1505     phase-&gt;register_new_node(next_index, ctrl);
1506 
1507     Node* buffer  = new LoadPNode(ctrl, raw_mem, buffer_adr, adr_type, TypeRawPtr::NOTNULL, MemNode::unordered);
1508     phase-&gt;register_new_node(buffer, ctrl);
1509     Node *log_addr = new AddPNode(phase-&gt;C-&gt;top(), buffer, next_index);
1510     phase-&gt;register_new_node(log_addr, ctrl);
1511     Node* log_store = new StorePNode(ctrl, raw_mem, log_addr, adr_type, pre_val, MemNode::unordered);
1512     phase-&gt;register_new_node(log_store, ctrl);
1513     // update the index
1514     Node* index_update = new StoreXNode(ctrl, log_store, index_adr, adr_type, next_index, MemNode::unordered);
1515     phase-&gt;register_new_node(index_update, ctrl);
1516 
1517     // Fast-path case
1518     region2-&gt;init_req(_fast_path, ctrl);
1519     phi2-&gt;init_req(_fast_path, index_update);
1520 
1521     ctrl = full;
1522 
1523     Node* base = find_bottom_mem(ctrl, phase);
1524 
1525     MergeMemNode* mm = MergeMemNode::make(base);
1526     mm-&gt;set_memory_at(Compile::AliasIdxRaw, raw_mem);
1527     phase-&gt;register_new_node(mm, ctrl);
1528 
1529     Node* call = new CallLeafNode(ShenandoahBarrierSetC2::write_ref_field_pre_entry_Type(), CAST_FROM_FN_PTR(address, ShenandoahRuntime::write_ref_field_pre_entry), &quot;shenandoah_wb_pre&quot;, TypeRawPtr::BOTTOM);
1530     call-&gt;init_req(TypeFunc::Control, ctrl);
1531     call-&gt;init_req(TypeFunc::I_O, phase-&gt;C-&gt;top());
1532     call-&gt;init_req(TypeFunc::Memory, mm);
1533     call-&gt;init_req(TypeFunc::FramePtr, phase-&gt;C-&gt;top());
1534     call-&gt;init_req(TypeFunc::ReturnAdr, phase-&gt;C-&gt;top());
1535     call-&gt;init_req(TypeFunc::Parms, pre_val);
1536     call-&gt;init_req(TypeFunc::Parms+1, thread);
1537     phase-&gt;register_control(call, loop, ctrl);
1538 
1539     Node* ctrl_proj = new ProjNode(call, TypeFunc::Control);
1540     phase-&gt;register_control(ctrl_proj, loop, call);
1541     Node* mem_proj = new ProjNode(call, TypeFunc::Memory);
1542     phase-&gt;register_new_node(mem_proj, call);
1543 
1544     // Slow-path case
1545     region2-&gt;init_req(_slow_path, ctrl_proj);
1546     phi2-&gt;init_req(_slow_path, mem_proj);
1547 
1548     phase-&gt;register_control(region2, loop, reg2_ctrl);
1549     phase-&gt;register_new_node(phi2, region2);
1550 
1551     region-&gt;init_req(_heap_unstable, region2);
1552     phi-&gt;init_req(_heap_unstable, phi2);
1553 
1554     phase-&gt;register_control(region, loop, heap_stable_ctrl-&gt;in(0));
1555     phase-&gt;register_new_node(phi, region);
1556 
1557     fix_ctrl(barrier, region, fixer, uses, uses_to_ignore, last, phase);
1558     for(uint next = 0; next &lt; uses.size(); next++ ) {
1559       Node *n = uses.at(next);
1560       assert(phase-&gt;get_ctrl(n) == init_ctrl, &quot;bad control&quot;);
1561       assert(n != init_raw_mem, &quot;should leave input raw mem above the barrier&quot;);
1562       phase-&gt;set_ctrl(n, region);
1563       follow_barrier_uses(n, init_ctrl, uses, phase);
1564     }
1565     fixer.fix_mem(init_ctrl, region, init_raw_mem, raw_mem_for_ctrl, phi, uses);
1566 
1567     phase-&gt;igvn().replace_node(barrier, pre_val);
1568   }
1569   assert(state-&gt;enqueue_barriers_count() == 0, &quot;all enqueue barrier nodes should have been replaced&quot;);
1570 
1571 }
1572 
1573 Node* ShenandoahBarrierC2Support::get_load_addr(PhaseIdealLoop* phase, VectorSet&amp; visited, Node* in) {
1574   if (visited.test_set(in-&gt;_idx)) {
1575     return NULL;
1576   }
1577   switch (in-&gt;Opcode()) {
1578     case Op_Proj:
1579       return get_load_addr(phase, visited, in-&gt;in(0));
1580     case Op_CastPP:
1581     case Op_CheckCastPP:
1582     case Op_DecodeN:
1583     case Op_EncodeP:
1584       return get_load_addr(phase, visited, in-&gt;in(1));
1585     case Op_LoadN:
1586     case Op_LoadP:
1587       return in-&gt;in(MemNode::Address);
1588     case Op_CompareAndExchangeN:
1589     case Op_CompareAndExchangeP:
1590     case Op_GetAndSetN:
1591     case Op_GetAndSetP:
1592     case Op_ShenandoahCompareAndExchangeP:
1593     case Op_ShenandoahCompareAndExchangeN:
1594       // Those instructions would just have stored a different
1595       // value into the field. No use to attempt to fix it at this point.
1596       return phase-&gt;igvn().zerocon(T_OBJECT);
1597     case Op_CMoveP:
1598     case Op_CMoveN: {
1599       Node* t = get_load_addr(phase, visited, in-&gt;in(CMoveNode::IfTrue));
1600       Node* f = get_load_addr(phase, visited, in-&gt;in(CMoveNode::IfFalse));
1601       // Handle unambiguous cases: single address reported on both branches.
1602       if (t != NULL &amp;&amp; f == NULL) return t;
1603       if (t == NULL &amp;&amp; f != NULL) return f;
1604       if (t != NULL &amp;&amp; t == f)    return t;
1605       // Ambiguity.
1606       return phase-&gt;igvn().zerocon(T_OBJECT);
1607     }
1608     case Op_Phi: {
1609       Node* addr = NULL;
1610       for (uint i = 1; i &lt; in-&gt;req(); i++) {
1611         Node* addr1 = get_load_addr(phase, visited, in-&gt;in(i));
1612         if (addr == NULL) {
1613           addr = addr1;
1614         }
1615         if (addr != addr1) {
1616           return phase-&gt;igvn().zerocon(T_OBJECT);
1617         }
1618       }
1619       return addr;
1620     }
1621     case Op_ShenandoahLoadReferenceBarrier:
1622       return get_load_addr(phase, visited, in-&gt;in(ShenandoahLoadReferenceBarrierNode::ValueIn));
1623     case Op_ShenandoahEnqueueBarrier:
1624       return get_load_addr(phase, visited, in-&gt;in(1));
1625     case Op_CallDynamicJava:
1626     case Op_CallLeaf:
1627     case Op_CallStaticJava:
1628     case Op_ConN:
1629     case Op_ConP:
1630     case Op_Parm:
1631     case Op_CreateEx:
1632       return phase-&gt;igvn().zerocon(T_OBJECT);
1633     default:
1634 #ifdef ASSERT
1635       fatal(&quot;Unknown node in get_load_addr: %s&quot;, NodeClassNames[in-&gt;Opcode()]);
1636 #endif
1637       return phase-&gt;igvn().zerocon(T_OBJECT);
1638   }
1639 
1640 }
1641 
1642 void ShenandoahBarrierC2Support::move_gc_state_test_out_of_loop(IfNode* iff, PhaseIdealLoop* phase) {
1643   IdealLoopTree *loop = phase-&gt;get_loop(iff);
1644   Node* loop_head = loop-&gt;_head;
1645   Node* entry_c = loop_head-&gt;in(LoopNode::EntryControl);
1646 
1647   Node* bol = iff-&gt;in(1);
1648   Node* cmp = bol-&gt;in(1);
1649   Node* andi = cmp-&gt;in(1);
1650   Node* load = andi-&gt;in(1);
1651 
1652   assert(is_gc_state_load(load), &quot;broken&quot;);
1653   if (!phase-&gt;is_dominator(load-&gt;in(0), entry_c)) {
1654     Node* mem_ctrl = NULL;
1655     Node* mem = dom_mem(load-&gt;in(MemNode::Memory), loop_head, Compile::AliasIdxRaw, mem_ctrl, phase);
1656     load = load-&gt;clone();
1657     load-&gt;set_req(MemNode::Memory, mem);
1658     load-&gt;set_req(0, entry_c);
1659     phase-&gt;register_new_node(load, entry_c);
1660     andi = andi-&gt;clone();
1661     andi-&gt;set_req(1, load);
1662     phase-&gt;register_new_node(andi, entry_c);
1663     cmp = cmp-&gt;clone();
1664     cmp-&gt;set_req(1, andi);
1665     phase-&gt;register_new_node(cmp, entry_c);
1666     bol = bol-&gt;clone();
1667     bol-&gt;set_req(1, cmp);
1668     phase-&gt;register_new_node(bol, entry_c);
1669 
1670     phase-&gt;igvn().replace_input_of(iff, 1, bol);
1671   }
1672 }
1673 
1674 bool ShenandoahBarrierC2Support::identical_backtoback_ifs(Node* n, PhaseIdealLoop* phase) {
1675   if (!n-&gt;is_If() || n-&gt;is_CountedLoopEnd()) {
1676     return false;
1677   }
1678   Node* region = n-&gt;in(0);
1679 
1680   if (!region-&gt;is_Region()) {
1681     return false;
1682   }
1683   Node* dom = phase-&gt;idom(region);
1684   if (!dom-&gt;is_If()) {
1685     return false;
1686   }
1687 
1688   if (!is_heap_stable_test(n) || !is_heap_stable_test(dom)) {
1689     return false;
1690   }
1691 
1692   IfNode* dom_if = dom-&gt;as_If();
1693   Node* proj_true = dom_if-&gt;proj_out(1);
1694   Node* proj_false = dom_if-&gt;proj_out(0);
1695 
1696   for (uint i = 1; i &lt; region-&gt;req(); i++) {
1697     if (phase-&gt;is_dominator(proj_true, region-&gt;in(i))) {
1698       continue;
1699     }
1700     if (phase-&gt;is_dominator(proj_false, region-&gt;in(i))) {
1701       continue;
1702     }
1703     return false;
1704   }
1705 
1706   return true;
1707 }
1708 
1709 void ShenandoahBarrierC2Support::merge_back_to_back_tests(Node* n, PhaseIdealLoop* phase) {
1710   assert(is_heap_stable_test(n), &quot;no other tests&quot;);
1711   if (identical_backtoback_ifs(n, phase)) {
1712     Node* n_ctrl = n-&gt;in(0);
1713     if (phase-&gt;can_split_if(n_ctrl)) {
1714       IfNode* dom_if = phase-&gt;idom(n_ctrl)-&gt;as_If();
1715       if (is_heap_stable_test(n)) {
1716         Node* gc_state_load = n-&gt;in(1)-&gt;in(1)-&gt;in(1)-&gt;in(1);
1717         assert(is_gc_state_load(gc_state_load), &quot;broken&quot;);
1718         Node* dom_gc_state_load = dom_if-&gt;in(1)-&gt;in(1)-&gt;in(1)-&gt;in(1);
1719         assert(is_gc_state_load(dom_gc_state_load), &quot;broken&quot;);
1720         if (gc_state_load != dom_gc_state_load) {
1721           phase-&gt;igvn().replace_node(gc_state_load, dom_gc_state_load);
1722         }
1723       }
1724       PhiNode* bolphi = PhiNode::make_blank(n_ctrl, n-&gt;in(1));
1725       Node* proj_true = dom_if-&gt;proj_out(1);
1726       Node* proj_false = dom_if-&gt;proj_out(0);
1727       Node* con_true = phase-&gt;igvn().makecon(TypeInt::ONE);
1728       Node* con_false = phase-&gt;igvn().makecon(TypeInt::ZERO);
1729 
1730       for (uint i = 1; i &lt; n_ctrl-&gt;req(); i++) {
1731         if (phase-&gt;is_dominator(proj_true, n_ctrl-&gt;in(i))) {
1732           bolphi-&gt;init_req(i, con_true);
1733         } else {
1734           assert(phase-&gt;is_dominator(proj_false, n_ctrl-&gt;in(i)), &quot;bad if&quot;);
1735           bolphi-&gt;init_req(i, con_false);
1736         }
1737       }
1738       phase-&gt;register_new_node(bolphi, n_ctrl);
1739       phase-&gt;igvn().replace_input_of(n, 1, bolphi);
1740       phase-&gt;do_split_if(n);
1741     }
1742   }
1743 }
1744 
1745 IfNode* ShenandoahBarrierC2Support::find_unswitching_candidate(const IdealLoopTree* loop, PhaseIdealLoop* phase) {
1746   // Find first invariant test that doesn&#39;t exit the loop
1747   LoopNode *head = loop-&gt;_head-&gt;as_Loop();
1748   IfNode* unswitch_iff = NULL;
1749   Node* n = head-&gt;in(LoopNode::LoopBackControl);
1750   int loop_has_sfpts = -1;
1751   while (n != head) {
1752     Node* n_dom = phase-&gt;idom(n);
1753     if (n-&gt;is_Region()) {
1754       if (n_dom-&gt;is_If()) {
1755         IfNode* iff = n_dom-&gt;as_If();
1756         if (iff-&gt;in(1)-&gt;is_Bool()) {
1757           BoolNode* bol = iff-&gt;in(1)-&gt;as_Bool();
1758           if (bol-&gt;in(1)-&gt;is_Cmp()) {
1759             // If condition is invariant and not a loop exit,
1760             // then found reason to unswitch.
1761             if (is_heap_stable_test(iff) &amp;&amp;
1762                 (loop_has_sfpts == -1 || loop_has_sfpts == 0)) {
1763               assert(!loop-&gt;is_loop_exit(iff), &quot;both branches should be in the loop&quot;);
1764               if (loop_has_sfpts == -1) {
1765                 for(uint i = 0; i &lt; loop-&gt;_body.size(); i++) {
1766                   Node *m = loop-&gt;_body[i];
1767                   if (m-&gt;is_SafePoint() &amp;&amp; !m-&gt;is_CallLeaf()) {
1768                     loop_has_sfpts = 1;
1769                     break;
1770                   }
1771                 }
1772                 if (loop_has_sfpts == -1) {
1773                   loop_has_sfpts = 0;
1774                 }
1775               }
1776               if (!loop_has_sfpts) {
1777                 unswitch_iff = iff;
1778               }
1779             }
1780           }
1781         }
1782       }
1783     }
1784     n = n_dom;
1785   }
1786   return unswitch_iff;
1787 }
1788 
1789 
1790 void ShenandoahBarrierC2Support::optimize_after_expansion(VectorSet &amp;visited, Node_Stack &amp;stack, Node_List &amp;old_new, PhaseIdealLoop* phase) {
1791   Node_List heap_stable_tests;
1792   stack.push(phase-&gt;C-&gt;start(), 0);
1793   do {
1794     Node* n = stack.node();
1795     uint i = stack.index();
1796 
1797     if (i &lt; n-&gt;outcnt()) {
1798       Node* u = n-&gt;raw_out(i);
1799       stack.set_index(i+1);
1800       if (!visited.test_set(u-&gt;_idx)) {
1801         stack.push(u, 0);
1802       }
1803     } else {
1804       stack.pop();
1805       if (n-&gt;is_If() &amp;&amp; is_heap_stable_test(n)) {
1806         heap_stable_tests.push(n);
1807       }
1808     }
1809   } while (stack.size() &gt; 0);
1810 
1811   for (uint i = 0; i &lt; heap_stable_tests.size(); i++) {
1812     Node* n = heap_stable_tests.at(i);
1813     assert(is_heap_stable_test(n), &quot;only evacuation test&quot;);
1814     merge_back_to_back_tests(n, phase);
1815   }
1816 
1817   if (!phase-&gt;C-&gt;major_progress()) {
1818     VectorSet seen(Thread::current()-&gt;resource_area());
1819     for (uint i = 0; i &lt; heap_stable_tests.size(); i++) {
1820       Node* n = heap_stable_tests.at(i);
1821       IdealLoopTree* loop = phase-&gt;get_loop(n);
1822       if (loop != phase-&gt;ltree_root() &amp;&amp;
1823           loop-&gt;_child == NULL &amp;&amp;
1824           !loop-&gt;_irreducible) {
1825         Node* head = loop-&gt;_head;
1826         if (head-&gt;is_Loop() &amp;&amp;
1827             (!head-&gt;is_CountedLoop() || head-&gt;as_CountedLoop()-&gt;is_main_loop() || head-&gt;as_CountedLoop()-&gt;is_normal_loop()) &amp;&amp;
1828             !seen.test_set(head-&gt;_idx)) {
1829           IfNode* iff = find_unswitching_candidate(loop, phase);
1830           if (iff != NULL) {
1831             Node* bol = iff-&gt;in(1);
1832             if (head-&gt;as_Loop()-&gt;is_strip_mined()) {
1833               head-&gt;as_Loop()-&gt;verify_strip_mined(0);
1834             }
1835             move_gc_state_test_out_of_loop(iff, phase);
1836 
1837             AutoNodeBudget node_budget(phase);
1838 
1839             if (loop-&gt;policy_unswitching(phase)) {
1840               if (head-&gt;as_Loop()-&gt;is_strip_mined()) {
1841                 OuterStripMinedLoopNode* outer = head-&gt;as_CountedLoop()-&gt;outer_loop();
1842                 hide_strip_mined_loop(outer, head-&gt;as_CountedLoop(), phase);
1843               }
1844               phase-&gt;do_unswitching(loop, old_new);
1845             } else {
1846               // Not proceeding with unswitching. Move load back in
1847               // the loop.
1848               phase-&gt;igvn().replace_input_of(iff, 1, bol);
1849             }
1850           }
1851         }
1852       }
1853     }
1854   }
1855 }
1856 
1857 #ifdef ASSERT
1858 void ShenandoahBarrierC2Support::verify_raw_mem(RootNode* root) {
1859   const bool trace = false;
1860   ResourceMark rm;
1861   Unique_Node_List nodes;
1862   Unique_Node_List controls;
1863   Unique_Node_List memories;
1864 
1865   nodes.push(root);
1866   for (uint next = 0; next &lt; nodes.size(); next++) {
1867     Node *n  = nodes.at(next);
1868     if (ShenandoahBarrierSetC2::is_shenandoah_lrb_call(n)) {
1869       controls.push(n);
1870       if (trace) { tty-&gt;print(&quot;XXXXXX verifying&quot;); n-&gt;dump(); }
1871       for (uint next2 = 0; next2 &lt; controls.size(); next2++) {
1872         Node *m = controls.at(next2);
1873         for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
1874           Node* u = m-&gt;fast_out(i);
1875           if (u-&gt;is_CFG() &amp;&amp; !u-&gt;is_Root() &amp;&amp;
1876               !(u-&gt;Opcode() == Op_CProj &amp;&amp; u-&gt;in(0)-&gt;Opcode() == Op_NeverBranch &amp;&amp; u-&gt;as_Proj()-&gt;_con == 1) &amp;&amp;
1877               !(u-&gt;is_Region() &amp;&amp; u-&gt;unique_ctrl_out()-&gt;Opcode() == Op_Halt)) {
1878             if (trace) { tty-&gt;print(&quot;XXXXXX pushing control&quot;); u-&gt;dump(); }
1879             controls.push(u);
1880           }
1881         }
1882       }
1883       memories.push(n-&gt;as_Call()-&gt;proj_out(TypeFunc::Memory));
1884       for (uint next2 = 0; next2 &lt; memories.size(); next2++) {
1885         Node *m = memories.at(next2);
1886         assert(m-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
1887         for (DUIterator_Fast imax, i = m-&gt;fast_outs(imax); i &lt; imax; i++) {
1888           Node* u = m-&gt;fast_out(i);
1889           if (u-&gt;bottom_type() == Type::MEMORY &amp;&amp; (u-&gt;is_Mem() || u-&gt;is_ClearArray())) {
1890             if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;dump(); }
1891             memories.push(u);
1892           } else if (u-&gt;is_LoadStore()) {
1893             if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;find_out_with(Op_SCMemProj)-&gt;dump(); }
1894             memories.push(u-&gt;find_out_with(Op_SCMemProj));
1895           } else if (u-&gt;is_MergeMem() &amp;&amp; u-&gt;as_MergeMem()-&gt;memory_at(Compile::AliasIdxRaw) == m) {
1896             if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;dump(); }
1897             memories.push(u);
1898           } else if (u-&gt;is_Phi()) {
1899             assert(u-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
1900             if (u-&gt;adr_type() == TypeRawPtr::BOTTOM || u-&gt;adr_type() == TypePtr::BOTTOM) {
1901               assert(controls.member(u-&gt;in(0)), &quot;&quot;);
1902               if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); u-&gt;dump(); }
1903               memories.push(u);
1904             }
1905           } else if (u-&gt;is_SafePoint() || u-&gt;is_MemBar()) {
1906             for (DUIterator_Fast jmax, j = u-&gt;fast_outs(jmax); j &lt; jmax; j++) {
1907               Node* uu = u-&gt;fast_out(j);
1908               if (uu-&gt;bottom_type() == Type::MEMORY) {
1909                 if (trace) { tty-&gt;print(&quot;XXXXXX pushing memory&quot;); uu-&gt;dump(); }
1910                 memories.push(uu);
1911               }
1912             }
1913           }
1914         }
1915       }
1916       for (uint next2 = 0; next2 &lt; controls.size(); next2++) {
1917         Node *m = controls.at(next2);
1918         if (m-&gt;is_Region()) {
1919           bool all_in = true;
1920           for (uint i = 1; i &lt; m-&gt;req(); i++) {
1921             if (!controls.member(m-&gt;in(i))) {
1922               all_in = false;
1923               break;
1924             }
1925           }
1926           if (trace) { tty-&gt;print(&quot;XXX verifying %s&quot;, all_in ? &quot;all in&quot; : &quot;&quot;); m-&gt;dump(); }
1927           bool found_phi = false;
1928           for (DUIterator_Fast jmax, j = m-&gt;fast_outs(jmax); j &lt; jmax &amp;&amp; !found_phi; j++) {
1929             Node* u = m-&gt;fast_out(j);
1930             if (u-&gt;is_Phi() &amp;&amp; memories.member(u)) {
1931               found_phi = true;
1932               for (uint i = 1; i &lt; u-&gt;req() &amp;&amp; found_phi; i++) {
1933                 Node* k = u-&gt;in(i);
1934                 if (memories.member(k) != controls.member(m-&gt;in(i))) {
1935                   found_phi = false;
1936                 }
1937               }
1938             }
1939           }
1940           assert(found_phi || all_in, &quot;&quot;);
1941         }
1942       }
1943       controls.clear();
1944       memories.clear();
1945     }
1946     for( uint i = 0; i &lt; n-&gt;len(); ++i ) {
1947       Node *m = n-&gt;in(i);
1948       if (m != NULL) {
1949         nodes.push(m);
1950       }
1951     }
1952   }
1953 }
1954 #endif
1955 
1956 ShenandoahEnqueueBarrierNode::ShenandoahEnqueueBarrierNode(Node* val) : Node(NULL, val) {
1957   ShenandoahBarrierSetC2::bsc2()-&gt;state()-&gt;add_enqueue_barrier(this);
1958 }
1959 
1960 const Type* ShenandoahEnqueueBarrierNode::bottom_type() const {
1961   if (in(1) == NULL || in(1)-&gt;is_top()) {
1962     return Type::TOP;
1963   }
1964   const Type* t = in(1)-&gt;bottom_type();
1965   if (t == TypePtr::NULL_PTR) {
1966     return t;
1967   }
1968   return t-&gt;is_oopptr();
1969 }
1970 
1971 const Type* ShenandoahEnqueueBarrierNode::Value(PhaseGVN* phase) const {
1972   if (in(1) == NULL) {
1973     return Type::TOP;
1974   }
1975   const Type* t = phase-&gt;type(in(1));
1976   if (t == Type::TOP) {
1977     return Type::TOP;
1978   }
1979   if (t == TypePtr::NULL_PTR) {
1980     return t;
1981   }
1982   return t-&gt;is_oopptr();
1983 }
1984 
1985 int ShenandoahEnqueueBarrierNode::needed(Node* n) {
1986   if (n == NULL ||
1987       n-&gt;is_Allocate() ||
1988       n-&gt;Opcode() == Op_ShenandoahEnqueueBarrier ||
1989       n-&gt;bottom_type() == TypePtr::NULL_PTR ||
1990       (n-&gt;bottom_type()-&gt;make_oopptr() != NULL &amp;&amp; n-&gt;bottom_type()-&gt;make_oopptr()-&gt;const_oop() != NULL)) {
1991     return NotNeeded;
1992   }
1993   if (n-&gt;is_Phi() ||
1994       n-&gt;is_CMove()) {
1995     return MaybeNeeded;
1996   }
1997   return Needed;
1998 }
1999 
2000 Node* ShenandoahEnqueueBarrierNode::next(Node* n) {
2001   for (;;) {
2002     if (n == NULL) {
2003       return n;
2004     } else if (n-&gt;bottom_type() == TypePtr::NULL_PTR) {
2005       return n;
2006     } else if (n-&gt;bottom_type()-&gt;make_oopptr() != NULL &amp;&amp; n-&gt;bottom_type()-&gt;make_oopptr()-&gt;const_oop() != NULL) {
2007       return n;
2008     } else if (n-&gt;is_ConstraintCast() ||
2009                n-&gt;Opcode() == Op_DecodeN ||
2010                n-&gt;Opcode() == Op_EncodeP) {
2011       n = n-&gt;in(1);
2012     } else if (n-&gt;is_Proj()) {
2013       n = n-&gt;in(0);
2014     } else {
2015       return n;
2016     }
2017   }
2018   ShouldNotReachHere();
2019   return NULL;
2020 }
2021 
2022 Node* ShenandoahEnqueueBarrierNode::Identity(PhaseGVN* phase) {
2023   PhaseIterGVN* igvn = phase-&gt;is_IterGVN();
2024 
2025   Node* n = next(in(1));
2026 
2027   int cont = needed(n);
2028 
2029   if (cont == NotNeeded) {
2030     return in(1);
2031   } else if (cont == MaybeNeeded) {
2032     if (igvn == NULL) {
2033       phase-&gt;record_for_igvn(this);
2034       return this;
2035     } else {
2036       ResourceMark rm;
2037       Unique_Node_List wq;
2038       uint wq_i = 0;
2039 
2040       for (;;) {
2041         if (n-&gt;is_Phi()) {
2042           for (uint i = 1; i &lt; n-&gt;req(); i++) {
2043             Node* m = n-&gt;in(i);
2044             if (m != NULL) {
2045               wq.push(m);
2046             }
2047           }
2048         } else {
2049           assert(n-&gt;is_CMove(), &quot;nothing else here&quot;);
2050           Node* m = n-&gt;in(CMoveNode::IfFalse);
2051           wq.push(m);
2052           m = n-&gt;in(CMoveNode::IfTrue);
2053           wq.push(m);
2054         }
2055         Node* orig_n = NULL;
2056         do {
2057           if (wq_i &gt;= wq.size()) {
2058             return in(1);
2059           }
2060           n = wq.at(wq_i);
2061           wq_i++;
2062           orig_n = n;
2063           n = next(n);
2064           cont = needed(n);
2065           if (cont == Needed) {
2066             return this;
2067           }
2068         } while (cont != MaybeNeeded || (orig_n != n &amp;&amp; wq.member(n)));
2069       }
2070     }
2071   }
2072 
2073   return this;
2074 }
2075 
2076 #ifdef ASSERT
2077 static bool has_never_branch(Node* root) {
2078   for (uint i = 1; i &lt; root-&gt;req(); i++) {
2079     Node* in = root-&gt;in(i);
2080     if (in != NULL &amp;&amp; in-&gt;Opcode() == Op_Halt &amp;&amp; in-&gt;in(0)-&gt;is_Proj() &amp;&amp; in-&gt;in(0)-&gt;in(0)-&gt;Opcode() == Op_NeverBranch) {
2081       return true;
2082     }
2083   }
2084   return false;
2085 }
2086 #endif
2087 
2088 void MemoryGraphFixer::collect_memory_nodes() {
2089   Node_Stack stack(0);
2090   VectorSet visited(Thread::current()-&gt;resource_area());
2091   Node_List regions;
2092 
2093   // Walk the raw memory graph and create a mapping from CFG node to
2094   // memory node. Exclude phis for now.
2095   stack.push(_phase-&gt;C-&gt;root(), 1);
2096   do {
2097     Node* n = stack.node();
2098     int opc = n-&gt;Opcode();
2099     uint i = stack.index();
2100     if (i &lt; n-&gt;req()) {
2101       Node* mem = NULL;
2102       if (opc == Op_Root) {
2103         Node* in = n-&gt;in(i);
2104         int in_opc = in-&gt;Opcode();
2105         if (in_opc == Op_Return || in_opc == Op_Rethrow) {
2106           mem = in-&gt;in(TypeFunc::Memory);
2107         } else if (in_opc == Op_Halt) {
2108           if (in-&gt;in(0)-&gt;is_Region()) {
2109             Node* r = in-&gt;in(0);
2110             for (uint j = 1; j &lt; r-&gt;req(); j++) {
2111               assert(r-&gt;in(j)-&gt;Opcode() != Op_NeverBranch, &quot;&quot;);
2112             }
2113           } else {
2114             Node* proj = in-&gt;in(0);
2115             assert(proj-&gt;is_Proj(), &quot;&quot;);
2116             Node* in = proj-&gt;in(0);
2117             assert(in-&gt;is_CallStaticJava() || in-&gt;Opcode() == Op_NeverBranch || in-&gt;Opcode() == Op_Catch || proj-&gt;is_IfProj(), &quot;&quot;);
2118             if (in-&gt;is_CallStaticJava()) {
2119               mem = in-&gt;in(TypeFunc::Memory);
2120             } else if (in-&gt;Opcode() == Op_Catch) {
2121               Node* call = in-&gt;in(0)-&gt;in(0);
2122               assert(call-&gt;is_Call(), &quot;&quot;);
2123               mem = call-&gt;in(TypeFunc::Memory);
2124             } else if (in-&gt;Opcode() == Op_NeverBranch) {
2125               Node* head = in-&gt;in(0);
2126               assert(head-&gt;is_Region(), &quot;unexpected infinite loop graph shape&quot;);
2127 
2128               Node* phi_mem = NULL;
2129               for (DUIterator_Fast jmax, j = head-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2130                 Node* u = head-&gt;fast_out(j);
2131                 if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY) {
2132                   if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias) {
2133                     assert(phi_mem == NULL || phi_mem-&gt;adr_type() == TypePtr::BOTTOM, &quot;&quot;);
2134                     phi_mem = u;
2135                   } else if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2136                     assert(phi_mem == NULL || _phase-&gt;C-&gt;get_alias_index(phi_mem-&gt;adr_type()) == _alias, &quot;&quot;);
2137                     if (phi_mem == NULL) {
2138                       phi_mem = u;
2139                     }
2140                   }
2141                 }
2142               }
2143               if (phi_mem == NULL) {
2144                 for (uint j = 1; j &lt; head-&gt;req(); j++) {
2145                   Node* tail = head-&gt;in(j);
2146                   if (!_phase-&gt;is_dominator(head, tail)) {
2147                     continue;
2148                   }
2149                   Node* c = tail;
2150                   while (c != head) {
2151                     if (c-&gt;is_SafePoint() &amp;&amp; !c-&gt;is_CallLeaf()) {
2152                       Node* m =c-&gt;in(TypeFunc::Memory);
2153                       if (m-&gt;is_MergeMem()) {
2154                         m = m-&gt;as_MergeMem()-&gt;memory_at(_alias);
2155                       }
2156                       assert(mem == NULL || mem == m, &quot;several memory states&quot;);
2157                       mem = m;
2158                     }
2159                     c = _phase-&gt;idom(c);
2160                   }
2161                   assert(mem != NULL, &quot;should have found safepoint&quot;);
2162                 }
2163                 assert(mem != NULL, &quot;should have found safepoint&quot;);
2164               } else {
2165                 mem = phi_mem;
2166               }
2167             }
2168           }
2169         } else {
2170 #ifdef ASSERT
2171           n-&gt;dump();
2172           in-&gt;dump();
2173 #endif
2174           ShouldNotReachHere();
2175         }
2176       } else {
2177         assert(n-&gt;is_Phi() &amp;&amp; n-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2178         assert(n-&gt;adr_type() == TypePtr::BOTTOM || _phase-&gt;C-&gt;get_alias_index(n-&gt;adr_type()) == _alias, &quot;&quot;);
2179         mem = n-&gt;in(i);
2180       }
2181       i++;
2182       stack.set_index(i);
2183       if (mem == NULL) {
2184         continue;
2185       }
2186       for (;;) {
2187         if (visited.test_set(mem-&gt;_idx) || mem-&gt;is_Start()) {
2188           break;
2189         }
2190         if (mem-&gt;is_Phi()) {
2191           stack.push(mem, 2);
2192           mem = mem-&gt;in(1);
2193         } else if (mem-&gt;is_Proj()) {
2194           stack.push(mem, mem-&gt;req());
2195           mem = mem-&gt;in(0);
2196         } else if (mem-&gt;is_SafePoint() || mem-&gt;is_MemBar()) {
2197           mem = mem-&gt;in(TypeFunc::Memory);
2198         } else if (mem-&gt;is_MergeMem()) {
2199           MergeMemNode* mm = mem-&gt;as_MergeMem();
2200           mem = mm-&gt;memory_at(_alias);
2201         } else if (mem-&gt;is_Store() || mem-&gt;is_LoadStore() || mem-&gt;is_ClearArray()) {
2202           assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2203           stack.push(mem, mem-&gt;req());
2204           mem = mem-&gt;in(MemNode::Memory);
2205         } else {
2206 #ifdef ASSERT
2207           mem-&gt;dump();
2208 #endif
2209           ShouldNotReachHere();
2210         }
2211       }
2212     } else {
2213       if (n-&gt;is_Phi()) {
2214         // Nothing
2215       } else if (!n-&gt;is_Root()) {
2216         Node* c = get_ctrl(n);
2217         _memory_nodes.map(c-&gt;_idx, n);
2218       }
2219       stack.pop();
2220     }
2221   } while(stack.is_nonempty());
2222 
2223   // Iterate over CFG nodes in rpo and propagate memory state to
2224   // compute memory state at regions, creating new phis if needed.
2225   Node_List rpo_list;
2226   visited.clear();
2227   _phase-&gt;rpo(_phase-&gt;C-&gt;root(), stack, visited, rpo_list);
2228   Node* root = rpo_list.pop();
2229   assert(root == _phase-&gt;C-&gt;root(), &quot;&quot;);
2230 
2231   const bool trace = false;
2232 #ifdef ASSERT
2233   if (trace) {
2234     for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2235       Node* c = rpo_list.at(i);
2236       if (_memory_nodes[c-&gt;_idx] != NULL) {
2237         tty-&gt;print(&quot;X %d&quot;, c-&gt;_idx);  _memory_nodes[c-&gt;_idx]-&gt;dump();
2238       }
2239     }
2240   }
2241 #endif
2242   uint last = _phase-&gt;C-&gt;unique();
2243 
2244 #ifdef ASSERT
2245   uint8_t max_depth = 0;
2246   for (LoopTreeIterator iter(_phase-&gt;ltree_root()); !iter.done(); iter.next()) {
2247     IdealLoopTree* lpt = iter.current();
2248     max_depth = MAX2(max_depth, lpt-&gt;_nest);
2249   }
2250 #endif
2251 
2252   bool progress = true;
2253   int iteration = 0;
2254   Node_List dead_phis;
2255   while (progress) {
2256     progress = false;
2257     iteration++;
2258     assert(iteration &lt;= 2+max_depth || _phase-&gt;C-&gt;has_irreducible_loop() || has_never_branch(_phase-&gt;C-&gt;root()), &quot;&quot;);
2259     if (trace) { tty-&gt;print_cr(&quot;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;); }
2260 
2261     for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2262       Node* c = rpo_list.at(i);
2263 
2264       Node* prev_mem = _memory_nodes[c-&gt;_idx];
2265       if (c-&gt;is_Region() &amp;&amp; (_include_lsm || !c-&gt;is_OuterStripMinedLoop())) {
2266         Node* prev_region = regions[c-&gt;_idx];
2267         Node* unique = NULL;
2268         for (uint j = 1; j &lt; c-&gt;req() &amp;&amp; unique != NodeSentinel; j++) {
2269           Node* m = _memory_nodes[c-&gt;in(j)-&gt;_idx];
2270           assert(m != NULL || (c-&gt;is_Loop() &amp;&amp; j == LoopNode::LoopBackControl &amp;&amp; iteration == 1) || _phase-&gt;C-&gt;has_irreducible_loop() || has_never_branch(_phase-&gt;C-&gt;root()), &quot;expect memory state&quot;);
2271           if (m != NULL) {
2272             if (m == prev_region &amp;&amp; ((c-&gt;is_Loop() &amp;&amp; j == LoopNode::LoopBackControl) || (prev_region-&gt;is_Phi() &amp;&amp; prev_region-&gt;in(0) == c))) {
2273               assert(c-&gt;is_Loop() &amp;&amp; j == LoopNode::LoopBackControl || _phase-&gt;C-&gt;has_irreducible_loop() || has_never_branch(_phase-&gt;C-&gt;root()), &quot;&quot;);
2274               // continue
2275             } else if (unique == NULL) {
2276               unique = m;
2277             } else if (m == unique) {
2278               // continue
2279             } else {
2280               unique = NodeSentinel;
2281             }
2282           }
2283         }
2284         assert(unique != NULL, &quot;empty phi???&quot;);
2285         if (unique != NodeSentinel) {
2286           if (prev_region != NULL &amp;&amp; prev_region-&gt;is_Phi() &amp;&amp; prev_region-&gt;in(0) == c) {
2287             dead_phis.push(prev_region);
2288           }
2289           regions.map(c-&gt;_idx, unique);
2290         } else {
2291           Node* phi = NULL;
2292           if (prev_region != NULL &amp;&amp; prev_region-&gt;is_Phi() &amp;&amp; prev_region-&gt;in(0) == c &amp;&amp; prev_region-&gt;_idx &gt;= last) {
2293             phi = prev_region;
2294             for (uint k = 1; k &lt; c-&gt;req(); k++) {
2295               Node* m = _memory_nodes[c-&gt;in(k)-&gt;_idx];
2296               assert(m != NULL, &quot;expect memory state&quot;);
2297               phi-&gt;set_req(k, m);
2298             }
2299           } else {
2300             for (DUIterator_Fast jmax, j = c-&gt;fast_outs(jmax); j &lt; jmax &amp;&amp; phi == NULL; j++) {
2301               Node* u = c-&gt;fast_out(j);
2302               if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY &amp;&amp;
2303                   (u-&gt;adr_type() == TypePtr::BOTTOM || _phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias)) {
2304                 phi = u;
2305                 for (uint k = 1; k &lt; c-&gt;req() &amp;&amp; phi != NULL; k++) {
2306                   Node* m = _memory_nodes[c-&gt;in(k)-&gt;_idx];
2307                   assert(m != NULL, &quot;expect memory state&quot;);
2308                   if (u-&gt;in(k) != m) {
2309                     phi = NULL;
2310                   }
2311                 }
2312               }
2313             }
2314             if (phi == NULL) {
2315               phi = new PhiNode(c, Type::MEMORY, _phase-&gt;C-&gt;get_adr_type(_alias));
2316               for (uint k = 1; k &lt; c-&gt;req(); k++) {
2317                 Node* m = _memory_nodes[c-&gt;in(k)-&gt;_idx];
2318                 assert(m != NULL, &quot;expect memory state&quot;);
2319                 phi-&gt;init_req(k, m);
2320               }
2321             }
2322           }
2323           assert(phi != NULL, &quot;&quot;);
2324           regions.map(c-&gt;_idx, phi);
2325         }
2326         Node* current_region = regions[c-&gt;_idx];
2327         if (current_region != prev_region) {
2328           progress = true;
2329           if (prev_region == prev_mem) {
2330             _memory_nodes.map(c-&gt;_idx, current_region);
2331           }
2332         }
2333       } else if (prev_mem == NULL || prev_mem-&gt;is_Phi() || ctrl_or_self(prev_mem) != c) {
2334         Node* m = _memory_nodes[_phase-&gt;idom(c)-&gt;_idx];
2335         assert(m != NULL, &quot;expect memory state&quot;);
2336         if (m != prev_mem) {
2337           _memory_nodes.map(c-&gt;_idx, m);
2338           progress = true;
2339         }
2340       }
2341 #ifdef ASSERT
2342       if (trace) { tty-&gt;print(&quot;X %d&quot;, c-&gt;_idx);  _memory_nodes[c-&gt;_idx]-&gt;dump(); }
2343 #endif
2344     }
2345   }
2346 
2347   // Replace existing phi with computed memory state for that region
2348   // if different (could be a new phi or a dominating memory node if
2349   // that phi was found to be useless).
2350   while (dead_phis.size() &gt; 0) {
2351     Node* n = dead_phis.pop();
2352     n-&gt;replace_by(_phase-&gt;C-&gt;top());
2353     n-&gt;destruct();
2354   }
2355   for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2356     Node* c = rpo_list.at(i);
2357     if (c-&gt;is_Region() &amp;&amp; (_include_lsm || !c-&gt;is_OuterStripMinedLoop())) {
2358       Node* n = regions[c-&gt;_idx];
2359       if (n-&gt;is_Phi() &amp;&amp; n-&gt;_idx &gt;= last &amp;&amp; n-&gt;in(0) == c) {
2360         _phase-&gt;register_new_node(n, c);
2361       }
2362     }
2363   }
2364   for (int i = rpo_list.size() - 1; i &gt;= 0; i--) {
2365     Node* c = rpo_list.at(i);
2366     if (c-&gt;is_Region() &amp;&amp; (_include_lsm || !c-&gt;is_OuterStripMinedLoop())) {
2367       Node* n = regions[c-&gt;_idx];
2368       for (DUIterator_Fast imax, i = c-&gt;fast_outs(imax); i &lt; imax; i++) {
2369         Node* u = c-&gt;fast_out(i);
2370         if (u-&gt;is_Phi() &amp;&amp; u-&gt;bottom_type() == Type::MEMORY &amp;&amp;
2371             u != n) {
2372           if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2373             fix_memory_uses(u, n, n, c);
2374           } else if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias) {
2375             _phase-&gt;lazy_replace(u, n);
2376             --i; --imax;
2377           }
2378         }
2379       }
2380     }
2381   }
2382 }
2383 
2384 Node* MemoryGraphFixer::get_ctrl(Node* n) const {
2385   Node* c = _phase-&gt;get_ctrl(n);
2386   if (n-&gt;is_Proj() &amp;&amp; n-&gt;in(0) != NULL &amp;&amp; n-&gt;in(0)-&gt;is_Call()) {
2387     assert(c == n-&gt;in(0), &quot;&quot;);
2388     CallNode* call = c-&gt;as_Call();
2389     CallProjections* projs = call-&gt;extract_projections(true, false);
2390     if (projs-&gt;catchall_memproj != NULL) {
2391       if (projs-&gt;fallthrough_memproj == n) {
2392         c = projs-&gt;fallthrough_catchproj;
2393       } else {
2394         assert(projs-&gt;catchall_memproj == n, &quot;&quot;);
2395         c = projs-&gt;catchall_catchproj;
2396       }
2397     }
2398   }
2399   return c;
2400 }
2401 
2402 Node* MemoryGraphFixer::ctrl_or_self(Node* n) const {
2403   if (_phase-&gt;has_ctrl(n))
2404     return get_ctrl(n);
2405   else {
2406     assert (n-&gt;is_CFG(), &quot;must be a CFG node&quot;);
2407     return n;
2408   }
2409 }
2410 
2411 bool MemoryGraphFixer::mem_is_valid(Node* m, Node* c) const {
2412   return m != NULL &amp;&amp; get_ctrl(m) == c;
2413 }
2414 
2415 Node* MemoryGraphFixer::find_mem(Node* ctrl, Node* n) const {
2416   assert(n == NULL || _phase-&gt;ctrl_or_self(n) == ctrl, &quot;&quot;);
2417   Node* mem = _memory_nodes[ctrl-&gt;_idx];
2418   Node* c = ctrl;
2419   while (!mem_is_valid(mem, c) &amp;&amp;
2420          (!c-&gt;is_CatchProj() || mem == NULL || c-&gt;in(0)-&gt;in(0)-&gt;in(0) != get_ctrl(mem))) {
2421     c = _phase-&gt;idom(c);
2422     mem = _memory_nodes[c-&gt;_idx];
2423   }
2424   if (n != NULL &amp;&amp; mem_is_valid(mem, c)) {
2425     while (!ShenandoahBarrierC2Support::is_dominator_same_ctrl(c, mem, n, _phase) &amp;&amp; _phase-&gt;ctrl_or_self(mem) == ctrl) {
2426       mem = next_mem(mem, _alias);
2427     }
2428     if (mem-&gt;is_MergeMem()) {
2429       mem = mem-&gt;as_MergeMem()-&gt;memory_at(_alias);
2430     }
2431     if (!mem_is_valid(mem, c)) {
2432       do {
2433         c = _phase-&gt;idom(c);
2434         mem = _memory_nodes[c-&gt;_idx];
2435       } while (!mem_is_valid(mem, c) &amp;&amp;
2436                (!c-&gt;is_CatchProj() || mem == NULL || c-&gt;in(0)-&gt;in(0)-&gt;in(0) != get_ctrl(mem)));
2437     }
2438   }
2439   assert(mem-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2440   return mem;
2441 }
2442 
2443 bool MemoryGraphFixer::has_mem_phi(Node* region) const {
2444   for (DUIterator_Fast imax, i = region-&gt;fast_outs(imax); i &lt; imax; i++) {
2445     Node* use = region-&gt;fast_out(i);
2446     if (use-&gt;is_Phi() &amp;&amp; use-&gt;bottom_type() == Type::MEMORY &amp;&amp;
2447         (_phase-&gt;C-&gt;get_alias_index(use-&gt;adr_type()) == _alias)) {
2448       return true;
2449     }
2450   }
2451   return false;
2452 }
2453 
2454 void MemoryGraphFixer::fix_mem(Node* ctrl, Node* new_ctrl, Node* mem, Node* mem_for_ctrl, Node* new_mem, Unique_Node_List&amp; uses) {
2455   assert(_phase-&gt;ctrl_or_self(new_mem) == new_ctrl, &quot;&quot;);
2456   const bool trace = false;
2457   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ control is&quot;); ctrl-&gt;dump(); });
2458   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ mem is&quot;); mem-&gt;dump(); });
2459   GrowableArray&lt;Node*&gt; phis;
2460   if (mem_for_ctrl != mem) {
2461     Node* old = mem_for_ctrl;
2462     Node* prev = NULL;
2463     while (old != mem) {
2464       prev = old;
2465       if (old-&gt;is_Store() || old-&gt;is_ClearArray() || old-&gt;is_LoadStore()) {
2466         assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2467         old = old-&gt;in(MemNode::Memory);
2468       } else if (old-&gt;Opcode() == Op_SCMemProj) {
2469         assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2470         old = old-&gt;in(0);
2471       } else {
2472         ShouldNotReachHere();
2473       }
2474     }
2475     assert(prev != NULL, &quot;&quot;);
2476     if (new_ctrl != ctrl) {
2477       _memory_nodes.map(ctrl-&gt;_idx, mem);
2478       _memory_nodes.map(new_ctrl-&gt;_idx, mem_for_ctrl);
2479     }
2480     uint input = (uint)MemNode::Memory;
2481     _phase-&gt;igvn().replace_input_of(prev, input, new_mem);
2482   } else {
2483     uses.clear();
2484     _memory_nodes.map(new_ctrl-&gt;_idx, new_mem);
2485     uses.push(new_ctrl);
2486     for(uint next = 0; next &lt; uses.size(); next++ ) {
2487       Node *n = uses.at(next);
2488       assert(n-&gt;is_CFG(), &quot;&quot;);
2489       DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ ctrl&quot;); n-&gt;dump(); });
2490       for (DUIterator_Fast imax, i = n-&gt;fast_outs(imax); i &lt; imax; i++) {
2491         Node* u = n-&gt;fast_out(i);
2492         if (!u-&gt;is_Root() &amp;&amp; u-&gt;is_CFG() &amp;&amp; u != n) {
2493           Node* m = _memory_nodes[u-&gt;_idx];
2494           if (u-&gt;is_Region() &amp;&amp; (!u-&gt;is_OuterStripMinedLoop() || _include_lsm) &amp;&amp;
2495               !has_mem_phi(u) &amp;&amp;
2496               u-&gt;unique_ctrl_out()-&gt;Opcode() != Op_Halt) {
2497             DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ region&quot;); u-&gt;dump(); });
2498             DEBUG_ONLY(if (trace &amp;&amp; m != NULL) { tty-&gt;print(&quot;ZZZ mem&quot;); m-&gt;dump(); });
2499 
2500             if (!mem_is_valid(m, u) || !m-&gt;is_Phi()) {
2501               bool push = true;
2502               bool create_phi = true;
2503               if (_phase-&gt;is_dominator(new_ctrl, u)) {
2504                 create_phi = false;
2505               }
2506               if (create_phi) {
2507                 Node* phi = new PhiNode(u, Type::MEMORY, _phase-&gt;C-&gt;get_adr_type(_alias));
2508                 _phase-&gt;register_new_node(phi, u);
2509                 phis.push(phi);
2510                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ new phi&quot;); phi-&gt;dump(); });
2511                 if (!mem_is_valid(m, u)) {
2512                   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting mem&quot;); phi-&gt;dump(); });
2513                   _memory_nodes.map(u-&gt;_idx, phi);
2514                 } else {
2515                   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ NOT setting mem&quot;); m-&gt;dump(); });
2516                   for (;;) {
2517                     assert(m-&gt;is_Mem() || m-&gt;is_LoadStore() || m-&gt;is_Proj(), &quot;&quot;);
2518                     Node* next = NULL;
2519                     if (m-&gt;is_Proj()) {
2520                       next = m-&gt;in(0);
2521                     } else {
2522                       assert(m-&gt;is_Mem() || m-&gt;is_LoadStore(), &quot;&quot;);
2523                       assert(_alias == Compile::AliasIdxRaw, &quot;&quot;);
2524                       next = m-&gt;in(MemNode::Memory);
2525                     }
2526                     if (_phase-&gt;get_ctrl(next) != u) {
2527                       break;
2528                     }
2529                     if (next-&gt;is_MergeMem()) {
2530                       assert(_phase-&gt;get_ctrl(next-&gt;as_MergeMem()-&gt;memory_at(_alias)) != u, &quot;&quot;);
2531                       break;
2532                     }
2533                     if (next-&gt;is_Phi()) {
2534                       assert(next-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; next-&gt;in(0) == u, &quot;&quot;);
2535                       break;
2536                     }
2537                     m = next;
2538                   }
2539 
2540                   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting to phi&quot;); m-&gt;dump(); });
2541                   assert(m-&gt;is_Mem() || m-&gt;is_LoadStore(), &quot;&quot;);
2542                   uint input = (uint)MemNode::Memory;
2543                   _phase-&gt;igvn().replace_input_of(m, input, phi);
2544                   push = false;
2545                 }
2546               } else {
2547                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ skipping region&quot;); u-&gt;dump(); });
2548               }
2549               if (push) {
2550                 uses.push(u);
2551               }
2552             }
2553           } else if (!mem_is_valid(m, u) &amp;&amp;
2554                      !(u-&gt;Opcode() == Op_CProj &amp;&amp; u-&gt;in(0)-&gt;Opcode() == Op_NeverBranch &amp;&amp; u-&gt;as_Proj()-&gt;_con == 1)) {
2555             uses.push(u);
2556           }
2557         }
2558       }
2559     }
2560     for (int i = 0; i &lt; phis.length(); i++) {
2561       Node* n = phis.at(i);
2562       Node* r = n-&gt;in(0);
2563       DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ fixing new phi&quot;); n-&gt;dump(); });
2564       for (uint j = 1; j &lt; n-&gt;req(); j++) {
2565         Node* m = find_mem(r-&gt;in(j), NULL);
2566         _phase-&gt;igvn().replace_input_of(n, j, m);
2567         DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ fixing new phi: %d&quot;, j); m-&gt;dump(); });
2568       }
2569     }
2570   }
2571   uint last = _phase-&gt;C-&gt;unique();
2572   MergeMemNode* mm = NULL;
2573   int alias = _alias;
2574   DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ raw mem is&quot;); mem-&gt;dump(); });
2575   // Process loads first to not miss an anti-dependency: if the memory
2576   // edge of a store is updated before a load is processed then an
2577   // anti-dependency may be missed.
2578   for (DUIterator i = mem-&gt;outs(); mem-&gt;has_out(i); i++) {
2579     Node* u = mem-&gt;out(i);
2580     if (u-&gt;_idx &lt; last &amp;&amp; u-&gt;is_Load() &amp;&amp; _phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias) {
2581       Node* m = find_mem(_phase-&gt;get_ctrl(u), u);
2582       if (m != mem) {
2583         DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2584         _phase-&gt;igvn().replace_input_of(u, MemNode::Memory, m);
2585         --i;
2586       }
2587     }
2588   }
2589   for (DUIterator i = mem-&gt;outs(); mem-&gt;has_out(i); i++) {
2590     Node* u = mem-&gt;out(i);
2591     if (u-&gt;_idx &lt; last) {
2592       if (u-&gt;is_Mem()) {
2593         if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias) {
2594           Node* m = find_mem(_phase-&gt;get_ctrl(u), u);
2595           if (m != mem) {
2596             DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2597             _phase-&gt;igvn().replace_input_of(u, MemNode::Memory, m);
2598             --i;
2599           }
2600         }
2601       } else if (u-&gt;is_MergeMem()) {
2602         MergeMemNode* u_mm = u-&gt;as_MergeMem();
2603         if (u_mm-&gt;memory_at(alias) == mem) {
2604           MergeMemNode* newmm = NULL;
2605           for (DUIterator_Fast jmax, j = u-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2606             Node* uu = u-&gt;fast_out(j);
2607             assert(!uu-&gt;is_MergeMem(), &quot;chain of MergeMems?&quot;);
2608             if (uu-&gt;is_Phi()) {
2609               assert(uu-&gt;adr_type() == TypePtr::BOTTOM, &quot;&quot;);
2610               Node* region = uu-&gt;in(0);
2611               int nb = 0;
2612               for (uint k = 1; k &lt; uu-&gt;req(); k++) {
2613                 if (uu-&gt;in(k) == u) {
2614                   Node* m = find_mem(region-&gt;in(k), NULL);
2615                   if (m != mem) {
2616                     DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of phi %d&quot;, k); uu-&gt;dump(); });
2617                     newmm = clone_merge_mem(u, mem, m, _phase-&gt;ctrl_or_self(m), i);
2618                     if (newmm != u) {
2619                       _phase-&gt;igvn().replace_input_of(uu, k, newmm);
2620                       nb++;
2621                       --jmax;
2622                     }
2623                   }
2624                 }
2625               }
2626               if (nb &gt; 0) {
2627                 --j;
2628               }
2629             } else {
2630               Node* m = find_mem(_phase-&gt;ctrl_or_self(uu), uu);
2631               if (m != mem) {
2632                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); uu-&gt;dump(); });
2633                 newmm = clone_merge_mem(u, mem, m, _phase-&gt;ctrl_or_self(m), i);
2634                 if (newmm != u) {
2635                   _phase-&gt;igvn().replace_input_of(uu, uu-&gt;find_edge(u), newmm);
2636                   --j, --jmax;
2637                 }
2638               }
2639             }
2640           }
2641         }
2642       } else if (u-&gt;is_Phi()) {
2643         assert(u-&gt;bottom_type() == Type::MEMORY, &quot;what else?&quot;);
2644         if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias || u-&gt;adr_type() == TypePtr::BOTTOM) {
2645           Node* region = u-&gt;in(0);
2646           bool replaced = false;
2647           for (uint j = 1; j &lt; u-&gt;req(); j++) {
2648             if (u-&gt;in(j) == mem) {
2649               Node* m = find_mem(region-&gt;in(j), NULL);
2650               Node* nnew = m;
2651               if (m != mem) {
2652                 if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2653                   mm = allocate_merge_mem(mem, m, _phase-&gt;ctrl_or_self(m));
2654                   nnew = mm;
2655                 }
2656                 DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of phi %d&quot;, j); u-&gt;dump(); });
2657                 _phase-&gt;igvn().replace_input_of(u, j, nnew);
2658                 replaced = true;
2659               }
2660             }
2661           }
2662           if (replaced) {
2663             --i;
2664           }
2665         }
2666       } else if ((u-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; u-&gt;Opcode() != Op_StrInflatedCopy) ||
2667                  u-&gt;adr_type() == NULL) {
2668         assert(u-&gt;adr_type() != NULL ||
2669                u-&gt;Opcode() == Op_Rethrow ||
2670                u-&gt;Opcode() == Op_Return ||
2671                u-&gt;Opcode() == Op_SafePoint ||
2672                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0) ||
2673                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;_entry_point == OptoRuntime::rethrow_stub()) ||
2674                u-&gt;Opcode() == Op_CallLeaf, &quot;&quot;);
2675         Node* m = find_mem(_phase-&gt;ctrl_or_self(u), u);
2676         if (m != mem) {
2677           mm = allocate_merge_mem(mem, m, _phase-&gt;get_ctrl(m));
2678           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), mm);
2679           --i;
2680         }
2681       } else if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == alias) {
2682         Node* m = find_mem(_phase-&gt;ctrl_or_self(u), u);
2683         if (m != mem) {
2684           DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2685           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), m);
2686           --i;
2687         }
2688       } else if (u-&gt;adr_type() != TypePtr::BOTTOM &amp;&amp;
2689                  _memory_nodes[_phase-&gt;ctrl_or_self(u)-&gt;_idx] == u) {
2690         Node* m = find_mem(_phase-&gt;ctrl_or_self(u), u);
2691         assert(m != mem, &quot;&quot;);
2692         // u is on the wrong slice...
2693         assert(u-&gt;is_ClearArray(), &quot;&quot;);
2694         DEBUG_ONLY(if (trace) { tty-&gt;print(&quot;ZZZ setting memory of use&quot;); u-&gt;dump(); });
2695         _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), m);
2696         --i;
2697       }
2698     }
2699   }
2700 #ifdef ASSERT
2701   assert(new_mem-&gt;outcnt() &gt; 0, &quot;&quot;);
2702   for (int i = 0; i &lt; phis.length(); i++) {
2703     Node* n = phis.at(i);
2704     assert(n-&gt;outcnt() &gt; 0, &quot;new phi must have uses now&quot;);
2705   }
2706 #endif
2707 }
2708 
2709 MergeMemNode* MemoryGraphFixer::allocate_merge_mem(Node* mem, Node* rep_proj, Node* rep_ctrl) const {
2710   MergeMemNode* mm = MergeMemNode::make(mem);
2711   mm-&gt;set_memory_at(_alias, rep_proj);
2712   _phase-&gt;register_new_node(mm, rep_ctrl);
2713   return mm;
2714 }
2715 
2716 MergeMemNode* MemoryGraphFixer::clone_merge_mem(Node* u, Node* mem, Node* rep_proj, Node* rep_ctrl, DUIterator&amp; i) const {
2717   MergeMemNode* newmm = NULL;
2718   MergeMemNode* u_mm = u-&gt;as_MergeMem();
2719   Node* c = _phase-&gt;get_ctrl(u);
2720   if (_phase-&gt;is_dominator(c, rep_ctrl)) {
2721     c = rep_ctrl;
2722   } else {
2723     assert(_phase-&gt;is_dominator(rep_ctrl, c), &quot;one must dominate the other&quot;);
2724   }
2725   if (u-&gt;outcnt() == 1) {
2726     if (u-&gt;req() &gt; (uint)_alias &amp;&amp; u-&gt;in(_alias) == mem) {
2727       _phase-&gt;igvn().replace_input_of(u, _alias, rep_proj);
2728       --i;
2729     } else {
2730       _phase-&gt;igvn().rehash_node_delayed(u);
2731       u_mm-&gt;set_memory_at(_alias, rep_proj);
2732     }
2733     newmm = u_mm;
2734     _phase-&gt;set_ctrl_and_loop(u, c);
2735   } else {
2736     // can&#39;t simply clone u and then change one of its input because
2737     // it adds and then removes an edge which messes with the
2738     // DUIterator
2739     newmm = MergeMemNode::make(u_mm-&gt;base_memory());
2740     for (uint j = 0; j &lt; u-&gt;req(); j++) {
2741       if (j &lt; newmm-&gt;req()) {
2742         if (j == (uint)_alias) {
2743           newmm-&gt;set_req(j, rep_proj);
2744         } else if (newmm-&gt;in(j) != u-&gt;in(j)) {
2745           newmm-&gt;set_req(j, u-&gt;in(j));
2746         }
2747       } else if (j == (uint)_alias) {
2748         newmm-&gt;add_req(rep_proj);
2749       } else {
2750         newmm-&gt;add_req(u-&gt;in(j));
2751       }
2752     }
2753     if ((uint)_alias &gt;= u-&gt;req()) {
2754       newmm-&gt;set_memory_at(_alias, rep_proj);
2755     }
2756     _phase-&gt;register_new_node(newmm, c);
2757   }
2758   return newmm;
2759 }
2760 
2761 bool MemoryGraphFixer::should_process_phi(Node* phi) const {
2762   if (phi-&gt;adr_type() == TypePtr::BOTTOM) {
2763     Node* region = phi-&gt;in(0);
2764     for (DUIterator_Fast jmax, j = region-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2765       Node* uu = region-&gt;fast_out(j);
2766       if (uu-&gt;is_Phi() &amp;&amp; uu != phi &amp;&amp; uu-&gt;bottom_type() == Type::MEMORY &amp;&amp; _phase-&gt;C-&gt;get_alias_index(uu-&gt;adr_type()) == _alias) {
2767         return false;
2768       }
2769     }
2770     return true;
2771   }
2772   return _phase-&gt;C-&gt;get_alias_index(phi-&gt;adr_type()) == _alias;
2773 }
2774 
2775 void MemoryGraphFixer::fix_memory_uses(Node* mem, Node* replacement, Node* rep_proj, Node* rep_ctrl) const {
2776   uint last = _phase-&gt; C-&gt;unique();
2777   MergeMemNode* mm = NULL;
2778   assert(mem-&gt;bottom_type() == Type::MEMORY, &quot;&quot;);
2779   for (DUIterator i = mem-&gt;outs(); mem-&gt;has_out(i); i++) {
2780     Node* u = mem-&gt;out(i);
2781     if (u != replacement &amp;&amp; u-&gt;_idx &lt; last) {
2782       if (u-&gt;is_MergeMem()) {
2783         MergeMemNode* u_mm = u-&gt;as_MergeMem();
2784         if (u_mm-&gt;memory_at(_alias) == mem) {
2785           MergeMemNode* newmm = NULL;
2786           for (DUIterator_Fast jmax, j = u-&gt;fast_outs(jmax); j &lt; jmax; j++) {
2787             Node* uu = u-&gt;fast_out(j);
2788             assert(!uu-&gt;is_MergeMem(), &quot;chain of MergeMems?&quot;);
2789             if (uu-&gt;is_Phi()) {
2790               if (should_process_phi(uu)) {
2791                 Node* region = uu-&gt;in(0);
2792                 int nb = 0;
2793                 for (uint k = 1; k &lt; uu-&gt;req(); k++) {
2794                   if (uu-&gt;in(k) == u &amp;&amp; _phase-&gt;is_dominator(rep_ctrl, region-&gt;in(k))) {
2795                     if (newmm == NULL) {
2796                       newmm = clone_merge_mem(u, mem, rep_proj, rep_ctrl, i);
2797                     }
2798                     if (newmm != u) {
2799                       _phase-&gt;igvn().replace_input_of(uu, k, newmm);
2800                       nb++;
2801                       --jmax;
2802                     }
2803                   }
2804                 }
2805                 if (nb &gt; 0) {
2806                   --j;
2807                 }
2808               }
2809             } else {
2810               if (rep_ctrl != uu &amp;&amp; ShenandoahBarrierC2Support::is_dominator(rep_ctrl, _phase-&gt;ctrl_or_self(uu), replacement, uu, _phase)) {
2811                 if (newmm == NULL) {
2812                   newmm = clone_merge_mem(u, mem, rep_proj, rep_ctrl, i);
2813                 }
2814                 if (newmm != u) {
2815                   _phase-&gt;igvn().replace_input_of(uu, uu-&gt;find_edge(u), newmm);
2816                   --j, --jmax;
2817                 }
2818               }
2819             }
2820           }
2821         }
2822       } else if (u-&gt;is_Phi()) {
2823         assert(u-&gt;bottom_type() == Type::MEMORY, &quot;what else?&quot;);
2824         Node* region = u-&gt;in(0);
2825         if (should_process_phi(u)) {
2826           bool replaced = false;
2827           for (uint j = 1; j &lt; u-&gt;req(); j++) {
2828             if (u-&gt;in(j) == mem &amp;&amp; _phase-&gt;is_dominator(rep_ctrl, region-&gt;in(j))) {
2829               Node* nnew = rep_proj;
2830               if (u-&gt;adr_type() == TypePtr::BOTTOM) {
2831                 if (mm == NULL) {
2832                   mm = allocate_merge_mem(mem, rep_proj, rep_ctrl);
2833                 }
2834                 nnew = mm;
2835               }
2836               _phase-&gt;igvn().replace_input_of(u, j, nnew);
2837               replaced = true;
2838             }
2839           }
2840           if (replaced) {
2841             --i;
2842           }
2843 
2844         }
2845       } else if ((u-&gt;adr_type() == TypePtr::BOTTOM &amp;&amp; u-&gt;Opcode() != Op_StrInflatedCopy) ||
2846                  u-&gt;adr_type() == NULL) {
2847         assert(u-&gt;adr_type() != NULL ||
2848                u-&gt;Opcode() == Op_Rethrow ||
2849                u-&gt;Opcode() == Op_Return ||
2850                u-&gt;Opcode() == Op_SafePoint ||
2851                u-&gt;Opcode() == Op_StoreIConditional ||
2852                u-&gt;Opcode() == Op_StoreLConditional ||
2853                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;uncommon_trap_request() != 0) ||
2854                (u-&gt;is_CallStaticJava() &amp;&amp; u-&gt;as_CallStaticJava()-&gt;_entry_point == OptoRuntime::rethrow_stub()) ||
2855                u-&gt;Opcode() == Op_CallLeaf, &quot;%s&quot;, u-&gt;Name());
2856         if (ShenandoahBarrierC2Support::is_dominator(rep_ctrl, _phase-&gt;ctrl_or_self(u), replacement, u, _phase)) {
2857           if (mm == NULL) {
2858             mm = allocate_merge_mem(mem, rep_proj, rep_ctrl);
2859           }
2860           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), mm);
2861           --i;
2862         }
2863       } else if (_phase-&gt;C-&gt;get_alias_index(u-&gt;adr_type()) == _alias) {
2864         if (ShenandoahBarrierC2Support::is_dominator(rep_ctrl, _phase-&gt;ctrl_or_self(u), replacement, u, _phase)) {
2865           _phase-&gt;igvn().replace_input_of(u, u-&gt;find_edge(mem), rep_proj);
2866           --i;
2867         }
2868       }
2869     }
2870   }
2871 }
2872 
2873 ShenandoahLoadReferenceBarrierNode::ShenandoahLoadReferenceBarrierNode(Node* ctrl, Node* obj, bool native)
2874 : Node(ctrl, obj), _native(native) {
2875   ShenandoahBarrierSetC2::bsc2()-&gt;state()-&gt;add_load_reference_barrier(this);
2876 }
2877 
2878 bool ShenandoahLoadReferenceBarrierNode::is_native() const {
2879   return _native;
2880 }
2881 
2882 uint ShenandoahLoadReferenceBarrierNode::size_of() const {
2883   return sizeof(*this);
2884 }
2885 
2886 uint ShenandoahLoadReferenceBarrierNode::hash() const {
2887   return Node::hash() + (_native ? 1 : 0);
2888 }
2889 
2890 bool ShenandoahLoadReferenceBarrierNode::cmp( const Node &amp;n ) const {
2891   return Node::cmp(n) &amp;&amp; n.Opcode() == Op_ShenandoahLoadReferenceBarrier &amp;&amp;
2892          _native == ((const ShenandoahLoadReferenceBarrierNode&amp;)n)._native;
2893 }
2894 
2895 const Type* ShenandoahLoadReferenceBarrierNode::bottom_type() const {
2896   if (in(ValueIn) == NULL || in(ValueIn)-&gt;is_top()) {
2897     return Type::TOP;
2898   }
2899   const Type* t = in(ValueIn)-&gt;bottom_type();
2900   if (t == TypePtr::NULL_PTR) {
2901     return t;
2902   }
2903   return t-&gt;is_oopptr();
2904 }
2905 
2906 const Type* ShenandoahLoadReferenceBarrierNode::Value(PhaseGVN* phase) const {
2907   // Either input is TOP ==&gt; the result is TOP
2908   const Type *t2 = phase-&gt;type(in(ValueIn));
2909   if( t2 == Type::TOP ) return Type::TOP;
2910 
2911   if (t2 == TypePtr::NULL_PTR) {
2912     return t2;
2913   }
2914 
2915   const Type* type = t2-&gt;is_oopptr();
2916   return type;
2917 }
2918 
2919 Node* ShenandoahLoadReferenceBarrierNode::Identity(PhaseGVN* phase) {
2920   Node* value = in(ValueIn);
2921   if (!needs_barrier(phase, value)) {
2922     return value;
2923   }
2924   return this;
2925 }
2926 
2927 bool ShenandoahLoadReferenceBarrierNode::needs_barrier(PhaseGVN* phase, Node* n) {
2928   Unique_Node_List visited;
2929   return needs_barrier_impl(phase, n, visited);
2930 }
2931 
2932 bool ShenandoahLoadReferenceBarrierNode::needs_barrier_impl(PhaseGVN* phase, Node* n, Unique_Node_List &amp;visited) {
2933   if (n == NULL) return false;
2934   if (visited.member(n)) {
2935     return false; // Been there.
2936   }
2937   visited.push(n);
2938 
2939   if (n-&gt;is_Allocate()) {
2940     // tty-&gt;print_cr(&quot;optimize barrier on alloc&quot;);
2941     return false;
2942   }
2943   if (n-&gt;is_Call()) {
2944     // tty-&gt;print_cr(&quot;optimize barrier on call&quot;);
2945     return false;
2946   }
2947 
2948   const Type* type = phase-&gt;type(n);
2949   if (type == Type::TOP) {
2950     return false;
2951   }
2952   if (type-&gt;make_ptr()-&gt;higher_equal(TypePtr::NULL_PTR)) {
2953     // tty-&gt;print_cr(&quot;optimize barrier on null&quot;);
2954     return false;
2955   }
2956   if (type-&gt;make_oopptr() &amp;&amp; type-&gt;make_oopptr()-&gt;const_oop() != NULL) {
2957     // tty-&gt;print_cr(&quot;optimize barrier on constant&quot;);
2958     return false;
2959   }
2960 
2961   switch (n-&gt;Opcode()) {
2962     case Op_AddP:
2963       return true; // TODO: Can refine?
2964     case Op_LoadP:
2965     case Op_ShenandoahCompareAndExchangeN:
2966     case Op_ShenandoahCompareAndExchangeP:
2967     case Op_CompareAndExchangeN:
2968     case Op_CompareAndExchangeP:
2969     case Op_GetAndSetN:
2970     case Op_GetAndSetP:
2971       return true;
2972     case Op_Phi: {
2973       for (uint i = 1; i &lt; n-&gt;req(); i++) {
2974         if (needs_barrier_impl(phase, n-&gt;in(i), visited)) return true;
2975       }
2976       return false;
2977     }
2978     case Op_CheckCastPP:
2979     case Op_CastPP:
2980       return needs_barrier_impl(phase, n-&gt;in(1), visited);
2981     case Op_Proj:
2982       return needs_barrier_impl(phase, n-&gt;in(0), visited);
2983     case Op_ShenandoahLoadReferenceBarrier:
2984       // tty-&gt;print_cr(&quot;optimize barrier on barrier&quot;);
2985       return false;
2986     case Op_Parm:
2987       // tty-&gt;print_cr(&quot;optimize barrier on input arg&quot;);
2988       return false;
2989     case Op_DecodeN:
2990     case Op_EncodeP:
2991       return needs_barrier_impl(phase, n-&gt;in(1), visited);
2992     case Op_LoadN:
2993       return true;
2994     case Op_CMoveN:
2995     case Op_CMoveP:
2996       return needs_barrier_impl(phase, n-&gt;in(2), visited) ||
2997              needs_barrier_impl(phase, n-&gt;in(3), visited);
2998     case Op_ShenandoahEnqueueBarrier:
2999       return needs_barrier_impl(phase, n-&gt;in(1), visited);
3000     case Op_CreateEx:
3001       return false;
3002     default:
3003       break;
3004   }
3005 #ifdef ASSERT
3006   tty-&gt;print(&quot;need barrier on?: &quot;);
3007   tty-&gt;print_cr(&quot;ins:&quot;);
3008   n-&gt;dump(2);
3009   tty-&gt;print_cr(&quot;outs:&quot;);
3010   n-&gt;dump(-2);
3011   ShouldNotReachHere();
3012 #endif
3013   return true;
3014 }
    </pre>
  </body>
</html>