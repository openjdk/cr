<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/interpreter/interpreterRuntime.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include &quot;precompiled.hpp&quot;
  26 #include &quot;classfile/javaClasses.inline.hpp&quot;
  27 #include &quot;classfile/symbolTable.hpp&quot;
  28 #include &quot;classfile/systemDictionary.hpp&quot;
  29 #include &quot;classfile/vmSymbols.hpp&quot;
  30 #include &quot;code/codeCache.hpp&quot;
  31 #include &quot;compiler/compilationPolicy.hpp&quot;
  32 #include &quot;compiler/compileBroker.hpp&quot;
  33 #include &quot;compiler/disassembler.hpp&quot;
  34 #include &quot;gc/shared/barrierSetNMethod.hpp&quot;
  35 #include &quot;gc/shared/collectedHeap.hpp&quot;
  36 #include &quot;interpreter/interpreter.hpp&quot;
  37 #include &quot;interpreter/interpreterRuntime.hpp&quot;
  38 #include &quot;interpreter/linkResolver.hpp&quot;
  39 #include &quot;interpreter/templateTable.hpp&quot;
  40 #include &quot;logging/log.hpp&quot;
  41 #include &quot;memory/oopFactory.hpp&quot;
  42 #include &quot;memory/resourceArea.hpp&quot;
  43 #include &quot;memory/universe.hpp&quot;
  44 #include &quot;oops/constantPool.hpp&quot;
  45 #include &quot;oops/cpCache.inline.hpp&quot;
  46 #include &quot;oops/instanceKlass.hpp&quot;
  47 #include &quot;oops/methodData.hpp&quot;
  48 #include &quot;oops/objArrayKlass.hpp&quot;
  49 #include &quot;oops/objArrayOop.inline.hpp&quot;
  50 #include &quot;oops/oop.inline.hpp&quot;
  51 #include &quot;oops/symbol.hpp&quot;
  52 #include &quot;oops/valueArrayKlass.hpp&quot;
  53 #include &quot;oops/valueArrayOop.inline.hpp&quot;
  54 #include &quot;oops/valueKlass.inline.hpp&quot;
  55 #include &quot;prims/jvmtiExport.hpp&quot;
  56 #include &quot;prims/nativeLookup.hpp&quot;
  57 #include &quot;runtime/atomic.hpp&quot;
  58 #include &quot;runtime/biasedLocking.hpp&quot;
  59 #include &quot;runtime/deoptimization.hpp&quot;
  60 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
  61 #include &quot;runtime/frame.inline.hpp&quot;
  62 #include &quot;runtime/handles.inline.hpp&quot;
  63 #include &quot;runtime/icache.hpp&quot;
  64 #include &quot;runtime/interfaceSupport.inline.hpp&quot;
  65 #include &quot;runtime/java.hpp&quot;
  66 #include &quot;runtime/javaCalls.hpp&quot;
  67 #include &quot;runtime/jfieldIDWorkaround.hpp&quot;
  68 #include &quot;runtime/osThread.hpp&quot;
  69 #include &quot;runtime/sharedRuntime.hpp&quot;
  70 #include &quot;runtime/stubRoutines.hpp&quot;
  71 #include &quot;runtime/synchronizer.hpp&quot;
  72 #include &quot;runtime/threadCritical.hpp&quot;
  73 #include &quot;utilities/align.hpp&quot;
  74 #include &quot;utilities/copy.hpp&quot;
  75 #include &quot;utilities/events.hpp&quot;
  76 #include &quot;utilities/globalDefinitions.hpp&quot;
  77 #ifdef COMPILER2
  78 #include &quot;opto/runtime.hpp&quot;
  79 #endif
  80 
  81 class UnlockFlagSaver {
  82   private:
  83     JavaThread* _thread;
  84     bool _do_not_unlock;
  85   public:
  86     UnlockFlagSaver(JavaThread* t) {
  87       _thread = t;
  88       _do_not_unlock = t-&gt;do_not_unlock_if_synchronized();
  89       t-&gt;set_do_not_unlock_if_synchronized(false);
  90     }
  91     ~UnlockFlagSaver() {
  92       _thread-&gt;set_do_not_unlock_if_synchronized(_do_not_unlock);
  93     }
  94 };
  95 
  96 // Helper class to access current interpreter state
  97 class LastFrameAccessor : public StackObj {
  98   frame _last_frame;
  99 public:
 100   LastFrameAccessor(JavaThread* thread) {
 101     assert(thread == Thread::current(), &quot;sanity&quot;);
 102     _last_frame = thread-&gt;last_frame();
 103   }
 104   bool is_interpreted_frame() const              { return _last_frame.is_interpreted_frame(); }
 105   Method*   method() const                       { return _last_frame.interpreter_frame_method(); }
 106   address   bcp() const                          { return _last_frame.interpreter_frame_bcp(); }
 107   int       bci() const                          { return _last_frame.interpreter_frame_bci(); }
 108   address   mdp() const                          { return _last_frame.interpreter_frame_mdp(); }
 109 
 110   void      set_bcp(address bcp)                 { _last_frame.interpreter_frame_set_bcp(bcp); }
 111   void      set_mdp(address dp)                  { _last_frame.interpreter_frame_set_mdp(dp); }
 112 
 113   // pass method to avoid calling unsafe bcp_to_method (partial fix 4926272)
 114   Bytecodes::Code code() const                   { return Bytecodes::code_at(method(), bcp()); }
 115 
 116   Bytecode  bytecode() const                     { return Bytecode(method(), bcp()); }
 117   int get_index_u1(Bytecodes::Code bc) const     { return bytecode().get_index_u1(bc); }
 118   int get_index_u2(Bytecodes::Code bc) const     { return bytecode().get_index_u2(bc); }
 119   int get_index_u2_cpcache(Bytecodes::Code bc) const
 120                                                  { return bytecode().get_index_u2_cpcache(bc); }
 121   int get_index_u4(Bytecodes::Code bc) const     { return bytecode().get_index_u4(bc); }
 122   int number_of_dimensions() const               { return bcp()[3]; }
 123   ConstantPoolCacheEntry* cache_entry_at(int i) const
 124                                                  { return method()-&gt;constants()-&gt;cache()-&gt;entry_at(i); }
 125   ConstantPoolCacheEntry* cache_entry() const    { return cache_entry_at(Bytes::get_native_u2(bcp() + 1)); }
 126 
 127   oop callee_receiver(Symbol* signature) {
 128     return _last_frame.interpreter_callee_receiver(signature);
 129   }
 130   BasicObjectLock* monitor_begin() const {
 131     return _last_frame.interpreter_frame_monitor_begin();
 132   }
 133   BasicObjectLock* monitor_end() const {
 134     return _last_frame.interpreter_frame_monitor_end();
 135   }
 136   BasicObjectLock* next_monitor(BasicObjectLock* current) const {
 137     return _last_frame.next_monitor_in_interpreter_frame(current);
 138   }
 139 
 140   frame&amp; get_frame()                             { return _last_frame; }
 141 };
 142 
 143 //------------------------------------------------------------------------------------------------------------------------
 144 // State accessors
 145 
 146 void InterpreterRuntime::set_bcp_and_mdp(address bcp, JavaThread *thread) {
 147   LastFrameAccessor last_frame(thread);
 148   last_frame.set_bcp(bcp);
 149   if (ProfileInterpreter) {
 150     // ProfileTraps uses MDOs independently of ProfileInterpreter.
 151     // That is why we must check both ProfileInterpreter and mdo != NULL.
 152     MethodData* mdo = last_frame.method()-&gt;method_data();
 153     if (mdo != NULL) {
 154       NEEDS_CLEANUP;
 155       last_frame.set_mdp(mdo-&gt;bci_to_dp(last_frame.bci()));
 156     }
 157   }
 158 }
 159 
 160 //------------------------------------------------------------------------------------------------------------------------
 161 // Constants
 162 
 163 
 164 JRT_ENTRY(void, InterpreterRuntime::ldc(JavaThread* thread, bool wide))
 165   // access constant pool
 166   LastFrameAccessor last_frame(thread);
 167   ConstantPool* pool = last_frame.method()-&gt;constants();
 168   int index = wide ? last_frame.get_index_u2(Bytecodes::_ldc_w) : last_frame.get_index_u1(Bytecodes::_ldc);
 169   constantTag tag = pool-&gt;tag_at(index);
 170 
 171   assert (tag.is_unresolved_klass() || tag.is_klass(), &quot;wrong ldc call&quot;);
 172   Klass* klass = pool-&gt;klass_at(index, CHECK);
 173     oop java_class = klass-&gt;java_mirror();
 174     thread-&gt;set_vm_result(java_class);
 175 JRT_END
 176 
 177 JRT_ENTRY(void, InterpreterRuntime::resolve_ldc(JavaThread* thread, Bytecodes::Code bytecode)) {
 178   assert(bytecode == Bytecodes::_ldc ||
 179          bytecode == Bytecodes::_ldc_w ||
 180          bytecode == Bytecodes::_ldc2_w ||
 181          bytecode == Bytecodes::_fast_aldc ||
 182          bytecode == Bytecodes::_fast_aldc_w, &quot;wrong bc&quot;);
 183   ResourceMark rm(thread);
 184   const bool is_fast_aldc = (bytecode == Bytecodes::_fast_aldc ||
 185                              bytecode == Bytecodes::_fast_aldc_w);
 186   LastFrameAccessor last_frame(thread);
 187   methodHandle m (thread, last_frame.method());
 188   Bytecode_loadconstant ldc(m, last_frame.bci());
 189 
 190   // Double-check the size.  (Condy can have any type.)
 191   BasicType type = ldc.result_type();
 192   switch (type2size[type]) {
 193   case 2: guarantee(bytecode == Bytecodes::_ldc2_w, &quot;&quot;); break;
 194   case 1: guarantee(bytecode != Bytecodes::_ldc2_w, &quot;&quot;); break;
 195   default: ShouldNotReachHere();
 196   }
 197 
 198   // Resolve the constant.  This does not do unboxing.
 199   // But it does replace Universe::the_null_sentinel by null.
 200   oop result = ldc.resolve_constant(CHECK);
 201   assert(result != NULL || is_fast_aldc, &quot;null result only valid for fast_aldc&quot;);
 202 
 203 #ifdef ASSERT
 204   {
 205     // The bytecode wrappers aren&#39;t GC-safe so construct a new one
 206     Bytecode_loadconstant ldc2(m, last_frame.bci());
 207     int rindex = ldc2.cache_index();
 208     if (rindex &lt; 0)
 209       rindex = m-&gt;constants()-&gt;cp_to_object_index(ldc2.pool_index());
 210     if (rindex &gt;= 0) {
 211       oop coop = m-&gt;constants()-&gt;resolved_references()-&gt;obj_at(rindex);
 212       oop roop = (result == NULL ? Universe::the_null_sentinel() : result);
 213       assert(roop == coop, &quot;expected result for assembly code&quot;);
 214     }
 215   }
 216 #endif
 217   thread-&gt;set_vm_result(result);
 218   if (!is_fast_aldc) {
 219     // Tell the interpreter how to unbox the primitive.
 220     guarantee(java_lang_boxing_object::is_instance(result, type), &quot;&quot;);
 221     int offset = java_lang_boxing_object::value_offset(type);
 222     intptr_t flags = ((as_TosState(type) &lt;&lt; ConstantPoolCacheEntry::tos_state_shift)
 223                       | (offset &amp; ConstantPoolCacheEntry::field_index_mask));
 224     thread-&gt;set_vm_result_2((Metadata*)flags);
 225   }
 226 }
 227 JRT_END
 228 
 229 
 230 //------------------------------------------------------------------------------------------------------------------------
 231 // Allocation
 232 
 233 JRT_ENTRY(void, InterpreterRuntime::_new(JavaThread* thread, ConstantPool* pool, int index))
 234   Klass* k = pool-&gt;klass_at(index, CHECK);
 235   InstanceKlass* klass = InstanceKlass::cast(k);
 236 
 237   if (klass-&gt;is_inline_klass()) {
 238     THROW(vmSymbols::java_lang_InstantiationError());
 239   }
 240 
 241   // Make sure we are not instantiating an abstract klass
 242   klass-&gt;check_valid_for_instantiation(true, CHECK);
 243 
 244   // Make sure klass is initialized
 245   klass-&gt;initialize(CHECK);
 246 
 247   // At this point the class may not be fully initialized
 248   // because of recursive initialization. If it is fully
 249   // initialized &amp; has_finalized is not set, we rewrite
 250   // it into its fast version (Note: no locking is needed
 251   // here since this is an atomic byte write and can be
 252   // done more than once).
 253   //
 254   // Note: In case of classes with has_finalized we don&#39;t
 255   //       rewrite since that saves us an extra check in
 256   //       the fast version which then would call the
 257   //       slow version anyway (and do a call back into
 258   //       Java).
 259   //       If we have a breakpoint, then we don&#39;t rewrite
 260   //       because the _breakpoint bytecode would be lost.
 261   oop obj = klass-&gt;allocate_instance(CHECK);
 262   thread-&gt;set_vm_result(obj);
 263 JRT_END
 264 
 265 void copy_primitive_argument(intptr_t* addr, Handle instance, int offset, BasicType type) {
 266   switch (type) {
 267   case T_BOOLEAN:
 268     instance()-&gt;bool_field_put(offset, (jboolean)*((int*)addr));
 269     break;
 270   case T_CHAR:
 271     instance()-&gt;char_field_put(offset, (jchar) *((int*)addr));
 272     break;
 273   case T_FLOAT:
 274     instance()-&gt;float_field_put(offset, (jfloat)*((float*)addr));
 275     break;
 276   case T_DOUBLE:
 277     instance()-&gt;double_field_put(offset, (jdouble)*((double*)addr));
 278     break;
 279   case T_BYTE:
 280     instance()-&gt;byte_field_put(offset, (jbyte)*((int*)addr));
 281     break;
 282   case T_SHORT:
 283     instance()-&gt;short_field_put(offset, (jshort)*((int*)addr));
 284     break;
 285   case T_INT:
 286     instance()-&gt;int_field_put(offset, (jint)*((int*)addr));
 287     break;
 288   case T_LONG:
 289     instance()-&gt;long_field_put(offset, (jlong)*((long long*)addr));
 290     break;
 291   case T_OBJECT:
 292   case T_ARRAY:
 293   case T_VALUETYPE:
 294     fatal(&quot;Should not be handled with this method&quot;);
 295     break;
 296   default:
 297     fatal(&quot;Unsupported BasicType&quot;);
 298   }
 299 }
 300 
 301 JRT_ENTRY(void, InterpreterRuntime::defaultvalue(JavaThread* thread, ConstantPool* pool, int index))
 302   // Getting the ValueKlass
 303   Klass* k = pool-&gt;klass_at(index, CHECK);
 304   if (!k-&gt;is_inline_klass()) {
 305     // inconsistency with &#39;new&#39; which throws an InstantiationError
 306     // in the future, defaultvalue will just return null instead of throwing an exception
 307     THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
 308   }
 309   assert(k-&gt;is_inline_klass(), &quot;defaultvalue argument must be the inline type class&quot;);
 310   ValueKlass* vklass = ValueKlass::cast(k);
 311 
 312   vklass-&gt;initialize(THREAD);
 313   oop res = vklass-&gt;default_value();
 314   thread-&gt;set_vm_result(res);
 315 JRT_END
 316 
 317 JRT_ENTRY(int, InterpreterRuntime::withfield(JavaThread* thread, ConstantPoolCache* cp_cache))
 318   LastFrameAccessor last_frame(thread);
 319   // Getting the ValueKlass
 320   int index = ConstantPool::decode_cpcache_index(last_frame.get_index_u2_cpcache(Bytecodes::_withfield));
 321   ConstantPoolCacheEntry* cp_entry = cp_cache-&gt;entry_at(index);
 322   assert(cp_entry-&gt;is_resolved(Bytecodes::_withfield), &quot;Should have been resolved&quot;);
 323   Klass* klass = cp_entry-&gt;f1_as_klass();
 324   assert(klass-&gt;is_inline_klass(), &quot;withfield only applies to inline types&quot;);
 325   ValueKlass* vklass = ValueKlass::cast(klass);
 326 
 327   // Getting Field information
 328   int offset = cp_entry-&gt;f2_as_index();
 329   int field_index = cp_entry-&gt;field_index();
 330   int field_offset = cp_entry-&gt;f2_as_offset();
 331   Symbol* field_signature = vklass-&gt;field_signature(field_index);
 332   BasicType field_type = Signature::basic_type(field_signature);
 333   int return_offset = (type2size[field_type] + type2size[T_OBJECT]) * AbstractInterpreter::stackElementSize;
 334 
 335   // Getting old value
 336   frame&amp; f = last_frame.get_frame();
 337   jint tos_idx = f.interpreter_frame_expression_stack_size() - 1;
 338   int vt_offset = type2size[field_type];
 339   oop old_value = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx - vt_offset);
 340   assert(old_value != NULL &amp;&amp; oopDesc::is_oop(old_value) &amp;&amp; old_value-&gt;is_inline_type(),&quot;Verifying receiver&quot;);
 341   Handle old_value_h(THREAD, old_value);
 342 
 343   // Creating new value by copying the one passed in argument
 344   instanceOop new_value = vklass-&gt;allocate_instance(
 345       CHECK_((type2size[field_type]) * AbstractInterpreter::stackElementSize));
 346   Handle new_value_h = Handle(THREAD, new_value);
 347   vklass-&gt;value_copy_oop_to_new_oop(old_value_h(), new_value_h());
 348 
 349   // Updating the field specified in arguments
 350   if (field_type == T_ARRAY || field_type == T_OBJECT) {
 351     oop aoop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
 352     assert(aoop == NULL || oopDesc::is_oop(aoop),&quot;argument must be a reference type&quot;);
 353     new_value_h()-&gt;obj_field_put(field_offset, aoop);
 354   } else if (field_type == T_VALUETYPE) {
 355     if (cp_entry-&gt;is_inlined()) {
 356       oop vt_oop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
 357       assert(vt_oop != NULL &amp;&amp; oopDesc::is_oop(vt_oop) &amp;&amp; vt_oop-&gt;is_inline_type(),&quot;argument must be an inline type&quot;);
 358       ValueKlass* field_vk = ValueKlass::cast(vklass-&gt;get_inline_type_field_klass(field_index));
 359       assert(vt_oop != NULL &amp;&amp; field_vk == vt_oop-&gt;klass(), &quot;Must match&quot;);
 360       field_vk-&gt;write_inlined_field(new_value_h(), offset, vt_oop, CHECK_(return_offset));
 361     } else { // not inlined
 362       oop voop = *(oop*)f.interpreter_frame_expression_stack_at(tos_idx);
 363       if (voop == NULL &amp;&amp; cp_entry-&gt;is_inline_type()) {
 364         THROW_(vmSymbols::java_lang_NullPointerException(), return_offset);
 365       }
 366       assert(voop == NULL || oopDesc::is_oop(voop),&quot;checking argument&quot;);
 367       new_value_h()-&gt;obj_field_put(field_offset, voop);
 368     }
 369   } else { // not T_OBJECT nor T_ARRAY nor T_VALUETYPE
 370     intptr_t* addr = f.interpreter_frame_expression_stack_at(tos_idx);
 371     copy_primitive_argument(addr, new_value_h, field_offset, field_type);
 372   }
 373 
 374   // returning result
 375   thread-&gt;set_vm_result(new_value_h());
 376   return return_offset;
 377 JRT_END
 378 
 379 JRT_ENTRY(void, InterpreterRuntime::uninitialized_static_value_field(JavaThread* thread, oopDesc* mirror, int index))
 380   // The interpreter tries to access an inline static field that has not been initialized.
 381   // This situation can happen in different scenarios:
 382   //   1 - if the load or initialization of the field failed during step 8 of
 383   //       the initialization of the holder of the field, in this case the access to the field
 384   //       must fail
 385   //   2 - it can also happen when the initialization of the holder class triggered the initialization of
 386   //       another class which accesses this field in its static initializer, in this case the
 387   //       access must succeed to allow circularity
 388   // The code below tries to load and initialize the field&#39;s class again before returning the default value.
 389   // If the field was not initialized because of an error, a exception should be thrown.
 390   // If the class is being initialized, the default value is returned.
 391   instanceHandle mirror_h(THREAD, (instanceOop)mirror);
 392   InstanceKlass* klass = InstanceKlass::cast(java_lang_Class::as_Klass(mirror));
 393   if (klass-&gt;is_being_initialized() &amp;&amp; klass-&gt;is_reentrant_initialization(THREAD)) {
 394     int offset = klass-&gt;field_offset(index);
 395     Klass* field_k = klass-&gt;get_inline_type_field_klass_or_null(index);
 396     if (field_k == NULL) {
 397       field_k = SystemDictionary::resolve_or_fail(klass-&gt;field_signature(index)-&gt;fundamental_name(THREAD),
 398           Handle(THREAD, klass-&gt;class_loader()),
 399           Handle(THREAD, klass-&gt;protection_domain()),
 400           true, CHECK);
 401       assert(field_k != NULL, &quot;Should have been loaded or an exception thrown above&quot;);
 402       klass-&gt;set_inline_type_field_klass(index, field_k);
 403     }
 404     field_k-&gt;initialize(CHECK);
 405     oop defaultvalue = ValueKlass::cast(field_k)-&gt;default_value();
 406     // It is safe to initialized the static field because 1) the current thread is the initializing thread
 407     // and is the only one that can access it, and 2) the field is actually not initialized (i.e. null)
 408     // otherwise the JVM should not be executing this code.
 409     mirror-&gt;obj_field_put(offset, defaultvalue);
 410     thread-&gt;set_vm_result(defaultvalue);
 411   } else {
 412     assert(klass-&gt;is_in_error_state(), &quot;If not initializing, initialization must have failed to get there&quot;);
 413     ResourceMark rm(THREAD);
 414     const char* desc = &quot;Could not initialize class &quot;;
 415     const char* className = klass-&gt;external_name();
 416     size_t msglen = strlen(desc) + strlen(className) + 1;
 417     char* message = NEW_RESOURCE_ARRAY(char, msglen);
 418     if (NULL == message) {
 419       // Out of memory: can&#39;t create detailed error message
 420       THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), className);
 421     } else {
 422       jio_snprintf(message, msglen, &quot;%s%s&quot;, desc, className);
 423       THROW_MSG(vmSymbols::java_lang_NoClassDefFoundError(), message);
 424     }
 425   }
 426 JRT_END
 427 
 428 JRT_ENTRY(void, InterpreterRuntime::read_inlined_field(JavaThread* thread, oopDesc* obj, int index, Klass* field_holder))
 429   Handle obj_h(THREAD, obj);
 430 
 431   assert(oopDesc::is_oop(obj), &quot;Sanity check&quot;);
 432 
 433   assert(field_holder-&gt;is_instance_klass(), &quot;Sanity check&quot;);
 434   InstanceKlass* klass = InstanceKlass::cast(field_holder);
 435 
 436   assert(klass-&gt;field_is_inlined(index), &quot;Sanity check&quot;);
 437 
 438   ValueKlass* field_vklass = ValueKlass::cast(klass-&gt;get_inline_type_field_klass(index));
 439   assert(field_vklass-&gt;is_initialized(), &quot;Must be initialized at this point&quot;);
 440 
 441   oop res = field_vklass-&gt;read_inlined_field(obj_h(), klass-&gt;field_offset(index), CHECK);
 442   thread-&gt;set_vm_result(res);
 443 JRT_END
 444 
 445 JRT_ENTRY(void, InterpreterRuntime::newarray(JavaThread* thread, BasicType type, jint size))
 446   oop obj = oopFactory::new_typeArray(type, size, CHECK);
 447   thread-&gt;set_vm_result(obj);
 448 JRT_END
 449 
 450 
 451 JRT_ENTRY(void, InterpreterRuntime::anewarray(JavaThread* thread, ConstantPool* pool, int index, jint size))
 452   Klass*    klass = pool-&gt;klass_at(index, CHECK);
 453   bool      is_qtype_desc = pool-&gt;tag_at(index).is_Qdescriptor_klass();
 454   arrayOop obj;
 455   if ((!klass-&gt;is_array_klass()) &amp;&amp; is_qtype_desc) { // Logically creates elements, ensure klass init
 456     klass-&gt;initialize(CHECK);
 457     obj = oopFactory::new_valueArray(klass, size, CHECK);
 458   } else {
 459     obj = oopFactory::new_objArray(klass, size, CHECK);
 460   }
 461   thread-&gt;set_vm_result(obj);
 462 JRT_END
 463 
 464 JRT_ENTRY(void, InterpreterRuntime::value_array_load(JavaThread* thread, arrayOopDesc* array, int index))
 465   valueArrayHandle vah(thread, (valueArrayOop)array);
 466   oop value_holder = valueArrayOopDesc::value_alloc_copy_from_index(vah, index, CHECK);
 467   thread-&gt;set_vm_result(value_holder);
 468 JRT_END
 469 
 470 JRT_ENTRY(void, InterpreterRuntime::value_array_store(JavaThread* thread, void* val, arrayOopDesc* array, int index))
 471   assert(val != NULL, &quot;can&#39;t store null into flat array&quot;);
 472   ((valueArrayOop)array)-&gt;value_copy_to_index((oop)val, index);
 473 JRT_END
 474 
 475 JRT_ENTRY(void, InterpreterRuntime::multianewarray(JavaThread* thread, jint* first_size_address))
 476   // We may want to pass in more arguments - could make this slightly faster
 477   LastFrameAccessor last_frame(thread);
 478   ConstantPool* constants = last_frame.method()-&gt;constants();
 479   int i = last_frame.get_index_u2(Bytecodes::_multianewarray);
 480   Klass* klass = constants-&gt;klass_at(i, CHECK);
 481   bool is_qtype = klass-&gt;name()-&gt;is_Q_array_signature();
 482   int   nof_dims = last_frame.number_of_dimensions();
 483   assert(klass-&gt;is_klass(), &quot;not a class&quot;);
 484   assert(nof_dims &gt;= 1, &quot;multianewarray rank must be nonzero&quot;);
 485 
 486   if (is_qtype) { // Logically creates elements, ensure klass init
 487     klass-&gt;initialize(CHECK);
 488   }
 489 
 490   // We must create an array of jints to pass to multi_allocate.
 491   ResourceMark rm(thread);
 492   const int small_dims = 10;
 493   jint dim_array[small_dims];
 494   jint *dims = &amp;dim_array[0];
 495   if (nof_dims &gt; small_dims) {
 496     dims = (jint*) NEW_RESOURCE_ARRAY(jint, nof_dims);
 497   }
 498   for (int index = 0; index &lt; nof_dims; index++) {
 499     // offset from first_size_address is addressed as local[index]
 500     int n = Interpreter::local_offset_in_bytes(index)/jintSize;
 501     dims[index] = first_size_address[n];
 502   }
 503   oop obj = ArrayKlass::cast(klass)-&gt;multi_allocate(nof_dims, dims, CHECK);
 504   thread-&gt;set_vm_result(obj);
 505 JRT_END
 506 
 507 
 508 JRT_ENTRY(void, InterpreterRuntime::register_finalizer(JavaThread* thread, oopDesc* obj))
 509   assert(oopDesc::is_oop(obj), &quot;must be a valid oop&quot;);
 510   assert(obj-&gt;klass()-&gt;has_finalizer(), &quot;shouldn&#39;t be here otherwise&quot;);
 511   InstanceKlass::register_finalizer(instanceOop(obj), CHECK);
 512 JRT_END
 513 
 514 JRT_ENTRY(jboolean, InterpreterRuntime::is_substitutable(JavaThread* thread, oopDesc* aobj, oopDesc* bobj))
 515   assert(oopDesc::is_oop(aobj) &amp;&amp; oopDesc::is_oop(bobj), &quot;must be valid oops&quot;);
 516 
 517   Handle ha(THREAD, aobj);
 518   Handle hb(THREAD, bobj);
 519   JavaValue result(T_BOOLEAN);
 520   JavaCallArguments args;
 521   args.push_oop(ha);
 522   args.push_oop(hb);
 523   methodHandle method(thread, Universe::is_substitutable_method());
 524   JavaCalls::call(&amp;result, method, &amp;args, THREAD);
 525   if (HAS_PENDING_EXCEPTION) {
 526     // Something really bad happened because isSubstitutable() should not throw exceptions
 527     // If it is an error, just let it propagate
 528     // If it is an exception, wrap it into an InternalError
 529     if (!PENDING_EXCEPTION-&gt;is_a(SystemDictionary::Error_klass())) {
 530       Handle e(THREAD, PENDING_EXCEPTION);
 531       CLEAR_PENDING_EXCEPTION;
 532       THROW_MSG_CAUSE_(vmSymbols::java_lang_InternalError(), &quot;Internal error in substitutability test&quot;, e, false);
 533     }
 534   }
 535   return result.get_jboolean();
 536 JRT_END
 537 
 538 // Quicken instance-of and check-cast bytecodes
 539 JRT_ENTRY(void, InterpreterRuntime::quicken_io_cc(JavaThread* thread))
 540   // Force resolving; quicken the bytecode
 541   LastFrameAccessor last_frame(thread);
 542   int which = last_frame.get_index_u2(Bytecodes::_checkcast);
 543   ConstantPool* cpool = last_frame.method()-&gt;constants();
 544   // We&#39;d expect to assert that we&#39;re only here to quicken bytecodes, but in a multithreaded
 545   // program we might have seen an unquick&#39;d bytecode in the interpreter but have another
 546   // thread quicken the bytecode before we get here.
 547   // assert( cpool-&gt;tag_at(which).is_unresolved_klass(), &quot;should only come here to quicken bytecodes&quot; );
 548   Klass* klass = cpool-&gt;klass_at(which, CHECK);
 549   thread-&gt;set_vm_result_2(klass);
 550 JRT_END
 551 
 552 
 553 //------------------------------------------------------------------------------------------------------------------------
 554 // Exceptions
 555 
 556 void InterpreterRuntime::note_trap_inner(JavaThread* thread, int reason,
 557                                          const methodHandle&amp; trap_method, int trap_bci, TRAPS) {
 558   if (trap_method.not_null()) {
 559     MethodData* trap_mdo = trap_method-&gt;method_data();
 560     if (trap_mdo == NULL) {
 561       Method::build_interpreter_method_data(trap_method, THREAD);
 562       if (HAS_PENDING_EXCEPTION) {
 563         assert((PENDING_EXCEPTION-&gt;is_a(SystemDictionary::OutOfMemoryError_klass())),
 564                &quot;we expect only an OOM error here&quot;);
 565         CLEAR_PENDING_EXCEPTION;
 566       }
 567       trap_mdo = trap_method-&gt;method_data();
 568       // and fall through...
 569     }
 570     if (trap_mdo != NULL) {
 571       // Update per-method count of trap events.  The interpreter
 572       // is updating the MDO to simulate the effect of compiler traps.
 573       Deoptimization::update_method_data_from_interpreter(trap_mdo, trap_bci, reason);
 574     }
 575   }
 576 }
 577 
 578 // Assume the compiler is (or will be) interested in this event.
 579 // If necessary, create an MDO to hold the information, and record it.
 580 void InterpreterRuntime::note_trap(JavaThread* thread, int reason, TRAPS) {
 581   assert(ProfileTraps, &quot;call me only if profiling&quot;);
 582   LastFrameAccessor last_frame(thread);
 583   methodHandle trap_method(thread, last_frame.method());
 584   int trap_bci = trap_method-&gt;bci_from(last_frame.bcp());
 585   note_trap_inner(thread, reason, trap_method, trap_bci, THREAD);
 586 }
 587 
 588 #ifdef CC_INTERP
 589 // As legacy note_trap, but we have more arguments.
 590 JRT_ENTRY(void, InterpreterRuntime::note_trap(JavaThread* thread, int reason, Method *method, int trap_bci))
 591   methodHandle trap_method(thread, method);
 592   note_trap_inner(thread, reason, trap_method, trap_bci, THREAD);
 593 JRT_END
 594 
 595 // Class Deoptimization is not visible in BytecodeInterpreter, so we need a wrapper
 596 // for each exception.
 597 void InterpreterRuntime::note_nullCheck_trap(JavaThread* thread, Method *method, int trap_bci)
 598   { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_null_check, method, trap_bci); }
 599 void InterpreterRuntime::note_div0Check_trap(JavaThread* thread, Method *method, int trap_bci)
 600   { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_div0_check, method, trap_bci); }
 601 void InterpreterRuntime::note_rangeCheck_trap(JavaThread* thread, Method *method, int trap_bci)
 602   { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_range_check, method, trap_bci); }
 603 void InterpreterRuntime::note_classCheck_trap(JavaThread* thread, Method *method, int trap_bci)
 604   { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_class_check, method, trap_bci); }
 605 void InterpreterRuntime::note_arrayCheck_trap(JavaThread* thread, Method *method, int trap_bci)
 606   { if (ProfileTraps) note_trap(thread, Deoptimization::Reason_array_check, method, trap_bci); }
 607 #endif // CC_INTERP
 608 
 609 
 610 static Handle get_preinitialized_exception(Klass* k, TRAPS) {
 611   // get klass
 612   InstanceKlass* klass = InstanceKlass::cast(k);
 613   assert(klass-&gt;is_initialized(),
 614          &quot;this klass should have been initialized during VM initialization&quot;);
 615   // create instance - do not call constructor since we may have no
 616   // (java) stack space left (should assert constructor is empty)
 617   Handle exception;
 618   oop exception_oop = klass-&gt;allocate_instance(CHECK_(exception));
 619   exception = Handle(THREAD, exception_oop);
 620   if (StackTraceInThrowable) {
 621     java_lang_Throwable::fill_in_stack_trace(exception);
 622   }
 623   return exception;
 624 }
 625 
 626 // Special handling for stack overflow: since we don&#39;t have any (java) stack
 627 // space left we use the pre-allocated &amp; pre-initialized StackOverflowError
 628 // klass to create an stack overflow error instance.  We do not call its
 629 // constructor for the same reason (it is empty, anyway).
 630 JRT_ENTRY(void, InterpreterRuntime::throw_StackOverflowError(JavaThread* thread))
 631   Handle exception = get_preinitialized_exception(
 632                                  SystemDictionary::StackOverflowError_klass(),
 633                                  CHECK);
 634   // Increment counter for hs_err file reporting
 635   Atomic::inc(&amp;Exceptions::_stack_overflow_errors);
 636   THROW_HANDLE(exception);
 637 JRT_END
 638 
 639 JRT_ENTRY(void, InterpreterRuntime::throw_delayed_StackOverflowError(JavaThread* thread))
 640   Handle exception = get_preinitialized_exception(
 641                                  SystemDictionary::StackOverflowError_klass(),
 642                                  CHECK);
 643   java_lang_Throwable::set_message(exception(),
 644           Universe::delayed_stack_overflow_error_message());
 645   // Increment counter for hs_err file reporting
 646   Atomic::inc(&amp;Exceptions::_stack_overflow_errors);
 647   THROW_HANDLE(exception);
 648 JRT_END
 649 
 650 JRT_ENTRY(void, InterpreterRuntime::create_exception(JavaThread* thread, char* name, char* message))
 651   // lookup exception klass
 652   TempNewSymbol s = SymbolTable::new_symbol(name);
 653   if (ProfileTraps) {
 654     if (s == vmSymbols::java_lang_ArithmeticException()) {
 655       note_trap(thread, Deoptimization::Reason_div0_check, CHECK);
 656     } else if (s == vmSymbols::java_lang_NullPointerException()) {
 657       note_trap(thread, Deoptimization::Reason_null_check, CHECK);
 658     }
 659   }
 660   // create exception
 661   Handle exception = Exceptions::new_exception(thread, s, message);
 662   thread-&gt;set_vm_result(exception());
 663 JRT_END
 664 
 665 
 666 JRT_ENTRY(void, InterpreterRuntime::create_klass_exception(JavaThread* thread, char* name, oopDesc* obj))
 667   // Produce the error message first because note_trap can safepoint
 668   ResourceMark rm(thread);
 669   const char* klass_name = obj-&gt;klass()-&gt;external_name();
 670   // lookup exception klass
 671   TempNewSymbol s = SymbolTable::new_symbol(name);
 672   if (ProfileTraps) {
 673     note_trap(thread, Deoptimization::Reason_class_check, CHECK);
 674   }
 675   // create exception, with klass name as detail message
 676   Handle exception = Exceptions::new_exception(thread, s, klass_name);
 677   thread-&gt;set_vm_result(exception());
 678 JRT_END
 679 
 680 JRT_ENTRY(void, InterpreterRuntime::throw_ArrayIndexOutOfBoundsException(JavaThread* thread, arrayOopDesc* a, jint index))
 681   // Produce the error message first because note_trap can safepoint
 682   ResourceMark rm(thread);
 683   stringStream ss;
 684   ss.print(&quot;Index %d out of bounds for length %d&quot;, index, a-&gt;length());
 685 
 686   if (ProfileTraps) {
 687     note_trap(thread, Deoptimization::Reason_range_check, CHECK);
 688   }
 689 
 690   THROW_MSG(vmSymbols::java_lang_ArrayIndexOutOfBoundsException(), ss.as_string());
 691 JRT_END
 692 
 693 JRT_ENTRY(void, InterpreterRuntime::throw_ClassCastException(
 694   JavaThread* thread, oopDesc* obj))
 695 
 696   // Produce the error message first because note_trap can safepoint
 697   ResourceMark rm(thread);
 698   char* message = SharedRuntime::generate_class_cast_message(
 699     thread, obj-&gt;klass());
 700 
 701   if (ProfileTraps) {
 702     note_trap(thread, Deoptimization::Reason_class_check, CHECK);
 703   }
 704 
 705   // create exception
 706   THROW_MSG(vmSymbols::java_lang_ClassCastException(), message);
 707 JRT_END
 708 
 709 // exception_handler_for_exception(...) returns the continuation address,
 710 // the exception oop (via TLS) and sets the bci/bcp for the continuation.
 711 // The exception oop is returned to make sure it is preserved over GC (it
 712 // is only on the stack if the exception was thrown explicitly via athrow).
 713 // During this operation, the expression stack contains the values for the
 714 // bci where the exception happened. If the exception was propagated back
 715 // from a call, the expression stack contains the values for the bci at the
 716 // invoke w/o arguments (i.e., as if one were inside the call).
 717 JRT_ENTRY(address, InterpreterRuntime::exception_handler_for_exception(JavaThread* thread, oopDesc* exception))
 718 
 719   LastFrameAccessor last_frame(thread);
 720   Handle             h_exception(thread, exception);
 721   methodHandle       h_method   (thread, last_frame.method());
 722   constantPoolHandle h_constants(thread, h_method-&gt;constants());
 723   bool               should_repeat;
 724   int                handler_bci;
 725   int                current_bci = last_frame.bci();
 726 
 727   if (thread-&gt;frames_to_pop_failed_realloc() &gt; 0) {
 728     // Allocation of scalar replaced object used in this frame
 729     // failed. Unconditionally pop the frame.
 730     thread-&gt;dec_frames_to_pop_failed_realloc();
 731     thread-&gt;set_vm_result(h_exception());
 732     // If the method is synchronized we already unlocked the monitor
 733     // during deoptimization so the interpreter needs to skip it when
 734     // the frame is popped.
 735     thread-&gt;set_do_not_unlock_if_synchronized(true);
 736 #ifdef CC_INTERP
 737     return (address) -1;
 738 #else
 739     return Interpreter::remove_activation_entry();
 740 #endif
 741   }
 742 
 743   // Need to do this check first since when _do_not_unlock_if_synchronized
 744   // is set, we don&#39;t want to trigger any classloading which may make calls
 745   // into java, or surprisingly find a matching exception handler for bci 0
 746   // since at this moment the method hasn&#39;t been &quot;officially&quot; entered yet.
 747   if (thread-&gt;do_not_unlock_if_synchronized()) {
 748     ResourceMark rm;
 749     assert(current_bci == 0,  &quot;bci isn&#39;t zero for do_not_unlock_if_synchronized&quot;);
 750     thread-&gt;set_vm_result(exception);
 751 #ifdef CC_INTERP
 752     return (address) -1;
 753 #else
 754     return Interpreter::remove_activation_entry();
 755 #endif
 756   }
 757 
 758   do {
 759     should_repeat = false;
 760 
 761     // assertions
 762 #ifdef ASSERT
 763     assert(h_exception.not_null(), &quot;NULL exceptions should be handled by athrow&quot;);
 764     // Check that exception is a subclass of Throwable, otherwise we have a VerifyError
 765     if (!(h_exception-&gt;is_a(SystemDictionary::Throwable_klass()))) {
 766       if (ExitVMOnVerifyError) vm_exit(-1);
 767       ShouldNotReachHere();
 768     }
 769 #endif
 770 
 771     // tracing
 772     if (log_is_enabled(Info, exceptions)) {
 773       ResourceMark rm(thread);
 774       stringStream tempst;
 775       tempst.print(&quot;interpreter method &lt;%s&gt;\n&quot;
 776                    &quot; at bci %d for thread &quot; INTPTR_FORMAT &quot; (%s)&quot;,
 777                    h_method-&gt;print_value_string(), current_bci, p2i(thread), thread-&gt;name());
 778       Exceptions::log_exception(h_exception, tempst.as_string());
 779     }
 780 // Don&#39;t go paging in something which won&#39;t be used.
 781 //     else if (extable-&gt;length() == 0) {
 782 //       // disabled for now - interpreter is not using shortcut yet
 783 //       // (shortcut is not to call runtime if we have no exception handlers)
 784 //       // warning(&quot;performance bug: should not call runtime if method has no exception handlers&quot;);
 785 //     }
 786     // for AbortVMOnException flag
 787     Exceptions::debug_check_abort(h_exception);
 788 
 789     // exception handler lookup
 790     Klass* klass = h_exception-&gt;klass();
 791     handler_bci = Method::fast_exception_handler_bci_for(h_method, klass, current_bci, THREAD);
 792     if (HAS_PENDING_EXCEPTION) {
 793       // We threw an exception while trying to find the exception handler.
 794       // Transfer the new exception to the exception handle which will
 795       // be set into thread local storage, and do another lookup for an
 796       // exception handler for this exception, this time starting at the
 797       // BCI of the exception handler which caused the exception to be
 798       // thrown (bug 4307310).
 799       h_exception = Handle(THREAD, PENDING_EXCEPTION);
 800       CLEAR_PENDING_EXCEPTION;
 801       if (handler_bci &gt;= 0) {
 802         current_bci = handler_bci;
 803         should_repeat = true;
 804       }
 805     }
 806   } while (should_repeat == true);
 807 
 808 #if INCLUDE_JVMCI
 809   if (EnableJVMCI &amp;&amp; h_method-&gt;method_data() != NULL) {
 810     ResourceMark rm(thread);
 811     ProfileData* pdata = h_method-&gt;method_data()-&gt;allocate_bci_to_data(current_bci, NULL);
 812     if (pdata != NULL &amp;&amp; pdata-&gt;is_BitData()) {
 813       BitData* bit_data = (BitData*) pdata;
 814       bit_data-&gt;set_exception_seen();
 815     }
 816   }
 817 #endif
 818 
 819   // notify JVMTI of an exception throw; JVMTI will detect if this is a first
 820   // time throw or a stack unwinding throw and accordingly notify the debugger
 821   if (JvmtiExport::can_post_on_exceptions()) {
 822     JvmtiExport::post_exception_throw(thread, h_method(), last_frame.bcp(), h_exception());
 823   }
 824 
 825 #ifdef CC_INTERP
 826   address continuation = (address)(intptr_t) handler_bci;
 827 #else
 828   address continuation = NULL;
 829 #endif
 830   address handler_pc = NULL;
 831   if (handler_bci &lt; 0 || !thread-&gt;reguard_stack((address) &amp;continuation)) {
 832     // Forward exception to callee (leaving bci/bcp untouched) because (a) no
 833     // handler in this method, or (b) after a stack overflow there is not yet
 834     // enough stack space available to reprotect the stack.
 835 #ifndef CC_INTERP
 836     continuation = Interpreter::remove_activation_entry();
 837 #endif
 838 #if COMPILER2_OR_JVMCI
 839     // Count this for compilation purposes
 840     h_method-&gt;interpreter_throwout_increment(THREAD);
 841 #endif
 842   } else {
 843     // handler in this method =&gt; change bci/bcp to handler bci/bcp and continue there
 844     handler_pc = h_method-&gt;code_base() + handler_bci;
 845 #ifndef CC_INTERP
 846     set_bcp_and_mdp(handler_pc, thread);
 847     continuation = Interpreter::dispatch_table(vtos)[*handler_pc];
 848 #endif
 849   }
 850   // notify debugger of an exception catch
 851   // (this is good for exceptions caught in native methods as well)
 852   if (JvmtiExport::can_post_on_exceptions()) {
 853     JvmtiExport::notice_unwind_due_to_exception(thread, h_method(), handler_pc, h_exception(), (handler_pc != NULL));
 854   }
 855 
 856   thread-&gt;set_vm_result(h_exception());
 857   return continuation;
 858 JRT_END
 859 
 860 
 861 JRT_ENTRY(void, InterpreterRuntime::throw_pending_exception(JavaThread* thread))
 862   assert(thread-&gt;has_pending_exception(), &quot;must only ne called if there&#39;s an exception pending&quot;);
 863   // nothing to do - eventually we should remove this code entirely (see comments @ call sites)
 864 JRT_END
 865 
 866 
 867 JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodError(JavaThread* thread))
 868   THROW(vmSymbols::java_lang_AbstractMethodError());
 869 JRT_END
 870 
 871 // This method is called from the &quot;abstract_entry&quot; of the interpreter.
 872 // At that point, the arguments have already been removed from the stack
 873 // and therefore we don&#39;t have the receiver object at our fingertips. (Though,
 874 // on some platforms the receiver still resides in a register...). Thus,
 875 // we have no choice but print an error message not containing the receiver
 876 // type.
 877 JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorWithMethod(JavaThread* thread,
 878                                                                         Method* missingMethod))
 879   ResourceMark rm(thread);
 880   assert(missingMethod != NULL, &quot;sanity&quot;);
 881   methodHandle m(thread, missingMethod);
 882   LinkResolver::throw_abstract_method_error(m, THREAD);
 883 JRT_END
 884 
 885 JRT_ENTRY(void, InterpreterRuntime::throw_AbstractMethodErrorVerbose(JavaThread* thread,
 886                                                                      Klass* recvKlass,
 887                                                                      Method* missingMethod))
 888   ResourceMark rm(thread);
 889   methodHandle mh = methodHandle(thread, missingMethod);
 890   LinkResolver::throw_abstract_method_error(mh, recvKlass, THREAD);
 891 JRT_END
 892 
 893 JRT_ENTRY(void, InterpreterRuntime::throw_InstantiationError(JavaThread* thread))
 894   THROW(vmSymbols::java_lang_InstantiationError());
 895 JRT_END
 896 
 897 
 898 JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeError(JavaThread* thread))
 899   THROW(vmSymbols::java_lang_IncompatibleClassChangeError());
 900 JRT_END
 901 
 902 JRT_ENTRY(void, InterpreterRuntime::throw_IncompatibleClassChangeErrorVerbose(JavaThread* thread,
 903                                                                               Klass* recvKlass,
 904                                                                               Klass* interfaceKlass))
 905   ResourceMark rm(thread);
 906   char buf[1000];
 907   buf[0] = &#39;\0&#39;;
 908   jio_snprintf(buf, sizeof(buf),
 909                &quot;Class %s does not implement the requested interface %s&quot;,
 910                recvKlass ? recvKlass-&gt;external_name() : &quot;NULL&quot;,
 911                interfaceKlass ? interfaceKlass-&gt;external_name() : &quot;NULL&quot;);
 912   THROW_MSG(vmSymbols::java_lang_IncompatibleClassChangeError(), buf);
 913 JRT_END
 914 
 915 //------------------------------------------------------------------------------------------------------------------------
 916 // Fields
 917 //
 918 
 919 void InterpreterRuntime::resolve_get_put(JavaThread* thread, Bytecodes::Code bytecode) {
 920   Thread* THREAD = thread;
 921   // resolve field
 922   fieldDescriptor info;
 923   LastFrameAccessor last_frame(thread);
 924   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
 925   methodHandle m(thread, last_frame.method());
 926   bool is_put    = (bytecode == Bytecodes::_putfield  || bytecode == Bytecodes::_nofast_putfield ||
 927                     bytecode == Bytecodes::_putstatic || bytecode == Bytecodes::_withfield);
 928   bool is_static = (bytecode == Bytecodes::_getstatic || bytecode == Bytecodes::_putstatic);
 929   bool is_inline_type  = bytecode == Bytecodes::_withfield;
 930 
 931   {
 932     JvmtiHideSingleStepping jhss(thread);
 933     LinkResolver::resolve_field_access(info, pool, last_frame.get_index_u2_cpcache(bytecode),
 934                                        m, bytecode, CHECK);
 935   } // end JvmtiHideSingleStepping
 936 
 937   // check if link resolution caused cpCache to be updated
 938   ConstantPoolCacheEntry* cp_cache_entry = last_frame.cache_entry();
 939   if (cp_cache_entry-&gt;is_resolved(bytecode)) return;
 940 
 941   // compute auxiliary field attributes
 942   TosState state  = as_TosState(info.field_type());
 943 
 944   // Resolution of put instructions on final fields is delayed. That is required so that
 945   // exceptions are thrown at the correct place (when the instruction is actually invoked).
 946   // If we do not resolve an instruction in the current pass, leaving the put_code
 947   // set to zero will cause the next put instruction to the same field to reresolve.
 948 
 949   // Resolution of put instructions to final instance fields with invalid updates (i.e.,
 950   // to final instance fields with updates originating from a method different than &lt;init&gt;)
 951   // is inhibited. A putfield instruction targeting an instance final field must throw
 952   // an IllegalAccessError if the instruction is not in an instance
 953   // initializer method &lt;init&gt;. If resolution were not inhibited, a putfield
 954   // in an initializer method could be resolved in the initializer. Subsequent
 955   // putfield instructions to the same field would then use cached information.
 956   // As a result, those instructions would not pass through the VM. That is,
 957   // checks in resolve_field_access() would not be executed for those instructions
 958   // and the required IllegalAccessError would not be thrown.
 959   //
 960   // Also, we need to delay resolving getstatic and putstatic instructions until the
 961   // class is initialized.  This is required so that access to the static
 962   // field will call the initialization function every time until the class
 963   // is completely initialized ala. in 2.17.5 in JVM Specification.
 964   InstanceKlass* klass = info.field_holder();
 965   bool uninitialized_static = is_static &amp;&amp; !klass-&gt;is_initialized();
 966   bool has_initialized_final_update = info.field_holder()-&gt;major_version() &gt;= 53 &amp;&amp;
 967                                       info.has_initialized_final_update();
 968   assert(!(has_initialized_final_update &amp;&amp; !info.access_flags().is_final()), &quot;Fields with initialized final updates must be final&quot;);
 969 
 970   Bytecodes::Code get_code = (Bytecodes::Code)0;
 971   Bytecodes::Code put_code = (Bytecodes::Code)0;
 972   if (!uninitialized_static) {
 973     if (is_static) {
 974       get_code = Bytecodes::_getstatic;
 975     } else {
 976       get_code = Bytecodes::_getfield;
 977     }
 978     if (is_put &amp;&amp; is_inline_type) {
 979         put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_withfield);
 980     } else if ((is_put &amp;&amp; !has_initialized_final_update) || !info.access_flags().is_final()) {
 981         put_code = ((is_static) ? Bytecodes::_putstatic : Bytecodes::_putfield);
 982     }
 983   }
 984 
 985   cp_cache_entry-&gt;set_field(
 986     get_code,
 987     put_code,
 988     info.field_holder(),
 989     info.index(),
 990     info.offset(),
 991     state,
 992     info.access_flags().is_final(),
 993     info.access_flags().is_volatile(),
 994     info.is_inlined(),
 995     info.is_inline_type(),
 996     pool-&gt;pool_holder()
 997   );
 998 }
 999 
1000 
1001 //------------------------------------------------------------------------------------------------------------------------
1002 // Synchronization
1003 //
1004 // The interpreter&#39;s synchronization code is factored out so that it can
1005 // be shared by method invocation and synchronized blocks.
1006 //%note synchronization_3
1007 
1008 //%note monitor_1
1009 JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))
1010 #ifdef ASSERT
1011   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
1012 #endif
1013   if (PrintBiasedLockingStatistics) {
1014     Atomic::inc(BiasedLocking::slow_path_entry_count_addr());
1015   }
1016   Handle h_obj(thread, elem-&gt;obj());
1017   assert(Universe::heap()-&gt;is_in_or_null(h_obj()),
1018          &quot;must be NULL or an object&quot;);
1019   ObjectSynchronizer::enter(h_obj, elem-&gt;lock(), CHECK);
1020   assert(Universe::heap()-&gt;is_in_or_null(elem-&gt;obj()),
1021          &quot;must be NULL or an object&quot;);
1022 #ifdef ASSERT
1023   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
1024 #endif
1025 JRT_END
1026 
1027 
1028 //%note monitor_1
1029 JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorexit(JavaThread* thread, BasicObjectLock* elem))
1030 #ifdef ASSERT
1031   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
1032 #endif
1033   Handle h_obj(thread, elem-&gt;obj());
1034   assert(Universe::heap()-&gt;is_in_or_null(h_obj()),
1035          &quot;must be NULL or an object&quot;);
1036   if (elem == NULL || h_obj()-&gt;is_unlocked()) {
1037     THROW(vmSymbols::java_lang_IllegalMonitorStateException());
1038   }
1039   ObjectSynchronizer::exit(h_obj(), elem-&gt;lock(), thread);
1040   // Free entry. This must be done here, since a pending exception might be installed on
1041   // exit. If it is not cleared, the exception handling code will try to unlock the monitor again.
1042   elem-&gt;set_obj(NULL);
1043 #ifdef ASSERT
1044   thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);
1045 #endif
1046 JRT_END
1047 
1048 
1049 JRT_ENTRY(void, InterpreterRuntime::throw_illegal_monitor_state_exception(JavaThread* thread))
1050   THROW(vmSymbols::java_lang_IllegalMonitorStateException());
1051 JRT_END
1052 
1053 
1054 JRT_ENTRY(void, InterpreterRuntime::new_illegal_monitor_state_exception(JavaThread* thread))
1055   // Returns an illegal exception to install into the current thread. The
1056   // pending_exception flag is cleared so normal exception handling does not
1057   // trigger. Any current installed exception will be overwritten. This
1058   // method will be called during an exception unwind.
1059 
1060   assert(!HAS_PENDING_EXCEPTION, &quot;no pending exception&quot;);
1061   Handle exception(thread, thread-&gt;vm_result());
1062   assert(exception() != NULL, &quot;vm result should be set&quot;);
1063   thread-&gt;set_vm_result(NULL); // clear vm result before continuing (may cause memory leaks and assert failures)
1064   if (!exception-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
1065     exception = get_preinitialized_exception(
1066                        SystemDictionary::IllegalMonitorStateException_klass(),
1067                        CATCH);
1068   }
1069   thread-&gt;set_vm_result(exception());
1070 JRT_END
1071 
1072 
1073 //------------------------------------------------------------------------------------------------------------------------
1074 // Invokes
1075 
1076 JRT_ENTRY(Bytecodes::Code, InterpreterRuntime::get_original_bytecode_at(JavaThread* thread, Method* method, address bcp))
1077   return method-&gt;orig_bytecode_at(method-&gt;bci_from(bcp));
1078 JRT_END
1079 
1080 JRT_ENTRY(void, InterpreterRuntime::set_original_bytecode_at(JavaThread* thread, Method* method, address bcp, Bytecodes::Code new_code))
1081   method-&gt;set_orig_bytecode_at(method-&gt;bci_from(bcp), new_code);
1082 JRT_END
1083 
1084 JRT_ENTRY(void, InterpreterRuntime::_breakpoint(JavaThread* thread, Method* method, address bcp))
1085   JvmtiExport::post_raw_breakpoint(thread, method, bcp);
1086 JRT_END
1087 
1088 void InterpreterRuntime::resolve_invoke(JavaThread* thread, Bytecodes::Code bytecode) {
1089   Thread* THREAD = thread;
1090   LastFrameAccessor last_frame(thread);
1091   // extract receiver from the outgoing argument list if necessary
1092   Handle receiver(thread, NULL);
1093   if (bytecode == Bytecodes::_invokevirtual || bytecode == Bytecodes::_invokeinterface ||
1094       bytecode == Bytecodes::_invokespecial) {
1095     ResourceMark rm(thread);
1096     methodHandle m (thread, last_frame.method());
1097     Bytecode_invoke call(m, last_frame.bci());
1098     Symbol* signature = call.signature();
1099     receiver = Handle(thread, last_frame.callee_receiver(signature));
1100 
1101     assert(Universe::heap()-&gt;is_in_or_null(receiver()),
1102            &quot;sanity check&quot;);
1103     assert(receiver.is_null() ||
1104            !Universe::heap()-&gt;is_in(receiver-&gt;klass()),
1105            &quot;sanity check&quot;);
1106   }
1107 
1108   // resolve method
1109   CallInfo info;
1110   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
1111 
1112   {
1113     JvmtiHideSingleStepping jhss(thread);
1114     LinkResolver::resolve_invoke(info, receiver, pool,
1115                                  last_frame.get_index_u2_cpcache(bytecode), bytecode,
1116                                  CHECK);
1117     if (JvmtiExport::can_hotswap_or_post_breakpoint()) {
1118       int retry_count = 0;
1119       while (info.resolved_method()-&gt;is_old()) {
1120         // It is very unlikely that method is redefined more than 100 times
1121         // in the middle of resolve. If it is looping here more than 100 times
1122         // means then there could be a bug here.
1123         guarantee((retry_count++ &lt; 100),
1124                   &quot;Could not resolve to latest version of redefined method&quot;);
1125         // method is redefined in the middle of resolve so re-try.
1126         LinkResolver::resolve_invoke(info, receiver, pool,
1127                                      last_frame.get_index_u2_cpcache(bytecode), bytecode,
1128                                      CHECK);
1129       }
1130     }
1131   } // end JvmtiHideSingleStepping
1132 
1133   // check if link resolution caused cpCache to be updated
1134   ConstantPoolCacheEntry* cp_cache_entry = last_frame.cache_entry();
1135   if (cp_cache_entry-&gt;is_resolved(bytecode)) return;
1136 
1137 #ifdef ASSERT
1138   if (bytecode == Bytecodes::_invokeinterface) {
1139     if (info.resolved_method()-&gt;method_holder() ==
1140                                             SystemDictionary::Object_klass()) {
1141       // NOTE: THIS IS A FIX FOR A CORNER CASE in the JVM spec
1142       // (see also CallInfo::set_interface for details)
1143       assert(info.call_kind() == CallInfo::vtable_call ||
1144              info.call_kind() == CallInfo::direct_call, &quot;&quot;);
1145       Method* rm = info.resolved_method();
1146       assert(rm-&gt;is_final() || info.has_vtable_index(),
1147              &quot;should have been set already&quot;);
1148     } else if (!info.resolved_method()-&gt;has_itable_index()) {
1149       // Resolved something like CharSequence.toString.  Use vtable not itable.
1150       assert(info.call_kind() != CallInfo::itable_call, &quot;&quot;);
1151     } else {
1152       // Setup itable entry
1153       assert(info.call_kind() == CallInfo::itable_call, &quot;&quot;);
1154       int index = info.resolved_method()-&gt;itable_index();
1155       assert(info.itable_index() == index, &quot;&quot;);
1156     }
1157   } else if (bytecode == Bytecodes::_invokespecial) {
1158     assert(info.call_kind() == CallInfo::direct_call, &quot;must be direct call&quot;);
1159   } else {
1160     assert(info.call_kind() == CallInfo::direct_call ||
1161            info.call_kind() == CallInfo::vtable_call, &quot;&quot;);
1162   }
1163 #endif
1164   // Get sender or sender&#39;s unsafe_anonymous_host, and only set cpCache entry to resolved if
1165   // it is not an interface.  The receiver for invokespecial calls within interface
1166   // methods must be checked for every call.
1167   InstanceKlass* sender = pool-&gt;pool_holder();
1168   sender = sender-&gt;is_unsafe_anonymous() ? sender-&gt;unsafe_anonymous_host() : sender;
1169   methodHandle resolved_method(THREAD, info.resolved_method());
1170 
1171   switch (info.call_kind()) {
1172   case CallInfo::direct_call:
1173     cp_cache_entry-&gt;set_direct_call(
1174       bytecode,
1175       resolved_method,
1176       sender-&gt;is_interface());
1177     break;
1178   case CallInfo::vtable_call:
1179     cp_cache_entry-&gt;set_vtable_call(
1180       bytecode,
1181       resolved_method,
1182       info.vtable_index());
1183     break;
1184   case CallInfo::itable_call:
1185     cp_cache_entry-&gt;set_itable_call(
1186       bytecode,
1187       info.resolved_klass(),
1188       resolved_method,
1189       info.itable_index());
1190     break;
1191   default:  ShouldNotReachHere();
1192   }
1193 }
1194 
1195 
1196 // First time execution:  Resolve symbols, create a permanent MethodType object.
1197 void InterpreterRuntime::resolve_invokehandle(JavaThread* thread) {
1198   Thread* THREAD = thread;
1199   const Bytecodes::Code bytecode = Bytecodes::_invokehandle;
1200   LastFrameAccessor last_frame(thread);
1201 
1202   // resolve method
1203   CallInfo info;
1204   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
1205   {
1206     JvmtiHideSingleStepping jhss(thread);
1207     LinkResolver::resolve_invoke(info, Handle(), pool,
1208                                  last_frame.get_index_u2_cpcache(bytecode), bytecode,
1209                                  CHECK);
1210   } // end JvmtiHideSingleStepping
1211 
1212   ConstantPoolCacheEntry* cp_cache_entry = last_frame.cache_entry();
1213   cp_cache_entry-&gt;set_method_handle(pool, info);
1214 }
1215 
1216 // First time execution:  Resolve symbols, create a permanent CallSite object.
1217 void InterpreterRuntime::resolve_invokedynamic(JavaThread* thread) {
1218   Thread* THREAD = thread;
1219   LastFrameAccessor last_frame(thread);
1220   const Bytecodes::Code bytecode = Bytecodes::_invokedynamic;
1221 
1222   // resolve method
1223   CallInfo info;
1224   constantPoolHandle pool(thread, last_frame.method()-&gt;constants());
1225   int index = last_frame.get_index_u4(bytecode);
1226   {
1227     JvmtiHideSingleStepping jhss(thread);
1228     LinkResolver::resolve_invoke(info, Handle(), pool,
1229                                  index, bytecode, CHECK);
1230   } // end JvmtiHideSingleStepping
1231 
1232   ConstantPoolCacheEntry* cp_cache_entry = pool-&gt;invokedynamic_cp_cache_entry_at(index);
1233   cp_cache_entry-&gt;set_dynamic_call(pool, info);
1234 }
1235 
1236 // This function is the interface to the assembly code. It returns the resolved
1237 // cpCache entry.  This doesn&#39;t safepoint, but the helper routines safepoint.
1238 // This function will check for redefinition!
1239 JRT_ENTRY(void, InterpreterRuntime::resolve_from_cache(JavaThread* thread, Bytecodes::Code bytecode)) {
1240   switch (bytecode) {
1241   case Bytecodes::_getstatic:
1242   case Bytecodes::_putstatic:
1243   case Bytecodes::_getfield:
1244   case Bytecodes::_putfield:
1245   case Bytecodes::_withfield:
1246     resolve_get_put(thread, bytecode);
1247     break;
1248   case Bytecodes::_invokevirtual:
1249   case Bytecodes::_invokespecial:
1250   case Bytecodes::_invokestatic:
1251   case Bytecodes::_invokeinterface:
1252     resolve_invoke(thread, bytecode);
1253     break;
1254   case Bytecodes::_invokehandle:
1255     resolve_invokehandle(thread);
1256     break;
1257   case Bytecodes::_invokedynamic:
1258     resolve_invokedynamic(thread);
1259     break;
1260   default:
1261     fatal(&quot;unexpected bytecode: %s&quot;, Bytecodes::name(bytecode));
1262     break;
1263   }
1264 }
1265 JRT_END
1266 
1267 //------------------------------------------------------------------------------------------------------------------------
1268 // Miscellaneous
1269 
1270 
1271 nmethod* InterpreterRuntime::frequency_counter_overflow(JavaThread* thread, address branch_bcp) {
1272   nmethod* nm = frequency_counter_overflow_inner(thread, branch_bcp);
1273   assert(branch_bcp != NULL || nm == NULL, &quot;always returns null for non OSR requests&quot;);
1274   if (branch_bcp != NULL &amp;&amp; nm != NULL) {
1275     // This was a successful request for an OSR nmethod.  Because
1276     // frequency_counter_overflow_inner ends with a safepoint check,
1277     // nm could have been unloaded so look it up again.  It&#39;s unsafe
1278     // to examine nm directly since it might have been freed and used
1279     // for something else.
1280     LastFrameAccessor last_frame(thread);
1281     Method* method =  last_frame.method();
1282     int bci = method-&gt;bci_from(last_frame.bcp());
1283     nm = method-&gt;lookup_osr_nmethod_for(bci, CompLevel_none, false);
1284     BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
1285     if (nm != NULL &amp;&amp; bs_nm != NULL) {
1286       // in case the transition passed a safepoint we need to barrier this again
1287       if (!bs_nm-&gt;nmethod_osr_entry_barrier(nm)) {
1288         nm = NULL;
1289       }
1290     }
1291   }
1292   if (nm != NULL &amp;&amp; thread-&gt;is_interp_only_mode()) {
1293     // Normally we never get an nm if is_interp_only_mode() is true, because
1294     // policy()-&gt;event has a check for this and won&#39;t compile the method when
1295     // true. However, it&#39;s possible for is_interp_only_mode() to become true
1296     // during the compilation. We don&#39;t want to return the nm in that case
1297     // because we want to continue to execute interpreted.
1298     nm = NULL;
1299   }
1300 #ifndef PRODUCT
1301   if (TraceOnStackReplacement) {
1302     if (nm != NULL) {
1303       tty-&gt;print(&quot;OSR entry @ pc: &quot; INTPTR_FORMAT &quot;: &quot;, p2i(nm-&gt;osr_entry()));
1304       nm-&gt;print();
1305     }
1306   }
1307 #endif
1308   return nm;
1309 }
1310 
1311 JRT_ENTRY(nmethod*,
1312           InterpreterRuntime::frequency_counter_overflow_inner(JavaThread* thread, address branch_bcp))
1313   // use UnlockFlagSaver to clear and restore the _do_not_unlock_if_synchronized
1314   // flag, in case this method triggers classloading which will call into Java.
1315   UnlockFlagSaver fs(thread);
1316 
1317   LastFrameAccessor last_frame(thread);
1318   assert(last_frame.is_interpreted_frame(), &quot;must come from interpreter&quot;);
1319   methodHandle method(thread, last_frame.method());
1320   const int branch_bci = branch_bcp != NULL ? method-&gt;bci_from(branch_bcp) : InvocationEntryBci;
1321   const int bci = branch_bcp != NULL ? method-&gt;bci_from(last_frame.bcp()) : InvocationEntryBci;
1322 
1323   assert(!HAS_PENDING_EXCEPTION, &quot;Should not have any exceptions pending&quot;);
1324   nmethod* osr_nm = CompilationPolicy::policy()-&gt;event(method, method, branch_bci, bci, CompLevel_none, NULL, thread);
1325   assert(!HAS_PENDING_EXCEPTION, &quot;Event handler should not throw any exceptions&quot;);
1326 
1327   BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()-&gt;barrier_set_nmethod();
1328   if (osr_nm != NULL &amp;&amp; bs_nm != NULL) {
1329     if (!bs_nm-&gt;nmethod_osr_entry_barrier(osr_nm)) {
1330       osr_nm = NULL;
1331     }
1332   }
1333 
1334   if (osr_nm != NULL) {
1335     // We may need to do on-stack replacement which requires that no
1336     // monitors in the activation are biased because their
1337     // BasicObjectLocks will need to migrate during OSR. Force
1338     // unbiasing of all monitors in the activation now (even though
1339     // the OSR nmethod might be invalidated) because we don&#39;t have a
1340     // safepoint opportunity later once the migration begins.
1341     if (UseBiasedLocking) {
1342       ResourceMark rm;
1343       GrowableArray&lt;Handle&gt;* objects_to_revoke = new GrowableArray&lt;Handle&gt;();
1344       for( BasicObjectLock *kptr = last_frame.monitor_end();
1345            kptr &lt; last_frame.monitor_begin();
1346            kptr = last_frame.next_monitor(kptr) ) {
1347         if( kptr-&gt;obj() != NULL ) {
1348           objects_to_revoke-&gt;append(Handle(THREAD, kptr-&gt;obj()));
1349         }
1350       }
1351       BiasedLocking::revoke(objects_to_revoke, thread);
1352     }
1353   }
1354   return osr_nm;
1355 JRT_END
1356 
1357 JRT_LEAF(jint, InterpreterRuntime::bcp_to_di(Method* method, address cur_bcp))
1358   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1359   int bci = method-&gt;bci_from(cur_bcp);
1360   MethodData* mdo = method-&gt;method_data();
1361   if (mdo == NULL)  return 0;
1362   return mdo-&gt;bci_to_di(bci);
1363 JRT_END
1364 
1365 JRT_ENTRY(void, InterpreterRuntime::profile_method(JavaThread* thread))
1366   // use UnlockFlagSaver to clear and restore the _do_not_unlock_if_synchronized
1367   // flag, in case this method triggers classloading which will call into Java.
1368   UnlockFlagSaver fs(thread);
1369 
1370   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1371   LastFrameAccessor last_frame(thread);
1372   assert(last_frame.is_interpreted_frame(), &quot;must come from interpreter&quot;);
1373   methodHandle method(thread, last_frame.method());
1374   Method::build_interpreter_method_data(method, THREAD);
1375   if (HAS_PENDING_EXCEPTION) {
1376     assert((PENDING_EXCEPTION-&gt;is_a(SystemDictionary::OutOfMemoryError_klass())), &quot;we expect only an OOM error here&quot;);
1377     CLEAR_PENDING_EXCEPTION;
1378     // and fall through...
1379   }
1380 JRT_END
1381 
1382 
1383 #ifdef ASSERT
1384 JRT_LEAF(void, InterpreterRuntime::verify_mdp(Method* method, address bcp, address mdp))
1385   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1386 
1387   MethodData* mdo = method-&gt;method_data();
1388   assert(mdo != NULL, &quot;must not be null&quot;);
1389 
1390   int bci = method-&gt;bci_from(bcp);
1391 
1392   address mdp2 = mdo-&gt;bci_to_dp(bci);
1393   if (mdp != mdp2) {
1394     ResourceMark rm;
1395     ResetNoHandleMark rnm; // In a LEAF entry.
1396     HandleMark hm;
1397     tty-&gt;print_cr(&quot;FAILED verify : actual mdp %p   expected mdp %p @ bci %d&quot;, mdp, mdp2, bci);
1398     int current_di = mdo-&gt;dp_to_di(mdp);
1399     int expected_di  = mdo-&gt;dp_to_di(mdp2);
1400     tty-&gt;print_cr(&quot;  actual di %d   expected di %d&quot;, current_di, expected_di);
1401     int expected_approx_bci = mdo-&gt;data_at(expected_di)-&gt;bci();
1402     int approx_bci = -1;
1403     if (current_di &gt;= 0) {
1404       approx_bci = mdo-&gt;data_at(current_di)-&gt;bci();
1405     }
1406     tty-&gt;print_cr(&quot;  actual bci is %d  expected bci %d&quot;, approx_bci, expected_approx_bci);
1407     mdo-&gt;print_on(tty);
1408     method-&gt;print_codes();
1409   }
1410   assert(mdp == mdp2, &quot;wrong mdp&quot;);
1411 JRT_END
1412 #endif // ASSERT
1413 
1414 JRT_ENTRY(void, InterpreterRuntime::update_mdp_for_ret(JavaThread* thread, int return_bci))
1415   assert(ProfileInterpreter, &quot;must be profiling interpreter&quot;);
1416   ResourceMark rm(thread);
1417   HandleMark hm(thread);
1418   LastFrameAccessor last_frame(thread);
1419   assert(last_frame.is_interpreted_frame(), &quot;must come from interpreter&quot;);
1420   MethodData* h_mdo = last_frame.method()-&gt;method_data();
1421 
1422   // Grab a lock to ensure atomic access to setting the return bci and
1423   // the displacement.  This can block and GC, invalidating all naked oops.
1424   MutexLocker ml(RetData_lock);
1425 
1426   // ProfileData is essentially a wrapper around a derived oop, so we
1427   // need to take the lock before making any ProfileData structures.
1428   ProfileData* data = h_mdo-&gt;data_at(h_mdo-&gt;dp_to_di(last_frame.mdp()));
1429   guarantee(data != NULL, &quot;profile data must be valid&quot;);
1430   RetData* rdata = data-&gt;as_RetData();
1431   address new_mdp = rdata-&gt;fixup_ret(return_bci, h_mdo);
1432   last_frame.set_mdp(new_mdp);
1433 JRT_END
1434 
1435 JRT_ENTRY(MethodCounters*, InterpreterRuntime::build_method_counters(JavaThread* thread, Method* m))
1436   MethodCounters* mcs = Method::build_method_counters(m, thread);
1437   if (HAS_PENDING_EXCEPTION) {
1438     assert((PENDING_EXCEPTION-&gt;is_a(SystemDictionary::OutOfMemoryError_klass())), &quot;we expect only an OOM error here&quot;);
1439     CLEAR_PENDING_EXCEPTION;
1440   }
1441   return mcs;
1442 JRT_END
1443 
1444 
1445 JRT_ENTRY(void, InterpreterRuntime::at_safepoint(JavaThread* thread))
1446   // We used to need an explict preserve_arguments here for invoke bytecodes. However,
1447   // stack traversal automatically takes care of preserving arguments for invoke, so
1448   // this is no longer needed.
1449 
1450   // JRT_END does an implicit safepoint check, hence we are guaranteed to block
1451   // if this is called during a safepoint
1452 
1453   if (JvmtiExport::should_post_single_step()) {
1454     // We are called during regular safepoints and when the VM is
1455     // single stepping. If any thread is marked for single stepping,
1456     // then we may have JVMTI work to do.
1457     LastFrameAccessor last_frame(thread);
1458     JvmtiExport::at_single_stepping_point(thread, last_frame.method(), last_frame.bcp());
1459   }
1460 JRT_END
1461 
1462 JRT_ENTRY(void, InterpreterRuntime::post_field_access(JavaThread *thread, oopDesc* obj,
1463 ConstantPoolCacheEntry *cp_entry))
1464 
1465   // check the access_flags for the field in the klass
1466 
1467   InstanceKlass* ik = InstanceKlass::cast(cp_entry-&gt;f1_as_klass());
1468   int index = cp_entry-&gt;field_index();
1469   if ((ik-&gt;field_access_flags(index) &amp; JVM_ACC_FIELD_ACCESS_WATCHED) == 0) return;
1470 
1471   bool is_static = (obj == NULL);
1472   bool is_inlined = cp_entry-&gt;is_inlined();
1473   HandleMark hm(thread);
1474 
1475   Handle h_obj;
1476   if (!is_static) {
1477     // non-static field accessors have an object, but we need a handle
1478     h_obj = Handle(thread, obj);
1479   }
1480   InstanceKlass* cp_entry_f1 = InstanceKlass::cast(cp_entry-&gt;f1_as_klass());
1481   jfieldID fid = jfieldIDWorkaround::to_jfieldID(cp_entry_f1, cp_entry-&gt;f2_as_index(), is_static, is_inlined);
1482   LastFrameAccessor last_frame(thread);
1483   JvmtiExport::post_field_access(thread, last_frame.method(), last_frame.bcp(), cp_entry_f1, h_obj, fid);
1484 JRT_END
1485 
1486 JRT_ENTRY(void, InterpreterRuntime::post_field_modification(JavaThread *thread,
1487   oopDesc* obj, ConstantPoolCacheEntry *cp_entry, jvalue *value))
1488 
1489   Klass* k = cp_entry-&gt;f1_as_klass();
1490 
1491   // check the access_flags for the field in the klass
1492   InstanceKlass* ik = InstanceKlass::cast(k);
1493   int index = cp_entry-&gt;field_index();
1494   // bail out if field modifications are not watched
1495   if ((ik-&gt;field_access_flags(index) &amp; JVM_ACC_FIELD_MODIFICATION_WATCHED) == 0) return;
1496 
1497   char sig_type = &#39;\0&#39;;
1498 
1499   switch(cp_entry-&gt;flag_state()) {
1500     case btos: sig_type = JVM_SIGNATURE_BYTE;    break;
1501     case ztos: sig_type = JVM_SIGNATURE_BOOLEAN; break;
1502     case ctos: sig_type = JVM_SIGNATURE_CHAR;    break;
1503     case stos: sig_type = JVM_SIGNATURE_SHORT;   break;
1504     case itos: sig_type = JVM_SIGNATURE_INT;     break;
1505     case ftos: sig_type = JVM_SIGNATURE_FLOAT;   break;
1506     case atos: sig_type = JVM_SIGNATURE_CLASS;   break;
1507     case ltos: sig_type = JVM_SIGNATURE_LONG;    break;
1508     case dtos: sig_type = JVM_SIGNATURE_DOUBLE;  break;
1509     default:  ShouldNotReachHere(); return;
1510   }
1511 
1512   // Both Q-signatures and L-signatures are mapped to atos
1513   if (cp_entry-&gt;flag_state() == atos &amp;&amp; ik-&gt;field_signature(index)-&gt;is_Q_signature()) {
1514     sig_type = JVM_SIGNATURE_INLINE_TYPE;
1515   }
1516 
1517   bool is_static = (obj == NULL);
1518   bool is_inlined = cp_entry-&gt;is_inlined();
1519 
1520   HandleMark hm(thread);
1521   jfieldID fid = jfieldIDWorkaround::to_jfieldID(ik, cp_entry-&gt;f2_as_index(), is_static, is_inlined);
1522   jvalue fvalue;
1523 #ifdef _LP64
1524   fvalue = *value;
1525 #else
1526   // Long/double values are stored unaligned and also noncontiguously with
1527   // tagged stacks.  We can&#39;t just do a simple assignment even in the non-
1528   // J/D cases because a C++ compiler is allowed to assume that a jvalue is
1529   // 8-byte aligned, and interpreter stack slots are only 4-byte aligned.
1530   // We assume that the two halves of longs/doubles are stored in interpreter
1531   // stack slots in platform-endian order.
1532   jlong_accessor u;
1533   jint* newval = (jint*)value;
1534   u.words[0] = newval[0];
1535   u.words[1] = newval[Interpreter::stackElementWords]; // skip if tag
1536   fvalue.j = u.long_value;
1537 #endif // _LP64
1538 
1539   Handle h_obj;
1540   if (!is_static) {
1541     // non-static field accessors have an object, but we need a handle
1542     h_obj = Handle(thread, obj);
1543   }
1544 
1545   LastFrameAccessor last_frame(thread);
1546   JvmtiExport::post_raw_field_modification(thread, last_frame.method(), last_frame.bcp(), ik, h_obj,
1547                                            fid, sig_type, &amp;fvalue);
1548 JRT_END
1549 
1550 JRT_ENTRY(void, InterpreterRuntime::post_method_entry(JavaThread *thread))
1551   LastFrameAccessor last_frame(thread);
1552   JvmtiExport::post_method_entry(thread, last_frame.method(), last_frame.get_frame());
1553 JRT_END
1554 
1555 
1556 JRT_ENTRY(void, InterpreterRuntime::post_method_exit(JavaThread *thread))
1557   LastFrameAccessor last_frame(thread);
1558   JvmtiExport::post_method_exit(thread, last_frame.method(), last_frame.get_frame());
1559 JRT_END
1560 
1561 JRT_LEAF(int, InterpreterRuntime::interpreter_contains(address pc))
1562 {
1563   return (Interpreter::contains(pc) ? 1 : 0);
1564 }
1565 JRT_END
1566 
1567 
1568 // Implementation of SignatureHandlerLibrary
1569 
1570 #ifndef SHARING_FAST_NATIVE_FINGERPRINTS
1571 // Dummy definition (else normalization method is defined in CPU
1572 // dependant code)
1573 uint64_t InterpreterRuntime::normalize_fast_native_fingerprint(uint64_t fingerprint) {
1574   return fingerprint;
1575 }
1576 #endif
1577 
1578 address SignatureHandlerLibrary::set_handler_blob() {
1579   BufferBlob* handler_blob = BufferBlob::create(&quot;native signature handlers&quot;, blob_size);
1580   if (handler_blob == NULL) {
1581     return NULL;
1582   }
1583   address handler = handler_blob-&gt;code_begin();
1584   _handler_blob = handler_blob;
1585   _handler = handler;
1586   return handler;
1587 }
1588 
1589 void SignatureHandlerLibrary::initialize() {
1590   if (_fingerprints != NULL) {
1591     return;
1592   }
1593   if (set_handler_blob() == NULL) {
1594     vm_exit_out_of_memory(blob_size, OOM_MALLOC_ERROR, &quot;native signature handlers&quot;);
1595   }
1596 
1597   BufferBlob* bb = BufferBlob::create(&quot;Signature Handler Temp Buffer&quot;,
1598                                       SignatureHandlerLibrary::buffer_size);
1599   _buffer = bb-&gt;code_begin();
1600 
1601   _fingerprints = new(ResourceObj::C_HEAP, mtCode)GrowableArray&lt;uint64_t&gt;(32, mtCode);
1602   _handlers     = new(ResourceObj::C_HEAP, mtCode)GrowableArray&lt;address&gt;(32, mtCode);
1603 }
1604 
1605 address SignatureHandlerLibrary::set_handler(CodeBuffer* buffer) {
1606   address handler   = _handler;
1607   int     insts_size = buffer-&gt;pure_insts_size();
1608   if (handler + insts_size &gt; _handler_blob-&gt;code_end()) {
1609     // get a new handler blob
1610     handler = set_handler_blob();
1611   }
1612   if (handler != NULL) {
1613     memcpy(handler, buffer-&gt;insts_begin(), insts_size);
1614     pd_set_handler(handler);
1615     ICache::invalidate_range(handler, insts_size);
1616     _handler = handler + insts_size;
1617   }
1618   return handler;
1619 }
1620 
1621 void SignatureHandlerLibrary::add(const methodHandle&amp; method) {
1622   if (method-&gt;signature_handler() == NULL) {
1623     // use slow signature handler if we can&#39;t do better
1624     int handler_index = -1;
1625     // check if we can use customized (fast) signature handler
1626     if (UseFastSignatureHandlers &amp;&amp; method-&gt;size_of_parameters() &lt;= Fingerprinter::fp_max_size_of_parameters) {
1627       // use customized signature handler
1628       MutexLocker mu(SignatureHandlerLibrary_lock);
1629       // make sure data structure is initialized
1630       initialize();
1631       // lookup method signature&#39;s fingerprint
1632       uint64_t fingerprint = Fingerprinter(method).fingerprint();
1633       // allow CPU dependant code to optimize the fingerprints for the fast handler
1634       fingerprint = InterpreterRuntime::normalize_fast_native_fingerprint(fingerprint);
1635       handler_index = _fingerprints-&gt;find(fingerprint);
1636       // create handler if necessary
1637       if (handler_index &lt; 0) {
1638         ResourceMark rm;
1639         ptrdiff_t align_offset = align_up(_buffer, CodeEntryAlignment) - (address)_buffer;
1640         CodeBuffer buffer((address)(_buffer + align_offset),
1641                           SignatureHandlerLibrary::buffer_size - align_offset);
1642         InterpreterRuntime::SignatureHandlerGenerator(method, &amp;buffer).generate(fingerprint);
1643         // copy into code heap
1644         address handler = set_handler(&amp;buffer);
1645         if (handler == NULL) {
1646           // use slow signature handler (without memorizing it in the fingerprints)
1647         } else {
1648           // debugging suppport
1649           if (PrintSignatureHandlers &amp;&amp; (handler != Interpreter::slow_signature_handler())) {
1650             ttyLocker ttyl;
1651             tty-&gt;cr();
1652             tty-&gt;print_cr(&quot;argument handler #%d for: %s %s (fingerprint = &quot; UINT64_FORMAT &quot;, %d bytes generated)&quot;,
1653                           _handlers-&gt;length(),
1654                           (method-&gt;is_static() ? &quot;static&quot; : &quot;receiver&quot;),
1655                           method-&gt;name_and_sig_as_C_string(),
1656                           fingerprint,
1657                           buffer.insts_size());
1658             if (buffer.insts_size() &gt; 0) {
1659               Disassembler::decode(handler, handler + buffer.insts_size());
1660             }
1661 #ifndef PRODUCT
1662             address rh_begin = Interpreter::result_handler(method()-&gt;result_type());
1663             if (CodeCache::contains(rh_begin)) {
1664               // else it might be special platform dependent values
1665               tty-&gt;print_cr(&quot; --- associated result handler ---&quot;);
1666               address rh_end = rh_begin;
1667               while (*(int*)rh_end != 0) {
1668                 rh_end += sizeof(int);
1669               }
1670               Disassembler::decode(rh_begin, rh_end);
1671             } else {
1672               tty-&gt;print_cr(&quot; associated result handler: &quot; PTR_FORMAT, p2i(rh_begin));
1673             }
1674 #endif
1675           }
1676           // add handler to library
1677           _fingerprints-&gt;append(fingerprint);
1678           _handlers-&gt;append(handler);
1679           // set handler index
1680           assert(_fingerprints-&gt;length() == _handlers-&gt;length(), &quot;sanity check&quot;);
1681           handler_index = _fingerprints-&gt;length() - 1;
1682         }
1683       }
1684       // Set handler under SignatureHandlerLibrary_lock
1685       if (handler_index &lt; 0) {
1686         // use generic signature handler
1687         method-&gt;set_signature_handler(Interpreter::slow_signature_handler());
1688       } else {
1689         // set handler
1690         method-&gt;set_signature_handler(_handlers-&gt;at(handler_index));
1691       }
1692     } else {
1693       DEBUG_ONLY(Thread::current()-&gt;check_possible_safepoint());
1694       // use generic signature handler
1695       method-&gt;set_signature_handler(Interpreter::slow_signature_handler());
1696     }
1697   }
1698 #ifdef ASSERT
1699   int handler_index = -1;
1700   int fingerprint_index = -2;
1701   {
1702     // &#39;_handlers&#39; and &#39;_fingerprints&#39; are &#39;GrowableArray&#39;s and are NOT synchronized
1703     // in any way if accessed from multiple threads. To avoid races with another
1704     // thread which may change the arrays in the above, mutex protected block, we
1705     // have to protect this read access here with the same mutex as well!
1706     MutexLocker mu(SignatureHandlerLibrary_lock);
1707     if (_handlers != NULL) {
1708       handler_index = _handlers-&gt;find(method-&gt;signature_handler());
1709       uint64_t fingerprint = Fingerprinter(method).fingerprint();
1710       fingerprint = InterpreterRuntime::normalize_fast_native_fingerprint(fingerprint);
1711       fingerprint_index = _fingerprints-&gt;find(fingerprint);
1712     }
1713   }
1714   assert(method-&gt;signature_handler() == Interpreter::slow_signature_handler() ||
1715          handler_index == fingerprint_index, &quot;sanity check&quot;);
1716 #endif // ASSERT
1717 }
1718 
1719 void SignatureHandlerLibrary::add(uint64_t fingerprint, address handler) {
1720   int handler_index = -1;
1721   // use customized signature handler
1722   MutexLocker mu(SignatureHandlerLibrary_lock);
1723   // make sure data structure is initialized
1724   initialize();
1725   fingerprint = InterpreterRuntime::normalize_fast_native_fingerprint(fingerprint);
1726   handler_index = _fingerprints-&gt;find(fingerprint);
1727   // create handler if necessary
1728   if (handler_index &lt; 0) {
1729     if (PrintSignatureHandlers &amp;&amp; (handler != Interpreter::slow_signature_handler())) {
1730       tty-&gt;cr();
1731       tty-&gt;print_cr(&quot;argument handler #%d at &quot; PTR_FORMAT &quot; for fingerprint &quot; UINT64_FORMAT,
1732                     _handlers-&gt;length(),
1733                     p2i(handler),
1734                     fingerprint);
1735     }
1736     _fingerprints-&gt;append(fingerprint);
1737     _handlers-&gt;append(handler);
1738   } else {
1739     if (PrintSignatureHandlers) {
1740       tty-&gt;cr();
1741       tty-&gt;print_cr(&quot;duplicate argument handler #%d for fingerprint &quot; UINT64_FORMAT &quot;(old: &quot; PTR_FORMAT &quot;, new : &quot; PTR_FORMAT &quot;)&quot;,
1742                     _handlers-&gt;length(),
1743                     fingerprint,
1744                     p2i(_handlers-&gt;at(handler_index)),
1745                     p2i(handler));
1746     }
1747   }
1748 }
1749 
1750 
1751 BufferBlob*              SignatureHandlerLibrary::_handler_blob = NULL;
1752 address                  SignatureHandlerLibrary::_handler      = NULL;
1753 GrowableArray&lt;uint64_t&gt;* SignatureHandlerLibrary::_fingerprints = NULL;
1754 GrowableArray&lt;address&gt;*  SignatureHandlerLibrary::_handlers     = NULL;
1755 address                  SignatureHandlerLibrary::_buffer       = NULL;
1756 
1757 
1758 JRT_ENTRY(void, InterpreterRuntime::prepare_native_call(JavaThread* thread, Method* method))
1759   methodHandle m(thread, method);
1760   assert(m-&gt;is_native(), &quot;sanity check&quot;);
1761   // lookup native function entry point if it doesn&#39;t exist
1762   bool in_base_library;
1763   if (!m-&gt;has_native_function()) {
1764     NativeLookup::lookup(m, in_base_library, CHECK);
1765   }
1766   // make sure signature handler is installed
1767   SignatureHandlerLibrary::add(m);
1768   // The interpreter entry point checks the signature handler first,
1769   // before trying to fetch the native entry point and klass mirror.
1770   // We must set the signature handler last, so that multiple processors
1771   // preparing the same method will be sure to see non-null entry &amp; mirror.
1772 JRT_END
1773 
1774 #if defined(IA32) || defined(AMD64) || defined(ARM)
1775 JRT_LEAF(void, InterpreterRuntime::popframe_move_outgoing_args(JavaThread* thread, void* src_address, void* dest_address))
1776   if (src_address == dest_address) {
1777     return;
1778   }
1779   ResetNoHandleMark rnm; // In a LEAF entry.
1780   HandleMark hm;
1781   ResourceMark rm;
1782   LastFrameAccessor last_frame(thread);
1783   assert(last_frame.is_interpreted_frame(), &quot;&quot;);
1784   jint bci = last_frame.bci();
1785   methodHandle mh(thread, last_frame.method());
1786   Bytecode_invoke invoke(mh, bci);
1787   ArgumentSizeComputer asc(invoke.signature());
1788   int size_of_arguments = (asc.size() + (invoke.has_receiver() ? 1 : 0)); // receiver
1789   Copy::conjoint_jbytes(src_address, dest_address,
1790                        size_of_arguments * Interpreter::stackElementSize);
1791 JRT_END
1792 #endif
1793 
1794 #if INCLUDE_JVMTI
1795 // This is a support of the JVMTI PopFrame interface.
1796 // Make sure it is an invokestatic of a polymorphic intrinsic that has a member_name argument
1797 // and return it as a vm_result so that it can be reloaded in the list of invokestatic parameters.
1798 // The member_name argument is a saved reference (in local#0) to the member_name.
1799 // For backward compatibility with some JDK versions (7, 8) it can also be a direct method handle.
1800 // FIXME: remove DMH case after j.l.i.InvokerBytecodeGenerator code shape is updated.
1801 JRT_ENTRY(void, InterpreterRuntime::member_name_arg_or_null(JavaThread* thread, address member_name,
1802                                                             Method* method, address bcp))
1803   Bytecodes::Code code = Bytecodes::code_at(method, bcp);
1804   if (code != Bytecodes::_invokestatic) {
1805     return;
1806   }
1807   ConstantPool* cpool = method-&gt;constants();
1808   int cp_index = Bytes::get_native_u2(bcp + 1) + ConstantPool::CPCACHE_INDEX_TAG;
1809   Symbol* cname = cpool-&gt;klass_name_at(cpool-&gt;klass_ref_index_at(cp_index));
1810   Symbol* mname = cpool-&gt;name_ref_at(cp_index);
1811 
1812   if (MethodHandles::has_member_arg(cname, mname)) {
1813     oop member_name_oop = (oop) member_name;
1814     if (java_lang_invoke_DirectMethodHandle::is_instance(member_name_oop)) {
1815       // FIXME: remove after j.l.i.InvokerBytecodeGenerator code shape is updated.
1816       member_name_oop = java_lang_invoke_DirectMethodHandle::member(member_name_oop);
1817     }
1818     thread-&gt;set_vm_result(member_name_oop);
1819   } else {
1820     thread-&gt;set_vm_result(NULL);
1821   }
1822 JRT_END
1823 #endif // INCLUDE_JVMTI
1824 
1825 #ifndef PRODUCT
1826 // This must be a JRT_LEAF function because the interpreter must save registers on x86 to
1827 // call this, which changes rsp and makes the interpreter&#39;s expression stack not walkable.
1828 // The generated code still uses call_VM because that will set up the frame pointer for
1829 // bcp and method.
1830 JRT_LEAF(intptr_t, InterpreterRuntime::trace_bytecode(JavaThread* thread, intptr_t preserve_this_value, intptr_t tos, intptr_t tos2))
1831   LastFrameAccessor last_frame(thread);
1832   assert(last_frame.is_interpreted_frame(), &quot;must be an interpreted frame&quot;);
1833   methodHandle mh(thread, last_frame.method());
1834   BytecodeTracer::trace(mh, last_frame.bcp(), tos, tos2);
1835   return preserve_this_value;
1836 JRT_END
1837 #endif // !PRODUCT
    </pre>
  </body>
</html>