<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/cpu/aarch64/aarch64.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
    1 //
    2 // Copyright (c) 2003, 2020, Oracle and/or its affiliates. All rights reserved.
    3 // Copyright (c) 2014, 2020, Red Hat, Inc. All rights reserved.
    4 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    5 //
    6 // This code is free software; you can redistribute it and/or modify it
    7 // under the terms of the GNU General Public License version 2 only, as
    8 // published by the Free Software Foundation.
    9 //
   10 // This code is distributed in the hope that it will be useful, but WITHOUT
   11 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   12 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   13 // version 2 for more details (a copy is included in the LICENSE file that
   14 // accompanied this code).
   15 //
   16 // You should have received a copy of the GNU General Public License version
   17 // 2 along with this work; if not, write to the Free Software Foundation,
   18 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   19 //
   20 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   21 // or visit www.oracle.com if you need additional information or have any
   22 // questions.
   23 //
   24 //
   25 
   26 // AArch64 Architecture Description File
   27 
   28 //----------REGISTER DEFINITION BLOCK------------------------------------------
   29 // This information is used by the matcher and the register allocator to
   30 // describe individual registers and classes of registers within the target
   31 // archtecture.
   32 
   33 register %{
   34 //----------Architecture Description Register Definitions----------------------
   35 // General Registers
   36 // &quot;reg_def&quot;  name ( register save type, C convention save type,
   37 //                   ideal register type, encoding );
   38 // Register Save Types:
   39 //
   40 // NS  = No-Save:       The register allocator assumes that these registers
   41 //                      can be used without saving upon entry to the method, &amp;
   42 //                      that they do not need to be saved at call sites.
   43 //
   44 // SOC = Save-On-Call:  The register allocator assumes that these registers
   45 //                      can be used without saving upon entry to the method,
   46 //                      but that they must be saved at call sites.
   47 //
   48 // SOE = Save-On-Entry: The register allocator assumes that these registers
   49 //                      must be saved before using them upon entry to the
   50 //                      method, but they do not need to be saved at call
   51 //                      sites.
   52 //
   53 // AS  = Always-Save:   The register allocator assumes that these registers
   54 //                      must be saved before using them upon entry to the
   55 //                      method, &amp; that they must be saved at call sites.
   56 //
   57 // Ideal Register Type is used to determine how to save &amp; restore a
   58 // register.  Op_RegI will get spilled with LoadI/StoreI, Op_RegP will get
   59 // spilled with LoadP/StoreP.  If the register supports both, use Op_RegI.
   60 //
   61 // The encoding number is the actual bit-pattern placed into the opcodes.
   62 
   63 // We must define the 64 bit int registers in two 32 bit halves, the
   64 // real lower register and a virtual upper half register. upper halves
   65 // are used by the register allocator but are not actually supplied as
   66 // operands to memory ops.
   67 //
   68 // follow the C1 compiler in making registers
   69 //
   70 //   r0-r7,r10-r26 volatile (caller save)
   71 //   r27-r32 system (no save, no allocate)
   72 //   r8-r9 invisible to the allocator (so we can use them as scratch regs)
   73 //
   74 // as regards Java usage. we don&#39;t use any callee save registers
   75 // because this makes it difficult to de-optimise a frame (see comment
   76 // in x86 implementation of Deoptimization::unwind_callee_save_values)
   77 //
   78 
   79 // General Registers
   80 
   81 reg_def R0      ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()         );
   82 reg_def R0_H    ( SOC, SOC, Op_RegI,  0, r0-&gt;as_VMReg()-&gt;next() );
   83 reg_def R1      ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()         );
   84 reg_def R1_H    ( SOC, SOC, Op_RegI,  1, r1-&gt;as_VMReg()-&gt;next() );
   85 reg_def R2      ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()         );
   86 reg_def R2_H    ( SOC, SOC, Op_RegI,  2, r2-&gt;as_VMReg()-&gt;next() );
   87 reg_def R3      ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()         );
   88 reg_def R3_H    ( SOC, SOC, Op_RegI,  3, r3-&gt;as_VMReg()-&gt;next() );
   89 reg_def R4      ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()         );
   90 reg_def R4_H    ( SOC, SOC, Op_RegI,  4, r4-&gt;as_VMReg()-&gt;next() );
   91 reg_def R5      ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()         );
   92 reg_def R5_H    ( SOC, SOC, Op_RegI,  5, r5-&gt;as_VMReg()-&gt;next() );
   93 reg_def R6      ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()         );
   94 reg_def R6_H    ( SOC, SOC, Op_RegI,  6, r6-&gt;as_VMReg()-&gt;next() );
   95 reg_def R7      ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()         );
   96 reg_def R7_H    ( SOC, SOC, Op_RegI,  7, r7-&gt;as_VMReg()-&gt;next() );
   97 reg_def R10     ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()        );
   98 reg_def R10_H   ( SOC, SOC, Op_RegI, 10, r10-&gt;as_VMReg()-&gt;next());
   99 reg_def R11     ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()        );
  100 reg_def R11_H   ( SOC, SOC, Op_RegI, 11, r11-&gt;as_VMReg()-&gt;next());
  101 reg_def R12     ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()        );
  102 reg_def R12_H   ( SOC, SOC, Op_RegI, 12, r12-&gt;as_VMReg()-&gt;next());
  103 reg_def R13     ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()        );
  104 reg_def R13_H   ( SOC, SOC, Op_RegI, 13, r13-&gt;as_VMReg()-&gt;next());
  105 reg_def R14     ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()        );
  106 reg_def R14_H   ( SOC, SOC, Op_RegI, 14, r14-&gt;as_VMReg()-&gt;next());
  107 reg_def R15     ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()        );
  108 reg_def R15_H   ( SOC, SOC, Op_RegI, 15, r15-&gt;as_VMReg()-&gt;next());
  109 reg_def R16     ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()        );
  110 reg_def R16_H   ( SOC, SOC, Op_RegI, 16, r16-&gt;as_VMReg()-&gt;next());
  111 reg_def R17     ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()        );
  112 reg_def R17_H   ( SOC, SOC, Op_RegI, 17, r17-&gt;as_VMReg()-&gt;next());
  113 reg_def R18     ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()        );
  114 reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18-&gt;as_VMReg()-&gt;next());
  115 reg_def R19     ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()        );
  116 reg_def R19_H   ( SOC, SOE, Op_RegI, 19, r19-&gt;as_VMReg()-&gt;next());
  117 reg_def R20     ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()        ); // caller esp
  118 reg_def R20_H   ( SOC, SOE, Op_RegI, 20, r20-&gt;as_VMReg()-&gt;next());
  119 reg_def R21     ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()        );
  120 reg_def R21_H   ( SOC, SOE, Op_RegI, 21, r21-&gt;as_VMReg()-&gt;next());
  121 reg_def R22     ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()        );
  122 reg_def R22_H   ( SOC, SOE, Op_RegI, 22, r22-&gt;as_VMReg()-&gt;next());
  123 reg_def R23     ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()        );
  124 reg_def R23_H   ( SOC, SOE, Op_RegI, 23, r23-&gt;as_VMReg()-&gt;next());
  125 reg_def R24     ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()        );
  126 reg_def R24_H   ( SOC, SOE, Op_RegI, 24, r24-&gt;as_VMReg()-&gt;next());
  127 reg_def R25     ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()        );
  128 reg_def R25_H   ( SOC, SOE, Op_RegI, 25, r25-&gt;as_VMReg()-&gt;next());
  129 reg_def R26     ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()        );
  130 reg_def R26_H   ( SOC, SOE, Op_RegI, 26, r26-&gt;as_VMReg()-&gt;next());
  131 reg_def R27     ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()        ); // heapbase
  132 reg_def R27_H   ( SOC, SOE, Op_RegI, 27, r27-&gt;as_VMReg()-&gt;next());
  133 reg_def R28     (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()        ); // thread
  134 reg_def R28_H   (  NS, SOE, Op_RegI, 28, r28-&gt;as_VMReg()-&gt;next());
  135 reg_def R29     (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()        ); // fp
  136 reg_def R29_H   (  NS,  NS, Op_RegI, 29, r29-&gt;as_VMReg()-&gt;next());
  137 reg_def R30     (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()        ); // lr
  138 reg_def R30_H   (  NS,  NS, Op_RegI, 30, r30-&gt;as_VMReg()-&gt;next());
  139 reg_def R31     (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()     ); // sp
  140 reg_def R31_H   (  NS,  NS, Op_RegI, 31, r31_sp-&gt;as_VMReg()-&gt;next());
  141 
  142 // ----------------------------
  143 // Float/Double Registers
  144 // ----------------------------
  145 
  146 // Double Registers
  147 
  148 // The rules of ADL require that double registers be defined in pairs.
  149 // Each pair must be two 32-bit values, but not necessarily a pair of
  150 // single float registers. In each pair, ADLC-assigned register numbers
  151 // must be adjacent, with the lower number even. Finally, when the
  152 // CPU stores such a register pair to memory, the word associated with
  153 // the lower ADLC-assigned number must be stored to the lower address.
  154 
  155 // AArch64 has 32 floating-point registers. Each can store a vector of
  156 // single or double precision floating-point values up to 8 * 32
  157 // floats, 4 * 64 bit floats or 2 * 128 bit floats.  We currently only
  158 // use the first float or double element of the vector.
  159 
  160 // for Java use float registers v0-v15 are always save on call whereas
  161 // the platform ABI treats v8-v15 as callee save). float registers
  162 // v16-v31 are SOC as per the platform spec
  163 
  164   reg_def V0   ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()          );
  165   reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next()  );
  166   reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(2) );
  167   reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0-&gt;as_VMReg()-&gt;next(3) );
  168 
  169   reg_def V1   ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()          );
  170   reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next()  );
  171   reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(2) );
  172   reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1-&gt;as_VMReg()-&gt;next(3) );
  173 
  174   reg_def V2   ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()          );
  175   reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next()  );
  176   reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(2) );
  177   reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2-&gt;as_VMReg()-&gt;next(3) );
  178 
  179   reg_def V3   ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()          );
  180   reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next()  );
  181   reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(2) );
  182   reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3-&gt;as_VMReg()-&gt;next(3) );
  183 
  184   reg_def V4   ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()          );
  185   reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next()  );
  186   reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(2) );
  187   reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4-&gt;as_VMReg()-&gt;next(3) );
  188 
  189   reg_def V5   ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()          );
  190   reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next()  );
  191   reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(2) );
  192   reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5-&gt;as_VMReg()-&gt;next(3) );
  193 
  194   reg_def V6   ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()          );
  195   reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next()  );
  196   reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(2) );
  197   reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6-&gt;as_VMReg()-&gt;next(3) );
  198 
  199   reg_def V7   ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()          );
  200   reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next()  );
  201   reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(2) );
  202   reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7-&gt;as_VMReg()-&gt;next(3) );
  203 
  204   reg_def V8   ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()          );
  205   reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next()  );
  206   reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(2) );
  207   reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8-&gt;as_VMReg()-&gt;next(3) );
  208 
  209   reg_def V9   ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()          );
  210   reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next()  );
  211   reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(2) );
  212   reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9-&gt;as_VMReg()-&gt;next(3) );
  213 
  214   reg_def V10  ( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()         );
  215   reg_def V10_H( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next() );
  216   reg_def V10_J( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(2));
  217   reg_def V10_K( SOC, SOC, Op_RegF, 10, v10-&gt;as_VMReg()-&gt;next(3));
  218 
  219   reg_def V11  ( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()         );
  220   reg_def V11_H( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next() );
  221   reg_def V11_J( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(2));
  222   reg_def V11_K( SOC, SOC, Op_RegF, 11, v11-&gt;as_VMReg()-&gt;next(3));
  223 
  224   reg_def V12  ( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()         );
  225   reg_def V12_H( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next() );
  226   reg_def V12_J( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(2));
  227   reg_def V12_K( SOC, SOC, Op_RegF, 12, v12-&gt;as_VMReg()-&gt;next(3));
  228 
  229   reg_def V13  ( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()         );
  230   reg_def V13_H( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next() );
  231   reg_def V13_J( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(2));
  232   reg_def V13_K( SOC, SOC, Op_RegF, 13, v13-&gt;as_VMReg()-&gt;next(3));
  233 
  234   reg_def V14  ( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()         );
  235   reg_def V14_H( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next() );
  236   reg_def V14_J( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(2));
  237   reg_def V14_K( SOC, SOC, Op_RegF, 14, v14-&gt;as_VMReg()-&gt;next(3));
  238 
  239   reg_def V15  ( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()         );
  240   reg_def V15_H( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next() );
  241   reg_def V15_J( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(2));
  242   reg_def V15_K( SOC, SOC, Op_RegF, 15, v15-&gt;as_VMReg()-&gt;next(3));
  243 
  244   reg_def V16  ( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()         );
  245   reg_def V16_H( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next() );
  246   reg_def V16_J( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(2));
  247   reg_def V16_K( SOC, SOC, Op_RegF, 16, v16-&gt;as_VMReg()-&gt;next(3));
  248 
  249   reg_def V17  ( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()         );
  250   reg_def V17_H( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next() );
  251   reg_def V17_J( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(2));
  252   reg_def V17_K( SOC, SOC, Op_RegF, 17, v17-&gt;as_VMReg()-&gt;next(3));
  253 
  254   reg_def V18  ( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()         );
  255   reg_def V18_H( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next() );
  256   reg_def V18_J( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(2));
  257   reg_def V18_K( SOC, SOC, Op_RegF, 18, v18-&gt;as_VMReg()-&gt;next(3));
  258 
  259   reg_def V19  ( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()         );
  260   reg_def V19_H( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next() );
  261   reg_def V19_J( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(2));
  262   reg_def V19_K( SOC, SOC, Op_RegF, 19, v19-&gt;as_VMReg()-&gt;next(3));
  263 
  264   reg_def V20  ( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()         );
  265   reg_def V20_H( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next() );
  266   reg_def V20_J( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(2));
  267   reg_def V20_K( SOC, SOC, Op_RegF, 20, v20-&gt;as_VMReg()-&gt;next(3));
  268 
  269   reg_def V21  ( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()         );
  270   reg_def V21_H( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next() );
  271   reg_def V21_J( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(2));
  272   reg_def V21_K( SOC, SOC, Op_RegF, 21, v21-&gt;as_VMReg()-&gt;next(3));
  273 
  274   reg_def V22  ( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()         );
  275   reg_def V22_H( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next() );
  276   reg_def V22_J( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(2));
  277   reg_def V22_K( SOC, SOC, Op_RegF, 22, v22-&gt;as_VMReg()-&gt;next(3));
  278 
  279   reg_def V23  ( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()         );
  280   reg_def V23_H( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next() );
  281   reg_def V23_J( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(2));
  282   reg_def V23_K( SOC, SOC, Op_RegF, 23, v23-&gt;as_VMReg()-&gt;next(3));
  283 
  284   reg_def V24  ( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()         );
  285   reg_def V24_H( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next() );
  286   reg_def V24_J( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(2));
  287   reg_def V24_K( SOC, SOC, Op_RegF, 24, v24-&gt;as_VMReg()-&gt;next(3));
  288 
  289   reg_def V25  ( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()         );
  290   reg_def V25_H( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next() );
  291   reg_def V25_J( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(2));
  292   reg_def V25_K( SOC, SOC, Op_RegF, 25, v25-&gt;as_VMReg()-&gt;next(3));
  293 
  294   reg_def V26  ( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()         );
  295   reg_def V26_H( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next() );
  296   reg_def V26_J( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(2));
  297   reg_def V26_K( SOC, SOC, Op_RegF, 26, v26-&gt;as_VMReg()-&gt;next(3));
  298 
  299   reg_def V27  ( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()         );
  300   reg_def V27_H( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next() );
  301   reg_def V27_J( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(2));
  302   reg_def V27_K( SOC, SOC, Op_RegF, 27, v27-&gt;as_VMReg()-&gt;next(3));
  303 
  304   reg_def V28  ( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()         );
  305   reg_def V28_H( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next() );
  306   reg_def V28_J( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(2));
  307   reg_def V28_K( SOC, SOC, Op_RegF, 28, v28-&gt;as_VMReg()-&gt;next(3));
  308 
  309   reg_def V29  ( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()         );
  310   reg_def V29_H( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next() );
  311   reg_def V29_J( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(2));
  312   reg_def V29_K( SOC, SOC, Op_RegF, 29, v29-&gt;as_VMReg()-&gt;next(3));
  313 
  314   reg_def V30  ( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()         );
  315   reg_def V30_H( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next() );
  316   reg_def V30_J( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(2));
  317   reg_def V30_K( SOC, SOC, Op_RegF, 30, v30-&gt;as_VMReg()-&gt;next(3));
  318 
  319   reg_def V31  ( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()         );
  320   reg_def V31_H( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next() );
  321   reg_def V31_J( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(2));
  322   reg_def V31_K( SOC, SOC, Op_RegF, 31, v31-&gt;as_VMReg()-&gt;next(3));
  323 
  324 // ----------------------------
  325 // Special Registers
  326 // ----------------------------
  327 
  328 // the AArch64 CSPR status flag register is not directly acessible as
  329 // instruction operand. the FPSR status flag register is a system
  330 // register which can be written/read using MSR/MRS but again does not
  331 // appear as an operand (a code identifying the FSPR occurs as an
  332 // immediate value in the instruction).
  333 
  334 reg_def RFLAGS(SOC, SOC, 0, 32, VMRegImpl::Bad());
  335 
  336 
  337 // Specify priority of register selection within phases of register
  338 // allocation.  Highest priority is first.  A useful heuristic is to
  339 // give registers a low priority when they are required by machine
  340 // instructions, like EAX and EDX on I486, and choose no-save registers
  341 // before save-on-call, &amp; save-on-call before save-on-entry.  Registers
  342 // which participate in fixed calling sequences should come last.
  343 // Registers which are used as pairs must fall on an even boundary.
  344 
  345 alloc_class chunk0(
  346     // volatiles
  347     R10, R10_H,
  348     R11, R11_H,
  349     R12, R12_H,
  350     R13, R13_H,
  351     R14, R14_H,
  352     R15, R15_H,
  353     R16, R16_H,
  354     R17, R17_H,
  355     R18, R18_H,
  356 
  357     // arg registers
  358     R0, R0_H,
  359     R1, R1_H,
  360     R2, R2_H,
  361     R3, R3_H,
  362     R4, R4_H,
  363     R5, R5_H,
  364     R6, R6_H,
  365     R7, R7_H,
  366 
  367     // non-volatiles
  368     R19, R19_H,
  369     R20, R20_H,
  370     R21, R21_H,
  371     R22, R22_H,
  372     R23, R23_H,
  373     R24, R24_H,
  374     R25, R25_H,
  375     R26, R26_H,
  376 
  377     // non-allocatable registers
  378 
  379     R27, R27_H, // heapbase
  380     R28, R28_H, // thread
  381     R29, R29_H, // fp
  382     R30, R30_H, // lr
  383     R31, R31_H, // sp
  384 );
  385 
  386 alloc_class chunk1(
  387 
  388     // no save
  389     V16, V16_H, V16_J, V16_K,
  390     V17, V17_H, V17_J, V17_K,
  391     V18, V18_H, V18_J, V18_K,
  392     V19, V19_H, V19_J, V19_K,
  393     V20, V20_H, V20_J, V20_K,
  394     V21, V21_H, V21_J, V21_K,
  395     V22, V22_H, V22_J, V22_K,
  396     V23, V23_H, V23_J, V23_K,
  397     V24, V24_H, V24_J, V24_K,
  398     V25, V25_H, V25_J, V25_K,
  399     V26, V26_H, V26_J, V26_K,
  400     V27, V27_H, V27_J, V27_K,
  401     V28, V28_H, V28_J, V28_K,
  402     V29, V29_H, V29_J, V29_K,
  403     V30, V30_H, V30_J, V30_K,
  404     V31, V31_H, V31_J, V31_K,
  405 
  406     // arg registers
  407     V0, V0_H, V0_J, V0_K,
  408     V1, V1_H, V1_J, V1_K,
  409     V2, V2_H, V2_J, V2_K,
  410     V3, V3_H, V3_J, V3_K,
  411     V4, V4_H, V4_J, V4_K,
  412     V5, V5_H, V5_J, V5_K,
  413     V6, V6_H, V6_J, V6_K,
  414     V7, V7_H, V7_J, V7_K,
  415 
  416     // non-volatiles
  417     V8, V8_H, V8_J, V8_K,
  418     V9, V9_H, V9_J, V9_K,
  419     V10, V10_H, V10_J, V10_K,
  420     V11, V11_H, V11_J, V11_K,
  421     V12, V12_H, V12_J, V12_K,
  422     V13, V13_H, V13_J, V13_K,
  423     V14, V14_H, V14_J, V14_K,
  424     V15, V15_H, V15_J, V15_K,
  425 );
  426 
  427 alloc_class chunk2(RFLAGS);
  428 
  429 //----------Architecture Description Register Classes--------------------------
  430 // Several register classes are automatically defined based upon information in
  431 // this architecture description.
  432 // 1) reg_class inline_cache_reg           ( /* as def&#39;d in frame section */ )
  433 // 2) reg_class compiler_method_oop_reg    ( /* as def&#39;d in frame section */ )
  434 // 2) reg_class interpreter_method_oop_reg ( /* as def&#39;d in frame section */ )
  435 // 3) reg_class stack_slots( /* one chunk of stack-based &quot;registers&quot; */ )
  436 //
  437 
  438 // Class for all 32 bit general purpose registers
  439 reg_class all_reg32(
  440     R0,
  441     R1,
  442     R2,
  443     R3,
  444     R4,
  445     R5,
  446     R6,
  447     R7,
  448     R10,
  449     R11,
  450     R12,
  451     R13,
  452     R14,
  453     R15,
  454     R16,
  455     R17,
  456     R18,
  457     R19,
  458     R20,
  459     R21,
  460     R22,
  461     R23,
  462     R24,
  463     R25,
  464     R26,
  465     R27,
  466     R28,
  467     R29,
  468     R30,
  469     R31
  470 );
  471 
  472 
  473 // Class for all 32 bit integer registers (excluding SP which
  474 // will never be used as an integer register)
  475 reg_class any_reg32 %{
  476   return _ANY_REG32_mask;
  477 %}
  478 
  479 // Singleton class for R0 int register
  480 reg_class int_r0_reg(R0);
  481 
  482 // Singleton class for R2 int register
  483 reg_class int_r2_reg(R2);
  484 
  485 // Singleton class for R3 int register
  486 reg_class int_r3_reg(R3);
  487 
  488 // Singleton class for R4 int register
  489 reg_class int_r4_reg(R4);
  490 
  491 // Singleton class for R31 int register
  492 reg_class int_r31_reg(R31);
  493 
  494 // Class for all 64 bit general purpose registers
  495 reg_class all_reg(
  496     R0, R0_H,
  497     R1, R1_H,
  498     R2, R2_H,
  499     R3, R3_H,
  500     R4, R4_H,
  501     R5, R5_H,
  502     R6, R6_H,
  503     R7, R7_H,
  504     R10, R10_H,
  505     R11, R11_H,
  506     R12, R12_H,
  507     R13, R13_H,
  508     R14, R14_H,
  509     R15, R15_H,
  510     R16, R16_H,
  511     R17, R17_H,
  512     R18, R18_H,
  513     R19, R19_H,
  514     R20, R20_H,
  515     R21, R21_H,
  516     R22, R22_H,
  517     R23, R23_H,
  518     R24, R24_H,
  519     R25, R25_H,
  520     R26, R26_H,
  521     R27, R27_H,
  522     R28, R28_H,
  523     R29, R29_H,
  524     R30, R30_H,
  525     R31, R31_H
  526 );
  527 
  528 // Class for all long integer registers (including SP)
  529 reg_class any_reg %{
  530   return _ANY_REG_mask;
  531 %}
  532 
  533 // Class for non-allocatable 32 bit registers
  534 reg_class non_allocatable_reg32(
  535     R28,                        // thread
  536     R30,                        // lr
  537     R31                         // sp
  538 );
  539 
  540 // Class for non-allocatable 64 bit registers
  541 reg_class non_allocatable_reg(
  542     R28, R28_H,                 // thread
  543     R30, R30_H,                 // lr
  544     R31, R31_H                  // sp
  545 );
  546 
  547 // Class for all non-special integer registers
  548 reg_class no_special_reg32 %{
  549   return _NO_SPECIAL_REG32_mask;
  550 %}
  551 
  552 // Class for all non-special long integer registers
  553 reg_class no_special_reg %{
  554   return _NO_SPECIAL_REG_mask;
  555 %}
  556 
  557 // Class for 64 bit register r0
  558 reg_class r0_reg(
  559     R0, R0_H
  560 );
  561 
  562 // Class for 64 bit register r1
  563 reg_class r1_reg(
  564     R1, R1_H
  565 );
  566 
  567 // Class for 64 bit register r2
  568 reg_class r2_reg(
  569     R2, R2_H
  570 );
  571 
  572 // Class for 64 bit register r3
  573 reg_class r3_reg(
  574     R3, R3_H
  575 );
  576 
  577 // Class for 64 bit register r4
  578 reg_class r4_reg(
  579     R4, R4_H
  580 );
  581 
  582 // Class for 64 bit register r5
  583 reg_class r5_reg(
  584     R5, R5_H
  585 );
  586 
  587 // Class for 64 bit register r10
  588 reg_class r10_reg(
  589     R10, R10_H
  590 );
  591 
  592 // Class for 64 bit register r11
  593 reg_class r11_reg(
  594     R11, R11_H
  595 );
  596 
  597 // Class for method register
  598 reg_class method_reg(
  599     R12, R12_H
  600 );
  601 
  602 // Class for heapbase register
  603 reg_class heapbase_reg(
  604     R27, R27_H
  605 );
  606 
  607 // Class for thread register
  608 reg_class thread_reg(
  609     R28, R28_H
  610 );
  611 
  612 // Class for frame pointer register
  613 reg_class fp_reg(
  614     R29, R29_H
  615 );
  616 
  617 // Class for link register
  618 reg_class lr_reg(
  619     R30, R30_H
  620 );
  621 
  622 // Class for long sp register
  623 reg_class sp_reg(
  624   R31, R31_H
  625 );
  626 
  627 // Class for all pointer registers
  628 reg_class ptr_reg %{
  629   return _PTR_REG_mask;
  630 %}
  631 
  632 // Class for all non_special pointer registers
  633 reg_class no_special_ptr_reg %{
  634   return _NO_SPECIAL_PTR_REG_mask;
  635 %}
  636 
  637 // Class for all float registers
  638 reg_class float_reg(
  639     V0,
  640     V1,
  641     V2,
  642     V3,
  643     V4,
  644     V5,
  645     V6,
  646     V7,
  647     V8,
  648     V9,
  649     V10,
  650     V11,
  651     V12,
  652     V13,
  653     V14,
  654     V15,
  655     V16,
  656     V17,
  657     V18,
  658     V19,
  659     V20,
  660     V21,
  661     V22,
  662     V23,
  663     V24,
  664     V25,
  665     V26,
  666     V27,
  667     V28,
  668     V29,
  669     V30,
  670     V31
  671 );
  672 
  673 // Double precision float registers have virtual `high halves&#39; that
  674 // are needed by the allocator.
  675 // Class for all double registers
  676 reg_class double_reg(
  677     V0, V0_H,
  678     V1, V1_H,
  679     V2, V2_H,
  680     V3, V3_H,
  681     V4, V4_H,
  682     V5, V5_H,
  683     V6, V6_H,
  684     V7, V7_H,
  685     V8, V8_H,
  686     V9, V9_H,
  687     V10, V10_H,
  688     V11, V11_H,
  689     V12, V12_H,
  690     V13, V13_H,
  691     V14, V14_H,
  692     V15, V15_H,
  693     V16, V16_H,
  694     V17, V17_H,
  695     V18, V18_H,
  696     V19, V19_H,
  697     V20, V20_H,
  698     V21, V21_H,
  699     V22, V22_H,
  700     V23, V23_H,
  701     V24, V24_H,
  702     V25, V25_H,
  703     V26, V26_H,
  704     V27, V27_H,
  705     V28, V28_H,
  706     V29, V29_H,
  707     V30, V30_H,
  708     V31, V31_H
  709 );
  710 
  711 // Class for all 64bit vector registers
  712 reg_class vectord_reg(
  713     V0, V0_H,
  714     V1, V1_H,
  715     V2, V2_H,
  716     V3, V3_H,
  717     V4, V4_H,
  718     V5, V5_H,
  719     V6, V6_H,
  720     V7, V7_H,
  721     V8, V8_H,
  722     V9, V9_H,
  723     V10, V10_H,
  724     V11, V11_H,
  725     V12, V12_H,
  726     V13, V13_H,
  727     V14, V14_H,
  728     V15, V15_H,
  729     V16, V16_H,
  730     V17, V17_H,
  731     V18, V18_H,
  732     V19, V19_H,
  733     V20, V20_H,
  734     V21, V21_H,
  735     V22, V22_H,
  736     V23, V23_H,
  737     V24, V24_H,
  738     V25, V25_H,
  739     V26, V26_H,
  740     V27, V27_H,
  741     V28, V28_H,
  742     V29, V29_H,
  743     V30, V30_H,
  744     V31, V31_H
  745 );
  746 
  747 // Class for all 128bit vector registers
  748 reg_class vectorx_reg(
  749     V0, V0_H, V0_J, V0_K,
  750     V1, V1_H, V1_J, V1_K,
  751     V2, V2_H, V2_J, V2_K,
  752     V3, V3_H, V3_J, V3_K,
  753     V4, V4_H, V4_J, V4_K,
  754     V5, V5_H, V5_J, V5_K,
  755     V6, V6_H, V6_J, V6_K,
  756     V7, V7_H, V7_J, V7_K,
  757     V8, V8_H, V8_J, V8_K,
  758     V9, V9_H, V9_J, V9_K,
  759     V10, V10_H, V10_J, V10_K,
  760     V11, V11_H, V11_J, V11_K,
  761     V12, V12_H, V12_J, V12_K,
  762     V13, V13_H, V13_J, V13_K,
  763     V14, V14_H, V14_J, V14_K,
  764     V15, V15_H, V15_J, V15_K,
  765     V16, V16_H, V16_J, V16_K,
  766     V17, V17_H, V17_J, V17_K,
  767     V18, V18_H, V18_J, V18_K,
  768     V19, V19_H, V19_J, V19_K,
  769     V20, V20_H, V20_J, V20_K,
  770     V21, V21_H, V21_J, V21_K,
  771     V22, V22_H, V22_J, V22_K,
  772     V23, V23_H, V23_J, V23_K,
  773     V24, V24_H, V24_J, V24_K,
  774     V25, V25_H, V25_J, V25_K,
  775     V26, V26_H, V26_J, V26_K,
  776     V27, V27_H, V27_J, V27_K,
  777     V28, V28_H, V28_J, V28_K,
  778     V29, V29_H, V29_J, V29_K,
  779     V30, V30_H, V30_J, V30_K,
  780     V31, V31_H, V31_J, V31_K
  781 );
  782 
  783 // Class for 128 bit register v0
  784 reg_class v0_reg(
  785     V0, V0_H
  786 );
  787 
  788 // Class for 128 bit register v1
  789 reg_class v1_reg(
  790     V1, V1_H
  791 );
  792 
  793 // Class for 128 bit register v2
  794 reg_class v2_reg(
  795     V2, V2_H
  796 );
  797 
  798 // Class for 128 bit register v3
  799 reg_class v3_reg(
  800     V3, V3_H
  801 );
  802 
  803 // Class for 128 bit register v4
  804 reg_class v4_reg(
  805     V4, V4_H
  806 );
  807 
  808 // Class for 128 bit register v5
  809 reg_class v5_reg(
  810     V5, V5_H
  811 );
  812 
  813 // Class for 128 bit register v6
  814 reg_class v6_reg(
  815     V6, V6_H
  816 );
  817 
  818 // Class for 128 bit register v7
  819 reg_class v7_reg(
  820     V7, V7_H
  821 );
  822 
  823 // Class for 128 bit register v8
  824 reg_class v8_reg(
  825     V8, V8_H
  826 );
  827 
  828 // Class for 128 bit register v9
  829 reg_class v9_reg(
  830     V9, V9_H
  831 );
  832 
  833 // Class for 128 bit register v10
  834 reg_class v10_reg(
  835     V10, V10_H
  836 );
  837 
  838 // Class for 128 bit register v11
  839 reg_class v11_reg(
  840     V11, V11_H
  841 );
  842 
  843 // Class for 128 bit register v12
  844 reg_class v12_reg(
  845     V12, V12_H
  846 );
  847 
  848 // Class for 128 bit register v13
  849 reg_class v13_reg(
  850     V13, V13_H
  851 );
  852 
  853 // Class for 128 bit register v14
  854 reg_class v14_reg(
  855     V14, V14_H
  856 );
  857 
  858 // Class for 128 bit register v15
  859 reg_class v15_reg(
  860     V15, V15_H
  861 );
  862 
  863 // Class for 128 bit register v16
  864 reg_class v16_reg(
  865     V16, V16_H
  866 );
  867 
  868 // Class for 128 bit register v17
  869 reg_class v17_reg(
  870     V17, V17_H
  871 );
  872 
  873 // Class for 128 bit register v18
  874 reg_class v18_reg(
  875     V18, V18_H
  876 );
  877 
  878 // Class for 128 bit register v19
  879 reg_class v19_reg(
  880     V19, V19_H
  881 );
  882 
  883 // Class for 128 bit register v20
  884 reg_class v20_reg(
  885     V20, V20_H
  886 );
  887 
  888 // Class for 128 bit register v21
  889 reg_class v21_reg(
  890     V21, V21_H
  891 );
  892 
  893 // Class for 128 bit register v22
  894 reg_class v22_reg(
  895     V22, V22_H
  896 );
  897 
  898 // Class for 128 bit register v23
  899 reg_class v23_reg(
  900     V23, V23_H
  901 );
  902 
  903 // Class for 128 bit register v24
  904 reg_class v24_reg(
  905     V24, V24_H
  906 );
  907 
  908 // Class for 128 bit register v25
  909 reg_class v25_reg(
  910     V25, V25_H
  911 );
  912 
  913 // Class for 128 bit register v26
  914 reg_class v26_reg(
  915     V26, V26_H
  916 );
  917 
  918 // Class for 128 bit register v27
  919 reg_class v27_reg(
  920     V27, V27_H
  921 );
  922 
  923 // Class for 128 bit register v28
  924 reg_class v28_reg(
  925     V28, V28_H
  926 );
  927 
  928 // Class for 128 bit register v29
  929 reg_class v29_reg(
  930     V29, V29_H
  931 );
  932 
  933 // Class for 128 bit register v30
  934 reg_class v30_reg(
  935     V30, V30_H
  936 );
  937 
  938 // Class for 128 bit register v31
  939 reg_class v31_reg(
  940     V31, V31_H
  941 );
  942 
  943 // Singleton class for condition codes
  944 reg_class int_flags(RFLAGS);
  945 
  946 %}
  947 
  948 //----------DEFINITION BLOCK---------------------------------------------------
  949 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
  950 // Current support includes integer values in the range [0, 0x7FFFFFFF]
  951 // Format:
  952 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
  953 // Generated Code in ad_&lt;arch&gt;.hpp
  954 //        #define  &lt;name&gt;   (&lt;expression&gt;)
  955 //        // value == &lt;int_value&gt;
  956 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
  957 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
  958 //
  959 
  960 // we follow the ppc-aix port in using a simple cost model which ranks
  961 // register operations as cheap, memory ops as more expensive and
  962 // branches as most expensive. the first two have a low as well as a
  963 // normal cost. huge cost appears to be a way of saying don&#39;t do
  964 // something
  965 
  966 definitions %{
  967   // The default cost (of a register move instruction).
  968   int_def INSN_COST            (    100,     100);
  969   int_def BRANCH_COST          (    200,     2 * INSN_COST);
  970   int_def CALL_COST            (    200,     2 * INSN_COST);
  971   int_def VOLATILE_REF_COST    (   1000,     10 * INSN_COST);
  972 %}
  973 
  974 
  975 //----------SOURCE BLOCK-------------------------------------------------------
  976 // This is a block of C++ code which provides values, functions, and
  977 // definitions necessary in the rest of the architecture description
  978 
  979 source_hpp %{
  980 
  981 #include &quot;asm/macroAssembler.hpp&quot;
  982 #include &quot;gc/shared/cardTable.hpp&quot;
  983 #include &quot;gc/shared/cardTableBarrierSet.hpp&quot;
  984 #include &quot;gc/shared/collectedHeap.hpp&quot;
  985 #include &quot;opto/addnode.hpp&quot;
  986 #include &quot;opto/convertnode.hpp&quot;
  987 
  988 extern RegMask _ANY_REG32_mask;
  989 extern RegMask _ANY_REG_mask;
  990 extern RegMask _PTR_REG_mask;
  991 extern RegMask _NO_SPECIAL_REG32_mask;
  992 extern RegMask _NO_SPECIAL_REG_mask;
  993 extern RegMask _NO_SPECIAL_PTR_REG_mask;
  994 
  995 class CallStubImpl {
  996 
  997   //--------------------------------------------------------------
  998   //---&lt;  Used for optimization in Compile::shorten_branches  &gt;---
  999   //--------------------------------------------------------------
 1000 
 1001  public:
 1002   // Size of call trampoline stub.
 1003   static uint size_call_trampoline() {
 1004     return 0; // no call trampolines on this platform
 1005   }
 1006 
 1007   // number of relocations needed by a call trampoline stub
 1008   static uint reloc_call_trampoline() {
 1009     return 0; // no call trampolines on this platform
 1010   }
 1011 };
 1012 
 1013 class HandlerImpl {
 1014 
 1015  public:
 1016 
 1017   static int emit_exception_handler(CodeBuffer &amp;cbuf);
 1018   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
 1019 
 1020   static uint size_exception_handler() {
 1021     return MacroAssembler::far_branch_size();
 1022   }
 1023 
 1024   static uint size_deopt_handler() {
 1025     // count one adr and one far branch instruction
 1026     return 4 * NativeInstruction::instruction_size;
 1027   }
 1028 };
 1029 
 1030 class Node::PD {
 1031 public:
 1032   enum NodeFlags {
 1033     _last_flag = Node::_last_flag
 1034   };
 1035 };
 1036 
 1037  bool is_CAS(int opcode, bool maybe_volatile);
 1038 
 1039   // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt; and associated dmb
 1040 
 1041   bool unnecessary_acquire(const Node *barrier);
 1042   bool needs_acquiring_load(const Node *load);
 1043 
 1044   // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt; and associated dmbs
 1045 
 1046   bool unnecessary_release(const Node *barrier);
 1047   bool unnecessary_volatile(const Node *barrier);
 1048   bool needs_releasing_store(const Node *store);
 1049 
 1050   // predicate controlling translation of CompareAndSwapX
 1051   bool needs_acquiring_load_exclusive(const Node *load);
 1052 
 1053   // predicate controlling addressing modes
 1054   bool size_fits_all_mem_uses(AddPNode* addp, int shift);
 1055 %}
 1056 
 1057 source %{
 1058 
 1059   // Derived RegMask with conditionally allocatable registers
 1060 
 1061   void PhaseOutput::pd_perform_mach_node_analysis() {
 1062   }
 1063 
 1064   int MachNode::pd_alignment_required() const {
 1065     return 1;
 1066   }
 1067 
 1068   int MachNode::compute_padding(int current_offset) const {
 1069     return 0;
 1070   }
 1071 
 1072   RegMask _ANY_REG32_mask;
 1073   RegMask _ANY_REG_mask;
 1074   RegMask _PTR_REG_mask;
 1075   RegMask _NO_SPECIAL_REG32_mask;
 1076   RegMask _NO_SPECIAL_REG_mask;
 1077   RegMask _NO_SPECIAL_PTR_REG_mask;
 1078 
 1079   void reg_mask_init() {
 1080     // We derive below RegMask(s) from the ones which are auto-generated from
 1081     // adlc register classes to make AArch64 rheapbase (r27) and rfp (r29)
 1082     // registers conditionally reserved.
 1083 
 1084     _ANY_REG32_mask = _ALL_REG32_mask;
 1085     _ANY_REG32_mask.Remove(OptoReg::as_OptoReg(r31_sp-&gt;as_VMReg()));
 1086 
 1087     _ANY_REG_mask = _ALL_REG_mask;
 1088 
 1089     _PTR_REG_mask = _ALL_REG_mask;
 1090 
 1091     _NO_SPECIAL_REG32_mask = _ALL_REG32_mask;
 1092     _NO_SPECIAL_REG32_mask.SUBTRACT(_NON_ALLOCATABLE_REG32_mask);
 1093 
 1094     _NO_SPECIAL_REG_mask = _ALL_REG_mask;
 1095     _NO_SPECIAL_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1096 
 1097     _NO_SPECIAL_PTR_REG_mask = _ALL_REG_mask;
 1098     _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_NON_ALLOCATABLE_REG_mask);
 1099 
 1100     // r27 is not allocatable when compressed oops is on and heapbase is not
 1101     // zero, compressed klass pointers doesn&#39;t use r27 after JDK-8234794
 1102     if (UseCompressedOops &amp;&amp; CompressedOops::ptrs_base() != NULL) {
 1103       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r27-&gt;as_VMReg()));
 1104       _NO_SPECIAL_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1105       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_HEAPBASE_REG_mask);
 1106     }
 1107 
 1108     // r29 is not allocatable when PreserveFramePointer is on
 1109     if (PreserveFramePointer) {
 1110       _NO_SPECIAL_REG32_mask.Remove(OptoReg::as_OptoReg(r29-&gt;as_VMReg()));
 1111       _NO_SPECIAL_REG_mask.SUBTRACT(_FP_REG_mask);
 1112       _NO_SPECIAL_PTR_REG_mask.SUBTRACT(_FP_REG_mask);
 1113     }
 1114   }
 1115 
 1116   // Optimizaton of volatile gets and puts
 1117   // -------------------------------------
 1118   //
 1119   // AArch64 has ldar&lt;x&gt; and stlr&lt;x&gt; instructions which we can safely
 1120   // use to implement volatile reads and writes. For a volatile read
 1121   // we simply need
 1122   //
 1123   //   ldar&lt;x&gt;
 1124   //
 1125   // and for a volatile write we need
 1126   //
 1127   //   stlr&lt;x&gt;
 1128   //
 1129   // Alternatively, we can implement them by pairing a normal
 1130   // load/store with a memory barrier. For a volatile read we need
 1131   //
 1132   //   ldr&lt;x&gt;
 1133   //   dmb ishld
 1134   //
 1135   // for a volatile write
 1136   //
 1137   //   dmb ish
 1138   //   str&lt;x&gt;
 1139   //   dmb ish
 1140   //
 1141   // We can also use ldaxr and stlxr to implement compare and swap CAS
 1142   // sequences. These are normally translated to an instruction
 1143   // sequence like the following
 1144   //
 1145   //   dmb      ish
 1146   // retry:
 1147   //   ldxr&lt;x&gt;   rval raddr
 1148   //   cmp       rval rold
 1149   //   b.ne done
 1150   //   stlxr&lt;x&gt;  rval, rnew, rold
 1151   //   cbnz      rval retry
 1152   // done:
 1153   //   cset      r0, eq
 1154   //   dmb ishld
 1155   //
 1156   // Note that the exclusive store is already using an stlxr
 1157   // instruction. That is required to ensure visibility to other
 1158   // threads of the exclusive write (assuming it succeeds) before that
 1159   // of any subsequent writes.
 1160   //
 1161   // The following instruction sequence is an improvement on the above
 1162   //
 1163   // retry:
 1164   //   ldaxr&lt;x&gt;  rval raddr
 1165   //   cmp       rval rold
 1166   //   b.ne done
 1167   //   stlxr&lt;x&gt;  rval, rnew, rold
 1168   //   cbnz      rval retry
 1169   // done:
 1170   //   cset      r0, eq
 1171   //
 1172   // We don&#39;t need the leading dmb ish since the stlxr guarantees
 1173   // visibility of prior writes in the case that the swap is
 1174   // successful. Crucially we don&#39;t have to worry about the case where
 1175   // the swap is not successful since no valid program should be
 1176   // relying on visibility of prior changes by the attempting thread
 1177   // in the case where the CAS fails.
 1178   //
 1179   // Similarly, we don&#39;t need the trailing dmb ishld if we substitute
 1180   // an ldaxr instruction since that will provide all the guarantees we
 1181   // require regarding observation of changes made by other threads
 1182   // before any change to the CAS address observed by the load.
 1183   //
 1184   // In order to generate the desired instruction sequence we need to
 1185   // be able to identify specific &#39;signature&#39; ideal graph node
 1186   // sequences which i) occur as a translation of a volatile reads or
 1187   // writes or CAS operations and ii) do not occur through any other
 1188   // translation or graph transformation. We can then provide
 1189   // alternative aldc matching rules which translate these node
 1190   // sequences to the desired machine code sequences. Selection of the
 1191   // alternative rules can be implemented by predicates which identify
 1192   // the relevant node sequences.
 1193   //
 1194   // The ideal graph generator translates a volatile read to the node
 1195   // sequence
 1196   //
 1197   //   LoadX[mo_acquire]
 1198   //   MemBarAcquire
 1199   //
 1200   // As a special case when using the compressed oops optimization we
 1201   // may also see this variant
 1202   //
 1203   //   LoadN[mo_acquire]
 1204   //   DecodeN
 1205   //   MemBarAcquire
 1206   //
 1207   // A volatile write is translated to the node sequence
 1208   //
 1209   //   MemBarRelease
 1210   //   StoreX[mo_release] {CardMark}-optional
 1211   //   MemBarVolatile
 1212   //
 1213   // n.b. the above node patterns are generated with a strict
 1214   // &#39;signature&#39; configuration of input and output dependencies (see
 1215   // the predicates below for exact details). The card mark may be as
 1216   // simple as a few extra nodes or, in a few GC configurations, may
 1217   // include more complex control flow between the leading and
 1218   // trailing memory barriers. However, whatever the card mark
 1219   // configuration these signatures are unique to translated volatile
 1220   // reads/stores -- they will not appear as a result of any other
 1221   // bytecode translation or inlining nor as a consequence of
 1222   // optimizing transforms.
 1223   //
 1224   // We also want to catch inlined unsafe volatile gets and puts and
 1225   // be able to implement them using either ldar&lt;x&gt;/stlr&lt;x&gt; or some
 1226   // combination of ldr&lt;x&gt;/stlr&lt;x&gt; and dmb instructions.
 1227   //
 1228   // Inlined unsafe volatiles puts manifest as a minor variant of the
 1229   // normal volatile put node sequence containing an extra cpuorder
 1230   // membar
 1231   //
 1232   //   MemBarRelease
 1233   //   MemBarCPUOrder
 1234   //   StoreX[mo_release] {CardMark}-optional
 1235   //   MemBarCPUOrder
 1236   //   MemBarVolatile
 1237   //
 1238   // n.b. as an aside, a cpuorder membar is not itself subject to
 1239   // matching and translation by adlc rules.  However, the rule
 1240   // predicates need to detect its presence in order to correctly
 1241   // select the desired adlc rules.
 1242   //
 1243   // Inlined unsafe volatile gets manifest as a slightly different
 1244   // node sequence to a normal volatile get because of the
 1245   // introduction of some CPUOrder memory barriers to bracket the
 1246   // Load. However, but the same basic skeleton of a LoadX feeding a
 1247   // MemBarAcquire, possibly thorugh an optional DecodeN, is still
 1248   // present
 1249   //
 1250   //   MemBarCPUOrder
 1251   //        ||       \\
 1252   //   MemBarCPUOrder LoadX[mo_acquire]
 1253   //        ||            |
 1254   //        ||       {DecodeN} optional
 1255   //        ||       /
 1256   //     MemBarAcquire
 1257   //
 1258   // In this case the acquire membar does not directly depend on the
 1259   // load. However, we can be sure that the load is generated from an
 1260   // inlined unsafe volatile get if we see it dependent on this unique
 1261   // sequence of membar nodes. Similarly, given an acquire membar we
 1262   // can know that it was added because of an inlined unsafe volatile
 1263   // get if it is fed and feeds a cpuorder membar and if its feed
 1264   // membar also feeds an acquiring load.
 1265   //
 1266   // Finally an inlined (Unsafe) CAS operation is translated to the
 1267   // following ideal graph
 1268   //
 1269   //   MemBarRelease
 1270   //   MemBarCPUOrder
 1271   //   CompareAndSwapX {CardMark}-optional
 1272   //   MemBarCPUOrder
 1273   //   MemBarAcquire
 1274   //
 1275   // So, where we can identify these volatile read and write
 1276   // signatures we can choose to plant either of the above two code
 1277   // sequences. For a volatile read we can simply plant a normal
 1278   // ldr&lt;x&gt; and translate the MemBarAcquire to a dmb. However, we can
 1279   // also choose to inhibit translation of the MemBarAcquire and
 1280   // inhibit planting of the ldr&lt;x&gt;, instead planting an ldar&lt;x&gt;.
 1281   //
 1282   // When we recognise a volatile store signature we can choose to
 1283   // plant at a dmb ish as a translation for the MemBarRelease, a
 1284   // normal str&lt;x&gt; and then a dmb ish for the MemBarVolatile.
 1285   // Alternatively, we can inhibit translation of the MemBarRelease
 1286   // and MemBarVolatile and instead plant a simple stlr&lt;x&gt;
 1287   // instruction.
 1288   //
 1289   // when we recognise a CAS signature we can choose to plant a dmb
 1290   // ish as a translation for the MemBarRelease, the conventional
 1291   // macro-instruction sequence for the CompareAndSwap node (which
 1292   // uses ldxr&lt;x&gt;) and then a dmb ishld for the MemBarAcquire.
 1293   // Alternatively, we can elide generation of the dmb instructions
 1294   // and plant the alternative CompareAndSwap macro-instruction
 1295   // sequence (which uses ldaxr&lt;x&gt;).
 1296   //
 1297   // Of course, the above only applies when we see these signature
 1298   // configurations. We still want to plant dmb instructions in any
 1299   // other cases where we may see a MemBarAcquire, MemBarRelease or
 1300   // MemBarVolatile. For example, at the end of a constructor which
 1301   // writes final/volatile fields we will see a MemBarRelease
 1302   // instruction and this needs a &#39;dmb ish&#39; lest we risk the
 1303   // constructed object being visible without making the
 1304   // final/volatile field writes visible.
 1305   //
 1306   // n.b. the translation rules below which rely on detection of the
 1307   // volatile signatures and insert ldar&lt;x&gt; or stlr&lt;x&gt; are failsafe.
 1308   // If we see anything other than the signature configurations we
 1309   // always just translate the loads and stores to ldr&lt;x&gt; and str&lt;x&gt;
 1310   // and translate acquire, release and volatile membars to the
 1311   // relevant dmb instructions.
 1312   //
 1313 
 1314   // is_CAS(int opcode, bool maybe_volatile)
 1315   //
 1316   // return true if opcode is one of the possible CompareAndSwapX
 1317   // values otherwise false.
 1318 
 1319   bool is_CAS(int opcode, bool maybe_volatile)
 1320   {
 1321     switch(opcode) {
 1322       // We handle these
 1323     case Op_CompareAndSwapI:
 1324     case Op_CompareAndSwapL:
 1325     case Op_CompareAndSwapP:
 1326     case Op_CompareAndSwapN:
 1327     case Op_ShenandoahCompareAndSwapP:
 1328     case Op_ShenandoahCompareAndSwapN:
 1329     case Op_CompareAndSwapB:
 1330     case Op_CompareAndSwapS:
 1331     case Op_GetAndSetI:
 1332     case Op_GetAndSetL:
 1333     case Op_GetAndSetP:
 1334     case Op_GetAndSetN:
 1335     case Op_GetAndAddI:
 1336     case Op_GetAndAddL:
 1337       return true;
 1338     case Op_CompareAndExchangeI:
 1339     case Op_CompareAndExchangeN:
 1340     case Op_CompareAndExchangeB:
 1341     case Op_CompareAndExchangeS:
 1342     case Op_CompareAndExchangeL:
 1343     case Op_CompareAndExchangeP:
 1344     case Op_WeakCompareAndSwapB:
 1345     case Op_WeakCompareAndSwapS:
 1346     case Op_WeakCompareAndSwapI:
 1347     case Op_WeakCompareAndSwapL:
 1348     case Op_WeakCompareAndSwapP:
 1349     case Op_WeakCompareAndSwapN:
 1350     case Op_ShenandoahWeakCompareAndSwapP:
 1351     case Op_ShenandoahWeakCompareAndSwapN:
 1352     case Op_ShenandoahCompareAndExchangeP:
 1353     case Op_ShenandoahCompareAndExchangeN:
 1354       return maybe_volatile;
 1355     default:
 1356       return false;
 1357     }
 1358   }
 1359 
 1360   // helper to determine the maximum number of Phi nodes we may need to
 1361   // traverse when searching from a card mark membar for the merge mem
 1362   // feeding a trailing membar or vice versa
 1363 
 1364 // predicates controlling emit of ldr&lt;x&gt;/ldar&lt;x&gt;
 1365 
 1366 bool unnecessary_acquire(const Node *barrier)
 1367 {
 1368   assert(barrier-&gt;is_MemBar(), &quot;expecting a membar&quot;);
 1369 
 1370   MemBarNode* mb = barrier-&gt;as_MemBar();
 1371 
 1372   if (mb-&gt;trailing_load()) {
 1373     return true;
 1374   }
 1375 
 1376   if (mb-&gt;trailing_load_store()) {
 1377     Node* load_store = mb-&gt;in(MemBarNode::Precedent);
 1378     assert(load_store-&gt;is_LoadStore(), &quot;unexpected graph shape&quot;);
 1379     return is_CAS(load_store-&gt;Opcode(), true);
 1380   }
 1381 
 1382   return false;
 1383 }
 1384 
 1385 bool needs_acquiring_load(const Node *n)
 1386 {
 1387   assert(n-&gt;is_Load(), &quot;expecting a load&quot;);
 1388   LoadNode *ld = n-&gt;as_Load();
 1389   return ld-&gt;is_acquire();
 1390 }
 1391 
 1392 bool unnecessary_release(const Node *n)
 1393 {
 1394   assert((n-&gt;is_MemBar() &amp;&amp;
 1395           n-&gt;Opcode() == Op_MemBarRelease),
 1396          &quot;expecting a release membar&quot;);
 1397 
 1398   MemBarNode *barrier = n-&gt;as_MemBar();
 1399   if (!barrier-&gt;leading()) {
 1400     return false;
 1401   } else {
 1402     Node* trailing = barrier-&gt;trailing_membar();
 1403     MemBarNode* trailing_mb = trailing-&gt;as_MemBar();
 1404     assert(trailing_mb-&gt;trailing(), &quot;Not a trailing membar?&quot;);
 1405     assert(trailing_mb-&gt;leading_membar() == n, &quot;inconsistent leading/trailing membars&quot;);
 1406 
 1407     Node* mem = trailing_mb-&gt;in(MemBarNode::Precedent);
 1408     if (mem-&gt;is_Store()) {
 1409       assert(mem-&gt;as_Store()-&gt;is_release(), &quot;&quot;);
 1410       assert(trailing_mb-&gt;Opcode() == Op_MemBarVolatile, &quot;&quot;);
 1411       return true;
 1412     } else {
 1413       assert(mem-&gt;is_LoadStore(), &quot;&quot;);
 1414       assert(trailing_mb-&gt;Opcode() == Op_MemBarAcquire, &quot;&quot;);
 1415       return is_CAS(mem-&gt;Opcode(), true);
 1416     }
 1417   }
 1418   return false;
 1419 }
 1420 
 1421 bool unnecessary_volatile(const Node *n)
 1422 {
 1423   // assert n-&gt;is_MemBar();
 1424   MemBarNode *mbvol = n-&gt;as_MemBar();
 1425 
 1426   bool release = mbvol-&gt;trailing_store();
 1427   assert(!release || (mbvol-&gt;in(MemBarNode::Precedent)-&gt;is_Store() &amp;&amp; mbvol-&gt;in(MemBarNode::Precedent)-&gt;as_Store()-&gt;is_release()), &quot;&quot;);
 1428 #ifdef ASSERT
 1429   if (release) {
 1430     Node* leading = mbvol-&gt;leading_membar();
 1431     assert(leading-&gt;Opcode() == Op_MemBarRelease, &quot;&quot;);
 1432     assert(leading-&gt;as_MemBar()-&gt;leading_store(), &quot;&quot;);
 1433     assert(leading-&gt;as_MemBar()-&gt;trailing_membar() == mbvol, &quot;&quot;);
 1434   }
 1435 #endif
 1436 
 1437   return release;
 1438 }
 1439 
 1440 // predicates controlling emit of str&lt;x&gt;/stlr&lt;x&gt;
 1441 
 1442 bool needs_releasing_store(const Node *n)
 1443 {
 1444   // assert n-&gt;is_Store();
 1445   StoreNode *st = n-&gt;as_Store();
 1446   return st-&gt;trailing_membar() != NULL;
 1447 }
 1448 
 1449 // predicate controlling translation of CAS
 1450 //
 1451 // returns true if CAS needs to use an acquiring load otherwise false
 1452 
 1453 bool needs_acquiring_load_exclusive(const Node *n)
 1454 {
 1455   assert(is_CAS(n-&gt;Opcode(), true), &quot;expecting a compare and swap&quot;);
 1456   LoadStoreNode* ldst = n-&gt;as_LoadStore();
 1457   if (is_CAS(n-&gt;Opcode(), false)) {
 1458     assert(ldst-&gt;trailing_membar() != NULL, &quot;expected trailing membar&quot;);
 1459   } else {
 1460     return ldst-&gt;trailing_membar() != NULL;
 1461   }
 1462 
 1463   // so we can just return true here
 1464   return true;
 1465 }
 1466 
 1467 #define __ _masm.
 1468 
 1469 // advance declarations for helper functions to convert register
 1470 // indices to register objects
 1471 
 1472 // the ad file has to provide implementations of certain methods
 1473 // expected by the generic code
 1474 //
 1475 // REQUIRED FUNCTIONALITY
 1476 
 1477 //=============================================================================
 1478 
 1479 // !!!!! Special hack to get all types of calls to specify the byte offset
 1480 //       from the start of the call to the point where the return address
 1481 //       will point.
 1482 
 1483 int MachCallStaticJavaNode::ret_addr_offset()
 1484 {
 1485   // call should be a simple bl
 1486   int off = 4;
 1487   return off;
 1488 }
 1489 
 1490 int MachCallDynamicJavaNode::ret_addr_offset()
 1491 {
 1492   return 16; // movz, movk, movk, bl
 1493 }
 1494 
 1495 int MachCallRuntimeNode::ret_addr_offset() {
 1496   // for generated stubs the call will be
 1497   //   far_call(addr)
 1498   // for real runtime callouts it will be six instructions
 1499   // see aarch64_enc_java_to_runtime
 1500   //   adr(rscratch2, retaddr)
 1501   //   lea(rscratch1, RuntimeAddress(addr)
 1502   //   stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)))
 1503   //   blr(rscratch1)
 1504   CodeBlob *cb = CodeCache::find_blob(_entry_point);
 1505   if (cb) {
 1506     return MacroAssembler::far_branch_size();
 1507   } else {
 1508     return 6 * NativeInstruction::instruction_size;
 1509   }
 1510 }
 1511 
 1512 // Indicate if the safepoint node needs the polling page as an input
 1513 
 1514 // the shared code plants the oop data at the start of the generated
 1515 // code for the safepoint node and that needs ot be at the load
 1516 // instruction itself. so we cannot plant a mov of the safepoint poll
 1517 // address followed by a load. setting this to true means the mov is
 1518 // scheduled as a prior instruction. that&#39;s better for scheduling
 1519 // anyway.
 1520 
 1521 bool SafePointNode::needs_polling_address_input()
 1522 {
 1523   return true;
 1524 }
 1525 
 1526 //=============================================================================
 1527 
 1528 #ifndef PRODUCT
 1529 void MachBreakpointNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1530   st-&gt;print(&quot;BREAKPOINT&quot;);
 1531 }
 1532 #endif
 1533 
 1534 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1535   C2_MacroAssembler _masm(&amp;cbuf);
 1536   __ brk(0);
 1537 }
 1538 
 1539 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
 1540   return MachNode::size(ra_);
 1541 }
 1542 
 1543 //=============================================================================
 1544 
 1545 #ifndef PRODUCT
 1546   void MachNopNode::format(PhaseRegAlloc*, outputStream* st) const {
 1547     st-&gt;print(&quot;nop \t# %d bytes pad for loops and calls&quot;, _count);
 1548   }
 1549 #endif
 1550 
 1551   void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc*) const {
 1552     C2_MacroAssembler _masm(&amp;cbuf);
 1553     for (int i = 0; i &lt; _count; i++) {
 1554       __ nop();
 1555     }
 1556   }
 1557 
 1558   uint MachNopNode::size(PhaseRegAlloc*) const {
 1559     return _count * NativeInstruction::instruction_size;
 1560   }
 1561 
 1562 //=============================================================================
 1563 const RegMask&amp; MachConstantBaseNode::_out_RegMask = RegMask::Empty;
 1564 
 1565 int ConstantTable::calculate_table_base_offset() const {
 1566   return 0;  // absolute addressing, no offset
 1567 }
 1568 
 1569 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
 1570 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
 1571   ShouldNotReachHere();
 1572 }
 1573 
 1574 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
 1575   // Empty encoding
 1576 }
 1577 
 1578 uint MachConstantBaseNode::size(PhaseRegAlloc* ra_) const {
 1579   return 0;
 1580 }
 1581 
 1582 #ifndef PRODUCT
 1583 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
 1584   st-&gt;print(&quot;-- \t// MachConstantBaseNode (empty encoding)&quot;);
 1585 }
 1586 #endif
 1587 
 1588 #ifndef PRODUCT
 1589 void MachPrologNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1590   Compile* C = ra_-&gt;C;
 1591 
 1592   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1593 
 1594   if (C-&gt;output()-&gt;need_stack_bang(framesize))
 1595     st-&gt;print(&quot;# stack bang size=%d\n\t&quot;, framesize);
 1596 
 1597   if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1598     st-&gt;print(&quot;sub  sp, sp, #%d\n\t&quot;, framesize);
 1599     st-&gt;print(&quot;stp  rfp, lr, [sp, #%d]&quot;, framesize - 2 * wordSize);
 1600     if (PreserveFramePointer) st-&gt;print(&quot;\n\tadd  rfp, sp, #%d&quot;, framesize - 2 * wordSize);
 1601   } else {
 1602     st-&gt;print(&quot;stp  lr, rfp, [sp, #%d]!\n\t&quot;, -(2 * wordSize));
 1603     if (PreserveFramePointer) st-&gt;print(&quot;mov  rfp, sp\n\t&quot;);
 1604     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1605     st-&gt;print(&quot;sub  sp, sp, rscratch1&quot;);
 1606   }
 1607   if (C-&gt;stub_function() == NULL &amp;&amp; BarrierSet::barrier_set()-&gt;barrier_set_nmethod() != NULL) {
 1608     st-&gt;print(&quot;\n\t&quot;);
 1609     st-&gt;print(&quot;ldr  rscratch1, [guard]\n\t&quot;);
 1610     st-&gt;print(&quot;dmb ishld\n\t&quot;);
 1611     st-&gt;print(&quot;ldr  rscratch2, [rthread, #thread_disarmed_offset]\n\t&quot;);
 1612     st-&gt;print(&quot;cmp  rscratch1, rscratch2\n\t&quot;);
 1613     st-&gt;print(&quot;b.eq skip&quot;);
 1614     st-&gt;print(&quot;\n\t&quot;);
 1615     st-&gt;print(&quot;blr #nmethod_entry_barrier_stub\n\t&quot;);
 1616     st-&gt;print(&quot;b skip\n\t&quot;);
 1617     st-&gt;print(&quot;guard: int\n\t&quot;);
 1618     st-&gt;print(&quot;\n\t&quot;);
 1619     st-&gt;print(&quot;skip:\n\t&quot;);
 1620   }
 1621 }
 1622 #endif
 1623 
 1624 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1625   Compile* C = ra_-&gt;C;
 1626   C2_MacroAssembler _masm(&amp;cbuf);
 1627 
 1628   __ verified_entry(C, 0);
 1629   __ bind(*_verified_entry);
 1630   // n.b. frame size includes space for return pc and rfp
 1631   const long framesize = C-&gt;output()-&gt;frame_size_in_bytes();
 1632   assert(framesize%(2*wordSize) == 0, &quot;must preserve 2*wordSize alignment&quot;);
 1633 
 1634   // insert a nop at the start of the prolog so we can patch in a
 1635   // branch if we need to invalidate the method later
 1636   __ nop();
 1637 
 1638   if (C-&gt;clinit_barrier_on_entry()) {
 1639     assert(!C-&gt;method()-&gt;holder()-&gt;is_not_initialized(), &quot;initialization should have been started&quot;);
 1640 
 1641     Label L_skip_barrier;
 1642 
 1643     __ mov_metadata(rscratch2, C-&gt;method()-&gt;holder()-&gt;constant_encoding());
 1644     __ clinit_barrier(rscratch2, rscratch1, &amp;L_skip_barrier);
 1645     __ far_jump(RuntimeAddress(SharedRuntime::get_handle_wrong_method_stub()));
 1646     __ bind(L_skip_barrier);
 1647   }
 1648 
 1649   int bangsize = C-&gt;output()-&gt;bang_size_in_bytes();
 1650   if (C-&gt;output()-&gt;need_stack_bang(bangsize) &amp;&amp; UseStackBanging)
 1651     __ generate_stack_overflow_check(bangsize);
 1652 
 1653   __ build_frame(framesize);
 1654 
 1655   if (C-&gt;stub_function() == NULL) {
 1656     BarrierSetAssembler* bs = BarrierSet::barrier_set()-&gt;barrier_set_assembler();
 1657     bs-&gt;nmethod_entry_barrier(&amp;_masm);
 1658   }
 1659 
 1660   if (VerifyStackAtCalls) {
 1661     Unimplemented();
 1662   }
 1663 
 1664   C-&gt;output()-&gt;set_frame_complete(cbuf.insts_size());
 1665 
 1666   if (C-&gt;has_mach_constant_base_node()) {
 1667     // NOTE: We set the table base offset here because users might be
 1668     // emitted before MachConstantBaseNode.
 1669     ConstantTable&amp; constant_table = C-&gt;output()-&gt;constant_table();
 1670     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
 1671   }
 1672 }
 1673 
 1674 uint MachPrologNode::size(PhaseRegAlloc* ra_) const
 1675 {
 1676   return MachNode::size(ra_); // too many variables; just compute it
 1677                               // the hard way
 1678 }
 1679 
 1680 int MachPrologNode::reloc() const
 1681 {
 1682   return 0;
 1683 }
 1684 
 1685 //=============================================================================
 1686 
 1687 #ifndef PRODUCT
 1688 void MachEpilogNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1689   Compile* C = ra_-&gt;C;
 1690   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1691 
 1692   st-&gt;print(&quot;# pop frame %d\n\t&quot;,framesize);
 1693 
 1694   if (framesize == 0) {
 1695     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1696   } else if (framesize &lt; ((1 &lt;&lt; 9) + 2 * wordSize)) {
 1697     st-&gt;print(&quot;ldp  lr, rfp, [sp,#%d]\n\t&quot;, framesize - 2 * wordSize);
 1698     st-&gt;print(&quot;add  sp, sp, #%d\n\t&quot;, framesize);
 1699   } else {
 1700     st-&gt;print(&quot;mov  rscratch1, #%d\n\t&quot;, framesize - 2 * wordSize);
 1701     st-&gt;print(&quot;add  sp, sp, rscratch1\n\t&quot;);
 1702     st-&gt;print(&quot;ldp  lr, rfp, [sp],#%d\n\t&quot;, (2 * wordSize));
 1703   }
 1704 
 1705   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1706     st-&gt;print(&quot;# touch polling page\n\t&quot;);
 1707     st-&gt;print(&quot;ldr rscratch1, [rthread],#polling_page_offset\n\t&quot;);
 1708     st-&gt;print(&quot;ldr zr, [rscratch1]&quot;);
 1709   }
 1710 }
 1711 #endif
 1712 
 1713 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1714   Compile* C = ra_-&gt;C;
 1715   C2_MacroAssembler _masm(&amp;cbuf);
 1716   int framesize = C-&gt;output()-&gt;frame_slots() &lt;&lt; LogBytesPerInt;
 1717 
 1718   __ remove_frame(framesize);
 1719 
 1720   if (StackReservedPages &gt; 0 &amp;&amp; C-&gt;has_reserved_stack_access()) {
 1721     __ reserved_stack_check();
 1722   }
 1723 
 1724   if (do_polling() &amp;&amp; C-&gt;is_method_compilation()) {
 1725     __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);
 1726   }
 1727 }
 1728 
 1729 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
 1730   // Variable size. Determine dynamically.
 1731   return MachNode::size(ra_);
 1732 }
 1733 
 1734 int MachEpilogNode::reloc() const {
 1735   // Return number of relocatable values contained in this instruction.
 1736   return 1; // 1 for polling page.
 1737 }
 1738 
 1739 const Pipeline * MachEpilogNode::pipeline() const {
 1740   return MachNode::pipeline_class();
 1741 }
 1742 
 1743 //=============================================================================
 1744 
 1745 // Figure out which register class each belongs in: rc_int, rc_float or
 1746 // rc_stack.
 1747 enum RC { rc_bad, rc_int, rc_float, rc_stack };
 1748 
 1749 static enum RC rc_class(OptoReg::Name reg) {
 1750 
 1751   if (reg == OptoReg::Bad) {
 1752     return rc_bad;
 1753   }
 1754 
 1755   // we have 30 int registers * 2 halves
 1756   // (rscratch1 and rscratch2 are omitted)
 1757   int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);
 1758 
 1759   if (reg &lt; slots_of_int_registers) {
 1760     return rc_int;
 1761   }
 1762 
 1763   // we have 32 float register * 4 halves
 1764   if (reg &lt; slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {
 1765     return rc_float;
 1766   }
 1767 
 1768   // Between float regs &amp; stack is the flags regs.
 1769   assert(OptoReg::is_stack(reg), &quot;blow up if spilling flags&quot;);
 1770 
 1771   return rc_stack;
 1772 }
 1773 
 1774 uint MachSpillCopyNode::implementation(CodeBuffer *cbuf, PhaseRegAlloc *ra_, bool do_size, outputStream *st) const {
 1775   Compile* C = ra_-&gt;C;
 1776 
 1777   // Get registers to move.
 1778   OptoReg::Name src_hi = ra_-&gt;get_reg_second(in(1));
 1779   OptoReg::Name src_lo = ra_-&gt;get_reg_first(in(1));
 1780   OptoReg::Name dst_hi = ra_-&gt;get_reg_second(this);
 1781   OptoReg::Name dst_lo = ra_-&gt;get_reg_first(this);
 1782 
 1783   enum RC src_hi_rc = rc_class(src_hi);
 1784   enum RC src_lo_rc = rc_class(src_lo);
 1785   enum RC dst_hi_rc = rc_class(dst_hi);
 1786   enum RC dst_lo_rc = rc_class(dst_lo);
 1787 
 1788   assert(src_lo != OptoReg::Bad &amp;&amp; dst_lo != OptoReg::Bad, &quot;must move at least 1 register&quot;);
 1789 
 1790   if (src_hi != OptoReg::Bad) {
 1791     assert((src_lo&amp;1)==0 &amp;&amp; src_lo+1==src_hi &amp;&amp;
 1792            (dst_lo&amp;1)==0 &amp;&amp; dst_lo+1==dst_hi,
 1793            &quot;expected aligned-adjacent pairs&quot;);
 1794   }
 1795 
 1796   if (src_lo == dst_lo &amp;&amp; src_hi == dst_hi) {
 1797     return 0;            // Self copy, no move.
 1798   }
 1799 
 1800   bool is64 = (src_lo &amp; 1) == 0 &amp;&amp; src_lo + 1 == src_hi &amp;&amp;
 1801               (dst_lo &amp; 1) == 0 &amp;&amp; dst_lo + 1 == dst_hi;
 1802   int src_offset = ra_-&gt;reg2offset(src_lo);
 1803   int dst_offset = ra_-&gt;reg2offset(dst_lo);
 1804 
 1805   if (bottom_type()-&gt;isa_vect() != NULL) {
 1806     uint ireg = ideal_reg();
 1807     assert(ireg == Op_VecD || ireg == Op_VecX, &quot;must be 64 bit or 128 bit vector&quot;);
 1808     if (cbuf) {
 1809       C2_MacroAssembler _masm(cbuf);
 1810       assert((src_lo_rc != rc_int &amp;&amp; dst_lo_rc != rc_int), &quot;sanity&quot;);
 1811       if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_stack) {
 1812         // stack-&gt;stack
 1813         assert((src_offset &amp; 7) == 0 &amp;&amp; (dst_offset &amp; 7) == 0, &quot;unaligned stack offset&quot;);
 1814         if (ireg == Op_VecD) {
 1815           __ unspill(rscratch1, true, src_offset);
 1816           __ spill(rscratch1, true, dst_offset);
 1817         } else {
 1818           __ spill_copy128(src_offset, dst_offset);
 1819         }
 1820       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_float) {
 1821         __ mov(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1822                ireg == Op_VecD ? __ T8B : __ T16B,
 1823                as_FloatRegister(Matcher::_regEncode[src_lo]));
 1824       } else if (src_lo_rc == rc_float &amp;&amp; dst_lo_rc == rc_stack) {
 1825         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1826                        ireg == Op_VecD ? __ D : __ Q,
 1827                        ra_-&gt;reg2offset(dst_lo));
 1828       } else if (src_lo_rc == rc_stack &amp;&amp; dst_lo_rc == rc_float) {
 1829         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1830                        ireg == Op_VecD ? __ D : __ Q,
 1831                        ra_-&gt;reg2offset(src_lo));
 1832       } else {
 1833         ShouldNotReachHere();
 1834       }
 1835     }
 1836   } else if (cbuf) {
 1837     C2_MacroAssembler _masm(cbuf);
 1838     switch (src_lo_rc) {
 1839     case rc_int:
 1840       if (dst_lo_rc == rc_int) {  // gpr --&gt; gpr copy
 1841         if (is64) {
 1842             __ mov(as_Register(Matcher::_regEncode[dst_lo]),
 1843                    as_Register(Matcher::_regEncode[src_lo]));
 1844         } else {
 1845             C2_MacroAssembler _masm(cbuf);
 1846             __ movw(as_Register(Matcher::_regEncode[dst_lo]),
 1847                     as_Register(Matcher::_regEncode[src_lo]));
 1848         }
 1849       } else if (dst_lo_rc == rc_float) { // gpr --&gt; fpr copy
 1850         if (is64) {
 1851             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1852                      as_Register(Matcher::_regEncode[src_lo]));
 1853         } else {
 1854             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1855                      as_Register(Matcher::_regEncode[src_lo]));
 1856         }
 1857       } else {                    // gpr --&gt; stack spill
 1858         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1859         __ spill(as_Register(Matcher::_regEncode[src_lo]), is64, dst_offset);
 1860       }
 1861       break;
 1862     case rc_float:
 1863       if (dst_lo_rc == rc_int) {  // fpr --&gt; gpr copy
 1864         if (is64) {
 1865             __ fmovd(as_Register(Matcher::_regEncode[dst_lo]),
 1866                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1867         } else {
 1868             __ fmovs(as_Register(Matcher::_regEncode[dst_lo]),
 1869                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1870         }
 1871       } else if (dst_lo_rc == rc_float) { // fpr --&gt; fpr copy
 1872           if (cbuf) {
 1873             __ fmovd(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1874                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1875         } else {
 1876             __ fmovs(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1877                      as_FloatRegister(Matcher::_regEncode[src_lo]));
 1878         }
 1879       } else {                    // fpr --&gt; stack spill
 1880         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1881         __ spill(as_FloatRegister(Matcher::_regEncode[src_lo]),
 1882                  is64 ? __ D : __ S, dst_offset);
 1883       }
 1884       break;
 1885     case rc_stack:
 1886       if (dst_lo_rc == rc_int) {  // stack --&gt; gpr load
 1887         __ unspill(as_Register(Matcher::_regEncode[dst_lo]), is64, src_offset);
 1888       } else if (dst_lo_rc == rc_float) { // stack --&gt; fpr load
 1889         __ unspill(as_FloatRegister(Matcher::_regEncode[dst_lo]),
 1890                    is64 ? __ D : __ S, src_offset);
 1891       } else {                    // stack --&gt; stack copy
 1892         assert(dst_lo_rc == rc_stack, &quot;spill to bad register class&quot;);
 1893         __ unspill(rscratch1, is64, src_offset);
 1894         __ spill(rscratch1, is64, dst_offset);
 1895       }
 1896       break;
 1897     default:
 1898       assert(false, &quot;bad rc_class for spill&quot;);
 1899       ShouldNotReachHere();
 1900     }
 1901   }
 1902 
 1903   if (st) {
 1904     st-&gt;print(&quot;spill &quot;);
 1905     if (src_lo_rc == rc_stack) {
 1906       st-&gt;print(&quot;[sp, #%d] -&gt; &quot;, ra_-&gt;reg2offset(src_lo));
 1907     } else {
 1908       st-&gt;print(&quot;%s -&gt; &quot;, Matcher::regName[src_lo]);
 1909     }
 1910     if (dst_lo_rc == rc_stack) {
 1911       st-&gt;print(&quot;[sp, #%d]&quot;, ra_-&gt;reg2offset(dst_lo));
 1912     } else {
 1913       st-&gt;print(&quot;%s&quot;, Matcher::regName[dst_lo]);
 1914     }
 1915     if (bottom_type()-&gt;isa_vect() != NULL) {
 1916       st-&gt;print(&quot;\t# vector spill size = %d&quot;, ideal_reg()==Op_VecD ? 64:128);
 1917     } else {
 1918       st-&gt;print(&quot;\t# spill size = %d&quot;, is64 ? 64:32);
 1919     }
 1920   }
 1921 
 1922   return 0;
 1923 
 1924 }
 1925 
 1926 #ifndef PRODUCT
 1927 void MachSpillCopyNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1928   if (!ra_)
 1929     st-&gt;print(&quot;N%d = SpillCopy(N%d)&quot;, _idx, in(1)-&gt;_idx);
 1930   else
 1931     implementation(NULL, ra_, false, st);
 1932 }
 1933 #endif
 1934 
 1935 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1936   implementation(&amp;cbuf, ra_, false, NULL);
 1937 }
 1938 
 1939 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
 1940   return MachNode::size(ra_);
 1941 }
 1942 
 1943 //=============================================================================
 1944 
 1945 #ifndef PRODUCT
 1946 void BoxLockNode::format(PhaseRegAlloc *ra_, outputStream *st) const {
 1947   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1948   int reg = ra_-&gt;get_reg_first(this);
 1949   st-&gt;print(&quot;add %s, rsp, #%d]\t# box lock&quot;,
 1950             Matcher::regName[reg], offset);
 1951 }
 1952 #endif
 1953 
 1954 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
 1955   C2_MacroAssembler _masm(&amp;cbuf);
 1956 
 1957   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
 1958   int reg    = ra_-&gt;get_encode(this);
 1959 
 1960   if (Assembler::operand_valid_for_add_sub_immediate(offset)) {
 1961     __ add(as_Register(reg), sp, offset);
 1962   } else {
 1963     ShouldNotReachHere();
 1964   }
 1965 }
 1966 
 1967 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
 1968   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_).
 1969   return 4;
 1970 }
 1971 
 1972 ///=============================================================================
 1973 #ifndef PRODUCT
 1974 void MachVEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 1975 {
 1976   st-&gt;print_cr(&quot;# MachVEPNode&quot;);
 1977   if (!_verified) {
 1978     st-&gt;print_cr(&quot;\t load_class&quot;);
 1979   } else {
 1980     st-&gt;print_cr(&quot;\t unpack_value_arg&quot;);
 1981   }
 1982 }
 1983 #endif
 1984 
 1985 void MachVEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 1986 {
 1987   MacroAssembler _masm(&amp;cbuf);
 1988 
 1989   if (!_verified) {
 1990     Label skip;
 1991     __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 1992     __ br(Assembler::EQ, skip);
 1993       __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 1994     __ bind(skip);
 1995 
 1996   } else {
 1997     // Unpack value type args passed as oop and then jump to
 1998     // the verified entry point (skipping the unverified entry).
 1999     __ unpack_value_args(ra_-&gt;C, _receiver_only);
 2000     __ b(*_verified_entry);
 2001   }
 2002 }
 2003 
 2004 
 2005 uint MachVEPNode::size(PhaseRegAlloc* ra_) const
 2006 {
 2007   return MachNode::size(ra_); // too many variables; just compute it the hard way
 2008 }
 2009 
 2010 
 2011 //=============================================================================
 2012 #ifndef PRODUCT
 2013 void MachUEPNode::format(PhaseRegAlloc* ra_, outputStream* st) const
 2014 {
 2015   st-&gt;print_cr(&quot;# MachUEPNode&quot;);
 2016   if (UseCompressedClassPointers) {
 2017     st-&gt;print_cr(&quot;\tldrw rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2018     if (CompressedKlassPointers::shift() != 0) {
 2019       st-&gt;print_cr(&quot;\tdecode_klass_not_null rscratch1, rscratch1&quot;);
 2020     }
 2021   } else {
 2022    st-&gt;print_cr(&quot;\tldr rscratch1, j_rarg0 + oopDesc::klass_offset_in_bytes()]\t# compressed klass&quot;);
 2023   }
 2024   st-&gt;print_cr(&quot;\tcmp r0, rscratch1\t # Inline cache check&quot;);
 2025   st-&gt;print_cr(&quot;\tbne, SharedRuntime::_ic_miss_stub&quot;);
 2026 }
 2027 #endif
 2028 
 2029 void MachUEPNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const
 2030 {
 2031   // This is the unverified entry point.
 2032   C2_MacroAssembler _masm(&amp;cbuf);
 2033   Label skip;
 2034 
 2035   // UseCompressedClassPointers logic are inside cmp_klass
 2036   __ cmp_klass(j_rarg0, rscratch2, rscratch1);
 2037 
 2038   // TODO
 2039   // can we avoid this skip and still use a reloc?
 2040   __ br(Assembler::EQ, skip);
 2041   __ far_jump(RuntimeAddress(SharedRuntime::get_ic_miss_stub()));
 2042   __ bind(skip);
 2043 }
 2044 
 2045 uint MachUEPNode::size(PhaseRegAlloc* ra_) const
 2046 {
 2047   return MachNode::size(ra_);
 2048 }
 2049 
 2050 // REQUIRED EMIT CODE
 2051 
 2052 //=============================================================================
 2053 
 2054 // Emit exception handler code.
 2055 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf)
 2056 {
 2057   // mov rscratch1 #exception_blob_entry_point
 2058   // br rscratch1
 2059   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2060   // That&#39;s why we must use the macroassembler to generate a handler.
 2061   C2_MacroAssembler _masm(&amp;cbuf);
 2062   address base = __ start_a_stub(size_exception_handler());
 2063   if (base == NULL) {
 2064     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2065     return 0;  // CodeBuffer::expand failed
 2066   }
 2067   int offset = __ offset();
 2068   __ far_jump(RuntimeAddress(OptoRuntime::exception_blob()-&gt;entry_point()));
 2069   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
 2070   __ end_a_stub();
 2071   return offset;
 2072 }
 2073 
 2074 // Emit deopt handler code.
 2075 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf)
 2076 {
 2077   // Note that the code buffer&#39;s insts_mark is always relative to insts.
 2078   // That&#39;s why we must use the macroassembler to generate a handler.
 2079   C2_MacroAssembler _masm(&amp;cbuf);
 2080   address base = __ start_a_stub(size_deopt_handler());
 2081   if (base == NULL) {
 2082     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 2083     return 0;  // CodeBuffer::expand failed
 2084   }
 2085   int offset = __ offset();
 2086 
 2087   __ adr(lr, __ pc());
 2088   __ far_jump(RuntimeAddress(SharedRuntime::deopt_blob()-&gt;unpack()));
 2089 
 2090   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
 2091   __ end_a_stub();
 2092   return offset;
 2093 }
 2094 
 2095 // REQUIRED MATCHER CODE
 2096 
 2097 //=============================================================================
 2098 
 2099 const bool Matcher::match_rule_supported(int opcode) {
 2100   if (!has_match_rule(opcode))
 2101     return false;
 2102 
 2103   bool ret_value = true;
 2104   switch (opcode) {
 2105     case Op_CacheWB:
 2106     case Op_CacheWBPreSync:
 2107     case Op_CacheWBPostSync:
 2108       if (!VM_Version::supports_data_cache_line_flush()) {
 2109         ret_value = false;
 2110       }
 2111       break;
 2112   }
 2113 
 2114   return ret_value; // Per default match rules are supported.
 2115 }
 2116 
 2117 // Identify extra cases that we might want to provide match rules for vector nodes and
 2118 // other intrinsics guarded with vector length (vlen) and element type (bt).
 2119 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
 2120   if (!match_rule_supported(opcode)) {
 2121     return false;
 2122   }
 2123 
 2124   // Special cases which require vector length
 2125   switch (opcode) {
 2126     case Op_MulAddVS2VI: {
 2127       if (vlen != 4) {
 2128         return false;
 2129       }
 2130       break;
 2131     }
 2132   }
 2133 
 2134   return true; // Per default match rules are supported.
 2135 }
 2136 
 2137 const bool Matcher::has_predicated_vectors(void) {
 2138   return false;
 2139 }
 2140 
 2141 const int Matcher::float_pressure(int default_pressure_threshold) {
 2142   return default_pressure_threshold;
 2143 }
 2144 
 2145 int Matcher::regnum_to_fpu_offset(int regnum)
 2146 {
 2147   Unimplemented();
 2148   return 0;
 2149 }
 2150 
 2151 // Is this branch offset short enough that a short branch can be used?
 2152 //
 2153 // NOTE: If the platform does not provide any short branch variants, then
 2154 //       this method should return false for offset 0.
 2155 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 2156   // The passed offset is relative to address of the branch.
 2157 
 2158   return (-32768 &lt;= offset &amp;&amp; offset &lt; 32768);
 2159 }
 2160 
 2161 const bool Matcher::isSimpleConstant64(jlong value) {
 2162   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 2163   // Probably always true, even if a temp register is required.
 2164   return true;
 2165 }
 2166 
 2167 // true just means we have fast l2f conversion
 2168 const bool Matcher::convL2FSupported(void) {
 2169   return true;
 2170 }
 2171 
 2172 // Vector width in bytes.
 2173 const int Matcher::vector_width_in_bytes(BasicType bt) {
 2174   int size = MIN2(16,(int)MaxVectorSize);
 2175   // Minimum 2 values in vector
 2176   if (size &lt; 2*type2aelembytes(bt)) size = 0;
 2177   // But never &lt; 4
 2178   if (size &lt; 4) size = 0;
 2179   return size;
 2180 }
 2181 
 2182 // Limits on vector size (number of elements) loaded into vector.
 2183 const int Matcher::max_vector_size(const BasicType bt) {
 2184   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 2185 }
 2186 const int Matcher::min_vector_size(const BasicType bt) {
 2187 //  For the moment limit the vector size to 8 bytes
 2188     int size = 8 / type2aelembytes(bt);
 2189     if (size &lt; 2) size = 2;
 2190     return size;
 2191 }
 2192 
 2193 // Vector ideal reg.
 2194 const uint Matcher::vector_ideal_reg(int len) {
 2195   switch(len) {
 2196     case  8: return Op_VecD;
 2197     case 16: return Op_VecX;
 2198   }
 2199   ShouldNotReachHere();
 2200   return 0;
 2201 }
 2202 
 2203 // AES support not yet implemented
 2204 const bool Matcher::pass_original_key_for_aes() {
 2205   return false;
 2206 }
 2207 
 2208 // aarch64 supports misaligned vectors store/load.
 2209 const bool Matcher::misaligned_vectors_ok() {
 2210   return true;
 2211 }
 2212 
 2213 // false =&gt; size gets scaled to BytesPerLong, ok.
 2214 const bool Matcher::init_array_count_is_in_bytes = false;
 2215 
 2216 // Use conditional move (CMOVL)
 2217 const int Matcher::long_cmove_cost() {
 2218   // long cmoves are no more expensive than int cmoves
 2219   return 0;
 2220 }
 2221 
 2222 const int Matcher::float_cmove_cost() {
 2223   // float cmoves are no more expensive than int cmoves
 2224   return 0;
 2225 }
 2226 
 2227 // Does the CPU require late expand (see block.cpp for description of late expand)?
 2228 const bool Matcher::require_postalloc_expand = false;
 2229 
 2230 // Do we need to mask the count passed to shift instructions or does
 2231 // the cpu only look at the lower 5/6 bits anyway?
 2232 const bool Matcher::need_masked_shift_count = false;
 2233 
 2234 // No support for generic vector operands.
 2235 const bool Matcher::supports_generic_vector_operands  = false;
 2236 
 2237 MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 2238   ShouldNotReachHere(); // generic vector operands not supported
 2239   return NULL;
 2240 }
 2241 
 2242 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 2243   ShouldNotReachHere();  // generic vector operands not supported
 2244   return false;
 2245 }
 2246 
 2247 bool Matcher::is_generic_vector(MachOper* opnd)  {
 2248   ShouldNotReachHere();  // generic vector operands not supported
 2249   return false;
 2250 }
 2251 
 2252 // This affects two different things:
 2253 //  - how Decode nodes are matched
 2254 //  - how ImplicitNullCheck opportunities are recognized
 2255 // If true, the matcher will try to remove all Decodes and match them
 2256 // (as operands) into nodes. NullChecks are not prepared to deal with
 2257 // Decodes by final_graph_reshaping().
 2258 // If false, final_graph_reshaping() forces the decode behind the Cmp
 2259 // for a NullCheck. The matcher matches the Decode node into a register.
 2260 // Implicit_null_check optimization moves the Decode along with the
 2261 // memory operation back up before the NullCheck.
 2262 bool Matcher::narrow_oop_use_complex_address() {
 2263   return CompressedOops::shift() == 0;
 2264 }
 2265 
 2266 bool Matcher::narrow_klass_use_complex_address() {
 2267 // TODO
 2268 // decide whether we need to set this to true
 2269   return false;
 2270 }
 2271 
 2272 bool Matcher::const_oop_prefer_decode() {
 2273   // Prefer ConN+DecodeN over ConP in simple compressed oops mode.
 2274   return CompressedOops::base() == NULL;
 2275 }
 2276 
 2277 bool Matcher::const_klass_prefer_decode() {
 2278   // Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.
 2279   return CompressedKlassPointers::base() == NULL;
 2280 }
 2281 
 2282 // Is it better to copy float constants, or load them directly from
 2283 // memory?  Intel can load a float constant from a direct address,
 2284 // requiring no extra registers.  Most RISCs will have to materialize
 2285 // an address into a register first, so they would do better to copy
 2286 // the constant from stack.
 2287 const bool Matcher::rematerialize_float_constants = false;
 2288 
 2289 // If CPU can load and store mis-aligned doubles directly then no
 2290 // fixup is needed.  Else we split the double into 2 integer pieces
 2291 // and move it piece-by-piece.  Only happens when passing doubles into
 2292 // C code as the Java calling convention forces doubles to be aligned.
 2293 const bool Matcher::misaligned_doubles_ok = true;
 2294 
 2295 // No-op on amd64
 2296 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 2297   Unimplemented();
 2298 }
 2299 
 2300 // Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.
 2301 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 2302 
 2303 // Are floats converted to double when stored to stack during
 2304 // deoptimization?
 2305 bool Matcher::float_in_double() { return false; }
 2306 
 2307 // Do ints take an entire long register or just half?
 2308 // The relevant question is how the int is callee-saved:
 2309 // the whole long is written but de-opt&#39;ing will have to extract
 2310 // the relevant 32 bits.
 2311 const bool Matcher::int_in_long = true;
 2312 
 2313 // Return whether or not this register is ever used as an argument.
 2314 // This function is used on startup to build the trampoline stubs in
 2315 // generateOptoStub.  Registers not mentioned will be killed by the VM
 2316 // call in the trampoline, and arguments in those registers not be
 2317 // available to the callee.
 2318 bool Matcher::can_be_java_arg(int reg)
 2319 {
 2320   return
 2321     reg ==  R0_num || reg == R0_H_num ||
 2322     reg ==  R1_num || reg == R1_H_num ||
 2323     reg ==  R2_num || reg == R2_H_num ||
 2324     reg ==  R3_num || reg == R3_H_num ||
 2325     reg ==  R4_num || reg == R4_H_num ||
 2326     reg ==  R5_num || reg == R5_H_num ||
 2327     reg ==  R6_num || reg == R6_H_num ||
 2328     reg ==  R7_num || reg == R7_H_num ||
 2329     reg ==  V0_num || reg == V0_H_num ||
 2330     reg ==  V1_num || reg == V1_H_num ||
 2331     reg ==  V2_num || reg == V2_H_num ||
 2332     reg ==  V3_num || reg == V3_H_num ||
 2333     reg ==  V4_num || reg == V4_H_num ||
 2334     reg ==  V5_num || reg == V5_H_num ||
 2335     reg ==  V6_num || reg == V6_H_num ||
 2336     reg ==  V7_num || reg == V7_H_num;
 2337 }
 2338 
 2339 bool Matcher::is_spillable_arg(int reg)
 2340 {
 2341   return can_be_java_arg(reg);
 2342 }
 2343 
 2344 bool Matcher::use_asm_for_ldiv_by_con(jlong divisor) {
 2345   return false;
 2346 }
 2347 
 2348 RegMask Matcher::divI_proj_mask() {
 2349   ShouldNotReachHere();
 2350   return RegMask();
 2351 }
 2352 
 2353 // Register for MODI projection of divmodI.
 2354 RegMask Matcher::modI_proj_mask() {
 2355   ShouldNotReachHere();
 2356   return RegMask();
 2357 }
 2358 
 2359 // Register for DIVL projection of divmodL.
 2360 RegMask Matcher::divL_proj_mask() {
 2361   ShouldNotReachHere();
 2362   return RegMask();
 2363 }
 2364 
 2365 // Register for MODL projection of divmodL.
 2366 RegMask Matcher::modL_proj_mask() {
 2367   ShouldNotReachHere();
 2368   return RegMask();
 2369 }
 2370 
 2371 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 2372   return FP_REG_mask();
 2373 }
 2374 
 2375 bool size_fits_all_mem_uses(AddPNode* addp, int shift) {
 2376   for (DUIterator_Fast imax, i = addp-&gt;fast_outs(imax); i &lt; imax; i++) {
 2377     Node* u = addp-&gt;fast_out(i);
 2378     if (u-&gt;is_Mem()) {
 2379       int opsize = u-&gt;as_Mem()-&gt;memory_size();
 2380       assert(opsize &gt; 0, &quot;unexpected memory operand size&quot;);
 2381       if (u-&gt;as_Mem()-&gt;memory_size() != (1&lt;&lt;shift)) {
 2382         return false;
 2383       }
 2384     }
 2385   }
 2386   return true;
 2387 }
 2388 
 2389 const bool Matcher::convi2l_type_required = false;
 2390 
 2391 // Should the matcher clone input &#39;m&#39; of node &#39;n&#39;?
 2392 bool Matcher::pd_clone_node(Node* n, Node* m, Matcher::MStack&amp; mstack) {
 2393   if (is_vshift_con_pattern(n, m)) { // ShiftV src (ShiftCntV con)
 2394     mstack.push(m, Visit);           // m = ShiftCntV
 2395     return true;
 2396   }
 2397   return false;
 2398 }
 2399 
 2400 // Should the Matcher clone shifts on addressing modes, expecting them
 2401 // to be subsumed into complex addressing expressions or compute them
 2402 // into registers?
 2403 bool Matcher::pd_clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 2404   if (clone_base_plus_offset_address(m, mstack, address_visited)) {
 2405     return true;
 2406   }
 2407 
 2408   Node *off = m-&gt;in(AddPNode::Offset);
 2409   if (off-&gt;Opcode() == Op_LShiftL &amp;&amp; off-&gt;in(2)-&gt;is_Con() &amp;&amp;
 2410       size_fits_all_mem_uses(m, off-&gt;in(2)-&gt;get_int()) &amp;&amp;
 2411       // Are there other uses besides address expressions?
 2412       !is_visited(off)) {
 2413     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2414     mstack.push(off-&gt;in(2), Visit);
 2415     Node *conv = off-&gt;in(1);
 2416     if (conv-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2417         // Are there other uses besides address expressions?
 2418         !is_visited(conv)) {
 2419       address_visited.set(conv-&gt;_idx); // Flag as address_visited
 2420       mstack.push(conv-&gt;in(1), Pre_Visit);
 2421     } else {
 2422       mstack.push(conv, Pre_Visit);
 2423     }
 2424     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2425     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2426     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2427     return true;
 2428   } else if (off-&gt;Opcode() == Op_ConvI2L &amp;&amp;
 2429              // Are there other uses besides address expressions?
 2430              !is_visited(off)) {
 2431     address_visited.test_set(m-&gt;_idx); // Flag as address_visited
 2432     address_visited.set(off-&gt;_idx); // Flag as address_visited
 2433     mstack.push(off-&gt;in(1), Pre_Visit);
 2434     mstack.push(m-&gt;in(AddPNode::Address), Pre_Visit);
 2435     mstack.push(m-&gt;in(AddPNode::Base), Pre_Visit);
 2436     return true;
 2437   }
 2438   return false;
 2439 }
 2440 
 2441 void Compile::reshape_address(AddPNode* addp) {
 2442 }
 2443 
 2444 #define MOV_VOLATILE(REG, BASE, INDEX, SCALE, DISP, SCRATCH, INSN)      \
 2445   C2_MacroAssembler _masm(&amp;cbuf);                                       \
 2446   {                                                                     \
 2447     guarantee(INDEX == -1, &quot;mode not permitted for volatile&quot;);          \
 2448     guarantee(DISP == 0, &quot;mode not permitted for volatile&quot;);            \
 2449     guarantee(SCALE == 0, &quot;mode not permitted for volatile&quot;);           \
 2450     __ INSN(REG, as_Register(BASE));                                    \
 2451   }
 2452 
 2453 
 2454 static Address mem2address(int opcode, Register base, int index, int size, int disp)
 2455   {
 2456     Address::extend scale;
 2457 
 2458     // Hooboy, this is fugly.  We need a way to communicate to the
 2459     // encoder that the index needs to be sign extended, so we have to
 2460     // enumerate all the cases.
 2461     switch (opcode) {
 2462     case INDINDEXSCALEDI2L:
 2463     case INDINDEXSCALEDI2LN:
 2464     case INDINDEXI2L:
 2465     case INDINDEXI2LN:
 2466       scale = Address::sxtw(size);
 2467       break;
 2468     default:
 2469       scale = Address::lsl(size);
 2470     }
 2471 
 2472     if (index == -1) {
 2473       return Address(base, disp);
 2474     } else {
 2475       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2476       return Address(base, as_Register(index), scale);
 2477     }
 2478   }
 2479 
 2480 
 2481 typedef void (MacroAssembler::* mem_insn)(Register Rt, const Address &amp;adr);
 2482 typedef void (MacroAssembler::* mem_insn2)(Register Rt, Register adr);
 2483 typedef void (MacroAssembler::* mem_float_insn)(FloatRegister Rt, const Address &amp;adr);
 2484 typedef void (MacroAssembler::* mem_vector_insn)(FloatRegister Rt,
 2485                                   MacroAssembler::SIMD_RegVariant T, const Address &amp;adr);
 2486 
 2487   // Used for all non-volatile memory accesses.  The use of
 2488   // $mem-&gt;opcode() to discover whether this pattern uses sign-extended
 2489   // offsets is something of a kludge.
 2490   static void loadStore(C2_MacroAssembler masm, mem_insn insn,
 2491                         Register reg, int opcode,
 2492                         Register base, int index, int scale, int disp,
 2493                         int size_in_memory)
 2494   {
 2495     Address addr = mem2address(opcode, base, index, scale, disp);
 2496     if (addr.getMode() == Address::base_plus_offset) {
 2497       /* If we get an out-of-range offset it is a bug in the compiler,
 2498          so we assert here. */
 2499       assert(Address::offset_ok_for_immed(addr.offset(), exact_log2(size_in_memory)),
 2500              &quot;c2 compiler bug&quot;);
 2501       /* Fix up any out-of-range offsets. */
 2502       assert_different_registers(rscratch1, base);
 2503       assert_different_registers(rscratch1, reg);
 2504       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2505     }
 2506     (masm.*insn)(reg, addr);
 2507   }
 2508 
 2509   static void loadStore(C2_MacroAssembler masm, mem_float_insn insn,
 2510                         FloatRegister reg, int opcode,
 2511                         Register base, int index, int size, int disp,
 2512                         int size_in_memory)
 2513   {
 2514     Address::extend scale;
 2515 
 2516     switch (opcode) {
 2517     case INDINDEXSCALEDI2L:
 2518     case INDINDEXSCALEDI2LN:
 2519       scale = Address::sxtw(size);
 2520       break;
 2521     default:
 2522       scale = Address::lsl(size);
 2523     }
 2524 
 2525     if (index == -1) {
 2526       /* If we get an out-of-range offset it is a bug in the compiler,
 2527          so we assert here. */
 2528       assert(Address::offset_ok_for_immed(disp, exact_log2(size_in_memory)), &quot;c2 compiler bug&quot;);
 2529       /* Fix up any out-of-range offsets. */
 2530       assert_different_registers(rscratch1, base);
 2531       Address addr = Address(base, disp);
 2532       addr = masm.legitimize_address(addr, size_in_memory, rscratch1);
 2533       (masm.*insn)(reg, addr);
 2534     } else {
 2535       assert(disp == 0, &quot;unsupported address mode: disp = %d&quot;, disp);
 2536       (masm.*insn)(reg, Address(base, as_Register(index), scale));
 2537     }
 2538   }
 2539 
 2540   static void loadStore(C2_MacroAssembler masm, mem_vector_insn insn,
 2541                         FloatRegister reg, MacroAssembler::SIMD_RegVariant T,
 2542                         int opcode, Register base, int index, int size, int disp)
 2543   {
 2544     if (index == -1) {
 2545       (masm.*insn)(reg, T, Address(base, disp));
 2546     } else {
 2547       assert(disp == 0, &quot;unsupported address mode&quot;);
 2548       (masm.*insn)(reg, T, Address(base, as_Register(index), Address::lsl(size)));
 2549     }
 2550   }
 2551 
 2552 %}
 2553 
 2554 
 2555 
 2556 //----------ENCODING BLOCK-----------------------------------------------------
 2557 // This block specifies the encoding classes used by the compiler to
 2558 // output byte streams.  Encoding classes are parameterized macros
 2559 // used by Machine Instruction Nodes in order to generate the bit
 2560 // encoding of the instruction.  Operands specify their base encoding
 2561 // interface with the interface keyword.  There are currently
 2562 // supported four interfaces, REG_INTER, CONST_INTER, MEMORY_INTER, &amp;
 2563 // COND_INTER.  REG_INTER causes an operand to generate a function
 2564 // which returns its register number when queried.  CONST_INTER causes
 2565 // an operand to generate a function which returns the value of the
 2566 // constant when queried.  MEMORY_INTER causes an operand to generate
 2567 // four functions which return the Base Register, the Index Register,
 2568 // the Scale Value, and the Offset Value of the operand when queried.
 2569 // COND_INTER causes an operand to generate six functions which return
 2570 // the encoding code (ie - encoding bits for the instruction)
 2571 // associated with each basic boolean condition for a conditional
 2572 // instruction.
 2573 //
 2574 // Instructions specify two basic values for encoding.  Again, a
 2575 // function is available to check if the constant displacement is an
 2576 // oop. They use the ins_encode keyword to specify their encoding
 2577 // classes (which must be a sequence of enc_class names, and their
 2578 // parameters, specified in the encoding block), and they use the
 2579 // opcode keyword to specify, in order, their primary, secondary, and
 2580 // tertiary opcode.  Only the opcode sections which a particular
 2581 // instruction needs for encoding need to be specified.
 2582 encode %{
 2583   // Build emit functions for each basic byte or larger field in the
 2584   // intel encoding scheme (opcode, rm, sib, immediate), and call them
 2585   // from C++ code in the enc_class source block.  Emit functions will
 2586   // live in the main source block for now.  In future, we can
 2587   // generalize this by adding a syntax that specifies the sizes of
 2588   // fields in an order, so that the adlc can build the emit functions
 2589   // automagically
 2590 
 2591   // catch all for unimplemented encodings
 2592   enc_class enc_unimplemented %{
 2593     C2_MacroAssembler _masm(&amp;cbuf);
 2594     __ unimplemented(&quot;C2 catch all&quot;);
 2595   %}
 2596 
 2597   // BEGIN Non-volatile memory access
 2598 
 2599   // This encoding class is generated automatically from ad_encode.m4.
 2600   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2601   enc_class aarch64_enc_ldrsbw(iRegI dst, memory1 mem) %{
 2602     Register dst_reg = as_Register($dst$$reg);
 2603     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsbw, dst_reg, $mem-&gt;opcode(),
 2604                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2605   %}
 2606 
 2607   // This encoding class is generated automatically from ad_encode.m4.
 2608   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2609   enc_class aarch64_enc_ldrsb(iRegI dst, memory1 mem) %{
 2610     Register dst_reg = as_Register($dst$$reg);
 2611     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsb, dst_reg, $mem-&gt;opcode(),
 2612                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2613   %}
 2614 
 2615   // This encoding class is generated automatically from ad_encode.m4.
 2616   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2617   enc_class aarch64_enc_ldrb(iRegI dst, memory1 mem) %{
 2618     Register dst_reg = as_Register($dst$$reg);
 2619     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2620                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2621   %}
 2622 
 2623   // This encoding class is generated automatically from ad_encode.m4.
 2624   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2625   enc_class aarch64_enc_ldrb(iRegL dst, memory1 mem) %{
 2626     Register dst_reg = as_Register($dst$$reg);
 2627     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrb, dst_reg, $mem-&gt;opcode(),
 2628                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2629   %}
 2630 
 2631   // This encoding class is generated automatically from ad_encode.m4.
 2632   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2633   enc_class aarch64_enc_ldrshw(iRegI dst, memory2 mem) %{
 2634     Register dst_reg = as_Register($dst$$reg);
 2635     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrshw, dst_reg, $mem-&gt;opcode(),
 2636                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2637   %}
 2638 
 2639   // This encoding class is generated automatically from ad_encode.m4.
 2640   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2641   enc_class aarch64_enc_ldrsh(iRegI dst, memory2 mem) %{
 2642     Register dst_reg = as_Register($dst$$reg);
 2643     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsh, dst_reg, $mem-&gt;opcode(),
 2644                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2645   %}
 2646 
 2647   // This encoding class is generated automatically from ad_encode.m4.
 2648   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2649   enc_class aarch64_enc_ldrh(iRegI dst, memory2 mem) %{
 2650     Register dst_reg = as_Register($dst$$reg);
 2651     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2652                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2653   %}
 2654 
 2655   // This encoding class is generated automatically from ad_encode.m4.
 2656   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2657   enc_class aarch64_enc_ldrh(iRegL dst, memory2 mem) %{
 2658     Register dst_reg = as_Register($dst$$reg);
 2659     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrh, dst_reg, $mem-&gt;opcode(),
 2660                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2661   %}
 2662 
 2663   // This encoding class is generated automatically from ad_encode.m4.
 2664   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2665   enc_class aarch64_enc_ldrw(iRegI dst, memory4 mem) %{
 2666     Register dst_reg = as_Register($dst$$reg);
 2667     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2668                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2669   %}
 2670 
 2671   // This encoding class is generated automatically from ad_encode.m4.
 2672   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2673   enc_class aarch64_enc_ldrw(iRegL dst, memory4 mem) %{
 2674     Register dst_reg = as_Register($dst$$reg);
 2675     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrw, dst_reg, $mem-&gt;opcode(),
 2676                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2677   %}
 2678 
 2679   // This encoding class is generated automatically from ad_encode.m4.
 2680   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2681   enc_class aarch64_enc_ldrsw(iRegL dst, memory4 mem) %{
 2682     Register dst_reg = as_Register($dst$$reg);
 2683     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrsw, dst_reg, $mem-&gt;opcode(),
 2684                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2685   %}
 2686 
 2687   // This encoding class is generated automatically from ad_encode.m4.
 2688   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2689   enc_class aarch64_enc_ldr(iRegL dst, memory8 mem) %{
 2690     Register dst_reg = as_Register($dst$$reg);
 2691     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, $mem-&gt;opcode(),
 2692                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2693   %}
 2694 
 2695   // This encoding class is generated automatically from ad_encode.m4.
 2696   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2697   enc_class aarch64_enc_ldrs(vRegF dst, memory4 mem) %{
 2698     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2699     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, dst_reg, $mem-&gt;opcode(),
 2700                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2701   %}
 2702 
 2703   // This encoding class is generated automatically from ad_encode.m4.
 2704   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2705   enc_class aarch64_enc_ldrd(vRegD dst, memory8 mem) %{
 2706     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2707     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, dst_reg, $mem-&gt;opcode(),
 2708                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2709   %}
 2710 
 2711   // This encoding class is generated automatically from ad_encode.m4.
 2712   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2713   enc_class aarch64_enc_strb(iRegI src, memory1 mem) %{
 2714     Register src_reg = as_Register($src$$reg);
 2715     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strb, src_reg, $mem-&gt;opcode(),
 2716                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2717   %}
 2718 
 2719   // This encoding class is generated automatically from ad_encode.m4.
 2720   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2721   enc_class aarch64_enc_strb0(memory1 mem) %{
 2722     C2_MacroAssembler _masm(&amp;cbuf);
 2723     loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2724                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2725   %}
 2726 
 2727   // This encoding class is generated automatically from ad_encode.m4.
 2728   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2729   enc_class aarch64_enc_strh(iRegI src, memory2 mem) %{
 2730     Register src_reg = as_Register($src$$reg);
 2731     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strh, src_reg, $mem-&gt;opcode(),
 2732                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2733   %}
 2734 
 2735   // This encoding class is generated automatically from ad_encode.m4.
 2736   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2737   enc_class aarch64_enc_strh0(memory2 mem) %{
 2738     C2_MacroAssembler _masm(&amp;cbuf);
 2739     loadStore(_masm, &amp;MacroAssembler::strh, zr, $mem-&gt;opcode(),
 2740                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 2);
 2741   %}
 2742 
 2743   // This encoding class is generated automatically from ad_encode.m4.
 2744   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2745   enc_class aarch64_enc_strw(iRegI src, memory4 mem) %{
 2746     Register src_reg = as_Register($src$$reg);
 2747     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strw, src_reg, $mem-&gt;opcode(),
 2748                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2749   %}
 2750 
 2751   // This encoding class is generated automatically from ad_encode.m4.
 2752   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2753   enc_class aarch64_enc_strw0(memory4 mem) %{
 2754     C2_MacroAssembler _masm(&amp;cbuf);
 2755     loadStore(_masm, &amp;MacroAssembler::strw, zr, $mem-&gt;opcode(),
 2756                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2757   %}
 2758 
 2759   // This encoding class is generated automatically from ad_encode.m4.
 2760   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2761   enc_class aarch64_enc_str(iRegL src, memory8 mem) %{
 2762     Register src_reg = as_Register($src$$reg);
 2763     // we sometimes get asked to store the stack pointer into the
 2764     // current thread -- we cannot do that directly on AArch64
 2765     if (src_reg == r31_sp) {
 2766       C2_MacroAssembler _masm(&amp;cbuf);
 2767       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2768       __ mov(rscratch2, sp);
 2769       src_reg = rscratch2;
 2770     }
 2771     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, $mem-&gt;opcode(),
 2772                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2773   %}
 2774 
 2775   // This encoding class is generated automatically from ad_encode.m4.
 2776   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2777   enc_class aarch64_enc_str0(memory8 mem) %{
 2778     C2_MacroAssembler _masm(&amp;cbuf);
 2779     loadStore(_masm, &amp;MacroAssembler::str, zr, $mem-&gt;opcode(),
 2780                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2781   %}
 2782 
 2783   // This encoding class is generated automatically from ad_encode.m4.
 2784   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2785   enc_class aarch64_enc_strs(vRegF src, memory4 mem) %{
 2786     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2787     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strs, src_reg, $mem-&gt;opcode(),
 2788                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2789   %}
 2790 
 2791   // This encoding class is generated automatically from ad_encode.m4.
 2792   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2793   enc_class aarch64_enc_strd(vRegD src, memory8 mem) %{
 2794     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2795     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::strd, src_reg, $mem-&gt;opcode(),
 2796                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 2797   %}
 2798 
 2799   // This encoding class is generated automatically from ad_encode.m4.
 2800   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2801   enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{
 2802     C2_MacroAssembler _masm(&amp;cbuf);
 2803     address con = (address)$src$$constant;
 2804     // need to do this the hard way until we can manage relocs
 2805     // for 32 bit constants
 2806     __ movoop(rscratch2, (jobject)con);
 2807     if (con) __ encode_heap_oop_not_null(rscratch2);
 2808     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2809                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2810   %}
 2811 
 2812   // This encoding class is generated automatically from ad_encode.m4.
 2813   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2814   enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{
 2815     C2_MacroAssembler _masm(&amp;cbuf);
 2816     address con = (address)$src$$constant;
 2817     // need to do this the hard way until we can manage relocs
 2818     // for 32 bit constants
 2819     __ movoop(rscratch2, (jobject)con);
 2820     __ encode_klass_not_null(rscratch2);
 2821     loadStore(_masm, &amp;MacroAssembler::strw, rscratch2, $mem-&gt;opcode(),
 2822                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 2823   %}
 2824 
 2825   // This encoding class is generated automatically from ad_encode.m4.
 2826   // DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE
 2827   enc_class aarch64_enc_strb0_ordered(memory4 mem) %{
 2828       C2_MacroAssembler _masm(&amp;cbuf);
 2829       __ membar(Assembler::StoreStore);
 2830       loadStore(_masm, &amp;MacroAssembler::strb, zr, $mem-&gt;opcode(),
 2831                as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 1);
 2832   %}
 2833 
 2834   // END Non-volatile memory access
 2835 
 2836   // Vector loads and stores
 2837   enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{
 2838     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2839     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::S,
 2840        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2841   %}
 2842 
 2843   enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{
 2844     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2845     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::D,
 2846        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2847   %}
 2848 
 2849   enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{
 2850     FloatRegister dst_reg = as_FloatRegister($dst$$reg);
 2851     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldr, dst_reg, MacroAssembler::Q,
 2852        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2853   %}
 2854 
 2855   enc_class aarch64_enc_strvS(vecD src, memory mem) %{
 2856     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2857     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::S,
 2858        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2859   %}
 2860 
 2861   enc_class aarch64_enc_strvD(vecD src, memory mem) %{
 2862     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2863     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::D,
 2864        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2865   %}
 2866 
 2867   enc_class aarch64_enc_strvQ(vecX src, memory mem) %{
 2868     FloatRegister src_reg = as_FloatRegister($src$$reg);
 2869     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::str, src_reg, MacroAssembler::Q,
 2870        $mem-&gt;opcode(), as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);
 2871   %}
 2872 
 2873   // volatile loads and stores
 2874 
 2875   enc_class aarch64_enc_stlrb(iRegI src, memory mem) %{
 2876     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2877                  rscratch1, stlrb);
 2878   %}
 2879 
 2880   enc_class aarch64_enc_stlrh(iRegI src, memory mem) %{
 2881     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2882                  rscratch1, stlrh);
 2883   %}
 2884 
 2885   enc_class aarch64_enc_stlrw(iRegI src, memory mem) %{
 2886     MOV_VOLATILE(as_Register($src$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2887                  rscratch1, stlrw);
 2888   %}
 2889 
 2890 
 2891   enc_class aarch64_enc_ldarsbw(iRegI dst, memory mem) %{
 2892     Register dst_reg = as_Register($dst$$reg);
 2893     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2894              rscratch1, ldarb);
 2895     __ sxtbw(dst_reg, dst_reg);
 2896   %}
 2897 
 2898   enc_class aarch64_enc_ldarsb(iRegL dst, memory mem) %{
 2899     Register dst_reg = as_Register($dst$$reg);
 2900     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2901              rscratch1, ldarb);
 2902     __ sxtb(dst_reg, dst_reg);
 2903   %}
 2904 
 2905   enc_class aarch64_enc_ldarbw(iRegI dst, memory mem) %{
 2906     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2907              rscratch1, ldarb);
 2908   %}
 2909 
 2910   enc_class aarch64_enc_ldarb(iRegL dst, memory mem) %{
 2911     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2912              rscratch1, ldarb);
 2913   %}
 2914 
 2915   enc_class aarch64_enc_ldarshw(iRegI dst, memory mem) %{
 2916     Register dst_reg = as_Register($dst$$reg);
 2917     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2918              rscratch1, ldarh);
 2919     __ sxthw(dst_reg, dst_reg);
 2920   %}
 2921 
 2922   enc_class aarch64_enc_ldarsh(iRegL dst, memory mem) %{
 2923     Register dst_reg = as_Register($dst$$reg);
 2924     MOV_VOLATILE(dst_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2925              rscratch1, ldarh);
 2926     __ sxth(dst_reg, dst_reg);
 2927   %}
 2928 
 2929   enc_class aarch64_enc_ldarhw(iRegI dst, memory mem) %{
 2930     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2931              rscratch1, ldarh);
 2932   %}
 2933 
 2934   enc_class aarch64_enc_ldarh(iRegL dst, memory mem) %{
 2935     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2936              rscratch1, ldarh);
 2937   %}
 2938 
 2939   enc_class aarch64_enc_ldarw(iRegI dst, memory mem) %{
 2940     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2941              rscratch1, ldarw);
 2942   %}
 2943 
 2944   enc_class aarch64_enc_ldarw(iRegL dst, memory mem) %{
 2945     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2946              rscratch1, ldarw);
 2947   %}
 2948 
 2949   enc_class aarch64_enc_ldar(iRegL dst, memory mem) %{
 2950     MOV_VOLATILE(as_Register($dst$$reg), $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2951              rscratch1, ldar);
 2952   %}
 2953 
 2954   enc_class aarch64_enc_fldars(vRegF dst, memory mem) %{
 2955     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2956              rscratch1, ldarw);
 2957     __ fmovs(as_FloatRegister($dst$$reg), rscratch1);
 2958   %}
 2959 
 2960   enc_class aarch64_enc_fldard(vRegD dst, memory mem) %{
 2961     MOV_VOLATILE(rscratch1, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2962              rscratch1, ldar);
 2963     __ fmovd(as_FloatRegister($dst$$reg), rscratch1);
 2964   %}
 2965 
 2966   enc_class aarch64_enc_stlr(iRegL src, memory mem) %{
 2967     Register src_reg = as_Register($src$$reg);
 2968     // we sometimes get asked to store the stack pointer into the
 2969     // current thread -- we cannot do that directly on AArch64
 2970     if (src_reg == r31_sp) {
 2971       C2_MacroAssembler _masm(&amp;cbuf);
 2972       assert(as_Register($mem$$base) == rthread, &quot;unexpected store for sp&quot;);
 2973       __ mov(rscratch2, sp);
 2974       src_reg = rscratch2;
 2975     }
 2976     MOV_VOLATILE(src_reg, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2977                  rscratch1, stlr);
 2978   %}
 2979 
 2980   enc_class aarch64_enc_fstlrs(vRegF src, memory mem) %{
 2981     {
 2982       C2_MacroAssembler _masm(&amp;cbuf);
 2983       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2984       __ fmovs(rscratch2, src_reg);
 2985     }
 2986     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2987                  rscratch1, stlrw);
 2988   %}
 2989 
 2990   enc_class aarch64_enc_fstlrd(vRegD src, memory mem) %{
 2991     {
 2992       C2_MacroAssembler _masm(&amp;cbuf);
 2993       FloatRegister src_reg = as_FloatRegister($src$$reg);
 2994       __ fmovd(rscratch2, src_reg);
 2995     }
 2996     MOV_VOLATILE(rscratch2, $mem$$base, $mem$$index, $mem$$scale, $mem$$disp,
 2997                  rscratch1, stlr);
 2998   %}
 2999 
 3000   // synchronized read/update encodings
 3001 
 3002   enc_class aarch64_enc_ldaxr(iRegL dst, memory8 mem) %{
 3003     C2_MacroAssembler _masm(&amp;cbuf);
 3004     Register dst_reg = as_Register($dst$$reg);
 3005     Register base = as_Register($mem$$base);
 3006     int index = $mem$$index;
 3007     int scale = $mem$$scale;
 3008     int disp = $mem$$disp;
 3009     if (index == -1) {
 3010        if (disp != 0) {
 3011         __ lea(rscratch1, Address(base, disp));
 3012         __ ldaxr(dst_reg, rscratch1);
 3013       } else {
 3014         // TODO
 3015         // should we ever get anything other than this case?
 3016         __ ldaxr(dst_reg, base);
 3017       }
 3018     } else {
 3019       Register index_reg = as_Register(index);
 3020       if (disp == 0) {
 3021         __ lea(rscratch1, Address(base, index_reg, Address::lsl(scale)));
 3022         __ ldaxr(dst_reg, rscratch1);
 3023       } else {
 3024         __ lea(rscratch1, Address(base, disp));
 3025         __ lea(rscratch1, Address(rscratch1, index_reg, Address::lsl(scale)));
 3026         __ ldaxr(dst_reg, rscratch1);
 3027       }
 3028     }
 3029   %}
 3030 
 3031   enc_class aarch64_enc_stlxr(iRegLNoSp src, memory8 mem) %{
 3032     C2_MacroAssembler _masm(&amp;cbuf);
 3033     Register src_reg = as_Register($src$$reg);
 3034     Register base = as_Register($mem$$base);
 3035     int index = $mem$$index;
 3036     int scale = $mem$$scale;
 3037     int disp = $mem$$disp;
 3038     if (index == -1) {
 3039        if (disp != 0) {
 3040         __ lea(rscratch2, Address(base, disp));
 3041         __ stlxr(rscratch1, src_reg, rscratch2);
 3042       } else {
 3043         // TODO
 3044         // should we ever get anything other than this case?
 3045         __ stlxr(rscratch1, src_reg, base);
 3046       }
 3047     } else {
 3048       Register index_reg = as_Register(index);
 3049       if (disp == 0) {
 3050         __ lea(rscratch2, Address(base, index_reg, Address::lsl(scale)));
 3051         __ stlxr(rscratch1, src_reg, rscratch2);
 3052       } else {
 3053         __ lea(rscratch2, Address(base, disp));
 3054         __ lea(rscratch2, Address(rscratch2, index_reg, Address::lsl(scale)));
 3055         __ stlxr(rscratch1, src_reg, rscratch2);
 3056       }
 3057     }
 3058     __ cmpw(rscratch1, zr);
 3059   %}
 3060 
 3061   enc_class aarch64_enc_cmpxchg(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3062     C2_MacroAssembler _masm(&amp;cbuf);
 3063     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3064     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3065                Assembler::xword, /*acquire*/ false, /*release*/ true,
 3066                /*weak*/ false, noreg);
 3067   %}
 3068 
 3069   enc_class aarch64_enc_cmpxchgw(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3070     C2_MacroAssembler _masm(&amp;cbuf);
 3071     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3072     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3073                Assembler::word, /*acquire*/ false, /*release*/ true,
 3074                /*weak*/ false, noreg);
 3075   %}
 3076 
 3077   enc_class aarch64_enc_cmpxchgs(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3078     C2_MacroAssembler _masm(&amp;cbuf);
 3079     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3080     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3081                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 3082                /*weak*/ false, noreg);
 3083   %}
 3084 
 3085   enc_class aarch64_enc_cmpxchgb(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3086     C2_MacroAssembler _masm(&amp;cbuf);
 3087     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3088     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3089                Assembler::byte, /*acquire*/ false, /*release*/ true,
 3090                /*weak*/ false, noreg);
 3091   %}
 3092 
 3093 
 3094   // The only difference between aarch64_enc_cmpxchg and
 3095   // aarch64_enc_cmpxchg_acq is that we use load-acquire in the
 3096   // CompareAndSwap sequence to serve as a barrier on acquiring a
 3097   // lock.
 3098   enc_class aarch64_enc_cmpxchg_acq(memory mem, iRegLNoSp oldval, iRegLNoSp newval) %{
 3099     C2_MacroAssembler _masm(&amp;cbuf);
 3100     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3101     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3102                Assembler::xword, /*acquire*/ true, /*release*/ true,
 3103                /*weak*/ false, noreg);
 3104   %}
 3105 
 3106   enc_class aarch64_enc_cmpxchgw_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3107     C2_MacroAssembler _masm(&amp;cbuf);
 3108     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3109     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3110                Assembler::word, /*acquire*/ true, /*release*/ true,
 3111                /*weak*/ false, noreg);
 3112   %}
 3113 
 3114   enc_class aarch64_enc_cmpxchgs_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3115     C2_MacroAssembler _masm(&amp;cbuf);
 3116     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3117     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3118                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 3119                /*weak*/ false, noreg);
 3120   %}
 3121 
 3122   enc_class aarch64_enc_cmpxchgb_acq(memory mem, iRegINoSp oldval, iRegINoSp newval) %{
 3123     C2_MacroAssembler _masm(&amp;cbuf);
 3124     guarantee($mem$$index == -1 &amp;&amp; $mem$$disp == 0, &quot;impossible encoding&quot;);
 3125     __ cmpxchg($mem$$base$$Register, $oldval$$Register, $newval$$Register,
 3126                Assembler::byte, /*acquire*/ true, /*release*/ true,
 3127                /*weak*/ false, noreg);
 3128   %}
 3129 
 3130   // auxiliary used for CompareAndSwapX to set result register
 3131   enc_class aarch64_enc_cset_eq(iRegINoSp res) %{
 3132     C2_MacroAssembler _masm(&amp;cbuf);
 3133     Register res_reg = as_Register($res$$reg);
 3134     __ cset(res_reg, Assembler::EQ);
 3135   %}
 3136 
 3137   // prefetch encodings
 3138 
 3139   enc_class aarch64_enc_prefetchw(memory mem) %{
 3140     C2_MacroAssembler _masm(&amp;cbuf);
 3141     Register base = as_Register($mem$$base);
 3142     int index = $mem$$index;
 3143     int scale = $mem$$scale;
 3144     int disp = $mem$$disp;
 3145     if (index == -1) {
 3146       __ prfm(Address(base, disp), PSTL1KEEP);
 3147     } else {
 3148       Register index_reg = as_Register(index);
 3149       if (disp == 0) {
 3150         __ prfm(Address(base, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3151       } else {
 3152         __ lea(rscratch1, Address(base, disp));
 3153 	__ prfm(Address(rscratch1, index_reg, Address::lsl(scale)), PSTL1KEEP);
 3154       }
 3155     }
 3156   %}
 3157 
 3158   /// mov envcodings
 3159 
 3160   enc_class aarch64_enc_movw_imm(iRegI dst, immI src) %{
 3161     C2_MacroAssembler _masm(&amp;cbuf);
 3162     u_int32_t con = (u_int32_t)$src$$constant;
 3163     Register dst_reg = as_Register($dst$$reg);
 3164     if (con == 0) {
 3165       __ movw(dst_reg, zr);
 3166     } else {
 3167       __ movw(dst_reg, con);
 3168     }
 3169   %}
 3170 
 3171   enc_class aarch64_enc_mov_imm(iRegL dst, immL src) %{
 3172     C2_MacroAssembler _masm(&amp;cbuf);
 3173     Register dst_reg = as_Register($dst$$reg);
 3174     u_int64_t con = (u_int64_t)$src$$constant;
 3175     if (con == 0) {
 3176       __ mov(dst_reg, zr);
 3177     } else {
 3178       __ mov(dst_reg, con);
 3179     }
 3180   %}
 3181 
 3182   enc_class aarch64_enc_mov_p(iRegP dst, immP src) %{
 3183     C2_MacroAssembler _masm(&amp;cbuf);
 3184     Register dst_reg = as_Register($dst$$reg);
 3185     address con = (address)$src$$constant;
 3186     if (con == NULL || con == (address)1) {
 3187       ShouldNotReachHere();
 3188     } else {
 3189       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3190       if (rtype == relocInfo::oop_type) {
 3191         __ movoop(dst_reg, (jobject)con, /*immediate*/true);
 3192       } else if (rtype == relocInfo::metadata_type) {
 3193         __ mov_metadata(dst_reg, (Metadata*)con);
 3194       } else {
 3195         assert(rtype == relocInfo::none, &quot;unexpected reloc type&quot;);
 3196         if (con &lt; (address)(uintptr_t)os::vm_page_size()) {
 3197           __ mov(dst_reg, con);
 3198         } else {
 3199           unsigned long offset;
 3200           __ adrp(dst_reg, con, offset);
 3201           __ add(dst_reg, dst_reg, offset);
 3202         }
 3203       }
 3204     }
 3205   %}
 3206 
 3207   enc_class aarch64_enc_mov_p0(iRegP dst, immP0 src) %{
 3208     C2_MacroAssembler _masm(&amp;cbuf);
 3209     Register dst_reg = as_Register($dst$$reg);
 3210     __ mov(dst_reg, zr);
 3211   %}
 3212 
 3213   enc_class aarch64_enc_mov_p1(iRegP dst, immP_1 src) %{
 3214     C2_MacroAssembler _masm(&amp;cbuf);
 3215     Register dst_reg = as_Register($dst$$reg);
 3216     __ mov(dst_reg, (u_int64_t)1);
 3217   %}
 3218 
 3219   enc_class aarch64_enc_mov_byte_map_base(iRegP dst, immByteMapBase src) %{
 3220     C2_MacroAssembler _masm(&amp;cbuf);
 3221     __ load_byte_map_base($dst$$Register);
 3222   %}
 3223 
 3224   enc_class aarch64_enc_mov_n(iRegN dst, immN src) %{
 3225     C2_MacroAssembler _masm(&amp;cbuf);
 3226     Register dst_reg = as_Register($dst$$reg);
 3227     address con = (address)$src$$constant;
 3228     if (con == NULL) {
 3229       ShouldNotReachHere();
 3230     } else {
 3231       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3232       assert(rtype == relocInfo::oop_type, &quot;unexpected reloc type&quot;);
 3233       __ set_narrow_oop(dst_reg, (jobject)con);
 3234     }
 3235   %}
 3236 
 3237   enc_class aarch64_enc_mov_n0(iRegN dst, immN0 src) %{
 3238     C2_MacroAssembler _masm(&amp;cbuf);
 3239     Register dst_reg = as_Register($dst$$reg);
 3240     __ mov(dst_reg, zr);
 3241   %}
 3242 
 3243   enc_class aarch64_enc_mov_nk(iRegN dst, immNKlass src) %{
 3244     C2_MacroAssembler _masm(&amp;cbuf);
 3245     Register dst_reg = as_Register($dst$$reg);
 3246     address con = (address)$src$$constant;
 3247     if (con == NULL) {
 3248       ShouldNotReachHere();
 3249     } else {
 3250       relocInfo::relocType rtype = $src-&gt;constant_reloc();
 3251       assert(rtype == relocInfo::metadata_type, &quot;unexpected reloc type&quot;);
 3252       __ set_narrow_klass(dst_reg, (Klass *)con);
 3253     }
 3254   %}
 3255 
 3256   // arithmetic encodings
 3257 
 3258   enc_class aarch64_enc_addsubw_imm(iRegI dst, iRegI src1, immIAddSub src2) %{
 3259     C2_MacroAssembler _masm(&amp;cbuf);
 3260     Register dst_reg = as_Register($dst$$reg);
 3261     Register src_reg = as_Register($src1$$reg);
 3262     int32_t con = (int32_t)$src2$$constant;
 3263     // add has primary == 0, subtract has primary == 1
 3264     if ($primary) { con = -con; }
 3265     if (con &lt; 0) {
 3266       __ subw(dst_reg, src_reg, -con);
 3267     } else {
 3268       __ addw(dst_reg, src_reg, con);
 3269     }
 3270   %}
 3271 
 3272   enc_class aarch64_enc_addsub_imm(iRegL dst, iRegL src1, immLAddSub src2) %{
 3273     C2_MacroAssembler _masm(&amp;cbuf);
 3274     Register dst_reg = as_Register($dst$$reg);
 3275     Register src_reg = as_Register($src1$$reg);
 3276     int32_t con = (int32_t)$src2$$constant;
 3277     // add has primary == 0, subtract has primary == 1
 3278     if ($primary) { con = -con; }
 3279     if (con &lt; 0) {
 3280       __ sub(dst_reg, src_reg, -con);
 3281     } else {
 3282       __ add(dst_reg, src_reg, con);
 3283     }
 3284   %}
 3285 
 3286   enc_class aarch64_enc_divw(iRegI dst, iRegI src1, iRegI src2) %{
 3287     C2_MacroAssembler _masm(&amp;cbuf);
 3288    Register dst_reg = as_Register($dst$$reg);
 3289    Register src1_reg = as_Register($src1$$reg);
 3290    Register src2_reg = as_Register($src2$$reg);
 3291     __ corrected_idivl(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3292   %}
 3293 
 3294   enc_class aarch64_enc_div(iRegI dst, iRegI src1, iRegI src2) %{
 3295     C2_MacroAssembler _masm(&amp;cbuf);
 3296    Register dst_reg = as_Register($dst$$reg);
 3297    Register src1_reg = as_Register($src1$$reg);
 3298    Register src2_reg = as_Register($src2$$reg);
 3299     __ corrected_idivq(dst_reg, src1_reg, src2_reg, false, rscratch1);
 3300   %}
 3301 
 3302   enc_class aarch64_enc_modw(iRegI dst, iRegI src1, iRegI src2) %{
 3303     C2_MacroAssembler _masm(&amp;cbuf);
 3304    Register dst_reg = as_Register($dst$$reg);
 3305    Register src1_reg = as_Register($src1$$reg);
 3306    Register src2_reg = as_Register($src2$$reg);
 3307     __ corrected_idivl(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3308   %}
 3309 
 3310   enc_class aarch64_enc_mod(iRegI dst, iRegI src1, iRegI src2) %{
 3311     C2_MacroAssembler _masm(&amp;cbuf);
 3312    Register dst_reg = as_Register($dst$$reg);
 3313    Register src1_reg = as_Register($src1$$reg);
 3314    Register src2_reg = as_Register($src2$$reg);
 3315     __ corrected_idivq(dst_reg, src1_reg, src2_reg, true, rscratch1);
 3316   %}
 3317 
 3318   // compare instruction encodings
 3319 
 3320   enc_class aarch64_enc_cmpw(iRegI src1, iRegI src2) %{
 3321     C2_MacroAssembler _masm(&amp;cbuf);
 3322     Register reg1 = as_Register($src1$$reg);
 3323     Register reg2 = as_Register($src2$$reg);
 3324     __ cmpw(reg1, reg2);
 3325   %}
 3326 
 3327   enc_class aarch64_enc_cmpw_imm_addsub(iRegI src1, immIAddSub src2) %{
 3328     C2_MacroAssembler _masm(&amp;cbuf);
 3329     Register reg = as_Register($src1$$reg);
 3330     int32_t val = $src2$$constant;
 3331     if (val &gt;= 0) {
 3332       __ subsw(zr, reg, val);
 3333     } else {
 3334       __ addsw(zr, reg, -val);
 3335     }
 3336   %}
 3337 
 3338   enc_class aarch64_enc_cmpw_imm(iRegI src1, immI src2) %{
 3339     C2_MacroAssembler _masm(&amp;cbuf);
 3340     Register reg1 = as_Register($src1$$reg);
 3341     u_int32_t val = (u_int32_t)$src2$$constant;
 3342     __ movw(rscratch1, val);
 3343     __ cmpw(reg1, rscratch1);
 3344   %}
 3345 
 3346   enc_class aarch64_enc_cmp(iRegL src1, iRegL src2) %{
 3347     C2_MacroAssembler _masm(&amp;cbuf);
 3348     Register reg1 = as_Register($src1$$reg);
 3349     Register reg2 = as_Register($src2$$reg);
 3350     __ cmp(reg1, reg2);
 3351   %}
 3352 
 3353   enc_class aarch64_enc_cmp_imm_addsub(iRegL src1, immL12 src2) %{
 3354     C2_MacroAssembler _masm(&amp;cbuf);
 3355     Register reg = as_Register($src1$$reg);
 3356     int64_t val = $src2$$constant;
 3357     if (val &gt;= 0) {
 3358       __ subs(zr, reg, val);
 3359     } else if (val != -val) {
 3360       __ adds(zr, reg, -val);
 3361     } else {
 3362     // aargh, Long.MIN_VALUE is a special case
 3363       __ orr(rscratch1, zr, (u_int64_t)val);
 3364       __ subs(zr, reg, rscratch1);
 3365     }
 3366   %}
 3367 
 3368   enc_class aarch64_enc_cmp_imm(iRegL src1, immL src2) %{
 3369     C2_MacroAssembler _masm(&amp;cbuf);
 3370     Register reg1 = as_Register($src1$$reg);
 3371     u_int64_t val = (u_int64_t)$src2$$constant;
 3372     __ mov(rscratch1, val);
 3373     __ cmp(reg1, rscratch1);
 3374   %}
 3375 
 3376   enc_class aarch64_enc_cmpp(iRegP src1, iRegP src2) %{
 3377     C2_MacroAssembler _masm(&amp;cbuf);
 3378     Register reg1 = as_Register($src1$$reg);
 3379     Register reg2 = as_Register($src2$$reg);
 3380     __ cmp(reg1, reg2);
 3381   %}
 3382 
 3383   enc_class aarch64_enc_cmpn(iRegN src1, iRegN src2) %{
 3384     C2_MacroAssembler _masm(&amp;cbuf);
 3385     Register reg1 = as_Register($src1$$reg);
 3386     Register reg2 = as_Register($src2$$reg);
 3387     __ cmpw(reg1, reg2);
 3388   %}
 3389 
 3390   enc_class aarch64_enc_testp(iRegP src) %{
 3391     C2_MacroAssembler _masm(&amp;cbuf);
 3392     Register reg = as_Register($src$$reg);
 3393     __ cmp(reg, zr);
 3394   %}
 3395 
 3396   enc_class aarch64_enc_testn(iRegN src) %{
 3397     C2_MacroAssembler _masm(&amp;cbuf);
 3398     Register reg = as_Register($src$$reg);
 3399     __ cmpw(reg, zr);
 3400   %}
 3401 
 3402   enc_class aarch64_enc_b(label lbl) %{
 3403     C2_MacroAssembler _masm(&amp;cbuf);
 3404     Label *L = $lbl$$label;
 3405     __ b(*L);
 3406   %}
 3407 
 3408   enc_class aarch64_enc_br_con(cmpOp cmp, label lbl) %{
 3409     C2_MacroAssembler _masm(&amp;cbuf);
 3410     Label *L = $lbl$$label;
 3411     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3412   %}
 3413 
 3414   enc_class aarch64_enc_br_conU(cmpOpU cmp, label lbl) %{
 3415     C2_MacroAssembler _masm(&amp;cbuf);
 3416     Label *L = $lbl$$label;
 3417     __ br ((Assembler::Condition)$cmp$$cmpcode, *L);
 3418   %}
 3419 
 3420   enc_class aarch64_enc_partial_subtype_check(iRegP sub, iRegP super, iRegP temp, iRegP result)
 3421   %{
 3422      Register sub_reg = as_Register($sub$$reg);
 3423      Register super_reg = as_Register($super$$reg);
 3424      Register temp_reg = as_Register($temp$$reg);
 3425      Register result_reg = as_Register($result$$reg);
 3426 
 3427      Label miss;
 3428      C2_MacroAssembler _masm(&amp;cbuf);
 3429      __ check_klass_subtype_slow_path(sub_reg, super_reg, temp_reg, result_reg,
 3430                                      NULL, &amp;miss,
 3431                                      /*set_cond_codes:*/ true);
 3432      if ($primary) {
 3433        __ mov(result_reg, zr);
 3434      }
 3435      __ bind(miss);
 3436   %}
 3437 
 3438   enc_class aarch64_enc_java_static_call(method meth) %{
 3439     C2_MacroAssembler _masm(&amp;cbuf);
 3440 
 3441     address addr = (address)$meth$$method;
 3442     address call;
 3443     if (!_method) {
 3444       // A call to a runtime wrapper, e.g. new, new_typeArray_Java, uncommon_trap.
 3445       call = __ trampoline_call(Address(addr, relocInfo::runtime_call_type), &amp;cbuf);
 3446     } else {
 3447       int method_index = resolved_method_index(cbuf);
 3448       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 3449                                                   : static_call_Relocation::spec(method_index);
 3450       call = __ trampoline_call(Address(addr, rspec), &amp;cbuf);
 3451 
 3452       // Emit stub for static call
 3453       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 3454       if (stub == NULL) {
 3455         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3456         return;
 3457       }
 3458     }
 3459     if (call == NULL) {
 3460       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3461       return;
 3462     }
 3463   %}
 3464 
 3465   enc_class aarch64_enc_java_dynamic_call(method meth) %{
 3466     C2_MacroAssembler _masm(&amp;cbuf);
 3467     int method_index = resolved_method_index(cbuf);
 3468     address call = __ ic_call((address)$meth$$method, method_index);
 3469     if (call == NULL) {
 3470       ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3471       return;
 3472     }
 3473   %}
 3474 
 3475   enc_class aarch64_enc_call_epilog() %{
 3476     C2_MacroAssembler _masm(&amp;cbuf);
 3477     if (VerifyStackAtCalls) {
 3478       // Check that stack depth is unchanged: find majik cookie on stack
 3479       __ call_Unimplemented();
 3480     }
 3481   %}
 3482 
 3483   enc_class aarch64_enc_java_to_runtime(method meth) %{
 3484     C2_MacroAssembler _masm(&amp;cbuf);
 3485 
 3486     // some calls to generated routines (arraycopy code) are scheduled
 3487     // by C2 as runtime calls. if so we can call them using a br (they
 3488     // will be in a reachable segment) otherwise we have to use a blr
 3489     // which loads the absolute address into a register.
 3490     address entry = (address)$meth$$method;
 3491     CodeBlob *cb = CodeCache::find_blob(entry);
 3492     if (cb) {
 3493       address call = __ trampoline_call(Address(entry, relocInfo::runtime_call_type));
 3494       if (call == NULL) {
 3495         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 3496         return;
 3497       }
 3498     } else {
 3499       Label retaddr;
 3500       __ adr(rscratch2, retaddr);
 3501       __ lea(rscratch1, RuntimeAddress(entry));
 3502       // Leave a breadcrumb for JavaFrameAnchor::capture_last_Java_pc()
 3503       __ stp(zr, rscratch2, Address(__ pre(sp, -2 * wordSize)));
 3504       __ blr(rscratch1);
 3505       __ bind(retaddr);
 3506       __ add(sp, sp, 2 * wordSize);
 3507     }
 3508   %}
 3509 
 3510   enc_class aarch64_enc_rethrow() %{
 3511     C2_MacroAssembler _masm(&amp;cbuf);
 3512     __ far_jump(RuntimeAddress(OptoRuntime::rethrow_stub()));
 3513   %}
 3514 
 3515   enc_class aarch64_enc_ret() %{
 3516     C2_MacroAssembler _masm(&amp;cbuf);
 3517     __ ret(lr);
 3518   %}
 3519 
 3520   enc_class aarch64_enc_tail_call(iRegP jump_target) %{
 3521     C2_MacroAssembler _masm(&amp;cbuf);
 3522     Register target_reg = as_Register($jump_target$$reg);
 3523     __ br(target_reg);
 3524   %}
 3525 
 3526   enc_class aarch64_enc_tail_jmp(iRegP jump_target) %{
 3527     C2_MacroAssembler _masm(&amp;cbuf);
 3528     Register target_reg = as_Register($jump_target$$reg);
 3529     // exception oop should be in r0
 3530     // ret addr has been popped into lr
 3531     // callee expects it in r3
 3532     __ mov(r3, lr);
 3533     __ br(target_reg);
 3534   %}
 3535 
 3536   enc_class aarch64_enc_fast_lock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3537     C2_MacroAssembler _masm(&amp;cbuf);
 3538     Register oop = as_Register($object$$reg);
 3539     Register box = as_Register($box$$reg);
 3540     Register disp_hdr = as_Register($tmp$$reg);
 3541     Register tmp = as_Register($tmp2$$reg);
 3542     Label cont;
 3543     Label object_has_monitor;
 3544     Label cas_failed;
 3545 
 3546     assert_different_registers(oop, box, tmp, disp_hdr);
 3547 
 3548     // Load markWord from object into displaced_header.
 3549     __ ldr(disp_hdr, Address(oop, oopDesc::mark_offset_in_bytes()));
 3550 
 3551     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3552       __ biased_locking_enter(box, oop, disp_hdr, tmp, true, cont);
 3553     }
 3554 
 3555     // Check for existing monitor
 3556     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3557 
 3558     // Set tmp to be (markWord of object | UNLOCK_VALUE).
 3559     __ orr(tmp, disp_hdr, markWord::unlocked_value);
 3560 
 3561     // Initialize the box. (Must happen before we update the object mark!)
 3562     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3563 
 3564     // Compare object markWord with an unlocked value (tmp) and if
 3565     // equal exchange the stack address of our box with object markWord.
 3566     // On failure disp_hdr contains the possibly locked markWord.
 3567     __ cmpxchg(oop, tmp, box, Assembler::xword, /*acquire*/ true,
 3568                /*release*/ true, /*weak*/ false, disp_hdr);
 3569     __ br(Assembler::EQ, cont);
 3570 
 3571     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3572 
 3573     // If the compare-and-exchange succeeded, then we found an unlocked
 3574     // object, will have now locked it will continue at label cont
 3575 
 3576     __ bind(cas_failed);
 3577     // We did not see an unlocked object so try the fast recursive case.
 3578 
 3579     // Check if the owner is self by comparing the value in the
 3580     // markWord of object (disp_hdr) with the stack pointer.
 3581     __ mov(rscratch1, sp);
 3582     __ sub(disp_hdr, disp_hdr, rscratch1);
 3583     __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));
 3584     // If condition is true we are cont and hence we can store 0 as the
 3585     // displaced header in the box, which indicates that it is a recursive lock.
 3586     __ ands(tmp/*==0?*/, disp_hdr, tmp);   // Sets flags for result
 3587     __ str(tmp/*==0, perhaps*/, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3588 
 3589     __ b(cont);
 3590 
 3591     // Handle existing monitor.
 3592     __ bind(object_has_monitor);
 3593 
 3594     // The object&#39;s monitor m is unlocked iff m-&gt;owner == NULL,
 3595     // otherwise m-&gt;owner may contain a thread or a stack address.
 3596     //
 3597     // Try to CAS m-&gt;owner from NULL to current thread.
 3598     __ add(tmp, disp_hdr, (ObjectMonitor::owner_offset_in_bytes()-markWord::monitor_value));
 3599     __ cmpxchg(tmp, zr, rthread, Assembler::xword, /*acquire*/ true,
 3600                /*release*/ true, /*weak*/ false, noreg); // Sets flags for result
 3601 
 3602     // Store a non-null value into the box to avoid looking like a re-entrant
 3603     // lock. The fast-path monitor unlock code checks for
 3604     // markWord::monitor_value so use markWord::unused_mark which has the
 3605     // relevant bit set, and also matches ObjectSynchronizer::enter.
 3606     __ mov(tmp, (address)markWord::unused_mark().value());
 3607     __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3608 
 3609     __ bind(cont);
 3610     // flag == EQ indicates success
 3611     // flag == NE indicates failure
 3612   %}
 3613 
 3614   enc_class aarch64_enc_fast_unlock(iRegP object, iRegP box, iRegP tmp, iRegP tmp2) %{
 3615     C2_MacroAssembler _masm(&amp;cbuf);
 3616     Register oop = as_Register($object$$reg);
 3617     Register box = as_Register($box$$reg);
 3618     Register disp_hdr = as_Register($tmp$$reg);
 3619     Register tmp = as_Register($tmp2$$reg);
 3620     Label cont;
 3621     Label object_has_monitor;
 3622 
 3623     assert_different_registers(oop, box, tmp, disp_hdr);
 3624 
 3625     if (UseBiasedLocking &amp;&amp; !UseOptoBiasInlining) {
 3626       __ biased_locking_exit(oop, tmp, cont);
 3627     }
 3628 
 3629     // Find the lock address and load the displaced header from the stack.
 3630     __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));
 3631 
 3632     // If the displaced header is 0, we have a recursive unlock.
 3633     __ cmp(disp_hdr, zr);
 3634     __ br(Assembler::EQ, cont);
 3635 
 3636     // Handle existing monitor.
 3637     __ ldr(tmp, Address(oop, oopDesc::mark_offset_in_bytes()));
 3638     __ tbnz(disp_hdr, exact_log2(markWord::monitor_value), object_has_monitor);
 3639 
 3640     // Check if it is still a light weight lock, this is is true if we
 3641     // see the stack address of the basicLock in the markWord of the
 3642     // object.
 3643 
 3644     __ cmpxchg(oop, box, disp_hdr, Assembler::xword, /*acquire*/ false,
 3645                /*release*/ true, /*weak*/ false, tmp);
 3646     __ b(cont);
 3647 
 3648     assert(oopDesc::mark_offset_in_bytes() == 0, &quot;offset of _mark is not 0&quot;);
 3649 
 3650     // Handle existing monitor.
 3651     __ bind(object_has_monitor);
 3652     STATIC_ASSERT(markWord::monitor_value &lt;= INT_MAX);
 3653     __ add(tmp, tmp, -(int)markWord::monitor_value); // monitor
 3654     __ ldr(rscratch1, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3655     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::recursions_offset_in_bytes()));
 3656     __ eor(rscratch1, rscratch1, rthread); // Will be 0 if we are the owner.
 3657     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if there are 0 recursions
 3658     __ cmp(rscratch1, zr); // Sets flags for result
 3659     __ br(Assembler::NE, cont);
 3660 
 3661     __ ldr(rscratch1, Address(tmp, ObjectMonitor::EntryList_offset_in_bytes()));
 3662     __ ldr(disp_hdr, Address(tmp, ObjectMonitor::cxq_offset_in_bytes()));
 3663     __ orr(rscratch1, rscratch1, disp_hdr); // Will be 0 if both are 0.
 3664     __ cmp(rscratch1, zr); // Sets flags for result
 3665     __ cbnz(rscratch1, cont);
 3666     // need a release store here
 3667     __ lea(tmp, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));
 3668     __ stlr(zr, tmp); // set unowned
 3669 
 3670     __ bind(cont);
 3671     // flag == EQ indicates success
 3672     // flag == NE indicates failure
 3673   %}
 3674 
 3675 %}
 3676 
 3677 //----------FRAME--------------------------------------------------------------
 3678 // Definition of frame structure and management information.
 3679 //
 3680 //  S T A C K   L A Y O U T    Allocators stack-slot number
 3681 //                             |   (to get allocators register number
 3682 //  G  Owned by    |        |  v    add OptoReg::stack0())
 3683 //  r   CALLER     |        |
 3684 //  o     |        +--------+      pad to even-align allocators stack-slot
 3685 //  w     V        |  pad0  |        numbers; owned by CALLER
 3686 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 3687 //  h     ^        |   in   |  5
 3688 //        |        |  args  |  4   Holes in incoming args owned by SELF
 3689 //  |     |        |        |  3
 3690 //  |     |        +--------+
 3691 //  V     |        | old out|      Empty on Intel, window on Sparc
 3692 //        |    old |preserve|      Must be even aligned.
 3693 //        |     SP-+--------+----&gt; Matcher::_old_SP, even aligned
 3694 //        |        |   in   |  3   area for Intel ret address
 3695 //     Owned by    |preserve|      Empty on Sparc.
 3696 //       SELF      +--------+
 3697 //        |        |  pad2  |  2   pad to align old SP
 3698 //        |        +--------+  1
 3699 //        |        | locks  |  0
 3700 //        |        +--------+----&gt; OptoReg::stack0(), even aligned
 3701 //        |        |  pad1  | 11   pad to align new SP
 3702 //        |        +--------+
 3703 //        |        |        | 10
 3704 //        |        | spills |  9   spills
 3705 //        V        |        |  8   (pad0 slot for callee)
 3706 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 3707 //        ^        |  out   |  7
 3708 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 3709 //     Owned by    +--------+
 3710 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 3711 //        |    new |preserve|      Must be even-aligned.
 3712 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 3713 //        |        |        |
 3714 //
 3715 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 3716 //         known from SELF&#39;s arguments and the Java calling convention.
 3717 //         Region 6-7 is determined per call site.
 3718 // Note 2: If the calling convention leaves holes in the incoming argument
 3719 //         area, those holes are owned by SELF.  Holes in the outgoing area
 3720 //         are owned by the CALLEE.  Holes should not be nessecary in the
 3721 //         incoming area, as the Java calling convention is completely under
 3722 //         the control of the AD file.  Doubles can be sorted and packed to
 3723 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 3724 //         varargs C calling conventions.
 3725 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 3726 //         even aligned with pad0 as needed.
 3727 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 3728 //           (the latter is true on Intel but is it false on AArch64?)
 3729 //         region 6-11 is even aligned; it may be padded out more so that
 3730 //         the region from SP to FP meets the minimum stack alignment.
 3731 // Note 4: For I2C adapters, the incoming FP may not meet the minimum stack
 3732 //         alignment.  Region 11, pad1, may be dynamically extended so that
 3733 //         SP meets the minimum alignment.
 3734 
 3735 frame %{
 3736   // What direction does stack grow in (assumed to be same for C &amp; Java)
 3737   stack_direction(TOWARDS_LOW);
 3738 
 3739   // These three registers define part of the calling convention
 3740   // between compiled code and the interpreter.
 3741 
 3742   // Inline Cache Register or methodOop for I2C.
 3743   inline_cache_reg(R12);
 3744 
 3745   // Method Oop Register when calling interpreter.
 3746   interpreter_method_oop_reg(R12);
 3747 
 3748   // Number of stack slots consumed by locking an object
 3749   sync_stack_slots(2);
 3750 
 3751   // Compiled code&#39;s Frame Pointer
 3752   frame_pointer(R31);
 3753 
 3754   // Interpreter stores its frame pointer in a register which is
 3755   // stored to the stack by I2CAdaptors.
 3756   // I2CAdaptors convert from interpreted java to compiled java.
 3757   interpreter_frame_pointer(R29);
 3758 
 3759   // Stack alignment requirement
 3760   stack_alignment(StackAlignmentInBytes); // Alignment size in bytes (128-bit -&gt; 16 bytes)
 3761 
 3762   // Number of stack slots between incoming argument block and the start of
 3763   // a new frame.  The PROLOG must add this many slots to the stack.  The
 3764   // EPILOG must remove this many slots. aarch64 needs two slots for
 3765   // return address and fp.
 3766   // TODO think this is correct but check
 3767   in_preserve_stack_slots(4);
 3768 
 3769   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 3770   // for calls to C.  Supports the var-args backing area for register parms.
 3771   varargs_C_out_slots_killed(frame::arg_reg_save_area_bytes/BytesPerInt);
 3772 
 3773   // The after-PROLOG location of the return address.  Location of
 3774   // return address specifies a type (REG or STACK) and a number
 3775   // representing the register number (i.e. - use a register name) or
 3776   // stack slot.
 3777   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 3778   // Otherwise, it is above the locks and verification slot and alignment word
 3779   // TODO this may well be correct but need to check why that - 2 is there
 3780   // ppc port uses 0 but we definitely need to allow for fixed_slots
 3781   // which folds in the space used for monitors
 3782   return_addr(STACK - 2 +
 3783               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 3784                         Compile::current()-&gt;fixed_slots()),
 3785                        stack_alignment_in_slots()));
 3786 
 3787   // Body of function which returns an integer array locating
 3788   // arguments either in registers or in stack slots.  Passed an array
 3789   // of ideal registers called &quot;sig&quot; and a &quot;length&quot; count.  Stack-slot
 3790   // offsets are based on outgoing arguments, i.e. a CALLER setting up
 3791   // arguments for a CALLEE.  Incoming stack arguments are
 3792   // automatically biased by the preserve_stack_slots field above.
 3793 
 3794   calling_convention
 3795   %{
 3796     // No difference between ingoing/outgoing just pass false
 3797     SharedRuntime::java_calling_convention(sig_bt, regs, length, false);
 3798   %}
 3799 
 3800   c_calling_convention
 3801   %{
 3802     // This is obviously always outgoing
 3803     (void) SharedRuntime::c_calling_convention(sig_bt, regs, NULL, length);
 3804   %}
 3805 
 3806   // Location of compiled Java return values.  Same as C for now.
 3807   return_value
 3808   %{
 3809     // TODO do we allow ideal_reg == Op_RegN???
 3810     assert(ideal_reg &gt;= Op_RegI &amp;&amp; ideal_reg &lt;= Op_RegL,
 3811            &quot;only return normal values&quot;);
 3812 
 3813     static const int lo[Op_RegL + 1] = { // enum name
 3814       0,                                 // Op_Node
 3815       0,                                 // Op_Set
 3816       R0_num,                            // Op_RegN
 3817       R0_num,                            // Op_RegI
 3818       R0_num,                            // Op_RegP
 3819       V0_num,                            // Op_RegF
 3820       V0_num,                            // Op_RegD
 3821       R0_num                             // Op_RegL
 3822     };
 3823 
 3824     static const int hi[Op_RegL + 1] = { // enum name
 3825       0,                                 // Op_Node
 3826       0,                                 // Op_Set
 3827       OptoReg::Bad,                      // Op_RegN
 3828       OptoReg::Bad,                      // Op_RegI
 3829       R0_H_num,                          // Op_RegP
 3830       OptoReg::Bad,                      // Op_RegF
 3831       V0_H_num,                          // Op_RegD
 3832       R0_H_num                           // Op_RegL
 3833     };
 3834 
 3835     return OptoRegPair(hi[ideal_reg], lo[ideal_reg]);
 3836   %}
 3837 %}
 3838 
 3839 //----------ATTRIBUTES---------------------------------------------------------
 3840 //----------Operand Attributes-------------------------------------------------
 3841 op_attrib op_cost(1);        // Required cost attribute
 3842 
 3843 //----------Instruction Attributes---------------------------------------------
 3844 ins_attrib ins_cost(INSN_COST); // Required cost attribute
 3845 ins_attrib ins_size(32);        // Required size attribute (in bits)
 3846 ins_attrib ins_short_branch(0); // Required flag: is this instruction
 3847                                 // a non-matching short branch variant
 3848                                 // of some long branch?
 3849 ins_attrib ins_alignment(4);    // Required alignment attribute (must
 3850                                 // be a power of 2) specifies the
 3851                                 // alignment that some part of the
 3852                                 // instruction (not necessarily the
 3853                                 // start) requires.  If &gt; 1, a
 3854                                 // compute_padding() function must be
 3855                                 // provided for the instruction
 3856 
 3857 //----------OPERANDS-----------------------------------------------------------
 3858 // Operand definitions must precede instruction definitions for correct parsing
 3859 // in the ADLC because operands constitute user defined types which are used in
 3860 // instruction definitions.
 3861 
 3862 //----------Simple Operands----------------------------------------------------
 3863 
 3864 // Integer operands 32 bit
 3865 // 32 bit immediate
 3866 operand immI()
 3867 %{
 3868   match(ConI);
 3869 
 3870   op_cost(0);
 3871   format %{ %}
 3872   interface(CONST_INTER);
 3873 %}
 3874 
 3875 // 32 bit zero
 3876 operand immI0()
 3877 %{
 3878   predicate(n-&gt;get_int() == 0);
 3879   match(ConI);
 3880 
 3881   op_cost(0);
 3882   format %{ %}
 3883   interface(CONST_INTER);
 3884 %}
 3885 
 3886 // 32 bit unit increment
 3887 operand immI_1()
 3888 %{
 3889   predicate(n-&gt;get_int() == 1);
 3890   match(ConI);
 3891 
 3892   op_cost(0);
 3893   format %{ %}
 3894   interface(CONST_INTER);
 3895 %}
 3896 
 3897 // 32 bit unit decrement
 3898 operand immI_M1()
 3899 %{
 3900   predicate(n-&gt;get_int() == -1);
 3901   match(ConI);
 3902 
 3903   op_cost(0);
 3904   format %{ %}
 3905   interface(CONST_INTER);
 3906 %}
 3907 
 3908 // Shift values for add/sub extension shift
 3909 operand immIExt()
 3910 %{
 3911   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 4));
 3912   match(ConI);
 3913 
 3914   op_cost(0);
 3915   format %{ %}
 3916   interface(CONST_INTER);
 3917 %}
 3918 
 3919 operand immI_le_4()
 3920 %{
 3921   predicate(n-&gt;get_int() &lt;= 4);
 3922   match(ConI);
 3923 
 3924   op_cost(0);
 3925   format %{ %}
 3926   interface(CONST_INTER);
 3927 %}
 3928 
 3929 operand immI_31()
 3930 %{
 3931   predicate(n-&gt;get_int() == 31);
 3932   match(ConI);
 3933 
 3934   op_cost(0);
 3935   format %{ %}
 3936   interface(CONST_INTER);
 3937 %}
 3938 
 3939 operand immI_8()
 3940 %{
 3941   predicate(n-&gt;get_int() == 8);
 3942   match(ConI);
 3943 
 3944   op_cost(0);
 3945   format %{ %}
 3946   interface(CONST_INTER);
 3947 %}
 3948 
 3949 operand immI_16()
 3950 %{
 3951   predicate(n-&gt;get_int() == 16);
 3952   match(ConI);
 3953 
 3954   op_cost(0);
 3955   format %{ %}
 3956   interface(CONST_INTER);
 3957 %}
 3958 
 3959 operand immI_24()
 3960 %{
 3961   predicate(n-&gt;get_int() == 24);
 3962   match(ConI);
 3963 
 3964   op_cost(0);
 3965   format %{ %}
 3966   interface(CONST_INTER);
 3967 %}
 3968 
 3969 operand immI_32()
 3970 %{
 3971   predicate(n-&gt;get_int() == 32);
 3972   match(ConI);
 3973 
 3974   op_cost(0);
 3975   format %{ %}
 3976   interface(CONST_INTER);
 3977 %}
 3978 
 3979 operand immI_48()
 3980 %{
 3981   predicate(n-&gt;get_int() == 48);
 3982   match(ConI);
 3983 
 3984   op_cost(0);
 3985   format %{ %}
 3986   interface(CONST_INTER);
 3987 %}
 3988 
 3989 operand immI_56()
 3990 %{
 3991   predicate(n-&gt;get_int() == 56);
 3992   match(ConI);
 3993 
 3994   op_cost(0);
 3995   format %{ %}
 3996   interface(CONST_INTER);
 3997 %}
 3998 
 3999 operand immI_63()
 4000 %{
 4001   predicate(n-&gt;get_int() == 63);
 4002   match(ConI);
 4003 
 4004   op_cost(0);
 4005   format %{ %}
 4006   interface(CONST_INTER);
 4007 %}
 4008 
 4009 operand immI_64()
 4010 %{
 4011   predicate(n-&gt;get_int() == 64);
 4012   match(ConI);
 4013 
 4014   op_cost(0);
 4015   format %{ %}
 4016   interface(CONST_INTER);
 4017 %}
 4018 
 4019 operand immI_255()
 4020 %{
 4021   predicate(n-&gt;get_int() == 255);
 4022   match(ConI);
 4023 
 4024   op_cost(0);
 4025   format %{ %}
 4026   interface(CONST_INTER);
 4027 %}
 4028 
 4029 operand immI_65535()
 4030 %{
 4031   predicate(n-&gt;get_int() == 65535);
 4032   match(ConI);
 4033 
 4034   op_cost(0);
 4035   format %{ %}
 4036   interface(CONST_INTER);
 4037 %}
 4038 
 4039 operand immL_255()
 4040 %{
 4041   predicate(n-&gt;get_long() == 255L);
 4042   match(ConL);
 4043 
 4044   op_cost(0);
 4045   format %{ %}
 4046   interface(CONST_INTER);
 4047 %}
 4048 
 4049 operand immL_65535()
 4050 %{
 4051   predicate(n-&gt;get_long() == 65535L);
 4052   match(ConL);
 4053 
 4054   op_cost(0);
 4055   format %{ %}
 4056   interface(CONST_INTER);
 4057 %}
 4058 
 4059 operand immL_4294967295()
 4060 %{
 4061   predicate(n-&gt;get_long() == 4294967295L);
 4062   match(ConL);
 4063 
 4064   op_cost(0);
 4065   format %{ %}
 4066   interface(CONST_INTER);
 4067 %}
 4068 
 4069 operand immL_bitmask()
 4070 %{
 4071   predicate((n-&gt;get_long() != 0)
 4072             &amp;&amp; ((n-&gt;get_long() &amp; 0xc000000000000000l) == 0)
 4073             &amp;&amp; is_power_of_2(n-&gt;get_long() + 1));
 4074   match(ConL);
 4075 
 4076   op_cost(0);
 4077   format %{ %}
 4078   interface(CONST_INTER);
 4079 %}
 4080 
 4081 operand immI_bitmask()
 4082 %{
 4083   predicate((n-&gt;get_int() != 0)
 4084             &amp;&amp; ((n-&gt;get_int() &amp; 0xc0000000) == 0)
 4085             &amp;&amp; is_power_of_2(n-&gt;get_int() + 1));
 4086   match(ConI);
 4087 
 4088   op_cost(0);
 4089   format %{ %}
 4090   interface(CONST_INTER);
 4091 %}
 4092 
 4093 // Scale values for scaled offset addressing modes (up to long but not quad)
 4094 operand immIScale()
 4095 %{
 4096   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 3));
 4097   match(ConI);
 4098 
 4099   op_cost(0);
 4100   format %{ %}
 4101   interface(CONST_INTER);
 4102 %}
 4103 
 4104 // 26 bit signed offset -- for pc-relative branches
 4105 operand immI26()
 4106 %{
 4107   predicate(((-(1 &lt;&lt; 25)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 25)));
 4108   match(ConI);
 4109 
 4110   op_cost(0);
 4111   format %{ %}
 4112   interface(CONST_INTER);
 4113 %}
 4114 
 4115 // 19 bit signed offset -- for pc-relative loads
 4116 operand immI19()
 4117 %{
 4118   predicate(((-(1 &lt;&lt; 18)) &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 18)));
 4119   match(ConI);
 4120 
 4121   op_cost(0);
 4122   format %{ %}
 4123   interface(CONST_INTER);
 4124 %}
 4125 
 4126 // 12 bit unsigned offset -- for base plus immediate loads
 4127 operand immIU12()
 4128 %{
 4129   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; (n-&gt;get_int() &lt; (1 &lt;&lt; 12)));
 4130   match(ConI);
 4131 
 4132   op_cost(0);
 4133   format %{ %}
 4134   interface(CONST_INTER);
 4135 %}
 4136 
 4137 operand immLU12()
 4138 %{
 4139   predicate((0 &lt;= n-&gt;get_long()) &amp;&amp; (n-&gt;get_long() &lt; (1 &lt;&lt; 12)));
 4140   match(ConL);
 4141 
 4142   op_cost(0);
 4143   format %{ %}
 4144   interface(CONST_INTER);
 4145 %}
 4146 
 4147 // Offset for scaled or unscaled immediate loads and stores
 4148 operand immIOffset()
 4149 %{
 4150   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4151   match(ConI);
 4152 
 4153   op_cost(0);
 4154   format %{ %}
 4155   interface(CONST_INTER);
 4156 %}
 4157 
 4158 operand immIOffset1()
 4159 %{
 4160   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 0));
 4161   match(ConI);
 4162 
 4163   op_cost(0);
 4164   format %{ %}
 4165   interface(CONST_INTER);
 4166 %}
 4167 
 4168 operand immIOffset2()
 4169 %{
 4170   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 1));
 4171   match(ConI);
 4172 
 4173   op_cost(0);
 4174   format %{ %}
 4175   interface(CONST_INTER);
 4176 %}
 4177 
 4178 operand immIOffset4()
 4179 %{
 4180   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 2));
 4181   match(ConI);
 4182 
 4183   op_cost(0);
 4184   format %{ %}
 4185   interface(CONST_INTER);
 4186 %}
 4187 
 4188 operand immIOffset8()
 4189 %{
 4190   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 3));
 4191   match(ConI);
 4192 
 4193   op_cost(0);
 4194   format %{ %}
 4195   interface(CONST_INTER);
 4196 %}
 4197 
 4198 operand immIOffset16()
 4199 %{
 4200   predicate(Address::offset_ok_for_immed(n-&gt;get_int(), 4));
 4201   match(ConI);
 4202 
 4203   op_cost(0);
 4204   format %{ %}
 4205   interface(CONST_INTER);
 4206 %}
 4207 
 4208 operand immLoffset()
 4209 %{
 4210   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4211   match(ConL);
 4212 
 4213   op_cost(0);
 4214   format %{ %}
 4215   interface(CONST_INTER);
 4216 %}
 4217 
 4218 operand immLoffset1()
 4219 %{
 4220   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 0));
 4221   match(ConL);
 4222 
 4223   op_cost(0);
 4224   format %{ %}
 4225   interface(CONST_INTER);
 4226 %}
 4227 
 4228 operand immLoffset2()
 4229 %{
 4230   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 1));
 4231   match(ConL);
 4232 
 4233   op_cost(0);
 4234   format %{ %}
 4235   interface(CONST_INTER);
 4236 %}
 4237 
 4238 operand immLoffset4()
 4239 %{
 4240   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 2));
 4241   match(ConL);
 4242 
 4243   op_cost(0);
 4244   format %{ %}
 4245   interface(CONST_INTER);
 4246 %}
 4247 
 4248 operand immLoffset8()
 4249 %{
 4250   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 3));
 4251   match(ConL);
 4252 
 4253   op_cost(0);
 4254   format %{ %}
 4255   interface(CONST_INTER);
 4256 %}
 4257 
 4258 operand immLoffset16()
 4259 %{
 4260   predicate(Address::offset_ok_for_immed(n-&gt;get_long(), 4));
 4261   match(ConL);
 4262 
 4263   op_cost(0);
 4264   format %{ %}
 4265   interface(CONST_INTER);
 4266 %}
 4267 
 4268 // 32 bit integer valid for add sub immediate
 4269 operand immIAddSub()
 4270 %{
 4271   predicate(Assembler::operand_valid_for_add_sub_immediate((long)n-&gt;get_int()));
 4272   match(ConI);
 4273   op_cost(0);
 4274   format %{ %}
 4275   interface(CONST_INTER);
 4276 %}
 4277 
 4278 // 32 bit unsigned integer valid for logical immediate
 4279 // TODO -- check this is right when e.g the mask is 0x80000000
 4280 operand immILog()
 4281 %{
 4282   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/true, (unsigned long)n-&gt;get_int()));
 4283   match(ConI);
 4284 
 4285   op_cost(0);
 4286   format %{ %}
 4287   interface(CONST_INTER);
 4288 %}
 4289 
 4290 // Integer operands 64 bit
 4291 // 64 bit immediate
 4292 operand immL()
 4293 %{
 4294   match(ConL);
 4295 
 4296   op_cost(0);
 4297   format %{ %}
 4298   interface(CONST_INTER);
 4299 %}
 4300 
 4301 // 64 bit zero
 4302 operand immL0()
 4303 %{
 4304   predicate(n-&gt;get_long() == 0);
 4305   match(ConL);
 4306 
 4307   op_cost(0);
 4308   format %{ %}
 4309   interface(CONST_INTER);
 4310 %}
 4311 
 4312 // 64 bit unit increment
 4313 operand immL_1()
 4314 %{
 4315   predicate(n-&gt;get_long() == 1);
 4316   match(ConL);
 4317 
 4318   op_cost(0);
 4319   format %{ %}
 4320   interface(CONST_INTER);
 4321 %}
 4322 
 4323 // 64 bit unit decrement
 4324 operand immL_M1()
 4325 %{
 4326   predicate(n-&gt;get_long() == -1);
 4327   match(ConL);
 4328 
 4329   op_cost(0);
 4330   format %{ %}
 4331   interface(CONST_INTER);
 4332 %}
 4333 
 4334 // 32 bit offset of pc in thread anchor
 4335 
 4336 operand immL_pc_off()
 4337 %{
 4338   predicate(n-&gt;get_long() == in_bytes(JavaThread::frame_anchor_offset()) +
 4339                              in_bytes(JavaFrameAnchor::last_Java_pc_offset()));
 4340   match(ConL);
 4341 
 4342   op_cost(0);
 4343   format %{ %}
 4344   interface(CONST_INTER);
 4345 %}
 4346 
 4347 // 64 bit integer valid for add sub immediate
 4348 operand immLAddSub()
 4349 %{
 4350   predicate(Assembler::operand_valid_for_add_sub_immediate(n-&gt;get_long()));
 4351   match(ConL);
 4352   op_cost(0);
 4353   format %{ %}
 4354   interface(CONST_INTER);
 4355 %}
 4356 
 4357 // 64 bit integer valid for logical immediate
 4358 operand immLLog()
 4359 %{
 4360   predicate(Assembler::operand_valid_for_logical_immediate(/*is32*/false, (unsigned long)n-&gt;get_long()));
 4361   match(ConL);
 4362   op_cost(0);
 4363   format %{ %}
 4364   interface(CONST_INTER);
 4365 %}
 4366 
 4367 // Long Immediate: low 32-bit mask
 4368 operand immL_32bits()
 4369 %{
 4370   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 4371   match(ConL);
 4372   op_cost(0);
 4373   format %{ %}
 4374   interface(CONST_INTER);
 4375 %}
 4376 
 4377 // Pointer operands
 4378 // Pointer Immediate
 4379 operand immP()
 4380 %{
 4381   match(ConP);
 4382 
 4383   op_cost(0);
 4384   format %{ %}
 4385   interface(CONST_INTER);
 4386 %}
 4387 
 4388 // NULL Pointer Immediate
 4389 operand immP0()
 4390 %{
 4391   predicate(n-&gt;get_ptr() == 0);
 4392   match(ConP);
 4393 
 4394   op_cost(0);
 4395   format %{ %}
 4396   interface(CONST_INTER);
 4397 %}
 4398 
 4399 // Pointer Immediate One
 4400 // this is used in object initialization (initial object header)
 4401 operand immP_1()
 4402 %{
 4403   predicate(n-&gt;get_ptr() == 1);
 4404   match(ConP);
 4405 
 4406   op_cost(0);
 4407   format %{ %}
 4408   interface(CONST_INTER);
 4409 %}
 4410 
 4411 // Card Table Byte Map Base
 4412 operand immByteMapBase()
 4413 %{
 4414   // Get base of card map
 4415   predicate(BarrierSet::barrier_set()-&gt;is_a(BarrierSet::CardTableBarrierSet) &amp;&amp;
 4416             (CardTable::CardValue*)n-&gt;get_ptr() == ((CardTableBarrierSet*)(BarrierSet::barrier_set()))-&gt;card_table()-&gt;byte_map_base());
 4417   match(ConP);
 4418 
 4419   op_cost(0);
 4420   format %{ %}
 4421   interface(CONST_INTER);
 4422 %}
 4423 
 4424 // Pointer Immediate Minus One
 4425 // this is used when we want to write the current PC to the thread anchor
 4426 operand immP_M1()
 4427 %{
 4428   predicate(n-&gt;get_ptr() == -1);
 4429   match(ConP);
 4430 
 4431   op_cost(0);
 4432   format %{ %}
 4433   interface(CONST_INTER);
 4434 %}
 4435 
 4436 // Pointer Immediate Minus Two
 4437 // this is used when we want to write the current PC to the thread anchor
 4438 operand immP_M2()
 4439 %{
 4440   predicate(n-&gt;get_ptr() == -2);
 4441   match(ConP);
 4442 
 4443   op_cost(0);
 4444   format %{ %}
 4445   interface(CONST_INTER);
 4446 %}
 4447 
 4448 // Float and Double operands
 4449 // Double Immediate
 4450 operand immD()
 4451 %{
 4452   match(ConD);
 4453   op_cost(0);
 4454   format %{ %}
 4455   interface(CONST_INTER);
 4456 %}
 4457 
 4458 // Double Immediate: +0.0d
 4459 operand immD0()
 4460 %{
 4461   predicate(jlong_cast(n-&gt;getd()) == 0);
 4462   match(ConD);
 4463 
 4464   op_cost(0);
 4465   format %{ %}
 4466   interface(CONST_INTER);
 4467 %}
 4468 
 4469 // constant &#39;double +0.0&#39;.
 4470 operand immDPacked()
 4471 %{
 4472   predicate(Assembler::operand_valid_for_float_immediate(n-&gt;getd()));
 4473   match(ConD);
 4474   op_cost(0);
 4475   format %{ %}
 4476   interface(CONST_INTER);
 4477 %}
 4478 
 4479 // Float Immediate
 4480 operand immF()
 4481 %{
 4482   match(ConF);
 4483   op_cost(0);
 4484   format %{ %}
 4485   interface(CONST_INTER);
 4486 %}
 4487 
 4488 // Float Immediate: +0.0f.
 4489 operand immF0()
 4490 %{
 4491   predicate(jint_cast(n-&gt;getf()) == 0);
 4492   match(ConF);
 4493 
 4494   op_cost(0);
 4495   format %{ %}
 4496   interface(CONST_INTER);
 4497 %}
 4498 
 4499 //
 4500 operand immFPacked()
 4501 %{
 4502   predicate(Assembler::operand_valid_for_float_immediate((double)n-&gt;getf()));
 4503   match(ConF);
 4504   op_cost(0);
 4505   format %{ %}
 4506   interface(CONST_INTER);
 4507 %}
 4508 
 4509 // Narrow pointer operands
 4510 // Narrow Pointer Immediate
 4511 operand immN()
 4512 %{
 4513   match(ConN);
 4514 
 4515   op_cost(0);
 4516   format %{ %}
 4517   interface(CONST_INTER);
 4518 %}
 4519 
 4520 // Narrow NULL Pointer Immediate
 4521 operand immN0()
 4522 %{
 4523   predicate(n-&gt;get_narrowcon() == 0);
 4524   match(ConN);
 4525 
 4526   op_cost(0);
 4527   format %{ %}
 4528   interface(CONST_INTER);
 4529 %}
 4530 
 4531 operand immNKlass()
 4532 %{
 4533   match(ConNKlass);
 4534 
 4535   op_cost(0);
 4536   format %{ %}
 4537   interface(CONST_INTER);
 4538 %}
 4539 
 4540 // Integer 32 bit Register Operands
 4541 // Integer 32 bitRegister (excludes SP)
 4542 operand iRegI()
 4543 %{
 4544   constraint(ALLOC_IN_RC(any_reg32));
 4545   match(RegI);
 4546   match(iRegINoSp);
 4547   op_cost(0);
 4548   format %{ %}
 4549   interface(REG_INTER);
 4550 %}
 4551 
 4552 // Integer 32 bit Register not Special
 4553 operand iRegINoSp()
 4554 %{
 4555   constraint(ALLOC_IN_RC(no_special_reg32));
 4556   match(RegI);
 4557   op_cost(0);
 4558   format %{ %}
 4559   interface(REG_INTER);
 4560 %}
 4561 
 4562 // Integer 64 bit Register Operands
 4563 // Integer 64 bit Register (includes SP)
 4564 operand iRegL()
 4565 %{
 4566   constraint(ALLOC_IN_RC(any_reg));
 4567   match(RegL);
 4568   match(iRegLNoSp);
 4569   op_cost(0);
 4570   format %{ %}
 4571   interface(REG_INTER);
 4572 %}
 4573 
 4574 // Integer 64 bit Register not Special
 4575 operand iRegLNoSp()
 4576 %{
 4577   constraint(ALLOC_IN_RC(no_special_reg));
 4578   match(RegL);
 4579   match(iRegL_R0);
 4580   format %{ %}
 4581   interface(REG_INTER);
 4582 %}
 4583 
 4584 // Pointer Register Operands
 4585 // Pointer Register
 4586 operand iRegP()
 4587 %{
 4588   constraint(ALLOC_IN_RC(ptr_reg));
 4589   match(RegP);
 4590   match(iRegPNoSp);
 4591   match(iRegP_R0);
 4592   //match(iRegP_R2);
 4593   //match(iRegP_R4);
 4594   //match(iRegP_R5);
 4595   match(thread_RegP);
 4596   op_cost(0);
 4597   format %{ %}
 4598   interface(REG_INTER);
 4599 %}
 4600 
 4601 // Pointer 64 bit Register not Special
 4602 operand iRegPNoSp()
 4603 %{
 4604   constraint(ALLOC_IN_RC(no_special_ptr_reg));
 4605   match(RegP);
 4606   // match(iRegP);
 4607   // match(iRegP_R0);
 4608   // match(iRegP_R2);
 4609   // match(iRegP_R4);
 4610   // match(iRegP_R5);
 4611   // match(thread_RegP);
 4612   op_cost(0);
 4613   format %{ %}
 4614   interface(REG_INTER);
 4615 %}
 4616 
 4617 // Pointer 64 bit Register R0 only
 4618 operand iRegP_R0()
 4619 %{
 4620   constraint(ALLOC_IN_RC(r0_reg));
 4621   match(RegP);
 4622   // match(iRegP);
 4623   match(iRegPNoSp);
 4624   op_cost(0);
 4625   format %{ %}
 4626   interface(REG_INTER);
 4627 %}
 4628 
 4629 // Pointer 64 bit Register R1 only
 4630 operand iRegP_R1()
 4631 %{
 4632   constraint(ALLOC_IN_RC(r1_reg));
 4633   match(RegP);
 4634   // match(iRegP);
 4635   match(iRegPNoSp);
 4636   op_cost(0);
 4637   format %{ %}
 4638   interface(REG_INTER);
 4639 %}
 4640 
 4641 // Pointer 64 bit Register R2 only
 4642 operand iRegP_R2()
 4643 %{
 4644   constraint(ALLOC_IN_RC(r2_reg));
 4645   match(RegP);
 4646   // match(iRegP);
 4647   match(iRegPNoSp);
 4648   op_cost(0);
 4649   format %{ %}
 4650   interface(REG_INTER);
 4651 %}
 4652 
 4653 // Pointer 64 bit Register R3 only
 4654 operand iRegP_R3()
 4655 %{
 4656   constraint(ALLOC_IN_RC(r3_reg));
 4657   match(RegP);
 4658   // match(iRegP);
 4659   match(iRegPNoSp);
 4660   op_cost(0);
 4661   format %{ %}
 4662   interface(REG_INTER);
 4663 %}
 4664 
 4665 // Pointer 64 bit Register R4 only
 4666 operand iRegP_R4()
 4667 %{
 4668   constraint(ALLOC_IN_RC(r4_reg));
 4669   match(RegP);
 4670   // match(iRegP);
 4671   match(iRegPNoSp);
 4672   op_cost(0);
 4673   format %{ %}
 4674   interface(REG_INTER);
 4675 %}
 4676 
 4677 // Pointer 64 bit Register R5 only
 4678 operand iRegP_R5()
 4679 %{
 4680   constraint(ALLOC_IN_RC(r5_reg));
 4681   match(RegP);
 4682   // match(iRegP);
 4683   match(iRegPNoSp);
 4684   op_cost(0);
 4685   format %{ %}
 4686   interface(REG_INTER);
 4687 %}
 4688 
 4689 // Pointer 64 bit Register R10 only
 4690 operand iRegP_R10()
 4691 %{
 4692   constraint(ALLOC_IN_RC(r10_reg));
 4693   match(RegP);
 4694   // match(iRegP);
 4695   match(iRegPNoSp);
 4696   op_cost(0);
 4697   format %{ %}
 4698   interface(REG_INTER);
 4699 %}
 4700 
 4701 // Long 64 bit Register R0 only
 4702 operand iRegL_R0()
 4703 %{
 4704   constraint(ALLOC_IN_RC(r0_reg));
 4705   match(RegL);
 4706   match(iRegLNoSp);
 4707   op_cost(0);
 4708   format %{ %}
 4709   interface(REG_INTER);
 4710 %}
 4711 
 4712 // Long 64 bit Register R2 only
 4713 operand iRegL_R2()
 4714 %{
 4715   constraint(ALLOC_IN_RC(r2_reg));
 4716   match(RegL);
 4717   match(iRegLNoSp);
 4718   op_cost(0);
 4719   format %{ %}
 4720   interface(REG_INTER);
 4721 %}
 4722 
 4723 // Long 64 bit Register R3 only
 4724 operand iRegL_R3()
 4725 %{
 4726   constraint(ALLOC_IN_RC(r3_reg));
 4727   match(RegL);
 4728   match(iRegLNoSp);
 4729   op_cost(0);
 4730   format %{ %}
 4731   interface(REG_INTER);
 4732 %}
 4733 
 4734 // Long 64 bit Register R11 only
 4735 operand iRegL_R11()
 4736 %{
 4737   constraint(ALLOC_IN_RC(r11_reg));
 4738   match(RegL);
 4739   match(iRegLNoSp);
 4740   op_cost(0);
 4741   format %{ %}
 4742   interface(REG_INTER);
 4743 %}
 4744 
 4745 // Pointer 64 bit Register FP only
 4746 operand iRegP_FP()
 4747 %{
 4748   constraint(ALLOC_IN_RC(fp_reg));
 4749   match(RegP);
 4750   // match(iRegP);
 4751   op_cost(0);
 4752   format %{ %}
 4753   interface(REG_INTER);
 4754 %}
 4755 
 4756 // Register R0 only
 4757 operand iRegI_R0()
 4758 %{
 4759   constraint(ALLOC_IN_RC(int_r0_reg));
 4760   match(RegI);
 4761   match(iRegINoSp);
 4762   op_cost(0);
 4763   format %{ %}
 4764   interface(REG_INTER);
 4765 %}
 4766 
 4767 // Register R2 only
 4768 operand iRegI_R2()
 4769 %{
 4770   constraint(ALLOC_IN_RC(int_r2_reg));
 4771   match(RegI);
 4772   match(iRegINoSp);
 4773   op_cost(0);
 4774   format %{ %}
 4775   interface(REG_INTER);
 4776 %}
 4777 
 4778 // Register R3 only
 4779 operand iRegI_R3()
 4780 %{
 4781   constraint(ALLOC_IN_RC(int_r3_reg));
 4782   match(RegI);
 4783   match(iRegINoSp);
 4784   op_cost(0);
 4785   format %{ %}
 4786   interface(REG_INTER);
 4787 %}
 4788 
 4789 
 4790 // Register R4 only
 4791 operand iRegI_R4()
 4792 %{
 4793   constraint(ALLOC_IN_RC(int_r4_reg));
 4794   match(RegI);
 4795   match(iRegINoSp);
 4796   op_cost(0);
 4797   format %{ %}
 4798   interface(REG_INTER);
 4799 %}
 4800 
 4801 
 4802 // Pointer Register Operands
 4803 // Narrow Pointer Register
 4804 operand iRegN()
 4805 %{
 4806   constraint(ALLOC_IN_RC(any_reg32));
 4807   match(RegN);
 4808   match(iRegNNoSp);
 4809   op_cost(0);
 4810   format %{ %}
 4811   interface(REG_INTER);
 4812 %}
 4813 
 4814 operand iRegN_R0()
 4815 %{
 4816   constraint(ALLOC_IN_RC(r0_reg));
 4817   match(iRegN);
 4818   op_cost(0);
 4819   format %{ %}
 4820   interface(REG_INTER);
 4821 %}
 4822 
 4823 operand iRegN_R2()
 4824 %{
 4825   constraint(ALLOC_IN_RC(r2_reg));
 4826   match(iRegN);
 4827   op_cost(0);
 4828   format %{ %}
 4829   interface(REG_INTER);
 4830 %}
 4831 
 4832 operand iRegN_R3()
 4833 %{
 4834   constraint(ALLOC_IN_RC(r3_reg));
 4835   match(iRegN);
 4836   op_cost(0);
 4837   format %{ %}
 4838   interface(REG_INTER);
 4839 %}
 4840 
 4841 // Integer 64 bit Register not Special
 4842 operand iRegNNoSp()
 4843 %{
 4844   constraint(ALLOC_IN_RC(no_special_reg32));
 4845   match(RegN);
 4846   op_cost(0);
 4847   format %{ %}
 4848   interface(REG_INTER);
 4849 %}
 4850 
 4851 // heap base register -- used for encoding immN0
 4852 
 4853 operand iRegIHeapbase()
 4854 %{
 4855   constraint(ALLOC_IN_RC(heapbase_reg));
 4856   match(RegI);
 4857   op_cost(0);
 4858   format %{ %}
 4859   interface(REG_INTER);
 4860 %}
 4861 
 4862 // Float Register
 4863 // Float register operands
 4864 operand vRegF()
 4865 %{
 4866   constraint(ALLOC_IN_RC(float_reg));
 4867   match(RegF);
 4868 
 4869   op_cost(0);
 4870   format %{ %}
 4871   interface(REG_INTER);
 4872 %}
 4873 
 4874 // Double Register
 4875 // Double register operands
 4876 operand vRegD()
 4877 %{
 4878   constraint(ALLOC_IN_RC(double_reg));
 4879   match(RegD);
 4880 
 4881   op_cost(0);
 4882   format %{ %}
 4883   interface(REG_INTER);
 4884 %}
 4885 
 4886 operand vecD()
 4887 %{
 4888   constraint(ALLOC_IN_RC(vectord_reg));
 4889   match(VecD);
 4890 
 4891   op_cost(0);
 4892   format %{ %}
 4893   interface(REG_INTER);
 4894 %}
 4895 
 4896 operand vecX()
 4897 %{
 4898   constraint(ALLOC_IN_RC(vectorx_reg));
 4899   match(VecX);
 4900 
 4901   op_cost(0);
 4902   format %{ %}
 4903   interface(REG_INTER);
 4904 %}
 4905 
 4906 operand vRegD_V0()
 4907 %{
 4908   constraint(ALLOC_IN_RC(v0_reg));
 4909   match(RegD);
 4910   op_cost(0);
 4911   format %{ %}
 4912   interface(REG_INTER);
 4913 %}
 4914 
 4915 operand vRegD_V1()
 4916 %{
 4917   constraint(ALLOC_IN_RC(v1_reg));
 4918   match(RegD);
 4919   op_cost(0);
 4920   format %{ %}
 4921   interface(REG_INTER);
 4922 %}
 4923 
 4924 operand vRegD_V2()
 4925 %{
 4926   constraint(ALLOC_IN_RC(v2_reg));
 4927   match(RegD);
 4928   op_cost(0);
 4929   format %{ %}
 4930   interface(REG_INTER);
 4931 %}
 4932 
 4933 operand vRegD_V3()
 4934 %{
 4935   constraint(ALLOC_IN_RC(v3_reg));
 4936   match(RegD);
 4937   op_cost(0);
 4938   format %{ %}
 4939   interface(REG_INTER);
 4940 %}
 4941 
 4942 operand vRegD_V4()
 4943 %{
 4944   constraint(ALLOC_IN_RC(v4_reg));
 4945   match(RegD);
 4946   op_cost(0);
 4947   format %{ %}
 4948   interface(REG_INTER);
 4949 %}
 4950 
 4951 operand vRegD_V5()
 4952 %{
 4953   constraint(ALLOC_IN_RC(v5_reg));
 4954   match(RegD);
 4955   op_cost(0);
 4956   format %{ %}
 4957   interface(REG_INTER);
 4958 %}
 4959 
 4960 operand vRegD_V6()
 4961 %{
 4962   constraint(ALLOC_IN_RC(v6_reg));
 4963   match(RegD);
 4964   op_cost(0);
 4965   format %{ %}
 4966   interface(REG_INTER);
 4967 %}
 4968 
 4969 operand vRegD_V7()
 4970 %{
 4971   constraint(ALLOC_IN_RC(v7_reg));
 4972   match(RegD);
 4973   op_cost(0);
 4974   format %{ %}
 4975   interface(REG_INTER);
 4976 %}
 4977 
 4978 operand vRegD_V8()
 4979 %{
 4980   constraint(ALLOC_IN_RC(v8_reg));
 4981   match(RegD);
 4982   op_cost(0);
 4983   format %{ %}
 4984   interface(REG_INTER);
 4985 %}
 4986 
 4987 operand vRegD_V9()
 4988 %{
 4989   constraint(ALLOC_IN_RC(v9_reg));
 4990   match(RegD);
 4991   op_cost(0);
 4992   format %{ %}
 4993   interface(REG_INTER);
 4994 %}
 4995 
 4996 operand vRegD_V10()
 4997 %{
 4998   constraint(ALLOC_IN_RC(v10_reg));
 4999   match(RegD);
 5000   op_cost(0);
 5001   format %{ %}
 5002   interface(REG_INTER);
 5003 %}
 5004 
 5005 operand vRegD_V11()
 5006 %{
 5007   constraint(ALLOC_IN_RC(v11_reg));
 5008   match(RegD);
 5009   op_cost(0);
 5010   format %{ %}
 5011   interface(REG_INTER);
 5012 %}
 5013 
 5014 operand vRegD_V12()
 5015 %{
 5016   constraint(ALLOC_IN_RC(v12_reg));
 5017   match(RegD);
 5018   op_cost(0);
 5019   format %{ %}
 5020   interface(REG_INTER);
 5021 %}
 5022 
 5023 operand vRegD_V13()
 5024 %{
 5025   constraint(ALLOC_IN_RC(v13_reg));
 5026   match(RegD);
 5027   op_cost(0);
 5028   format %{ %}
 5029   interface(REG_INTER);
 5030 %}
 5031 
 5032 operand vRegD_V14()
 5033 %{
 5034   constraint(ALLOC_IN_RC(v14_reg));
 5035   match(RegD);
 5036   op_cost(0);
 5037   format %{ %}
 5038   interface(REG_INTER);
 5039 %}
 5040 
 5041 operand vRegD_V15()
 5042 %{
 5043   constraint(ALLOC_IN_RC(v15_reg));
 5044   match(RegD);
 5045   op_cost(0);
 5046   format %{ %}
 5047   interface(REG_INTER);
 5048 %}
 5049 
 5050 operand vRegD_V16()
 5051 %{
 5052   constraint(ALLOC_IN_RC(v16_reg));
 5053   match(RegD);
 5054   op_cost(0);
 5055   format %{ %}
 5056   interface(REG_INTER);
 5057 %}
 5058 
 5059 operand vRegD_V17()
 5060 %{
 5061   constraint(ALLOC_IN_RC(v17_reg));
 5062   match(RegD);
 5063   op_cost(0);
 5064   format %{ %}
 5065   interface(REG_INTER);
 5066 %}
 5067 
 5068 operand vRegD_V18()
 5069 %{
 5070   constraint(ALLOC_IN_RC(v18_reg));
 5071   match(RegD);
 5072   op_cost(0);
 5073   format %{ %}
 5074   interface(REG_INTER);
 5075 %}
 5076 
 5077 operand vRegD_V19()
 5078 %{
 5079   constraint(ALLOC_IN_RC(v19_reg));
 5080   match(RegD);
 5081   op_cost(0);
 5082   format %{ %}
 5083   interface(REG_INTER);
 5084 %}
 5085 
 5086 operand vRegD_V20()
 5087 %{
 5088   constraint(ALLOC_IN_RC(v20_reg));
 5089   match(RegD);
 5090   op_cost(0);
 5091   format %{ %}
 5092   interface(REG_INTER);
 5093 %}
 5094 
 5095 operand vRegD_V21()
 5096 %{
 5097   constraint(ALLOC_IN_RC(v21_reg));
 5098   match(RegD);
 5099   op_cost(0);
 5100   format %{ %}
 5101   interface(REG_INTER);
 5102 %}
 5103 
 5104 operand vRegD_V22()
 5105 %{
 5106   constraint(ALLOC_IN_RC(v22_reg));
 5107   match(RegD);
 5108   op_cost(0);
 5109   format %{ %}
 5110   interface(REG_INTER);
 5111 %}
 5112 
 5113 operand vRegD_V23()
 5114 %{
 5115   constraint(ALLOC_IN_RC(v23_reg));
 5116   match(RegD);
 5117   op_cost(0);
 5118   format %{ %}
 5119   interface(REG_INTER);
 5120 %}
 5121 
 5122 operand vRegD_V24()
 5123 %{
 5124   constraint(ALLOC_IN_RC(v24_reg));
 5125   match(RegD);
 5126   op_cost(0);
 5127   format %{ %}
 5128   interface(REG_INTER);
 5129 %}
 5130 
 5131 operand vRegD_V25()
 5132 %{
 5133   constraint(ALLOC_IN_RC(v25_reg));
 5134   match(RegD);
 5135   op_cost(0);
 5136   format %{ %}
 5137   interface(REG_INTER);
 5138 %}
 5139 
 5140 operand vRegD_V26()
 5141 %{
 5142   constraint(ALLOC_IN_RC(v26_reg));
 5143   match(RegD);
 5144   op_cost(0);
 5145   format %{ %}
 5146   interface(REG_INTER);
 5147 %}
 5148 
 5149 operand vRegD_V27()
 5150 %{
 5151   constraint(ALLOC_IN_RC(v27_reg));
 5152   match(RegD);
 5153   op_cost(0);
 5154   format %{ %}
 5155   interface(REG_INTER);
 5156 %}
 5157 
 5158 operand vRegD_V28()
 5159 %{
 5160   constraint(ALLOC_IN_RC(v28_reg));
 5161   match(RegD);
 5162   op_cost(0);
 5163   format %{ %}
 5164   interface(REG_INTER);
 5165 %}
 5166 
 5167 operand vRegD_V29()
 5168 %{
 5169   constraint(ALLOC_IN_RC(v29_reg));
 5170   match(RegD);
 5171   op_cost(0);
 5172   format %{ %}
 5173   interface(REG_INTER);
 5174 %}
 5175 
 5176 operand vRegD_V30()
 5177 %{
 5178   constraint(ALLOC_IN_RC(v30_reg));
 5179   match(RegD);
 5180   op_cost(0);
 5181   format %{ %}
 5182   interface(REG_INTER);
 5183 %}
 5184 
 5185 operand vRegD_V31()
 5186 %{
 5187   constraint(ALLOC_IN_RC(v31_reg));
 5188   match(RegD);
 5189   op_cost(0);
 5190   format %{ %}
 5191   interface(REG_INTER);
 5192 %}
 5193 
 5194 // Flags register, used as output of signed compare instructions
 5195 
 5196 // note that on AArch64 we also use this register as the output for
 5197 // for floating point compare instructions (CmpF CmpD). this ensures
 5198 // that ordered inequality tests use GT, GE, LT or LE none of which
 5199 // pass through cases where the result is unordered i.e. one or both
 5200 // inputs to the compare is a NaN. this means that the ideal code can
 5201 // replace e.g. a GT with an LE and not end up capturing the NaN case
 5202 // (where the comparison should always fail). EQ and NE tests are
 5203 // always generated in ideal code so that unordered folds into the NE
 5204 // case, matching the behaviour of AArch64 NE.
 5205 //
 5206 // This differs from x86 where the outputs of FP compares use a
 5207 // special FP flags registers and where compares based on this
 5208 // register are distinguished into ordered inequalities (cmpOpUCF) and
 5209 // EQ/NEQ tests (cmpOpUCF2). x86 has to special case the latter tests
 5210 // to explicitly handle the unordered case in branches. x86 also has
 5211 // to include extra CMoveX rules to accept a cmpOpUCF input.
 5212 
 5213 operand rFlagsReg()
 5214 %{
 5215   constraint(ALLOC_IN_RC(int_flags));
 5216   match(RegFlags);
 5217 
 5218   op_cost(0);
 5219   format %{ &quot;RFLAGS&quot; %}
 5220   interface(REG_INTER);
 5221 %}
 5222 
 5223 // Flags register, used as output of unsigned compare instructions
 5224 operand rFlagsRegU()
 5225 %{
 5226   constraint(ALLOC_IN_RC(int_flags));
 5227   match(RegFlags);
 5228 
 5229   op_cost(0);
 5230   format %{ &quot;RFLAGSU&quot; %}
 5231   interface(REG_INTER);
 5232 %}
 5233 
 5234 // Special Registers
 5235 
 5236 // Method Register
 5237 operand inline_cache_RegP(iRegP reg)
 5238 %{
 5239   constraint(ALLOC_IN_RC(method_reg)); // inline_cache_reg
 5240   match(reg);
 5241   match(iRegPNoSp);
 5242   op_cost(0);
 5243   format %{ %}
 5244   interface(REG_INTER);
 5245 %}
 5246 
 5247 operand interpreter_method_oop_RegP(iRegP reg)
 5248 %{
 5249   constraint(ALLOC_IN_RC(method_reg)); // interpreter_method_oop_reg
 5250   match(reg);
 5251   match(iRegPNoSp);
 5252   op_cost(0);
 5253   format %{ %}
 5254   interface(REG_INTER);
 5255 %}
 5256 
 5257 // Thread Register
 5258 operand thread_RegP(iRegP reg)
 5259 %{
 5260   constraint(ALLOC_IN_RC(thread_reg)); // link_reg
 5261   match(reg);
 5262   op_cost(0);
 5263   format %{ %}
 5264   interface(REG_INTER);
 5265 %}
 5266 
 5267 operand lr_RegP(iRegP reg)
 5268 %{
 5269   constraint(ALLOC_IN_RC(lr_reg)); // link_reg
 5270   match(reg);
 5271   op_cost(0);
 5272   format %{ %}
 5273   interface(REG_INTER);
 5274 %}
 5275 
 5276 //----------Memory Operands----------------------------------------------------
 5277 
 5278 operand indirect(iRegP reg)
 5279 %{
 5280   constraint(ALLOC_IN_RC(ptr_reg));
 5281   match(reg);
 5282   op_cost(0);
 5283   format %{ &quot;[$reg]&quot; %}
 5284   interface(MEMORY_INTER) %{
 5285     base($reg);
 5286     index(0xffffffff);
 5287     scale(0x0);
 5288     disp(0x0);
 5289   %}
 5290 %}
 5291 
 5292 operand indIndexScaledI2L(iRegP reg, iRegI ireg, immIScale scale)
 5293 %{
 5294   constraint(ALLOC_IN_RC(ptr_reg));
 5295   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5296   match(AddP reg (LShiftL (ConvI2L ireg) scale));
 5297   op_cost(0);
 5298   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L&quot; %}
 5299   interface(MEMORY_INTER) %{
 5300     base($reg);
 5301     index($ireg);
 5302     scale($scale);
 5303     disp(0x0);
 5304   %}
 5305 %}
 5306 
 5307 operand indIndexScaled(iRegP reg, iRegL lreg, immIScale scale)
 5308 %{
 5309   constraint(ALLOC_IN_RC(ptr_reg));
 5310   predicate(size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5311   match(AddP reg (LShiftL lreg scale));
 5312   op_cost(0);
 5313   format %{ &quot;$reg, $lreg lsl($scale)&quot; %}
 5314   interface(MEMORY_INTER) %{
 5315     base($reg);
 5316     index($lreg);
 5317     scale($scale);
 5318     disp(0x0);
 5319   %}
 5320 %}
 5321 
 5322 operand indIndexI2L(iRegP reg, iRegI ireg)
 5323 %{
 5324   constraint(ALLOC_IN_RC(ptr_reg));
 5325   match(AddP reg (ConvI2L ireg));
 5326   op_cost(0);
 5327   format %{ &quot;$reg, $ireg, 0, I2L&quot; %}
 5328   interface(MEMORY_INTER) %{
 5329     base($reg);
 5330     index($ireg);
 5331     scale(0x0);
 5332     disp(0x0);
 5333   %}
 5334 %}
 5335 
 5336 operand indIndex(iRegP reg, iRegL lreg)
 5337 %{
 5338   constraint(ALLOC_IN_RC(ptr_reg));
 5339   match(AddP reg lreg);
 5340   op_cost(0);
 5341   format %{ &quot;$reg, $lreg&quot; %}
 5342   interface(MEMORY_INTER) %{
 5343     base($reg);
 5344     index($lreg);
 5345     scale(0x0);
 5346     disp(0x0);
 5347   %}
 5348 %}
 5349 
 5350 operand indOffI(iRegP reg, immIOffset off)
 5351 %{
 5352   constraint(ALLOC_IN_RC(ptr_reg));
 5353   match(AddP reg off);
 5354   op_cost(0);
 5355   format %{ &quot;[$reg, $off]&quot; %}
 5356   interface(MEMORY_INTER) %{
 5357     base($reg);
 5358     index(0xffffffff);
 5359     scale(0x0);
 5360     disp($off);
 5361   %}
 5362 %}
 5363 
 5364 operand indOffI1(iRegP reg, immIOffset1 off)
 5365 %{
 5366   constraint(ALLOC_IN_RC(ptr_reg));
 5367   match(AddP reg off);
 5368   op_cost(0);
 5369   format %{ &quot;[$reg, $off]&quot; %}
 5370   interface(MEMORY_INTER) %{
 5371     base($reg);
 5372     index(0xffffffff);
 5373     scale(0x0);
 5374     disp($off);
 5375   %}
 5376 %}
 5377 
 5378 operand indOffI2(iRegP reg, immIOffset2 off)
 5379 %{
 5380   constraint(ALLOC_IN_RC(ptr_reg));
 5381   match(AddP reg off);
 5382   op_cost(0);
 5383   format %{ &quot;[$reg, $off]&quot; %}
 5384   interface(MEMORY_INTER) %{
 5385     base($reg);
 5386     index(0xffffffff);
 5387     scale(0x0);
 5388     disp($off);
 5389   %}
 5390 %}
 5391 
 5392 operand indOffI4(iRegP reg, immIOffset4 off)
 5393 %{
 5394   constraint(ALLOC_IN_RC(ptr_reg));
 5395   match(AddP reg off);
 5396   op_cost(0);
 5397   format %{ &quot;[$reg, $off]&quot; %}
 5398   interface(MEMORY_INTER) %{
 5399     base($reg);
 5400     index(0xffffffff);
 5401     scale(0x0);
 5402     disp($off);
 5403   %}
 5404 %}
 5405 
 5406 operand indOffI8(iRegP reg, immIOffset8 off)
 5407 %{
 5408   constraint(ALLOC_IN_RC(ptr_reg));
 5409   match(AddP reg off);
 5410   op_cost(0);
 5411   format %{ &quot;[$reg, $off]&quot; %}
 5412   interface(MEMORY_INTER) %{
 5413     base($reg);
 5414     index(0xffffffff);
 5415     scale(0x0);
 5416     disp($off);
 5417   %}
 5418 %}
 5419 
 5420 operand indOffI16(iRegP reg, immIOffset16 off)
 5421 %{
 5422   constraint(ALLOC_IN_RC(ptr_reg));
 5423   match(AddP reg off);
 5424   op_cost(0);
 5425   format %{ &quot;[$reg, $off]&quot; %}
 5426   interface(MEMORY_INTER) %{
 5427     base($reg);
 5428     index(0xffffffff);
 5429     scale(0x0);
 5430     disp($off);
 5431   %}
 5432 %}
 5433 
 5434 operand indOffL(iRegP reg, immLoffset off)
 5435 %{
 5436   constraint(ALLOC_IN_RC(ptr_reg));
 5437   match(AddP reg off);
 5438   op_cost(0);
 5439   format %{ &quot;[$reg, $off]&quot; %}
 5440   interface(MEMORY_INTER) %{
 5441     base($reg);
 5442     index(0xffffffff);
 5443     scale(0x0);
 5444     disp($off);
 5445   %}
 5446 %}
 5447 
 5448 operand indOffL1(iRegP reg, immLoffset1 off)
 5449 %{
 5450   constraint(ALLOC_IN_RC(ptr_reg));
 5451   match(AddP reg off);
 5452   op_cost(0);
 5453   format %{ &quot;[$reg, $off]&quot; %}
 5454   interface(MEMORY_INTER) %{
 5455     base($reg);
 5456     index(0xffffffff);
 5457     scale(0x0);
 5458     disp($off);
 5459   %}
 5460 %}
 5461 
 5462 operand indOffL2(iRegP reg, immLoffset2 off)
 5463 %{
 5464   constraint(ALLOC_IN_RC(ptr_reg));
 5465   match(AddP reg off);
 5466   op_cost(0);
 5467   format %{ &quot;[$reg, $off]&quot; %}
 5468   interface(MEMORY_INTER) %{
 5469     base($reg);
 5470     index(0xffffffff);
 5471     scale(0x0);
 5472     disp($off);
 5473   %}
 5474 %}
 5475 
 5476 operand indOffL4(iRegP reg, immLoffset4 off)
 5477 %{
 5478   constraint(ALLOC_IN_RC(ptr_reg));
 5479   match(AddP reg off);
 5480   op_cost(0);
 5481   format %{ &quot;[$reg, $off]&quot; %}
 5482   interface(MEMORY_INTER) %{
 5483     base($reg);
 5484     index(0xffffffff);
 5485     scale(0x0);
 5486     disp($off);
 5487   %}
 5488 %}
 5489 
 5490 operand indOffL8(iRegP reg, immLoffset8 off)
 5491 %{
 5492   constraint(ALLOC_IN_RC(ptr_reg));
 5493   match(AddP reg off);
 5494   op_cost(0);
 5495   format %{ &quot;[$reg, $off]&quot; %}
 5496   interface(MEMORY_INTER) %{
 5497     base($reg);
 5498     index(0xffffffff);
 5499     scale(0x0);
 5500     disp($off);
 5501   %}
 5502 %}
 5503 
 5504 operand indOffL16(iRegP reg, immLoffset16 off)
 5505 %{
 5506   constraint(ALLOC_IN_RC(ptr_reg));
 5507   match(AddP reg off);
 5508   op_cost(0);
 5509   format %{ &quot;[$reg, $off]&quot; %}
 5510   interface(MEMORY_INTER) %{
 5511     base($reg);
 5512     index(0xffffffff);
 5513     scale(0x0);
 5514     disp($off);
 5515   %}
 5516 %}
 5517 
 5518 operand indirectN(iRegN reg)
 5519 %{
 5520   predicate(CompressedOops::shift() == 0);
 5521   constraint(ALLOC_IN_RC(ptr_reg));
 5522   match(DecodeN reg);
 5523   op_cost(0);
 5524   format %{ &quot;[$reg]\t# narrow&quot; %}
 5525   interface(MEMORY_INTER) %{
 5526     base($reg);
 5527     index(0xffffffff);
 5528     scale(0x0);
 5529     disp(0x0);
 5530   %}
 5531 %}
 5532 
 5533 operand indIndexScaledI2LN(iRegN reg, iRegI ireg, immIScale scale)
 5534 %{
 5535   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5536   constraint(ALLOC_IN_RC(ptr_reg));
 5537   match(AddP (DecodeN reg) (LShiftL (ConvI2L ireg) scale));
 5538   op_cost(0);
 5539   format %{ &quot;$reg, $ireg sxtw($scale), 0, I2L\t# narrow&quot; %}
 5540   interface(MEMORY_INTER) %{
 5541     base($reg);
 5542     index($ireg);
 5543     scale($scale);
 5544     disp(0x0);
 5545   %}
 5546 %}
 5547 
 5548 operand indIndexScaledN(iRegN reg, iRegL lreg, immIScale scale)
 5549 %{
 5550   predicate(CompressedOops::shift() == 0 &amp;&amp; size_fits_all_mem_uses(n-&gt;as_AddP(), n-&gt;in(AddPNode::Offset)-&gt;in(2)-&gt;get_int()));
 5551   constraint(ALLOC_IN_RC(ptr_reg));
 5552   match(AddP (DecodeN reg) (LShiftL lreg scale));
 5553   op_cost(0);
 5554   format %{ &quot;$reg, $lreg lsl($scale)\t# narrow&quot; %}
 5555   interface(MEMORY_INTER) %{
 5556     base($reg);
 5557     index($lreg);
 5558     scale($scale);
 5559     disp(0x0);
 5560   %}
 5561 %}
 5562 
 5563 operand indIndexI2LN(iRegN reg, iRegI ireg)
 5564 %{
 5565   predicate(CompressedOops::shift() == 0);
 5566   constraint(ALLOC_IN_RC(ptr_reg));
 5567   match(AddP (DecodeN reg) (ConvI2L ireg));
 5568   op_cost(0);
 5569   format %{ &quot;$reg, $ireg, 0, I2L\t# narrow&quot; %}
 5570   interface(MEMORY_INTER) %{
 5571     base($reg);
 5572     index($ireg);
 5573     scale(0x0);
 5574     disp(0x0);
 5575   %}
 5576 %}
 5577 
 5578 operand indIndexN(iRegN reg, iRegL lreg)
 5579 %{
 5580   predicate(CompressedOops::shift() == 0);
 5581   constraint(ALLOC_IN_RC(ptr_reg));
 5582   match(AddP (DecodeN reg) lreg);
 5583   op_cost(0);
 5584   format %{ &quot;$reg, $lreg\t# narrow&quot; %}
 5585   interface(MEMORY_INTER) %{
 5586     base($reg);
 5587     index($lreg);
 5588     scale(0x0);
 5589     disp(0x0);
 5590   %}
 5591 %}
 5592 
 5593 operand indOffIN(iRegN reg, immIOffset off)
 5594 %{
 5595   predicate(CompressedOops::shift() == 0);
 5596   constraint(ALLOC_IN_RC(ptr_reg));
 5597   match(AddP (DecodeN reg) off);
 5598   op_cost(0);
 5599   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5600   interface(MEMORY_INTER) %{
 5601     base($reg);
 5602     index(0xffffffff);
 5603     scale(0x0);
 5604     disp($off);
 5605   %}
 5606 %}
 5607 
 5608 operand indOffLN(iRegN reg, immLoffset off)
 5609 %{
 5610   predicate(CompressedOops::shift() == 0);
 5611   constraint(ALLOC_IN_RC(ptr_reg));
 5612   match(AddP (DecodeN reg) off);
 5613   op_cost(0);
 5614   format %{ &quot;[$reg, $off]\t# narrow&quot; %}
 5615   interface(MEMORY_INTER) %{
 5616     base($reg);
 5617     index(0xffffffff);
 5618     scale(0x0);
 5619     disp($off);
 5620   %}
 5621 %}
 5622 
 5623 
 5624 
 5625 // AArch64 opto stubs need to write to the pc slot in the thread anchor
 5626 operand thread_anchor_pc(thread_RegP reg, immL_pc_off off)
 5627 %{
 5628   constraint(ALLOC_IN_RC(ptr_reg));
 5629   match(AddP reg off);
 5630   op_cost(0);
 5631   format %{ &quot;[$reg, $off]&quot; %}
 5632   interface(MEMORY_INTER) %{
 5633     base($reg);
 5634     index(0xffffffff);
 5635     scale(0x0);
 5636     disp($off);
 5637   %}
 5638 %}
 5639 
 5640 //----------Special Memory Operands--------------------------------------------
 5641 // Stack Slot Operand - This operand is used for loading and storing temporary
 5642 //                      values on the stack where a match requires a value to
 5643 //                      flow through memory.
 5644 operand stackSlotP(sRegP reg)
 5645 %{
 5646   constraint(ALLOC_IN_RC(stack_slots));
 5647   op_cost(100);
 5648   // No match rule because this operand is only generated in matching
 5649   // match(RegP);
 5650   format %{ &quot;[$reg]&quot; %}
 5651   interface(MEMORY_INTER) %{
 5652     base(0x1e);  // RSP
 5653     index(0x0);  // No Index
 5654     scale(0x0);  // No Scale
 5655     disp($reg);  // Stack Offset
 5656   %}
 5657 %}
 5658 
 5659 operand stackSlotI(sRegI reg)
 5660 %{
 5661   constraint(ALLOC_IN_RC(stack_slots));
 5662   // No match rule because this operand is only generated in matching
 5663   // match(RegI);
 5664   format %{ &quot;[$reg]&quot; %}
 5665   interface(MEMORY_INTER) %{
 5666     base(0x1e);  // RSP
 5667     index(0x0);  // No Index
 5668     scale(0x0);  // No Scale
 5669     disp($reg);  // Stack Offset
 5670   %}
 5671 %}
 5672 
 5673 operand stackSlotF(sRegF reg)
 5674 %{
 5675   constraint(ALLOC_IN_RC(stack_slots));
 5676   // No match rule because this operand is only generated in matching
 5677   // match(RegF);
 5678   format %{ &quot;[$reg]&quot; %}
 5679   interface(MEMORY_INTER) %{
 5680     base(0x1e);  // RSP
 5681     index(0x0);  // No Index
 5682     scale(0x0);  // No Scale
 5683     disp($reg);  // Stack Offset
 5684   %}
 5685 %}
 5686 
 5687 operand stackSlotD(sRegD reg)
 5688 %{
 5689   constraint(ALLOC_IN_RC(stack_slots));
 5690   // No match rule because this operand is only generated in matching
 5691   // match(RegD);
 5692   format %{ &quot;[$reg]&quot; %}
 5693   interface(MEMORY_INTER) %{
 5694     base(0x1e);  // RSP
 5695     index(0x0);  // No Index
 5696     scale(0x0);  // No Scale
 5697     disp($reg);  // Stack Offset
 5698   %}
 5699 %}
 5700 
 5701 operand stackSlotL(sRegL reg)
 5702 %{
 5703   constraint(ALLOC_IN_RC(stack_slots));
 5704   // No match rule because this operand is only generated in matching
 5705   // match(RegL);
 5706   format %{ &quot;[$reg]&quot; %}
 5707   interface(MEMORY_INTER) %{
 5708     base(0x1e);  // RSP
 5709     index(0x0);  // No Index
 5710     scale(0x0);  // No Scale
 5711     disp($reg);  // Stack Offset
 5712   %}
 5713 %}
 5714 
 5715 // Operands for expressing Control Flow
 5716 // NOTE: Label is a predefined operand which should not be redefined in
 5717 //       the AD file. It is generically handled within the ADLC.
 5718 
 5719 //----------Conditional Branch Operands----------------------------------------
 5720 // Comparison Op  - This is the operation of the comparison, and is limited to
 5721 //                  the following set of codes:
 5722 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 5723 //
 5724 // Other attributes of the comparison, such as unsignedness, are specified
 5725 // by the comparison instruction that sets a condition code flags register.
 5726 // That result is represented by a flags operand whose subtype is appropriate
 5727 // to the unsignedness (etc.) of the comparison.
 5728 //
 5729 // Later, the instruction which matches both the Comparison Op (a Bool) and
 5730 // the flags (produced by the Cmp) specifies the coding of the comparison op
 5731 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 5732 
 5733 // used for signed integral comparisons and fp comparisons
 5734 
 5735 operand cmpOp()
 5736 %{
 5737   match(Bool);
 5738 
 5739   format %{ &quot;&quot; %}
 5740   interface(COND_INTER) %{
 5741     equal(0x0, &quot;eq&quot;);
 5742     not_equal(0x1, &quot;ne&quot;);
 5743     less(0xb, &quot;lt&quot;);
 5744     greater_equal(0xa, &quot;ge&quot;);
 5745     less_equal(0xd, &quot;le&quot;);
 5746     greater(0xc, &quot;gt&quot;);
 5747     overflow(0x6, &quot;vs&quot;);
 5748     no_overflow(0x7, &quot;vc&quot;);
 5749   %}
 5750 %}
 5751 
 5752 // used for unsigned integral comparisons
 5753 
 5754 operand cmpOpU()
 5755 %{
 5756   match(Bool);
 5757 
 5758   format %{ &quot;&quot; %}
 5759   interface(COND_INTER) %{
 5760     equal(0x0, &quot;eq&quot;);
 5761     not_equal(0x1, &quot;ne&quot;);
 5762     less(0x3, &quot;lo&quot;);
 5763     greater_equal(0x2, &quot;hs&quot;);
 5764     less_equal(0x9, &quot;ls&quot;);
 5765     greater(0x8, &quot;hi&quot;);
 5766     overflow(0x6, &quot;vs&quot;);
 5767     no_overflow(0x7, &quot;vc&quot;);
 5768   %}
 5769 %}
 5770 
 5771 // used for certain integral comparisons which can be
 5772 // converted to cbxx or tbxx instructions
 5773 
 5774 operand cmpOpEqNe()
 5775 %{
 5776   match(Bool);
 5777   op_cost(0);
 5778   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5779             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq);
 5780 
 5781   format %{ &quot;&quot; %}
 5782   interface(COND_INTER) %{
 5783     equal(0x0, &quot;eq&quot;);
 5784     not_equal(0x1, &quot;ne&quot;);
 5785     less(0xb, &quot;lt&quot;);
 5786     greater_equal(0xa, &quot;ge&quot;);
 5787     less_equal(0xd, &quot;le&quot;);
 5788     greater(0xc, &quot;gt&quot;);
 5789     overflow(0x6, &quot;vs&quot;);
 5790     no_overflow(0x7, &quot;vc&quot;);
 5791   %}
 5792 %}
 5793 
 5794 // used for certain integral comparisons which can be
 5795 // converted to cbxx or tbxx instructions
 5796 
 5797 operand cmpOpLtGe()
 5798 %{
 5799   match(Bool);
 5800   op_cost(0);
 5801 
 5802   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5803             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5804 
 5805   format %{ &quot;&quot; %}
 5806   interface(COND_INTER) %{
 5807     equal(0x0, &quot;eq&quot;);
 5808     not_equal(0x1, &quot;ne&quot;);
 5809     less(0xb, &quot;lt&quot;);
 5810     greater_equal(0xa, &quot;ge&quot;);
 5811     less_equal(0xd, &quot;le&quot;);
 5812     greater(0xc, &quot;gt&quot;);
 5813     overflow(0x6, &quot;vs&quot;);
 5814     no_overflow(0x7, &quot;vc&quot;);
 5815   %}
 5816 %}
 5817 
 5818 // used for certain unsigned integral comparisons which can be
 5819 // converted to cbxx or tbxx instructions
 5820 
 5821 operand cmpOpUEqNeLtGe()
 5822 %{
 5823   match(Bool);
 5824   op_cost(0);
 5825 
 5826   predicate(n-&gt;as_Bool()-&gt;_test._test == BoolTest::eq
 5827             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ne
 5828             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::lt
 5829             || n-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5830 
 5831   format %{ &quot;&quot; %}
 5832   interface(COND_INTER) %{
 5833     equal(0x0, &quot;eq&quot;);
 5834     not_equal(0x1, &quot;ne&quot;);
 5835     less(0xb, &quot;lt&quot;);
 5836     greater_equal(0xa, &quot;ge&quot;);
 5837     less_equal(0xd, &quot;le&quot;);
 5838     greater(0xc, &quot;gt&quot;);
 5839     overflow(0x6, &quot;vs&quot;);
 5840     no_overflow(0x7, &quot;vc&quot;);
 5841   %}
 5842 %}
 5843 
 5844 // Special operand allowing long args to int ops to be truncated for free
 5845 
 5846 operand iRegL2I(iRegL reg) %{
 5847 
 5848   op_cost(0);
 5849 
 5850   match(ConvL2I reg);
 5851 
 5852   format %{ &quot;l2i($reg)&quot; %}
 5853 
 5854   interface(REG_INTER)
 5855 %}
 5856 
 5857 opclass vmem4(indirect, indIndex, indOffI4, indOffL4);
 5858 opclass vmem8(indirect, indIndex, indOffI8, indOffL8);
 5859 opclass vmem16(indirect, indIndex, indOffI16, indOffL16);
 5860 
 5861 //----------OPERAND CLASSES----------------------------------------------------
 5862 // Operand Classes are groups of operands that are used as to simplify
 5863 // instruction definitions by not requiring the AD writer to specify
 5864 // separate instructions for every form of operand when the
 5865 // instruction accepts multiple operand types with the same basic
 5866 // encoding and format. The classic case of this is memory operands.
 5867 
 5868 // memory is used to define read/write location for load/store
 5869 // instruction defs. we can turn a memory op into an Address
 5870 
 5871 opclass memory1(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI1, indOffL1,
 5872                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5873 
 5874 opclass memory2(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI2, indOffL2,
 5875                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN);
 5876 
 5877 opclass memory4(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI4, indOffL4,
 5878                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5879 
 5880 opclass memory8(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex, indOffI8, indOffL8,
 5881                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5882 
 5883 // All of the memory operands. For the pipeline description.
 5884 opclass memory(indirect, indIndexScaled, indIndexScaledI2L, indIndexI2L, indIndex,
 5885                indOffI1, indOffL1, indOffI2, indOffL2, indOffI4, indOffL4, indOffI8, indOffL8,
 5886                indirectN, indIndexScaledN, indIndexScaledI2LN, indIndexI2LN, indIndexN, indOffIN, indOffLN);
 5887 
 5888 
 5889 // iRegIorL2I is used for src inputs in rules for 32 bit int (I)
 5890 // operations. it allows the src to be either an iRegI or a (ConvL2I
 5891 // iRegL). in the latter case the l2i normally planted for a ConvL2I
 5892 // can be elided because the 32-bit instruction will just employ the
 5893 // lower 32 bits anyway.
 5894 //
 5895 // n.b. this does not elide all L2I conversions. if the truncated
 5896 // value is consumed by more than one operation then the ConvL2I
 5897 // cannot be bundled into the consuming nodes so an l2i gets planted
 5898 // (actually a movw $dst $src) and the downstream instructions consume
 5899 // the result of the l2i as an iRegI input. That&#39;s a shame since the
 5900 // movw is actually redundant but its not too costly.
 5901 
 5902 opclass iRegIorL2I(iRegI, iRegL2I);
 5903 
 5904 //----------PIPELINE-----------------------------------------------------------
 5905 // Rules which define the behavior of the target architectures pipeline.
 5906 
 5907 // For specific pipelines, eg A53, define the stages of that pipeline
 5908 //pipe_desc(ISS, EX1, EX2, WR);
 5909 #define ISS S0
 5910 #define EX1 S1
 5911 #define EX2 S2
 5912 #define WR  S3
 5913 
 5914 // Integer ALU reg operation
 5915 pipeline %{
 5916 
 5917 attributes %{
 5918   // ARM instructions are of fixed length
 5919   fixed_size_instructions;        // Fixed size instructions TODO does
 5920   max_instructions_per_bundle = 2;   // A53 = 2, A57 = 4
 5921   // ARM instructions come in 32-bit word units
 5922   instruction_unit_size = 4;         // An instruction is 4 bytes long
 5923   instruction_fetch_unit_size = 64;  // The processor fetches one line
 5924   instruction_fetch_units = 1;       // of 64 bytes
 5925 
 5926   // List of nop instructions
 5927   nops( MachNop );
 5928 %}
 5929 
 5930 // We don&#39;t use an actual pipeline model so don&#39;t care about resources
 5931 // or description. we do use pipeline classes to introduce fixed
 5932 // latencies
 5933 
 5934 //----------RESOURCES----------------------------------------------------------
 5935 // Resources are the functional units available to the machine
 5936 
 5937 resources( INS0, INS1, INS01 = INS0 | INS1,
 5938            ALU0, ALU1, ALU = ALU0 | ALU1,
 5939            MAC,
 5940            DIV,
 5941            BRANCH,
 5942            LDST,
 5943            NEON_FP);
 5944 
 5945 //----------PIPELINE DESCRIPTION-----------------------------------------------
 5946 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 5947 
 5948 // Define the pipeline as a generic 6 stage pipeline
 5949 pipe_desc(S0, S1, S2, S3, S4, S5);
 5950 
 5951 //----------PIPELINE CLASSES---------------------------------------------------
 5952 // Pipeline Classes describe the stages in which input and output are
 5953 // referenced by the hardware pipeline.
 5954 
 5955 pipe_class fp_dop_reg_reg_s(vRegF dst, vRegF src1, vRegF src2)
 5956 %{
 5957   single_instruction;
 5958   src1   : S1(read);
 5959   src2   : S2(read);
 5960   dst    : S5(write);
 5961   INS01  : ISS;
 5962   NEON_FP : S5;
 5963 %}
 5964 
 5965 pipe_class fp_dop_reg_reg_d(vRegD dst, vRegD src1, vRegD src2)
 5966 %{
 5967   single_instruction;
 5968   src1   : S1(read);
 5969   src2   : S2(read);
 5970   dst    : S5(write);
 5971   INS01  : ISS;
 5972   NEON_FP : S5;
 5973 %}
 5974 
 5975 pipe_class fp_uop_s(vRegF dst, vRegF src)
 5976 %{
 5977   single_instruction;
 5978   src    : S1(read);
 5979   dst    : S5(write);
 5980   INS01  : ISS;
 5981   NEON_FP : S5;
 5982 %}
 5983 
 5984 pipe_class fp_uop_d(vRegD dst, vRegD src)
 5985 %{
 5986   single_instruction;
 5987   src    : S1(read);
 5988   dst    : S5(write);
 5989   INS01  : ISS;
 5990   NEON_FP : S5;
 5991 %}
 5992 
 5993 pipe_class fp_d2f(vRegF dst, vRegD src)
 5994 %{
 5995   single_instruction;
 5996   src    : S1(read);
 5997   dst    : S5(write);
 5998   INS01  : ISS;
 5999   NEON_FP : S5;
 6000 %}
 6001 
 6002 pipe_class fp_f2d(vRegD dst, vRegF src)
 6003 %{
 6004   single_instruction;
 6005   src    : S1(read);
 6006   dst    : S5(write);
 6007   INS01  : ISS;
 6008   NEON_FP : S5;
 6009 %}
 6010 
 6011 pipe_class fp_f2i(iRegINoSp dst, vRegF src)
 6012 %{
 6013   single_instruction;
 6014   src    : S1(read);
 6015   dst    : S5(write);
 6016   INS01  : ISS;
 6017   NEON_FP : S5;
 6018 %}
 6019 
 6020 pipe_class fp_f2l(iRegLNoSp dst, vRegF src)
 6021 %{
 6022   single_instruction;
 6023   src    : S1(read);
 6024   dst    : S5(write);
 6025   INS01  : ISS;
 6026   NEON_FP : S5;
 6027 %}
 6028 
 6029 pipe_class fp_i2f(vRegF dst, iRegIorL2I src)
 6030 %{
 6031   single_instruction;
 6032   src    : S1(read);
 6033   dst    : S5(write);
 6034   INS01  : ISS;
 6035   NEON_FP : S5;
 6036 %}
 6037 
 6038 pipe_class fp_l2f(vRegF dst, iRegL src)
 6039 %{
 6040   single_instruction;
 6041   src    : S1(read);
 6042   dst    : S5(write);
 6043   INS01  : ISS;
 6044   NEON_FP : S5;
 6045 %}
 6046 
 6047 pipe_class fp_d2i(iRegINoSp dst, vRegD src)
 6048 %{
 6049   single_instruction;
 6050   src    : S1(read);
 6051   dst    : S5(write);
 6052   INS01  : ISS;
 6053   NEON_FP : S5;
 6054 %}
 6055 
 6056 pipe_class fp_d2l(iRegLNoSp dst, vRegD src)
 6057 %{
 6058   single_instruction;
 6059   src    : S1(read);
 6060   dst    : S5(write);
 6061   INS01  : ISS;
 6062   NEON_FP : S5;
 6063 %}
 6064 
 6065 pipe_class fp_i2d(vRegD dst, iRegIorL2I src)
 6066 %{
 6067   single_instruction;
 6068   src    : S1(read);
 6069   dst    : S5(write);
 6070   INS01  : ISS;
 6071   NEON_FP : S5;
 6072 %}
 6073 
 6074 pipe_class fp_l2d(vRegD dst, iRegIorL2I src)
 6075 %{
 6076   single_instruction;
 6077   src    : S1(read);
 6078   dst    : S5(write);
 6079   INS01  : ISS;
 6080   NEON_FP : S5;
 6081 %}
 6082 
 6083 pipe_class fp_div_s(vRegF dst, vRegF src1, vRegF src2)
 6084 %{
 6085   single_instruction;
 6086   src1   : S1(read);
 6087   src2   : S2(read);
 6088   dst    : S5(write);
 6089   INS0   : ISS;
 6090   NEON_FP : S5;
 6091 %}
 6092 
 6093 pipe_class fp_div_d(vRegD dst, vRegD src1, vRegD src2)
 6094 %{
 6095   single_instruction;
 6096   src1   : S1(read);
 6097   src2   : S2(read);
 6098   dst    : S5(write);
 6099   INS0   : ISS;
 6100   NEON_FP : S5;
 6101 %}
 6102 
 6103 pipe_class fp_cond_reg_reg_s(vRegF dst, vRegF src1, vRegF src2, rFlagsReg cr)
 6104 %{
 6105   single_instruction;
 6106   cr     : S1(read);
 6107   src1   : S1(read);
 6108   src2   : S1(read);
 6109   dst    : S3(write);
 6110   INS01  : ISS;
 6111   NEON_FP : S3;
 6112 %}
 6113 
 6114 pipe_class fp_cond_reg_reg_d(vRegD dst, vRegD src1, vRegD src2, rFlagsReg cr)
 6115 %{
 6116   single_instruction;
 6117   cr     : S1(read);
 6118   src1   : S1(read);
 6119   src2   : S1(read);
 6120   dst    : S3(write);
 6121   INS01  : ISS;
 6122   NEON_FP : S3;
 6123 %}
 6124 
 6125 pipe_class fp_imm_s(vRegF dst)
 6126 %{
 6127   single_instruction;
 6128   dst    : S3(write);
 6129   INS01  : ISS;
 6130   NEON_FP : S3;
 6131 %}
 6132 
 6133 pipe_class fp_imm_d(vRegD dst)
 6134 %{
 6135   single_instruction;
 6136   dst    : S3(write);
 6137   INS01  : ISS;
 6138   NEON_FP : S3;
 6139 %}
 6140 
 6141 pipe_class fp_load_constant_s(vRegF dst)
 6142 %{
 6143   single_instruction;
 6144   dst    : S4(write);
 6145   INS01  : ISS;
 6146   NEON_FP : S4;
 6147 %}
 6148 
 6149 pipe_class fp_load_constant_d(vRegD dst)
 6150 %{
 6151   single_instruction;
 6152   dst    : S4(write);
 6153   INS01  : ISS;
 6154   NEON_FP : S4;
 6155 %}
 6156 
 6157 pipe_class vmul64(vecD dst, vecD src1, vecD src2)
 6158 %{
 6159   single_instruction;
 6160   dst    : S5(write);
 6161   src1   : S1(read);
 6162   src2   : S1(read);
 6163   INS01  : ISS;
 6164   NEON_FP : S5;
 6165 %}
 6166 
 6167 pipe_class vmul128(vecX dst, vecX src1, vecX src2)
 6168 %{
 6169   single_instruction;
 6170   dst    : S5(write);
 6171   src1   : S1(read);
 6172   src2   : S1(read);
 6173   INS0   : ISS;
 6174   NEON_FP : S5;
 6175 %}
 6176 
 6177 pipe_class vmla64(vecD dst, vecD src1, vecD src2)
 6178 %{
 6179   single_instruction;
 6180   dst    : S5(write);
 6181   src1   : S1(read);
 6182   src2   : S1(read);
 6183   dst    : S1(read);
 6184   INS01  : ISS;
 6185   NEON_FP : S5;
 6186 %}
 6187 
 6188 pipe_class vmla128(vecX dst, vecX src1, vecX src2)
 6189 %{
 6190   single_instruction;
 6191   dst    : S5(write);
 6192   src1   : S1(read);
 6193   src2   : S1(read);
 6194   dst    : S1(read);
 6195   INS0   : ISS;
 6196   NEON_FP : S5;
 6197 %}
 6198 
 6199 pipe_class vdop64(vecD dst, vecD src1, vecD src2)
 6200 %{
 6201   single_instruction;
 6202   dst    : S4(write);
 6203   src1   : S2(read);
 6204   src2   : S2(read);
 6205   INS01  : ISS;
 6206   NEON_FP : S4;
 6207 %}
 6208 
 6209 pipe_class vdop128(vecX dst, vecX src1, vecX src2)
 6210 %{
 6211   single_instruction;
 6212   dst    : S4(write);
 6213   src1   : S2(read);
 6214   src2   : S2(read);
 6215   INS0   : ISS;
 6216   NEON_FP : S4;
 6217 %}
 6218 
 6219 pipe_class vlogical64(vecD dst, vecD src1, vecD src2)
 6220 %{
 6221   single_instruction;
 6222   dst    : S3(write);
 6223   src1   : S2(read);
 6224   src2   : S2(read);
 6225   INS01  : ISS;
 6226   NEON_FP : S3;
 6227 %}
 6228 
 6229 pipe_class vlogical128(vecX dst, vecX src1, vecX src2)
 6230 %{
 6231   single_instruction;
 6232   dst    : S3(write);
 6233   src1   : S2(read);
 6234   src2   : S2(read);
 6235   INS0   : ISS;
 6236   NEON_FP : S3;
 6237 %}
 6238 
 6239 pipe_class vshift64(vecD dst, vecD src, vecX shift)
 6240 %{
 6241   single_instruction;
 6242   dst    : S3(write);
 6243   src    : S1(read);
 6244   shift  : S1(read);
 6245   INS01  : ISS;
 6246   NEON_FP : S3;
 6247 %}
 6248 
 6249 pipe_class vshift128(vecX dst, vecX src, vecX shift)
 6250 %{
 6251   single_instruction;
 6252   dst    : S3(write);
 6253   src    : S1(read);
 6254   shift  : S1(read);
 6255   INS0   : ISS;
 6256   NEON_FP : S3;
 6257 %}
 6258 
 6259 pipe_class vshift64_imm(vecD dst, vecD src, immI shift)
 6260 %{
 6261   single_instruction;
 6262   dst    : S3(write);
 6263   src    : S1(read);
 6264   INS01  : ISS;
 6265   NEON_FP : S3;
 6266 %}
 6267 
 6268 pipe_class vshift128_imm(vecX dst, vecX src, immI shift)
 6269 %{
 6270   single_instruction;
 6271   dst    : S3(write);
 6272   src    : S1(read);
 6273   INS0   : ISS;
 6274   NEON_FP : S3;
 6275 %}
 6276 
 6277 pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)
 6278 %{
 6279   single_instruction;
 6280   dst    : S5(write);
 6281   src1   : S1(read);
 6282   src2   : S1(read);
 6283   INS01  : ISS;
 6284   NEON_FP : S5;
 6285 %}
 6286 
 6287 pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)
 6288 %{
 6289   single_instruction;
 6290   dst    : S5(write);
 6291   src1   : S1(read);
 6292   src2   : S1(read);
 6293   INS0   : ISS;
 6294   NEON_FP : S5;
 6295 %}
 6296 
 6297 pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)
 6298 %{
 6299   single_instruction;
 6300   dst    : S5(write);
 6301   src1   : S1(read);
 6302   src2   : S1(read);
 6303   INS0   : ISS;
 6304   NEON_FP : S5;
 6305 %}
 6306 
 6307 pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)
 6308 %{
 6309   single_instruction;
 6310   dst    : S5(write);
 6311   src1   : S1(read);
 6312   src2   : S1(read);
 6313   INS0   : ISS;
 6314   NEON_FP : S5;
 6315 %}
 6316 
 6317 pipe_class vsqrt_fp128(vecX dst, vecX src)
 6318 %{
 6319   single_instruction;
 6320   dst    : S5(write);
 6321   src    : S1(read);
 6322   INS0   : ISS;
 6323   NEON_FP : S5;
 6324 %}
 6325 
 6326 pipe_class vunop_fp64(vecD dst, vecD src)
 6327 %{
 6328   single_instruction;
 6329   dst    : S5(write);
 6330   src    : S1(read);
 6331   INS01  : ISS;
 6332   NEON_FP : S5;
 6333 %}
 6334 
 6335 pipe_class vunop_fp128(vecX dst, vecX src)
 6336 %{
 6337   single_instruction;
 6338   dst    : S5(write);
 6339   src    : S1(read);
 6340   INS0   : ISS;
 6341   NEON_FP : S5;
 6342 %}
 6343 
 6344 pipe_class vdup_reg_reg64(vecD dst, iRegI src)
 6345 %{
 6346   single_instruction;
 6347   dst    : S3(write);
 6348   src    : S1(read);
 6349   INS01  : ISS;
 6350   NEON_FP : S3;
 6351 %}
 6352 
 6353 pipe_class vdup_reg_reg128(vecX dst, iRegI src)
 6354 %{
 6355   single_instruction;
 6356   dst    : S3(write);
 6357   src    : S1(read);
 6358   INS01  : ISS;
 6359   NEON_FP : S3;
 6360 %}
 6361 
 6362 pipe_class vdup_reg_freg64(vecD dst, vRegF src)
 6363 %{
 6364   single_instruction;
 6365   dst    : S3(write);
 6366   src    : S1(read);
 6367   INS01  : ISS;
 6368   NEON_FP : S3;
 6369 %}
 6370 
 6371 pipe_class vdup_reg_freg128(vecX dst, vRegF src)
 6372 %{
 6373   single_instruction;
 6374   dst    : S3(write);
 6375   src    : S1(read);
 6376   INS01  : ISS;
 6377   NEON_FP : S3;
 6378 %}
 6379 
 6380 pipe_class vdup_reg_dreg128(vecX dst, vRegD src)
 6381 %{
 6382   single_instruction;
 6383   dst    : S3(write);
 6384   src    : S1(read);
 6385   INS01  : ISS;
 6386   NEON_FP : S3;
 6387 %}
 6388 
 6389 pipe_class vmovi_reg_imm64(vecD dst)
 6390 %{
 6391   single_instruction;
 6392   dst    : S3(write);
 6393   INS01  : ISS;
 6394   NEON_FP : S3;
 6395 %}
 6396 
 6397 pipe_class vmovi_reg_imm128(vecX dst)
 6398 %{
 6399   single_instruction;
 6400   dst    : S3(write);
 6401   INS0   : ISS;
 6402   NEON_FP : S3;
 6403 %}
 6404 
 6405 pipe_class vload_reg_mem64(vecD dst, vmem8 mem)
 6406 %{
 6407   single_instruction;
 6408   dst    : S5(write);
 6409   mem    : ISS(read);
 6410   INS01  : ISS;
 6411   NEON_FP : S3;
 6412 %}
 6413 
 6414 pipe_class vload_reg_mem128(vecX dst, vmem16 mem)
 6415 %{
 6416   single_instruction;
 6417   dst    : S5(write);
 6418   mem    : ISS(read);
 6419   INS01  : ISS;
 6420   NEON_FP : S3;
 6421 %}
 6422 
 6423 pipe_class vstore_reg_mem64(vecD src, vmem8 mem)
 6424 %{
 6425   single_instruction;
 6426   mem    : ISS(read);
 6427   src    : S2(read);
 6428   INS01  : ISS;
 6429   NEON_FP : S3;
 6430 %}
 6431 
 6432 pipe_class vstore_reg_mem128(vecD src, vmem16 mem)
 6433 %{
 6434   single_instruction;
 6435   mem    : ISS(read);
 6436   src    : S2(read);
 6437   INS01  : ISS;
 6438   NEON_FP : S3;
 6439 %}
 6440 
 6441 //------- Integer ALU operations --------------------------
 6442 
 6443 // Integer ALU reg-reg operation
 6444 // Operands needed in EX1, result generated in EX2
 6445 // Eg.  ADD     x0, x1, x2
 6446 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6447 %{
 6448   single_instruction;
 6449   dst    : EX2(write);
 6450   src1   : EX1(read);
 6451   src2   : EX1(read);
 6452   INS01  : ISS; // Dual issue as instruction 0 or 1
 6453   ALU    : EX2;
 6454 %}
 6455 
 6456 // Integer ALU reg-reg operation with constant shift
 6457 // Shifted register must be available in LATE_ISS instead of EX1
 6458 // Eg.  ADD     x0, x1, x2, LSL #2
 6459 pipe_class ialu_reg_reg_shift(iRegI dst, iRegI src1, iRegI src2, immI shift)
 6460 %{
 6461   single_instruction;
 6462   dst    : EX2(write);
 6463   src1   : EX1(read);
 6464   src2   : ISS(read);
 6465   INS01  : ISS;
 6466   ALU    : EX2;
 6467 %}
 6468 
 6469 // Integer ALU reg operation with constant shift
 6470 // Eg.  LSL     x0, x1, #shift
 6471 pipe_class ialu_reg_shift(iRegI dst, iRegI src1)
 6472 %{
 6473   single_instruction;
 6474   dst    : EX2(write);
 6475   src1   : ISS(read);
 6476   INS01  : ISS;
 6477   ALU    : EX2;
 6478 %}
 6479 
 6480 // Integer ALU reg-reg operation with variable shift
 6481 // Both operands must be available in LATE_ISS instead of EX1
 6482 // Result is available in EX1 instead of EX2
 6483 // Eg.  LSLV    x0, x1, x2
 6484 pipe_class ialu_reg_reg_vshift(iRegI dst, iRegI src1, iRegI src2)
 6485 %{
 6486   single_instruction;
 6487   dst    : EX1(write);
 6488   src1   : ISS(read);
 6489   src2   : ISS(read);
 6490   INS01  : ISS;
 6491   ALU    : EX1;
 6492 %}
 6493 
 6494 // Integer ALU reg-reg operation with extract
 6495 // As for _vshift above, but result generated in EX2
 6496 // Eg.  EXTR    x0, x1, x2, #N
 6497 pipe_class ialu_reg_reg_extr(iRegI dst, iRegI src1, iRegI src2)
 6498 %{
 6499   single_instruction;
 6500   dst    : EX2(write);
 6501   src1   : ISS(read);
 6502   src2   : ISS(read);
 6503   INS1   : ISS; // Can only dual issue as Instruction 1
 6504   ALU    : EX1;
 6505 %}
 6506 
 6507 // Integer ALU reg operation
 6508 // Eg.  NEG     x0, x1
 6509 pipe_class ialu_reg(iRegI dst, iRegI src)
 6510 %{
 6511   single_instruction;
 6512   dst    : EX2(write);
 6513   src    : EX1(read);
 6514   INS01  : ISS;
 6515   ALU    : EX2;
 6516 %}
 6517 
 6518 // Integer ALU reg mmediate operation
 6519 // Eg.  ADD     x0, x1, #N
 6520 pipe_class ialu_reg_imm(iRegI dst, iRegI src1)
 6521 %{
 6522   single_instruction;
 6523   dst    : EX2(write);
 6524   src1   : EX1(read);
 6525   INS01  : ISS;
 6526   ALU    : EX2;
 6527 %}
 6528 
 6529 // Integer ALU immediate operation (no source operands)
 6530 // Eg.  MOV     x0, #N
 6531 pipe_class ialu_imm(iRegI dst)
 6532 %{
 6533   single_instruction;
 6534   dst    : EX1(write);
 6535   INS01  : ISS;
 6536   ALU    : EX1;
 6537 %}
 6538 
 6539 //------- Compare operation -------------------------------
 6540 
 6541 // Compare reg-reg
 6542 // Eg.  CMP     x0, x1
 6543 pipe_class icmp_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
 6544 %{
 6545   single_instruction;
 6546 //  fixed_latency(16);
 6547   cr     : EX2(write);
 6548   op1    : EX1(read);
 6549   op2    : EX1(read);
 6550   INS01  : ISS;
 6551   ALU    : EX2;
 6552 %}
 6553 
 6554 // Compare reg-reg
 6555 // Eg.  CMP     x0, #N
 6556 pipe_class icmp_reg_imm(rFlagsReg cr, iRegI op1)
 6557 %{
 6558   single_instruction;
 6559 //  fixed_latency(16);
 6560   cr     : EX2(write);
 6561   op1    : EX1(read);
 6562   INS01  : ISS;
 6563   ALU    : EX2;
 6564 %}
 6565 
 6566 //------- Conditional instructions ------------------------
 6567 
 6568 // Conditional no operands
 6569 // Eg.  CSINC   x0, zr, zr, &lt;cond&gt;
 6570 pipe_class icond_none(iRegI dst, rFlagsReg cr)
 6571 %{
 6572   single_instruction;
 6573   cr     : EX1(read);
 6574   dst    : EX2(write);
 6575   INS01  : ISS;
 6576   ALU    : EX2;
 6577 %}
 6578 
 6579 // Conditional 2 operand
 6580 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6581 pipe_class icond_reg_reg(iRegI dst, iRegI src1, iRegI src2, rFlagsReg cr)
 6582 %{
 6583   single_instruction;
 6584   cr     : EX1(read);
 6585   src1   : EX1(read);
 6586   src2   : EX1(read);
 6587   dst    : EX2(write);
 6588   INS01  : ISS;
 6589   ALU    : EX2;
 6590 %}
 6591 
 6592 // Conditional 2 operand
 6593 // EG.  CSEL    X0, X1, X2, &lt;cond&gt;
 6594 pipe_class icond_reg(iRegI dst, iRegI src, rFlagsReg cr)
 6595 %{
 6596   single_instruction;
 6597   cr     : EX1(read);
 6598   src    : EX1(read);
 6599   dst    : EX2(write);
 6600   INS01  : ISS;
 6601   ALU    : EX2;
 6602 %}
 6603 
 6604 //------- Multiply pipeline operations --------------------
 6605 
 6606 // Multiply reg-reg
 6607 // Eg.  MUL     w0, w1, w2
 6608 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6609 %{
 6610   single_instruction;
 6611   dst    : WR(write);
 6612   src1   : ISS(read);
 6613   src2   : ISS(read);
 6614   INS01  : ISS;
 6615   MAC    : WR;
 6616 %}
 6617 
 6618 // Multiply accumulate
 6619 // Eg.  MADD    w0, w1, w2, w3
 6620 pipe_class imac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6621 %{
 6622   single_instruction;
 6623   dst    : WR(write);
 6624   src1   : ISS(read);
 6625   src2   : ISS(read);
 6626   src3   : ISS(read);
 6627   INS01  : ISS;
 6628   MAC    : WR;
 6629 %}
 6630 
 6631 // Eg.  MUL     w0, w1, w2
 6632 pipe_class lmul_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6633 %{
 6634   single_instruction;
 6635   fixed_latency(3); // Maximum latency for 64 bit mul
 6636   dst    : WR(write);
 6637   src1   : ISS(read);
 6638   src2   : ISS(read);
 6639   INS01  : ISS;
 6640   MAC    : WR;
 6641 %}
 6642 
 6643 // Multiply accumulate
 6644 // Eg.  MADD    w0, w1, w2, w3
 6645 pipe_class lmac_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3)
 6646 %{
 6647   single_instruction;
 6648   fixed_latency(3); // Maximum latency for 64 bit mul
 6649   dst    : WR(write);
 6650   src1   : ISS(read);
 6651   src2   : ISS(read);
 6652   src3   : ISS(read);
 6653   INS01  : ISS;
 6654   MAC    : WR;
 6655 %}
 6656 
 6657 //------- Divide pipeline operations --------------------
 6658 
 6659 // Eg.  SDIV    w0, w1, w2
 6660 pipe_class idiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6661 %{
 6662   single_instruction;
 6663   fixed_latency(8); // Maximum latency for 32 bit divide
 6664   dst    : WR(write);
 6665   src1   : ISS(read);
 6666   src2   : ISS(read);
 6667   INS0   : ISS; // Can only dual issue as instruction 0
 6668   DIV    : WR;
 6669 %}
 6670 
 6671 // Eg.  SDIV    x0, x1, x2
 6672 pipe_class ldiv_reg_reg(iRegI dst, iRegI src1, iRegI src2)
 6673 %{
 6674   single_instruction;
 6675   fixed_latency(16); // Maximum latency for 64 bit divide
 6676   dst    : WR(write);
 6677   src1   : ISS(read);
 6678   src2   : ISS(read);
 6679   INS0   : ISS; // Can only dual issue as instruction 0
 6680   DIV    : WR;
 6681 %}
 6682 
 6683 //------- Load pipeline operations ------------------------
 6684 
 6685 // Load - prefetch
 6686 // Eg.  PFRM    &lt;mem&gt;
 6687 pipe_class iload_prefetch(memory mem)
 6688 %{
 6689   single_instruction;
 6690   mem    : ISS(read);
 6691   INS01  : ISS;
 6692   LDST   : WR;
 6693 %}
 6694 
 6695 // Load - reg, mem
 6696 // Eg.  LDR     x0, &lt;mem&gt;
 6697 pipe_class iload_reg_mem(iRegI dst, memory mem)
 6698 %{
 6699   single_instruction;
 6700   dst    : WR(write);
 6701   mem    : ISS(read);
 6702   INS01  : ISS;
 6703   LDST   : WR;
 6704 %}
 6705 
 6706 // Load - reg, reg
 6707 // Eg.  LDR     x0, [sp, x1]
 6708 pipe_class iload_reg_reg(iRegI dst, iRegI src)
 6709 %{
 6710   single_instruction;
 6711   dst    : WR(write);
 6712   src    : ISS(read);
 6713   INS01  : ISS;
 6714   LDST   : WR;
 6715 %}
 6716 
 6717 //------- Store pipeline operations -----------------------
 6718 
 6719 // Store - zr, mem
 6720 // Eg.  STR     zr, &lt;mem&gt;
 6721 pipe_class istore_mem(memory mem)
 6722 %{
 6723   single_instruction;
 6724   mem    : ISS(read);
 6725   INS01  : ISS;
 6726   LDST   : WR;
 6727 %}
 6728 
 6729 // Store - reg, mem
 6730 // Eg.  STR     x0, &lt;mem&gt;
 6731 pipe_class istore_reg_mem(iRegI src, memory mem)
 6732 %{
 6733   single_instruction;
 6734   mem    : ISS(read);
 6735   src    : EX2(read);
 6736   INS01  : ISS;
 6737   LDST   : WR;
 6738 %}
 6739 
 6740 // Store - reg, reg
 6741 // Eg. STR      x0, [sp, x1]
 6742 pipe_class istore_reg_reg(iRegI dst, iRegI src)
 6743 %{
 6744   single_instruction;
 6745   dst    : ISS(read);
 6746   src    : EX2(read);
 6747   INS01  : ISS;
 6748   LDST   : WR;
 6749 %}
 6750 
 6751 //------- Store pipeline operations -----------------------
 6752 
 6753 // Branch
 6754 pipe_class pipe_branch()
 6755 %{
 6756   single_instruction;
 6757   INS01  : ISS;
 6758   BRANCH : EX1;
 6759 %}
 6760 
 6761 // Conditional branch
 6762 pipe_class pipe_branch_cond(rFlagsReg cr)
 6763 %{
 6764   single_instruction;
 6765   cr     : EX1(read);
 6766   INS01  : ISS;
 6767   BRANCH : EX1;
 6768 %}
 6769 
 6770 // Compare &amp; Branch
 6771 // EG.  CBZ/CBNZ
 6772 pipe_class pipe_cmp_branch(iRegI op1)
 6773 %{
 6774   single_instruction;
 6775   op1    : EX1(read);
 6776   INS01  : ISS;
 6777   BRANCH : EX1;
 6778 %}
 6779 
 6780 //------- Synchronisation operations ----------------------
 6781 
 6782 // Any operation requiring serialization.
 6783 // EG.  DMB/Atomic Ops/Load Acquire/Str Release
 6784 pipe_class pipe_serial()
 6785 %{
 6786   single_instruction;
 6787   force_serialization;
 6788   fixed_latency(16);
 6789   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6790   LDST   : WR;
 6791 %}
 6792 
 6793 // Generic big/slow expanded idiom - also serialized
 6794 pipe_class pipe_slow()
 6795 %{
 6796   instruction_count(10);
 6797   multiple_bundles;
 6798   force_serialization;
 6799   fixed_latency(16);
 6800   INS01  : ISS(2); // Cannot dual issue with any other instruction
 6801   LDST   : WR;
 6802 %}
 6803 
 6804 // Empty pipeline class
 6805 pipe_class pipe_class_empty()
 6806 %{
 6807   single_instruction;
 6808   fixed_latency(0);
 6809 %}
 6810 
 6811 // Default pipeline class.
 6812 pipe_class pipe_class_default()
 6813 %{
 6814   single_instruction;
 6815   fixed_latency(2);
 6816 %}
 6817 
 6818 // Pipeline class for compares.
 6819 pipe_class pipe_class_compare()
 6820 %{
 6821   single_instruction;
 6822   fixed_latency(16);
 6823 %}
 6824 
 6825 // Pipeline class for memory operations.
 6826 pipe_class pipe_class_memory()
 6827 %{
 6828   single_instruction;
 6829   fixed_latency(16);
 6830 %}
 6831 
 6832 // Pipeline class for call.
 6833 pipe_class pipe_class_call()
 6834 %{
 6835   single_instruction;
 6836   fixed_latency(100);
 6837 %}
 6838 
 6839 // Define the class for the Nop node.
 6840 define %{
 6841    MachNop = pipe_class_empty;
 6842 %}
 6843 
 6844 %}
 6845 //----------INSTRUCTIONS-------------------------------------------------------
 6846 //
 6847 // match      -- States which machine-independent subtree may be replaced
 6848 //               by this instruction.
 6849 // ins_cost   -- The estimated cost of this instruction is used by instruction
 6850 //               selection to identify a minimum cost tree of machine
 6851 //               instructions that matches a tree of machine-independent
 6852 //               instructions.
 6853 // format     -- A string providing the disassembly for this instruction.
 6854 //               The value of an instruction&#39;s operand may be inserted
 6855 //               by referring to it with a &#39;$&#39; prefix.
 6856 // opcode     -- Three instruction opcodes may be provided.  These are referred
 6857 //               to within an encode class as $primary, $secondary, and $tertiary
 6858 //               rrspectively.  The primary opcode is commonly used to
 6859 //               indicate the type of machine instruction, while secondary
 6860 //               and tertiary are often used for prefix options or addressing
 6861 //               modes.
 6862 // ins_encode -- A list of encode classes with parameters. The encode class
 6863 //               name must have been defined in an &#39;enc_class&#39; specification
 6864 //               in the encode section of the architecture description.
 6865 
 6866 // ============================================================================
 6867 // Memory (Load/Store) Instructions
 6868 
 6869 // Load Instructions
 6870 
 6871 // Load Byte (8 bit signed)
 6872 instruct loadB(iRegINoSp dst, memory1 mem)
 6873 %{
 6874   match(Set dst (LoadB mem));
 6875   predicate(!needs_acquiring_load(n));
 6876 
 6877   ins_cost(4 * INSN_COST);
 6878   format %{ &quot;ldrsbw  $dst, $mem\t# byte&quot; %}
 6879 
 6880   ins_encode(aarch64_enc_ldrsbw(dst, mem));
 6881 
 6882   ins_pipe(iload_reg_mem);
 6883 %}
 6884 
 6885 // Load Byte (8 bit signed) into long
 6886 instruct loadB2L(iRegLNoSp dst, memory1 mem)
 6887 %{
 6888   match(Set dst (ConvI2L (LoadB mem)));
 6889   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6890 
 6891   ins_cost(4 * INSN_COST);
 6892   format %{ &quot;ldrsb  $dst, $mem\t# byte&quot; %}
 6893 
 6894   ins_encode(aarch64_enc_ldrsb(dst, mem));
 6895 
 6896   ins_pipe(iload_reg_mem);
 6897 %}
 6898 
 6899 // Load Byte (8 bit unsigned)
 6900 instruct loadUB(iRegINoSp dst, memory1 mem)
 6901 %{
 6902   match(Set dst (LoadUB mem));
 6903   predicate(!needs_acquiring_load(n));
 6904 
 6905   ins_cost(4 * INSN_COST);
 6906   format %{ &quot;ldrbw  $dst, $mem\t# byte&quot; %}
 6907 
 6908   ins_encode(aarch64_enc_ldrb(dst, mem));
 6909 
 6910   ins_pipe(iload_reg_mem);
 6911 %}
 6912 
 6913 // Load Byte (8 bit unsigned) into long
 6914 instruct loadUB2L(iRegLNoSp dst, memory1 mem)
 6915 %{
 6916   match(Set dst (ConvI2L (LoadUB mem)));
 6917   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6918 
 6919   ins_cost(4 * INSN_COST);
 6920   format %{ &quot;ldrb  $dst, $mem\t# byte&quot; %}
 6921 
 6922   ins_encode(aarch64_enc_ldrb(dst, mem));
 6923 
 6924   ins_pipe(iload_reg_mem);
 6925 %}
 6926 
 6927 // Load Short (16 bit signed)
 6928 instruct loadS(iRegINoSp dst, memory2 mem)
 6929 %{
 6930   match(Set dst (LoadS mem));
 6931   predicate(!needs_acquiring_load(n));
 6932 
 6933   ins_cost(4 * INSN_COST);
 6934   format %{ &quot;ldrshw  $dst, $mem\t# short&quot; %}
 6935 
 6936   ins_encode(aarch64_enc_ldrshw(dst, mem));
 6937 
 6938   ins_pipe(iload_reg_mem);
 6939 %}
 6940 
 6941 // Load Short (16 bit signed) into long
 6942 instruct loadS2L(iRegLNoSp dst, memory2 mem)
 6943 %{
 6944   match(Set dst (ConvI2L (LoadS mem)));
 6945   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6946 
 6947   ins_cost(4 * INSN_COST);
 6948   format %{ &quot;ldrsh  $dst, $mem\t# short&quot; %}
 6949 
 6950   ins_encode(aarch64_enc_ldrsh(dst, mem));
 6951 
 6952   ins_pipe(iload_reg_mem);
 6953 %}
 6954 
 6955 // Load Char (16 bit unsigned)
 6956 instruct loadUS(iRegINoSp dst, memory2 mem)
 6957 %{
 6958   match(Set dst (LoadUS mem));
 6959   predicate(!needs_acquiring_load(n));
 6960 
 6961   ins_cost(4 * INSN_COST);
 6962   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6963 
 6964   ins_encode(aarch64_enc_ldrh(dst, mem));
 6965 
 6966   ins_pipe(iload_reg_mem);
 6967 %}
 6968 
 6969 // Load Short/Char (16 bit unsigned) into long
 6970 instruct loadUS2L(iRegLNoSp dst, memory2 mem)
 6971 %{
 6972   match(Set dst (ConvI2L (LoadUS mem)));
 6973   predicate(!needs_acquiring_load(n-&gt;in(1)));
 6974 
 6975   ins_cost(4 * INSN_COST);
 6976   format %{ &quot;ldrh  $dst, $mem\t# short&quot; %}
 6977 
 6978   ins_encode(aarch64_enc_ldrh(dst, mem));
 6979 
 6980   ins_pipe(iload_reg_mem);
 6981 %}
 6982 
 6983 // Load Integer (32 bit signed)
 6984 instruct loadI(iRegINoSp dst, memory4 mem)
 6985 %{
 6986   match(Set dst (LoadI mem));
 6987   predicate(!needs_acquiring_load(n));
 6988 
 6989   ins_cost(4 * INSN_COST);
 6990   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 6991 
 6992   ins_encode(aarch64_enc_ldrw(dst, mem));
 6993 
 6994   ins_pipe(iload_reg_mem);
 6995 %}
 6996 
 6997 // Load Integer (32 bit signed) into long
 6998 instruct loadI2L(iRegLNoSp dst, memory4 mem)
 6999 %{
 7000   match(Set dst (ConvI2L (LoadI mem)));
 7001   predicate(!needs_acquiring_load(n-&gt;in(1)));
 7002 
 7003   ins_cost(4 * INSN_COST);
 7004   format %{ &quot;ldrsw  $dst, $mem\t# int&quot; %}
 7005 
 7006   ins_encode(aarch64_enc_ldrsw(dst, mem));
 7007 
 7008   ins_pipe(iload_reg_mem);
 7009 %}
 7010 
 7011 // Load Integer (32 bit unsigned) into long
 7012 instruct loadUI2L(iRegLNoSp dst, memory4 mem, immL_32bits mask)
 7013 %{
 7014   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7015   predicate(!needs_acquiring_load(n-&gt;in(1)-&gt;in(1)-&gt;as_Load()));
 7016 
 7017   ins_cost(4 * INSN_COST);
 7018   format %{ &quot;ldrw  $dst, $mem\t# int&quot; %}
 7019 
 7020   ins_encode(aarch64_enc_ldrw(dst, mem));
 7021 
 7022   ins_pipe(iload_reg_mem);
 7023 %}
 7024 
 7025 // Load Long (64 bit signed)
 7026 instruct loadL(iRegLNoSp dst, memory8 mem)
 7027 %{
 7028   match(Set dst (LoadL mem));
 7029   predicate(!needs_acquiring_load(n));
 7030 
 7031   ins_cost(4 * INSN_COST);
 7032   format %{ &quot;ldr  $dst, $mem\t# int&quot; %}
 7033 
 7034   ins_encode(aarch64_enc_ldr(dst, mem));
 7035 
 7036   ins_pipe(iload_reg_mem);
 7037 %}
 7038 
 7039 // Load Range
 7040 instruct loadRange(iRegINoSp dst, memory4 mem)
 7041 %{
 7042   match(Set dst (LoadRange mem));
 7043 
 7044   ins_cost(4 * INSN_COST);
 7045   format %{ &quot;ldrw  $dst, $mem\t# range&quot; %}
 7046 
 7047   ins_encode(aarch64_enc_ldrw(dst, mem));
 7048 
 7049   ins_pipe(iload_reg_mem);
 7050 %}
 7051 
 7052 // Load Pointer
 7053 instruct loadP(iRegPNoSp dst, memory8 mem)
 7054 %{
 7055   match(Set dst (LoadP mem));
 7056   predicate(!needs_acquiring_load(n) &amp;&amp; (n-&gt;as_Load()-&gt;barrier_data() == 0));
 7057 
 7058   ins_cost(4 * INSN_COST);
 7059   format %{ &quot;ldr  $dst, $mem\t# ptr&quot; %}
 7060 
 7061   ins_encode(aarch64_enc_ldr(dst, mem));
 7062 
 7063   ins_pipe(iload_reg_mem);
 7064 %}
 7065 
 7066 // Load Compressed Pointer
 7067 instruct loadN(iRegNNoSp dst, memory4 mem)
 7068 %{
 7069   match(Set dst (LoadN mem));
 7070   predicate(!needs_acquiring_load(n));
 7071 
 7072   ins_cost(4 * INSN_COST);
 7073   format %{ &quot;ldrw  $dst, $mem\t# compressed ptr&quot; %}
 7074 
 7075   ins_encode(aarch64_enc_ldrw(dst, mem));
 7076 
 7077   ins_pipe(iload_reg_mem);
 7078 %}
 7079 
 7080 // Load Klass Pointer
 7081 instruct loadKlass(iRegPNoSp dst, memory8 mem)
 7082 %{
 7083   match(Set dst (LoadKlass mem));
 7084   predicate(!needs_acquiring_load(n));
 7085 
 7086   ins_cost(4 * INSN_COST);
 7087   format %{ &quot;ldr  $dst, $mem\t# class&quot; %}
 7088 
 7089   ins_encode(aarch64_enc_ldr(dst, mem));
 7090 
 7091   ins_pipe(iload_reg_mem);
 7092 %}
 7093 
 7094 // Load Narrow Klass Pointer
 7095 instruct loadNKlass(iRegNNoSp dst, memory4 mem)
 7096 %{
 7097   match(Set dst (LoadNKlass mem));
 7098   predicate(!needs_acquiring_load(n));
 7099 
 7100   ins_cost(4 * INSN_COST);
 7101   format %{ &quot;ldrw  $dst, $mem\t# compressed class ptr&quot; %}
 7102 
 7103   ins_encode(aarch64_enc_ldrw(dst, mem));
 7104 
 7105   ins_pipe(iload_reg_mem);
 7106 %}
 7107 
 7108 // Load Float
 7109 instruct loadF(vRegF dst, memory4 mem)
 7110 %{
 7111   match(Set dst (LoadF mem));
 7112   predicate(!needs_acquiring_load(n));
 7113 
 7114   ins_cost(4 * INSN_COST);
 7115   format %{ &quot;ldrs  $dst, $mem\t# float&quot; %}
 7116 
 7117   ins_encode( aarch64_enc_ldrs(dst, mem) );
 7118 
 7119   ins_pipe(pipe_class_memory);
 7120 %}
 7121 
 7122 // Load Double
 7123 instruct loadD(vRegD dst, memory8 mem)
 7124 %{
 7125   match(Set dst (LoadD mem));
 7126   predicate(!needs_acquiring_load(n));
 7127 
 7128   ins_cost(4 * INSN_COST);
 7129   format %{ &quot;ldrd  $dst, $mem\t# double&quot; %}
 7130 
 7131   ins_encode( aarch64_enc_ldrd(dst, mem) );
 7132 
 7133   ins_pipe(pipe_class_memory);
 7134 %}
 7135 
 7136 
 7137 // Load Int Constant
 7138 instruct loadConI(iRegINoSp dst, immI src)
 7139 %{
 7140   match(Set dst src);
 7141 
 7142   ins_cost(INSN_COST);
 7143   format %{ &quot;mov $dst, $src\t# int&quot; %}
 7144 
 7145   ins_encode( aarch64_enc_movw_imm(dst, src) );
 7146 
 7147   ins_pipe(ialu_imm);
 7148 %}
 7149 
 7150 // Load Long Constant
 7151 instruct loadConL(iRegLNoSp dst, immL src)
 7152 %{
 7153   match(Set dst src);
 7154 
 7155   ins_cost(INSN_COST);
 7156   format %{ &quot;mov $dst, $src\t# long&quot; %}
 7157 
 7158   ins_encode( aarch64_enc_mov_imm(dst, src) );
 7159 
 7160   ins_pipe(ialu_imm);
 7161 %}
 7162 
 7163 // Load Pointer Constant
 7164 
 7165 instruct loadConP(iRegPNoSp dst, immP con)
 7166 %{
 7167   match(Set dst con);
 7168 
 7169   ins_cost(INSN_COST * 4);
 7170   format %{
 7171     &quot;mov  $dst, $con\t# ptr\n\t&quot;
 7172   %}
 7173 
 7174   ins_encode(aarch64_enc_mov_p(dst, con));
 7175 
 7176   ins_pipe(ialu_imm);
 7177 %}
 7178 
 7179 // Load Null Pointer Constant
 7180 
 7181 instruct loadConP0(iRegPNoSp dst, immP0 con)
 7182 %{
 7183   match(Set dst con);
 7184 
 7185   ins_cost(INSN_COST);
 7186   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7187 
 7188   ins_encode(aarch64_enc_mov_p0(dst, con));
 7189 
 7190   ins_pipe(ialu_imm);
 7191 %}
 7192 
 7193 // Load Pointer Constant One
 7194 
 7195 instruct loadConP1(iRegPNoSp dst, immP_1 con)
 7196 %{
 7197   match(Set dst con);
 7198 
 7199   ins_cost(INSN_COST);
 7200   format %{ &quot;mov  $dst, $con\t# NULL ptr&quot; %}
 7201 
 7202   ins_encode(aarch64_enc_mov_p1(dst, con));
 7203 
 7204   ins_pipe(ialu_imm);
 7205 %}
 7206 
 7207 // Load Byte Map Base Constant
 7208 
 7209 instruct loadByteMapBase(iRegPNoSp dst, immByteMapBase con)
 7210 %{
 7211   match(Set dst con);
 7212 
 7213   ins_cost(INSN_COST);
 7214   format %{ &quot;adr  $dst, $con\t# Byte Map Base&quot; %}
 7215 
 7216   ins_encode(aarch64_enc_mov_byte_map_base(dst, con));
 7217 
 7218   ins_pipe(ialu_imm);
 7219 %}
 7220 
 7221 // Load Narrow Pointer Constant
 7222 
 7223 instruct loadConN(iRegNNoSp dst, immN con)
 7224 %{
 7225   match(Set dst con);
 7226 
 7227   ins_cost(INSN_COST * 4);
 7228   format %{ &quot;mov  $dst, $con\t# compressed ptr&quot; %}
 7229 
 7230   ins_encode(aarch64_enc_mov_n(dst, con));
 7231 
 7232   ins_pipe(ialu_imm);
 7233 %}
 7234 
 7235 // Load Narrow Null Pointer Constant
 7236 
 7237 instruct loadConN0(iRegNNoSp dst, immN0 con)
 7238 %{
 7239   match(Set dst con);
 7240 
 7241   ins_cost(INSN_COST);
 7242   format %{ &quot;mov  $dst, $con\t# compressed NULL ptr&quot; %}
 7243 
 7244   ins_encode(aarch64_enc_mov_n0(dst, con));
 7245 
 7246   ins_pipe(ialu_imm);
 7247 %}
 7248 
 7249 // Load Narrow Klass Constant
 7250 
 7251 instruct loadConNKlass(iRegNNoSp dst, immNKlass con)
 7252 %{
 7253   match(Set dst con);
 7254 
 7255   ins_cost(INSN_COST);
 7256   format %{ &quot;mov  $dst, $con\t# compressed klass ptr&quot; %}
 7257 
 7258   ins_encode(aarch64_enc_mov_nk(dst, con));
 7259 
 7260   ins_pipe(ialu_imm);
 7261 %}
 7262 
 7263 // Load Packed Float Constant
 7264 
 7265 instruct loadConF_packed(vRegF dst, immFPacked con) %{
 7266   match(Set dst con);
 7267   ins_cost(INSN_COST * 4);
 7268   format %{ &quot;fmovs  $dst, $con&quot;%}
 7269   ins_encode %{
 7270     __ fmovs(as_FloatRegister($dst$$reg), (double)$con$$constant);
 7271   %}
 7272 
 7273   ins_pipe(fp_imm_s);
 7274 %}
 7275 
 7276 // Load Float Constant
 7277 
 7278 instruct loadConF(vRegF dst, immF con) %{
 7279   match(Set dst con);
 7280 
 7281   ins_cost(INSN_COST * 4);
 7282 
 7283   format %{
 7284     &quot;ldrs $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7285   %}
 7286 
 7287   ins_encode %{
 7288     __ ldrs(as_FloatRegister($dst$$reg), $constantaddress($con));
 7289   %}
 7290 
 7291   ins_pipe(fp_load_constant_s);
 7292 %}
 7293 
 7294 // Load Packed Double Constant
 7295 
 7296 instruct loadConD_packed(vRegD dst, immDPacked con) %{
 7297   match(Set dst con);
 7298   ins_cost(INSN_COST);
 7299   format %{ &quot;fmovd  $dst, $con&quot;%}
 7300   ins_encode %{
 7301     __ fmovd(as_FloatRegister($dst$$reg), $con$$constant);
 7302   %}
 7303 
 7304   ins_pipe(fp_imm_d);
 7305 %}
 7306 
 7307 // Load Double Constant
 7308 
 7309 instruct loadConD(vRegD dst, immD con) %{
 7310   match(Set dst con);
 7311 
 7312   ins_cost(INSN_COST * 5);
 7313   format %{
 7314     &quot;ldrd $dst, [$constantaddress]\t# load from constant table: float=$con\n\t&quot;
 7315   %}
 7316 
 7317   ins_encode %{
 7318     __ ldrd(as_FloatRegister($dst$$reg), $constantaddress($con));
 7319   %}
 7320 
 7321   ins_pipe(fp_load_constant_d);
 7322 %}
 7323 
 7324 // Store Instructions
 7325 
 7326 // Store CMS card-mark Immediate
 7327 instruct storeimmCM0(immI0 zero, memory1 mem)
 7328 %{
 7329   match(Set mem (StoreCM mem zero));
 7330 
 7331   ins_cost(INSN_COST);
 7332   format %{ &quot;storestore (elided)\n\t&quot;
 7333             &quot;strb zr, $mem\t# byte&quot; %}
 7334 
 7335   ins_encode(aarch64_enc_strb0(mem));
 7336 
 7337   ins_pipe(istore_mem);
 7338 %}
 7339 
 7340 // Store CMS card-mark Immediate with intervening StoreStore
 7341 // needed when using CMS with no conditional card marking
 7342 instruct storeimmCM0_ordered(immI0 zero, memory1 mem)
 7343 %{
 7344   match(Set mem (StoreCM mem zero));
 7345 
 7346   ins_cost(INSN_COST * 2);
 7347   format %{ &quot;storestore\n\t&quot;
 7348             &quot;dmb ishst&quot;
 7349             &quot;\n\tstrb zr, $mem\t# byte&quot; %}
 7350 
 7351   ins_encode(aarch64_enc_strb0_ordered(mem));
 7352 
 7353   ins_pipe(istore_mem);
 7354 %}
 7355 
 7356 // Store Byte
 7357 instruct storeB(iRegIorL2I src, memory1 mem)
 7358 %{
 7359   match(Set mem (StoreB mem src));
 7360   predicate(!needs_releasing_store(n));
 7361 
 7362   ins_cost(INSN_COST);
 7363   format %{ &quot;strb  $src, $mem\t# byte&quot; %}
 7364 
 7365   ins_encode(aarch64_enc_strb(src, mem));
 7366 
 7367   ins_pipe(istore_reg_mem);
 7368 %}
 7369 
 7370 
 7371 instruct storeimmB0(immI0 zero, memory1 mem)
 7372 %{
 7373   match(Set mem (StoreB mem zero));
 7374   predicate(!needs_releasing_store(n));
 7375 
 7376   ins_cost(INSN_COST);
 7377   format %{ &quot;strb rscractch2, $mem\t# byte&quot; %}
 7378 
 7379   ins_encode(aarch64_enc_strb0(mem));
 7380 
 7381   ins_pipe(istore_mem);
 7382 %}
 7383 
 7384 // Store Char/Short
 7385 instruct storeC(iRegIorL2I src, memory2 mem)
 7386 %{
 7387   match(Set mem (StoreC mem src));
 7388   predicate(!needs_releasing_store(n));
 7389 
 7390   ins_cost(INSN_COST);
 7391   format %{ &quot;strh  $src, $mem\t# short&quot; %}
 7392 
 7393   ins_encode(aarch64_enc_strh(src, mem));
 7394 
 7395   ins_pipe(istore_reg_mem);
 7396 %}
 7397 
 7398 instruct storeimmC0(immI0 zero, memory2 mem)
 7399 %{
 7400   match(Set mem (StoreC mem zero));
 7401   predicate(!needs_releasing_store(n));
 7402 
 7403   ins_cost(INSN_COST);
 7404   format %{ &quot;strh  zr, $mem\t# short&quot; %}
 7405 
 7406   ins_encode(aarch64_enc_strh0(mem));
 7407 
 7408   ins_pipe(istore_mem);
 7409 %}
 7410 
 7411 // Store Integer
 7412 
 7413 instruct storeI(iRegIorL2I src, memory4 mem)
 7414 %{
 7415   match(Set mem(StoreI mem src));
 7416   predicate(!needs_releasing_store(n));
 7417 
 7418   ins_cost(INSN_COST);
 7419   format %{ &quot;strw  $src, $mem\t# int&quot; %}
 7420 
 7421   ins_encode(aarch64_enc_strw(src, mem));
 7422 
 7423   ins_pipe(istore_reg_mem);
 7424 %}
 7425 
 7426 instruct storeimmI0(immI0 zero, memory4 mem)
 7427 %{
 7428   match(Set mem(StoreI mem zero));
 7429   predicate(!needs_releasing_store(n));
 7430 
 7431   ins_cost(INSN_COST);
 7432   format %{ &quot;strw  zr, $mem\t# int&quot; %}
 7433 
 7434   ins_encode(aarch64_enc_strw0(mem));
 7435 
 7436   ins_pipe(istore_mem);
 7437 %}
 7438 
 7439 // Store Long (64 bit signed)
 7440 instruct storeL(iRegL src, memory8 mem)
 7441 %{
 7442   match(Set mem (StoreL mem src));
 7443   predicate(!needs_releasing_store(n));
 7444 
 7445   ins_cost(INSN_COST);
 7446   format %{ &quot;str  $src, $mem\t# int&quot; %}
 7447 
 7448   ins_encode(aarch64_enc_str(src, mem));
 7449 
 7450   ins_pipe(istore_reg_mem);
 7451 %}
 7452 
 7453 // Store Long (64 bit signed)
 7454 instruct storeimmL0(immL0 zero, memory8 mem)
 7455 %{
 7456   match(Set mem (StoreL mem zero));
 7457   predicate(!needs_releasing_store(n));
 7458 
 7459   ins_cost(INSN_COST);
 7460   format %{ &quot;str  zr, $mem\t# int&quot; %}
 7461 
 7462   ins_encode(aarch64_enc_str0(mem));
 7463 
 7464   ins_pipe(istore_mem);
 7465 %}
 7466 
 7467 // Store Pointer
 7468 instruct storeP(iRegP src, memory8 mem)
 7469 %{
 7470   match(Set mem (StoreP mem src));
 7471   predicate(!needs_releasing_store(n));
 7472 
 7473   ins_cost(INSN_COST);
 7474   format %{ &quot;str  $src, $mem\t# ptr&quot; %}
 7475 
 7476   ins_encode(aarch64_enc_str(src, mem));
 7477 
 7478   ins_pipe(istore_reg_mem);
 7479 %}
 7480 
 7481 // Store Pointer
 7482 instruct storeimmP0(immP0 zero, memory8 mem)
 7483 %{
 7484   match(Set mem (StoreP mem zero));
 7485   predicate(!needs_releasing_store(n));
 7486 
 7487   ins_cost(INSN_COST);
 7488   format %{ &quot;str zr, $mem\t# ptr&quot; %}
 7489 
 7490   ins_encode(aarch64_enc_str0(mem));
 7491 
 7492   ins_pipe(istore_mem);
 7493 %}
 7494 
 7495 // Store Compressed Pointer
 7496 instruct storeN(iRegN src, memory4 mem)
 7497 %{
 7498   match(Set mem (StoreN mem src));
 7499   predicate(!needs_releasing_store(n));
 7500 
 7501   ins_cost(INSN_COST);
 7502   format %{ &quot;strw  $src, $mem\t# compressed ptr&quot; %}
 7503 
 7504   ins_encode(aarch64_enc_strw(src, mem));
 7505 
 7506   ins_pipe(istore_reg_mem);
 7507 %}
 7508 
 7509 instruct storeImmN0(immN0 zero, memory4 mem)
 7510 %{
 7511   match(Set mem (StoreN mem zero));
 7512   predicate(!needs_releasing_store(n));
 7513 
 7514   ins_cost(INSN_COST);
 7515   format %{ &quot;strw  zr, $mem\t# compressed ptr&quot; %}
 7516 
 7517   ins_encode(aarch64_enc_strw0(mem));
 7518 
 7519   ins_pipe(istore_mem);
 7520 %}
 7521 
 7522 // Store Float
 7523 instruct storeF(vRegF src, memory4 mem)
 7524 %{
 7525   match(Set mem (StoreF mem src));
 7526   predicate(!needs_releasing_store(n));
 7527 
 7528   ins_cost(INSN_COST);
 7529   format %{ &quot;strs  $src, $mem\t# float&quot; %}
 7530 
 7531   ins_encode( aarch64_enc_strs(src, mem) );
 7532 
 7533   ins_pipe(pipe_class_memory);
 7534 %}
 7535 
 7536 // TODO
 7537 // implement storeImmF0 and storeFImmPacked
 7538 
 7539 // Store Double
 7540 instruct storeD(vRegD src, memory8 mem)
 7541 %{
 7542   match(Set mem (StoreD mem src));
 7543   predicate(!needs_releasing_store(n));
 7544 
 7545   ins_cost(INSN_COST);
 7546   format %{ &quot;strd  $src, $mem\t# double&quot; %}
 7547 
 7548   ins_encode( aarch64_enc_strd(src, mem) );
 7549 
 7550   ins_pipe(pipe_class_memory);
 7551 %}
 7552 
 7553 // Store Compressed Klass Pointer
 7554 instruct storeNKlass(iRegN src, memory4 mem)
 7555 %{
 7556   predicate(!needs_releasing_store(n));
 7557   match(Set mem (StoreNKlass mem src));
 7558 
 7559   ins_cost(INSN_COST);
 7560   format %{ &quot;strw  $src, $mem\t# compressed klass ptr&quot; %}
 7561 
 7562   ins_encode(aarch64_enc_strw(src, mem));
 7563 
 7564   ins_pipe(istore_reg_mem);
 7565 %}
 7566 
 7567 // TODO
 7568 // implement storeImmD0 and storeDImmPacked
 7569 
 7570 // prefetch instructions
 7571 // Must be safe to execute with invalid address (cannot fault).
 7572 
 7573 instruct prefetchalloc( memory8 mem ) %{
 7574   match(PrefetchAllocation mem);
 7575 
 7576   ins_cost(INSN_COST);
 7577   format %{ &quot;prfm $mem, PSTL1KEEP\t# Prefetch into level 1 cache write keep&quot; %}
 7578 
 7579   ins_encode( aarch64_enc_prefetchw(mem) );
 7580 
 7581   ins_pipe(iload_prefetch);
 7582 %}
 7583 
 7584 //  ---------------- volatile loads and stores ----------------
 7585 
 7586 // Load Byte (8 bit signed)
 7587 instruct loadB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7588 %{
 7589   match(Set dst (LoadB mem));
 7590 
 7591   ins_cost(VOLATILE_REF_COST);
 7592   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7593 
 7594   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7595 
 7596   ins_pipe(pipe_serial);
 7597 %}
 7598 
 7599 // Load Byte (8 bit signed) into long
 7600 instruct loadB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7601 %{
 7602   match(Set dst (ConvI2L (LoadB mem)));
 7603 
 7604   ins_cost(VOLATILE_REF_COST);
 7605   format %{ &quot;ldarsb  $dst, $mem\t# byte&quot; %}
 7606 
 7607   ins_encode(aarch64_enc_ldarsb(dst, mem));
 7608 
 7609   ins_pipe(pipe_serial);
 7610 %}
 7611 
 7612 // Load Byte (8 bit unsigned)
 7613 instruct loadUB_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7614 %{
 7615   match(Set dst (LoadUB mem));
 7616 
 7617   ins_cost(VOLATILE_REF_COST);
 7618   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7619 
 7620   ins_encode(aarch64_enc_ldarb(dst, mem));
 7621 
 7622   ins_pipe(pipe_serial);
 7623 %}
 7624 
 7625 // Load Byte (8 bit unsigned) into long
 7626 instruct loadUB2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7627 %{
 7628   match(Set dst (ConvI2L (LoadUB mem)));
 7629 
 7630   ins_cost(VOLATILE_REF_COST);
 7631   format %{ &quot;ldarb  $dst, $mem\t# byte&quot; %}
 7632 
 7633   ins_encode(aarch64_enc_ldarb(dst, mem));
 7634 
 7635   ins_pipe(pipe_serial);
 7636 %}
 7637 
 7638 // Load Short (16 bit signed)
 7639 instruct loadS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7640 %{
 7641   match(Set dst (LoadS mem));
 7642 
 7643   ins_cost(VOLATILE_REF_COST);
 7644   format %{ &quot;ldarshw  $dst, $mem\t# short&quot; %}
 7645 
 7646   ins_encode(aarch64_enc_ldarshw(dst, mem));
 7647 
 7648   ins_pipe(pipe_serial);
 7649 %}
 7650 
 7651 instruct loadUS_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7652 %{
 7653   match(Set dst (LoadUS mem));
 7654 
 7655   ins_cost(VOLATILE_REF_COST);
 7656   format %{ &quot;ldarhw  $dst, $mem\t# short&quot; %}
 7657 
 7658   ins_encode(aarch64_enc_ldarhw(dst, mem));
 7659 
 7660   ins_pipe(pipe_serial);
 7661 %}
 7662 
 7663 // Load Short/Char (16 bit unsigned) into long
 7664 instruct loadUS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7665 %{
 7666   match(Set dst (ConvI2L (LoadUS mem)));
 7667 
 7668   ins_cost(VOLATILE_REF_COST);
 7669   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7670 
 7671   ins_encode(aarch64_enc_ldarh(dst, mem));
 7672 
 7673   ins_pipe(pipe_serial);
 7674 %}
 7675 
 7676 // Load Short/Char (16 bit signed) into long
 7677 instruct loadS2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7678 %{
 7679   match(Set dst (ConvI2L (LoadS mem)));
 7680 
 7681   ins_cost(VOLATILE_REF_COST);
 7682   format %{ &quot;ldarh  $dst, $mem\t# short&quot; %}
 7683 
 7684   ins_encode(aarch64_enc_ldarsh(dst, mem));
 7685 
 7686   ins_pipe(pipe_serial);
 7687 %}
 7688 
 7689 // Load Integer (32 bit signed)
 7690 instruct loadI_volatile(iRegINoSp dst, /* sync_memory*/indirect mem)
 7691 %{
 7692   match(Set dst (LoadI mem));
 7693 
 7694   ins_cost(VOLATILE_REF_COST);
 7695   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7696 
 7697   ins_encode(aarch64_enc_ldarw(dst, mem));
 7698 
 7699   ins_pipe(pipe_serial);
 7700 %}
 7701 
 7702 // Load Integer (32 bit unsigned) into long
 7703 instruct loadUI2L_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem, immL_32bits mask)
 7704 %{
 7705   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 7706 
 7707   ins_cost(VOLATILE_REF_COST);
 7708   format %{ &quot;ldarw  $dst, $mem\t# int&quot; %}
 7709 
 7710   ins_encode(aarch64_enc_ldarw(dst, mem));
 7711 
 7712   ins_pipe(pipe_serial);
 7713 %}
 7714 
 7715 // Load Long (64 bit signed)
 7716 instruct loadL_volatile(iRegLNoSp dst, /* sync_memory*/indirect mem)
 7717 %{
 7718   match(Set dst (LoadL mem));
 7719 
 7720   ins_cost(VOLATILE_REF_COST);
 7721   format %{ &quot;ldar  $dst, $mem\t# int&quot; %}
 7722 
 7723   ins_encode(aarch64_enc_ldar(dst, mem));
 7724 
 7725   ins_pipe(pipe_serial);
 7726 %}
 7727 
 7728 // Load Pointer
 7729 instruct loadP_volatile(iRegPNoSp dst, /* sync_memory*/indirect mem)
 7730 %{
 7731   match(Set dst (LoadP mem));
 7732   predicate(n-&gt;as_Load()-&gt;barrier_data() == 0);
 7733 
 7734   ins_cost(VOLATILE_REF_COST);
 7735   format %{ &quot;ldar  $dst, $mem\t# ptr&quot; %}
 7736 
 7737   ins_encode(aarch64_enc_ldar(dst, mem));
 7738 
 7739   ins_pipe(pipe_serial);
 7740 %}
 7741 
 7742 // Load Compressed Pointer
 7743 instruct loadN_volatile(iRegNNoSp dst, /* sync_memory*/indirect mem)
 7744 %{
 7745   match(Set dst (LoadN mem));
 7746 
 7747   ins_cost(VOLATILE_REF_COST);
 7748   format %{ &quot;ldarw  $dst, $mem\t# compressed ptr&quot; %}
 7749 
 7750   ins_encode(aarch64_enc_ldarw(dst, mem));
 7751 
 7752   ins_pipe(pipe_serial);
 7753 %}
 7754 
 7755 // Load Float
 7756 instruct loadF_volatile(vRegF dst, /* sync_memory*/indirect mem)
 7757 %{
 7758   match(Set dst (LoadF mem));
 7759 
 7760   ins_cost(VOLATILE_REF_COST);
 7761   format %{ &quot;ldars  $dst, $mem\t# float&quot; %}
 7762 
 7763   ins_encode( aarch64_enc_fldars(dst, mem) );
 7764 
 7765   ins_pipe(pipe_serial);
 7766 %}
 7767 
 7768 // Load Double
 7769 instruct loadD_volatile(vRegD dst, /* sync_memory*/indirect mem)
 7770 %{
 7771   match(Set dst (LoadD mem));
 7772 
 7773   ins_cost(VOLATILE_REF_COST);
 7774   format %{ &quot;ldard  $dst, $mem\t# double&quot; %}
 7775 
 7776   ins_encode( aarch64_enc_fldard(dst, mem) );
 7777 
 7778   ins_pipe(pipe_serial);
 7779 %}
 7780 
 7781 // Store Byte
 7782 instruct storeB_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7783 %{
 7784   match(Set mem (StoreB mem src));
 7785 
 7786   ins_cost(VOLATILE_REF_COST);
 7787   format %{ &quot;stlrb  $src, $mem\t# byte&quot; %}
 7788 
 7789   ins_encode(aarch64_enc_stlrb(src, mem));
 7790 
 7791   ins_pipe(pipe_class_memory);
 7792 %}
 7793 
 7794 // Store Char/Short
 7795 instruct storeC_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7796 %{
 7797   match(Set mem (StoreC mem src));
 7798 
 7799   ins_cost(VOLATILE_REF_COST);
 7800   format %{ &quot;stlrh  $src, $mem\t# short&quot; %}
 7801 
 7802   ins_encode(aarch64_enc_stlrh(src, mem));
 7803 
 7804   ins_pipe(pipe_class_memory);
 7805 %}
 7806 
 7807 // Store Integer
 7808 
 7809 instruct storeI_volatile(iRegIorL2I src, /* sync_memory*/indirect mem)
 7810 %{
 7811   match(Set mem(StoreI mem src));
 7812 
 7813   ins_cost(VOLATILE_REF_COST);
 7814   format %{ &quot;stlrw  $src, $mem\t# int&quot; %}
 7815 
 7816   ins_encode(aarch64_enc_stlrw(src, mem));
 7817 
 7818   ins_pipe(pipe_class_memory);
 7819 %}
 7820 
 7821 // Store Long (64 bit signed)
 7822 instruct storeL_volatile(iRegL src, /* sync_memory*/indirect mem)
 7823 %{
 7824   match(Set mem (StoreL mem src));
 7825 
 7826   ins_cost(VOLATILE_REF_COST);
 7827   format %{ &quot;stlr  $src, $mem\t# int&quot; %}
 7828 
 7829   ins_encode(aarch64_enc_stlr(src, mem));
 7830 
 7831   ins_pipe(pipe_class_memory);
 7832 %}
 7833 
 7834 // Store Pointer
 7835 instruct storeP_volatile(iRegP src, /* sync_memory*/indirect mem)
 7836 %{
 7837   match(Set mem (StoreP mem src));
 7838 
 7839   ins_cost(VOLATILE_REF_COST);
 7840   format %{ &quot;stlr  $src, $mem\t# ptr&quot; %}
 7841 
 7842   ins_encode(aarch64_enc_stlr(src, mem));
 7843 
 7844   ins_pipe(pipe_class_memory);
 7845 %}
 7846 
 7847 // Store Compressed Pointer
 7848 instruct storeN_volatile(iRegN src, /* sync_memory*/indirect mem)
 7849 %{
 7850   match(Set mem (StoreN mem src));
 7851 
 7852   ins_cost(VOLATILE_REF_COST);
 7853   format %{ &quot;stlrw  $src, $mem\t# compressed ptr&quot; %}
 7854 
 7855   ins_encode(aarch64_enc_stlrw(src, mem));
 7856 
 7857   ins_pipe(pipe_class_memory);
 7858 %}
 7859 
 7860 // Store Float
 7861 instruct storeF_volatile(vRegF src, /* sync_memory*/indirect mem)
 7862 %{
 7863   match(Set mem (StoreF mem src));
 7864 
 7865   ins_cost(VOLATILE_REF_COST);
 7866   format %{ &quot;stlrs  $src, $mem\t# float&quot; %}
 7867 
 7868   ins_encode( aarch64_enc_fstlrs(src, mem) );
 7869 
 7870   ins_pipe(pipe_class_memory);
 7871 %}
 7872 
 7873 // TODO
 7874 // implement storeImmF0 and storeFImmPacked
 7875 
 7876 // Store Double
 7877 instruct storeD_volatile(vRegD src, /* sync_memory*/indirect mem)
 7878 %{
 7879   match(Set mem (StoreD mem src));
 7880 
 7881   ins_cost(VOLATILE_REF_COST);
 7882   format %{ &quot;stlrd  $src, $mem\t# double&quot; %}
 7883 
 7884   ins_encode( aarch64_enc_fstlrd(src, mem) );
 7885 
 7886   ins_pipe(pipe_class_memory);
 7887 %}
 7888 
 7889 //  ---------------- end of volatile loads and stores ----------------
 7890 
 7891 instruct cacheWB(indirect addr)
 7892 %{
 7893   predicate(VM_Version::supports_data_cache_line_flush());
 7894   match(CacheWB addr);
 7895 
 7896   ins_cost(100);
 7897   format %{&quot;cache wb $addr&quot; %}
 7898   ins_encode %{
 7899     assert($addr-&gt;index_position() &lt; 0, &quot;should be&quot;);
 7900     assert($addr$$disp == 0, &quot;should be&quot;);
 7901     __ cache_wb(Address($addr$$base$$Register, 0));
 7902   %}
 7903   ins_pipe(pipe_slow); // XXX
 7904 %}
 7905 
 7906 instruct cacheWBPreSync()
 7907 %{
 7908   predicate(VM_Version::supports_data_cache_line_flush());
 7909   match(CacheWBPreSync);
 7910 
 7911   ins_cost(100);
 7912   format %{&quot;cache wb presync&quot; %}
 7913   ins_encode %{
 7914     __ cache_wbsync(true);
 7915   %}
 7916   ins_pipe(pipe_slow); // XXX
 7917 %}
 7918 
 7919 instruct cacheWBPostSync()
 7920 %{
 7921   predicate(VM_Version::supports_data_cache_line_flush());
 7922   match(CacheWBPostSync);
 7923 
 7924   ins_cost(100);
 7925   format %{&quot;cache wb postsync&quot; %}
 7926   ins_encode %{
 7927     __ cache_wbsync(false);
 7928   %}
 7929   ins_pipe(pipe_slow); // XXX
 7930 %}
 7931 
 7932 // ============================================================================
 7933 // BSWAP Instructions
 7934 
 7935 instruct bytes_reverse_int(iRegINoSp dst, iRegIorL2I src) %{
 7936   match(Set dst (ReverseBytesI src));
 7937 
 7938   ins_cost(INSN_COST);
 7939   format %{ &quot;revw  $dst, $src&quot; %}
 7940 
 7941   ins_encode %{
 7942     __ revw(as_Register($dst$$reg), as_Register($src$$reg));
 7943   %}
 7944 
 7945   ins_pipe(ialu_reg);
 7946 %}
 7947 
 7948 instruct bytes_reverse_long(iRegLNoSp dst, iRegL src) %{
 7949   match(Set dst (ReverseBytesL src));
 7950 
 7951   ins_cost(INSN_COST);
 7952   format %{ &quot;rev  $dst, $src&quot; %}
 7953 
 7954   ins_encode %{
 7955     __ rev(as_Register($dst$$reg), as_Register($src$$reg));
 7956   %}
 7957 
 7958   ins_pipe(ialu_reg);
 7959 %}
 7960 
 7961 instruct bytes_reverse_unsigned_short(iRegINoSp dst, iRegIorL2I src) %{
 7962   match(Set dst (ReverseBytesUS src));
 7963 
 7964   ins_cost(INSN_COST);
 7965   format %{ &quot;rev16w  $dst, $src&quot; %}
 7966 
 7967   ins_encode %{
 7968     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7969   %}
 7970 
 7971   ins_pipe(ialu_reg);
 7972 %}
 7973 
 7974 instruct bytes_reverse_short(iRegINoSp dst, iRegIorL2I src) %{
 7975   match(Set dst (ReverseBytesS src));
 7976 
 7977   ins_cost(INSN_COST);
 7978   format %{ &quot;rev16w  $dst, $src\n\t&quot;
 7979             &quot;sbfmw $dst, $dst, #0, #15&quot; %}
 7980 
 7981   ins_encode %{
 7982     __ rev16w(as_Register($dst$$reg), as_Register($src$$reg));
 7983     __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);
 7984   %}
 7985 
 7986   ins_pipe(ialu_reg);
 7987 %}
 7988 
 7989 // ============================================================================
 7990 // Zero Count Instructions
 7991 
 7992 instruct countLeadingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 7993   match(Set dst (CountLeadingZerosI src));
 7994 
 7995   ins_cost(INSN_COST);
 7996   format %{ &quot;clzw  $dst, $src&quot; %}
 7997   ins_encode %{
 7998     __ clzw(as_Register($dst$$reg), as_Register($src$$reg));
 7999   %}
 8000 
 8001   ins_pipe(ialu_reg);
 8002 %}
 8003 
 8004 instruct countLeadingZerosL(iRegINoSp dst, iRegL src) %{
 8005   match(Set dst (CountLeadingZerosL src));
 8006 
 8007   ins_cost(INSN_COST);
 8008   format %{ &quot;clz   $dst, $src&quot; %}
 8009   ins_encode %{
 8010     __ clz(as_Register($dst$$reg), as_Register($src$$reg));
 8011   %}
 8012 
 8013   ins_pipe(ialu_reg);
 8014 %}
 8015 
 8016 instruct countTrailingZerosI(iRegINoSp dst, iRegIorL2I src) %{
 8017   match(Set dst (CountTrailingZerosI src));
 8018 
 8019   ins_cost(INSN_COST * 2);
 8020   format %{ &quot;rbitw  $dst, $src\n\t&quot;
 8021             &quot;clzw   $dst, $dst&quot; %}
 8022   ins_encode %{
 8023     __ rbitw(as_Register($dst$$reg), as_Register($src$$reg));
 8024     __ clzw(as_Register($dst$$reg), as_Register($dst$$reg));
 8025   %}
 8026 
 8027   ins_pipe(ialu_reg);
 8028 %}
 8029 
 8030 instruct countTrailingZerosL(iRegINoSp dst, iRegL src) %{
 8031   match(Set dst (CountTrailingZerosL src));
 8032 
 8033   ins_cost(INSN_COST * 2);
 8034   format %{ &quot;rbit   $dst, $src\n\t&quot;
 8035             &quot;clz    $dst, $dst&quot; %}
 8036   ins_encode %{
 8037     __ rbit(as_Register($dst$$reg), as_Register($src$$reg));
 8038     __ clz(as_Register($dst$$reg), as_Register($dst$$reg));
 8039   %}
 8040 
 8041   ins_pipe(ialu_reg);
 8042 %}
 8043 
 8044 //---------- Population Count Instructions -------------------------------------
 8045 //
 8046 
 8047 instruct popCountI(iRegINoSp dst, iRegIorL2I src, vRegF tmp) %{
 8048   predicate(UsePopCountInstruction);
 8049   match(Set dst (PopCountI src));
 8050   effect(TEMP tmp);
 8051   ins_cost(INSN_COST * 13);
 8052 
 8053   format %{ &quot;movw   $src, $src\n\t&quot;
 8054             &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8055             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8056             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8057             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8058   ins_encode %{
 8059     __ movw($src$$Register, $src$$Register); // ensure top 32 bits 0
 8060     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8061     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8062     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8063     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8064   %}
 8065 
 8066   ins_pipe(pipe_class_default);
 8067 %}
 8068 
 8069 instruct popCountI_mem(iRegINoSp dst, memory4 mem, vRegF tmp) %{
 8070   predicate(UsePopCountInstruction);
 8071   match(Set dst (PopCountI (LoadI mem)));
 8072   effect(TEMP tmp);
 8073   ins_cost(INSN_COST * 13);
 8074 
 8075   format %{ &quot;ldrs   $tmp, $mem\n\t&quot;
 8076             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8077             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8078             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8079   ins_encode %{
 8080     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8081     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrs, tmp_reg, $mem-&gt;opcode(),
 8082               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);
 8083     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8084     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8085     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8086   %}
 8087 
 8088   ins_pipe(pipe_class_default);
 8089 %}
 8090 
 8091 // Note: Long.bitCount(long) returns an int.
 8092 instruct popCountL(iRegINoSp dst, iRegL src, vRegD tmp) %{
 8093   predicate(UsePopCountInstruction);
 8094   match(Set dst (PopCountL src));
 8095   effect(TEMP tmp);
 8096   ins_cost(INSN_COST * 13);
 8097 
 8098   format %{ &quot;mov    $tmp, $src\t# vector (1D)\n\t&quot;
 8099             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8100             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8101             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8102   ins_encode %{
 8103     __ mov($tmp$$FloatRegister, __ T1D, 0, $src$$Register);
 8104     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8105     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8106     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8107   %}
 8108 
 8109   ins_pipe(pipe_class_default);
 8110 %}
 8111 
 8112 instruct popCountL_mem(iRegINoSp dst, memory8 mem, vRegD tmp) %{
 8113   predicate(UsePopCountInstruction);
 8114   match(Set dst (PopCountL (LoadL mem)));
 8115   effect(TEMP tmp);
 8116   ins_cost(INSN_COST * 13);
 8117 
 8118   format %{ &quot;ldrd   $tmp, $mem\n\t&quot;
 8119             &quot;cnt    $tmp, $tmp\t# vector (8B)\n\t&quot;
 8120             &quot;addv   $tmp, $tmp\t# vector (8B)\n\t&quot;
 8121             &quot;mov    $dst, $tmp\t# vector (1D)&quot; %}
 8122   ins_encode %{
 8123     FloatRegister tmp_reg = as_FloatRegister($tmp$$reg);
 8124     loadStore(C2_MacroAssembler(&amp;cbuf), &amp;MacroAssembler::ldrd, tmp_reg, $mem-&gt;opcode(),
 8125               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 8);
 8126     __ cnt($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8127     __ addv($tmp$$FloatRegister, __ T8B, $tmp$$FloatRegister);
 8128     __ mov($dst$$Register, $tmp$$FloatRegister, __ T1D, 0);
 8129   %}
 8130 
 8131   ins_pipe(pipe_class_default);
 8132 %}
 8133 
 8134 // ============================================================================
 8135 // MemBar Instruction
 8136 
 8137 instruct load_fence() %{
 8138   match(LoadFence);
 8139   ins_cost(VOLATILE_REF_COST);
 8140 
 8141   format %{ &quot;load_fence&quot; %}
 8142 
 8143   ins_encode %{
 8144     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8145   %}
 8146   ins_pipe(pipe_serial);
 8147 %}
 8148 
 8149 instruct unnecessary_membar_acquire() %{
 8150   predicate(unnecessary_acquire(n));
 8151   match(MemBarAcquire);
 8152   ins_cost(0);
 8153 
 8154   format %{ &quot;membar_acquire (elided)&quot; %}
 8155 
 8156   ins_encode %{
 8157     __ block_comment(&quot;membar_acquire (elided)&quot;);
 8158   %}
 8159 
 8160   ins_pipe(pipe_class_empty);
 8161 %}
 8162 
 8163 instruct membar_acquire() %{
 8164   match(MemBarAcquire);
 8165   ins_cost(VOLATILE_REF_COST);
 8166 
 8167   format %{ &quot;membar_acquire\n\t&quot;
 8168             &quot;dmb ish&quot; %}
 8169 
 8170   ins_encode %{
 8171     __ block_comment(&quot;membar_acquire&quot;);
 8172     __ membar(Assembler::LoadLoad|Assembler::LoadStore);
 8173   %}
 8174 
 8175   ins_pipe(pipe_serial);
 8176 %}
 8177 
 8178 
 8179 instruct membar_acquire_lock() %{
 8180   match(MemBarAcquireLock);
 8181   ins_cost(VOLATILE_REF_COST);
 8182 
 8183   format %{ &quot;membar_acquire_lock (elided)&quot; %}
 8184 
 8185   ins_encode %{
 8186     __ block_comment(&quot;membar_acquire_lock (elided)&quot;);
 8187   %}
 8188 
 8189   ins_pipe(pipe_serial);
 8190 %}
 8191 
 8192 instruct store_fence() %{
 8193   match(StoreFence);
 8194   ins_cost(VOLATILE_REF_COST);
 8195 
 8196   format %{ &quot;store_fence&quot; %}
 8197 
 8198   ins_encode %{
 8199     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8200   %}
 8201   ins_pipe(pipe_serial);
 8202 %}
 8203 
 8204 instruct unnecessary_membar_release() %{
 8205   predicate(unnecessary_release(n));
 8206   match(MemBarRelease);
 8207   ins_cost(0);
 8208 
 8209   format %{ &quot;membar_release (elided)&quot; %}
 8210 
 8211   ins_encode %{
 8212     __ block_comment(&quot;membar_release (elided)&quot;);
 8213   %}
 8214   ins_pipe(pipe_serial);
 8215 %}
 8216 
 8217 instruct membar_release() %{
 8218   match(MemBarRelease);
 8219   ins_cost(VOLATILE_REF_COST);
 8220 
 8221   format %{ &quot;membar_release\n\t&quot;
 8222             &quot;dmb ish&quot; %}
 8223 
 8224   ins_encode %{
 8225     __ block_comment(&quot;membar_release&quot;);
 8226     __ membar(Assembler::LoadStore|Assembler::StoreStore);
 8227   %}
 8228   ins_pipe(pipe_serial);
 8229 %}
 8230 
 8231 instruct membar_storestore() %{
 8232   match(MemBarStoreStore);
 8233   ins_cost(VOLATILE_REF_COST);
 8234 
 8235   format %{ &quot;MEMBAR-store-store&quot; %}
 8236 
 8237   ins_encode %{
 8238     __ membar(Assembler::StoreStore);
 8239   %}
 8240   ins_pipe(pipe_serial);
 8241 %}
 8242 
 8243 instruct membar_release_lock() %{
 8244   match(MemBarReleaseLock);
 8245   ins_cost(VOLATILE_REF_COST);
 8246 
 8247   format %{ &quot;membar_release_lock (elided)&quot; %}
 8248 
 8249   ins_encode %{
 8250     __ block_comment(&quot;membar_release_lock (elided)&quot;);
 8251   %}
 8252 
 8253   ins_pipe(pipe_serial);
 8254 %}
 8255 
 8256 instruct unnecessary_membar_volatile() %{
 8257   predicate(unnecessary_volatile(n));
 8258   match(MemBarVolatile);
 8259   ins_cost(0);
 8260 
 8261   format %{ &quot;membar_volatile (elided)&quot; %}
 8262 
 8263   ins_encode %{
 8264     __ block_comment(&quot;membar_volatile (elided)&quot;);
 8265   %}
 8266 
 8267   ins_pipe(pipe_serial);
 8268 %}
 8269 
 8270 instruct membar_volatile() %{
 8271   match(MemBarVolatile);
 8272   ins_cost(VOLATILE_REF_COST*100);
 8273 
 8274   format %{ &quot;membar_volatile\n\t&quot;
 8275              &quot;dmb ish&quot;%}
 8276 
 8277   ins_encode %{
 8278     __ block_comment(&quot;membar_volatile&quot;);
 8279     __ membar(Assembler::StoreLoad);
 8280   %}
 8281 
 8282   ins_pipe(pipe_serial);
 8283 %}
 8284 
 8285 // ============================================================================
 8286 // Cast/Convert Instructions
 8287 
 8288 instruct castX2P(iRegPNoSp dst, iRegL src) %{
 8289   match(Set dst (CastX2P src));
 8290 
 8291   ins_cost(INSN_COST);
 8292   format %{ &quot;mov $dst, $src\t# long -&gt; ptr&quot; %}
 8293 
 8294   ins_encode %{
 8295     if ($dst$$reg != $src$$reg) {
 8296       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8297     }
 8298   %}
 8299 
 8300   ins_pipe(ialu_reg);
 8301 %}
 8302 
 8303 instruct castN2X(iRegLNoSp dst, iRegN src) %{
 8304   match(Set dst (CastP2X src));
 8305 
 8306   ins_cost(INSN_COST);
 8307   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8308 
 8309   ins_encode %{
 8310     if ($dst$$reg != $src$$reg) {
 8311       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8312     }
 8313   %}
 8314 
 8315   ins_pipe(ialu_reg);
 8316 %}
 8317 
 8318 instruct castP2X(iRegLNoSp dst, iRegP src) %{
 8319   match(Set dst (CastP2X src));
 8320 
 8321   ins_cost(INSN_COST);
 8322   format %{ &quot;mov $dst, $src\t# ptr -&gt; long&quot; %}
 8323 
 8324   ins_encode %{
 8325     if ($dst$$reg != $src$$reg) {
 8326       __ mov(as_Register($dst$$reg), as_Register($src$$reg));
 8327     }
 8328   %}
 8329 
 8330   ins_pipe(ialu_reg);
 8331 %}
 8332 
 8333 instruct castN2I(iRegINoSp dst, iRegN src) %{
 8334   match(Set dst (CastN2I src));
 8335 
 8336   ins_cost(INSN_COST);
 8337   format %{ &quot;movw $dst, $src\t# compressed ptr -&gt; int&quot; %}
 8338 
 8339   ins_encode %{
 8340     if ($dst$$reg != $src$$reg) {
 8341       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8342     }
 8343   %}
 8344 
 8345   ins_pipe(ialu_reg);
 8346 %}
 8347 
 8348 instruct castI2N(iRegNNoSp dst, iRegI src) %{
 8349   match(Set dst (CastI2N src));
 8350 
 8351   ins_cost(INSN_COST);
 8352   format %{ &quot;movw $dst, $src\t# int -&gt; compressed ptr&quot; %}
 8353 
 8354   ins_encode %{
 8355     if ($dst$$reg != $src$$reg) {
 8356       __ movw(as_Register($dst$$reg), as_Register($src$$reg));
 8357     }
 8358   %}
 8359 
 8360   ins_pipe(ialu_reg);
 8361 %}
 8362 
 8363 
 8364 // Convert oop into int for vectors alignment masking
 8365 instruct convP2I(iRegINoSp dst, iRegP src) %{
 8366   match(Set dst (ConvL2I (CastP2X src)));
 8367 
 8368   ins_cost(INSN_COST);
 8369   format %{ &quot;movw $dst, $src\t# ptr -&gt; int&quot; %}
 8370   ins_encode %{
 8371     __ movw($dst$$Register, $src$$Register);
 8372   %}
 8373 
 8374   ins_pipe(ialu_reg);
 8375 %}
 8376 
 8377 // Convert compressed oop into int for vectors alignment masking
 8378 // in case of 32bit oops (heap &lt; 4Gb).
 8379 instruct convN2I(iRegINoSp dst, iRegN src)
 8380 %{
 8381   predicate(CompressedOops::shift() == 0);
 8382   match(Set dst (ConvL2I (CastP2X (DecodeN src))));
 8383 
 8384   ins_cost(INSN_COST);
 8385   format %{ &quot;mov dst, $src\t# compressed ptr -&gt; int&quot; %}
 8386   ins_encode %{
 8387     __ movw($dst$$Register, $src$$Register);
 8388   %}
 8389 
 8390   ins_pipe(ialu_reg);
 8391 %}
 8392 
 8393 
 8394 // Convert oop pointer into compressed form
 8395 instruct encodeHeapOop(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8396   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() != TypePtr::NotNull);
 8397   match(Set dst (EncodeP src));
 8398   effect(KILL cr);
 8399   ins_cost(INSN_COST * 3);
 8400   format %{ &quot;encode_heap_oop $dst, $src&quot; %}
 8401   ins_encode %{
 8402     Register s = $src$$Register;
 8403     Register d = $dst$$Register;
 8404     __ encode_heap_oop(d, s);
 8405   %}
 8406   ins_pipe(ialu_reg);
 8407 %}
 8408 
 8409 instruct encodeHeapOop_not_null(iRegNNoSp dst, iRegP src, rFlagsReg cr) %{
 8410   predicate(n-&gt;bottom_type()-&gt;make_ptr()-&gt;ptr() == TypePtr::NotNull);
 8411   match(Set dst (EncodeP src));
 8412   ins_cost(INSN_COST * 3);
 8413   format %{ &quot;encode_heap_oop_not_null $dst, $src&quot; %}
 8414   ins_encode %{
 8415     __ encode_heap_oop_not_null($dst$$Register, $src$$Register);
 8416   %}
 8417   ins_pipe(ialu_reg);
 8418 %}
 8419 
 8420 instruct decodeHeapOop(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8421   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::NotNull &amp;&amp;
 8422             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() != TypePtr::Constant);
 8423   match(Set dst (DecodeN src));
 8424   ins_cost(INSN_COST * 3);
 8425   format %{ &quot;decode_heap_oop $dst, $src&quot; %}
 8426   ins_encode %{
 8427     Register s = $src$$Register;
 8428     Register d = $dst$$Register;
 8429     __ decode_heap_oop(d, s);
 8430   %}
 8431   ins_pipe(ialu_reg);
 8432 %}
 8433 
 8434 instruct decodeHeapOop_not_null(iRegPNoSp dst, iRegN src, rFlagsReg cr) %{
 8435   predicate(n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::NotNull ||
 8436             n-&gt;bottom_type()-&gt;is_ptr()-&gt;ptr() == TypePtr::Constant);
 8437   match(Set dst (DecodeN src));
 8438   ins_cost(INSN_COST * 3);
 8439   format %{ &quot;decode_heap_oop_not_null $dst, $src&quot; %}
 8440   ins_encode %{
 8441     Register s = $src$$Register;
 8442     Register d = $dst$$Register;
 8443     __ decode_heap_oop_not_null(d, s);
 8444   %}
 8445   ins_pipe(ialu_reg);
 8446 %}
 8447 
 8448 // n.b. AArch64 implementations of encode_klass_not_null and
 8449 // decode_klass_not_null do not modify the flags register so, unlike
 8450 // Intel, we don&#39;t kill CR as a side effect here
 8451 
 8452 instruct encodeKlass_not_null(iRegNNoSp dst, iRegP src) %{
 8453   match(Set dst (EncodePKlass src));
 8454 
 8455   ins_cost(INSN_COST * 3);
 8456   format %{ &quot;encode_klass_not_null $dst,$src&quot; %}
 8457 
 8458   ins_encode %{
 8459     Register src_reg = as_Register($src$$reg);
 8460     Register dst_reg = as_Register($dst$$reg);
 8461     __ encode_klass_not_null(dst_reg, src_reg);
 8462   %}
 8463 
 8464    ins_pipe(ialu_reg);
 8465 %}
 8466 
 8467 instruct decodeKlass_not_null(iRegPNoSp dst, iRegN src) %{
 8468   match(Set dst (DecodeNKlass src));
 8469 
 8470   ins_cost(INSN_COST * 3);
 8471   format %{ &quot;decode_klass_not_null $dst,$src&quot; %}
 8472 
 8473   ins_encode %{
 8474     Register src_reg = as_Register($src$$reg);
 8475     Register dst_reg = as_Register($dst$$reg);
 8476     if (dst_reg != src_reg) {
 8477       __ decode_klass_not_null(dst_reg, src_reg);
 8478     } else {
 8479       __ decode_klass_not_null(dst_reg);
 8480     }
 8481   %}
 8482 
 8483    ins_pipe(ialu_reg);
 8484 %}
 8485 
 8486 instruct checkCastPP(iRegPNoSp dst)
 8487 %{
 8488   match(Set dst (CheckCastPP dst));
 8489 
 8490   size(0);
 8491   format %{ &quot;# checkcastPP of $dst&quot; %}
 8492   ins_encode(/* empty encoding */);
 8493   ins_pipe(pipe_class_empty);
 8494 %}
 8495 
 8496 instruct castPP(iRegPNoSp dst)
 8497 %{
 8498   match(Set dst (CastPP dst));
 8499 
 8500   size(0);
 8501   format %{ &quot;# castPP of $dst&quot; %}
 8502   ins_encode(/* empty encoding */);
 8503   ins_pipe(pipe_class_empty);
 8504 %}
 8505 
 8506 instruct castII(iRegI dst)
 8507 %{
 8508   match(Set dst (CastII dst));
 8509 
 8510   size(0);
 8511   format %{ &quot;# castII of $dst&quot; %}
 8512   ins_encode(/* empty encoding */);
 8513   ins_cost(0);
 8514   ins_pipe(pipe_class_empty);
 8515 %}
 8516 
 8517 // ============================================================================
 8518 // Atomic operation instructions
 8519 //
 8520 // Intel and SPARC both implement Ideal Node LoadPLocked and
 8521 // Store{PIL}Conditional instructions using a normal load for the
 8522 // LoadPLocked and a CAS for the Store{PIL}Conditional.
 8523 //
 8524 // The ideal code appears only to use LoadPLocked/StorePLocked as a
 8525 // pair to lock object allocations from Eden space when not using
 8526 // TLABs.
 8527 //
 8528 // There does not appear to be a Load{IL}Locked Ideal Node and the
 8529 // Ideal code appears to use Store{IL}Conditional as an alias for CAS
 8530 // and to use StoreIConditional only for 32-bit and StoreLConditional
 8531 // only for 64-bit.
 8532 //
 8533 // We implement LoadPLocked and StorePLocked instructions using,
 8534 // respectively the AArch64 hw load-exclusive and store-conditional
 8535 // instructions. Whereas we must implement each of
 8536 // Store{IL}Conditional using a CAS which employs a pair of
 8537 // instructions comprising a load-exclusive followed by a
 8538 // store-conditional.
 8539 
 8540 
 8541 // Locked-load (linked load) of the current heap-top
 8542 // used when updating the eden heap top
 8543 // implemented using ldaxr on AArch64
 8544 
 8545 instruct loadPLocked(iRegPNoSp dst, indirect mem)
 8546 %{
 8547   match(Set dst (LoadPLocked mem));
 8548 
 8549   ins_cost(VOLATILE_REF_COST);
 8550 
 8551   format %{ &quot;ldaxr $dst, $mem\t# ptr linked acquire&quot; %}
 8552 
 8553   ins_encode(aarch64_enc_ldaxr(dst, mem));
 8554 
 8555   ins_pipe(pipe_serial);
 8556 %}
 8557 
 8558 // Conditional-store of the updated heap-top.
 8559 // Used during allocation of the shared heap.
 8560 // Sets flag (EQ) on success.
 8561 // implemented using stlxr on AArch64.
 8562 
 8563 instruct storePConditional(memory8 heap_top_ptr, iRegP oldval, iRegP newval, rFlagsReg cr)
 8564 %{
 8565   match(Set cr (StorePConditional heap_top_ptr (Binary oldval newval)));
 8566 
 8567   ins_cost(VOLATILE_REF_COST);
 8568 
 8569  // TODO
 8570  // do we need to do a store-conditional release or can we just use a
 8571  // plain store-conditional?
 8572 
 8573   format %{
 8574     &quot;stlxr rscratch1, $newval, $heap_top_ptr\t# ptr cond release&quot;
 8575     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8576   %}
 8577 
 8578   ins_encode(aarch64_enc_stlxr(newval, heap_top_ptr));
 8579 
 8580   ins_pipe(pipe_serial);
 8581 %}
 8582 
 8583 
 8584 // storeLConditional is used by PhaseMacroExpand::expand_lock_node
 8585 // when attempting to rebias a lock towards the current thread.  We
 8586 // must use the acquire form of cmpxchg in order to guarantee acquire
 8587 // semantics in this case.
 8588 instruct storeLConditional(indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr)
 8589 %{
 8590   match(Set cr (StoreLConditional mem (Binary oldval newval)));
 8591 
 8592   ins_cost(VOLATILE_REF_COST);
 8593 
 8594   format %{
 8595     &quot;cmpxchg rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8596     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8597   %}
 8598 
 8599   ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval));
 8600 
 8601   ins_pipe(pipe_slow);
 8602 %}
 8603 
 8604 // storeIConditional also has acquire semantics, for no better reason
 8605 // than matching storeLConditional.  At the time of writing this
 8606 // comment storeIConditional was not used anywhere by AArch64.
 8607 instruct storeIConditional(indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr)
 8608 %{
 8609   match(Set cr (StoreIConditional mem (Binary oldval newval)));
 8610 
 8611   ins_cost(VOLATILE_REF_COST);
 8612 
 8613   format %{
 8614     &quot;cmpxchgw rscratch1, $mem, $oldval, $newval, $mem\t# if $mem == $oldval then $mem &lt;-- $newval&quot;
 8615     &quot;cmpw rscratch1, zr\t# EQ on successful write&quot;
 8616   %}
 8617 
 8618   ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval));
 8619 
 8620   ins_pipe(pipe_slow);
 8621 %}
 8622 
 8623 // standard CompareAndSwapX when we are using barriers
 8624 // these have higher priority than the rules selected by a predicate
 8625 
 8626 // XXX No flag versions for CompareAndSwap{I,L,P,N} because matcher
 8627 // can&#39;t match them
 8628 
 8629 instruct compareAndSwapB(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8630 
 8631   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8632   ins_cost(2 * VOLATILE_REF_COST);
 8633 
 8634   effect(KILL cr);
 8635 
 8636   format %{
 8637     &quot;cmpxchgb $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8638     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8639   %}
 8640 
 8641   ins_encode(aarch64_enc_cmpxchgb(mem, oldval, newval),
 8642             aarch64_enc_cset_eq(res));
 8643 
 8644   ins_pipe(pipe_slow);
 8645 %}
 8646 
 8647 instruct compareAndSwapS(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8648 
 8649   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8650   ins_cost(2 * VOLATILE_REF_COST);
 8651 
 8652   effect(KILL cr);
 8653 
 8654   format %{
 8655     &quot;cmpxchgs $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8656     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8657   %}
 8658 
 8659   ins_encode(aarch64_enc_cmpxchgs(mem, oldval, newval),
 8660             aarch64_enc_cset_eq(res));
 8661 
 8662   ins_pipe(pipe_slow);
 8663 %}
 8664 
 8665 instruct compareAndSwapI(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8666 
 8667   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8668   ins_cost(2 * VOLATILE_REF_COST);
 8669 
 8670   effect(KILL cr);
 8671 
 8672  format %{
 8673     &quot;cmpxchgw $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8674     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8675  %}
 8676 
 8677  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8678             aarch64_enc_cset_eq(res));
 8679 
 8680   ins_pipe(pipe_slow);
 8681 %}
 8682 
 8683 instruct compareAndSwapL(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8684 
 8685   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8686   ins_cost(2 * VOLATILE_REF_COST);
 8687 
 8688   effect(KILL cr);
 8689 
 8690  format %{
 8691     &quot;cmpxchg $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8692     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8693  %}
 8694 
 8695  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8696             aarch64_enc_cset_eq(res));
 8697 
 8698   ins_pipe(pipe_slow);
 8699 %}
 8700 
 8701 instruct compareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8702 
 8703   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8704   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8705   ins_cost(2 * VOLATILE_REF_COST);
 8706 
 8707   effect(KILL cr);
 8708 
 8709  format %{
 8710     &quot;cmpxchg $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8711     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8712  %}
 8713 
 8714  ins_encode(aarch64_enc_cmpxchg(mem, oldval, newval),
 8715             aarch64_enc_cset_eq(res));
 8716 
 8717   ins_pipe(pipe_slow);
 8718 %}
 8719 
 8720 instruct compareAndSwapN(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8721 
 8722   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8723   ins_cost(2 * VOLATILE_REF_COST);
 8724 
 8725   effect(KILL cr);
 8726 
 8727  format %{
 8728     &quot;cmpxchgw $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8729     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8730  %}
 8731 
 8732  ins_encode(aarch64_enc_cmpxchgw(mem, oldval, newval),
 8733             aarch64_enc_cset_eq(res));
 8734 
 8735   ins_pipe(pipe_slow);
 8736 %}
 8737 
 8738 // alternative CompareAndSwapX when we are eliding barriers
 8739 
 8740 instruct compareAndSwapBAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8741 
 8742   predicate(needs_acquiring_load_exclusive(n));
 8743   match(Set res (CompareAndSwapB mem (Binary oldval newval)));
 8744   ins_cost(VOLATILE_REF_COST);
 8745 
 8746   effect(KILL cr);
 8747 
 8748   format %{
 8749     &quot;cmpxchgb_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8750     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8751   %}
 8752 
 8753   ins_encode(aarch64_enc_cmpxchgb_acq(mem, oldval, newval),
 8754             aarch64_enc_cset_eq(res));
 8755 
 8756   ins_pipe(pipe_slow);
 8757 %}
 8758 
 8759 instruct compareAndSwapSAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8760 
 8761   predicate(needs_acquiring_load_exclusive(n));
 8762   match(Set res (CompareAndSwapS mem (Binary oldval newval)));
 8763   ins_cost(VOLATILE_REF_COST);
 8764 
 8765   effect(KILL cr);
 8766 
 8767   format %{
 8768     &quot;cmpxchgs_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8769     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8770   %}
 8771 
 8772   ins_encode(aarch64_enc_cmpxchgs_acq(mem, oldval, newval),
 8773             aarch64_enc_cset_eq(res));
 8774 
 8775   ins_pipe(pipe_slow);
 8776 %}
 8777 
 8778 instruct compareAndSwapIAcq(iRegINoSp res, indirect mem, iRegINoSp oldval, iRegINoSp newval, rFlagsReg cr) %{
 8779 
 8780   predicate(needs_acquiring_load_exclusive(n));
 8781   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 8782   ins_cost(VOLATILE_REF_COST);
 8783 
 8784   effect(KILL cr);
 8785 
 8786  format %{
 8787     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (int) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8788     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8789  %}
 8790 
 8791  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8792             aarch64_enc_cset_eq(res));
 8793 
 8794   ins_pipe(pipe_slow);
 8795 %}
 8796 
 8797 instruct compareAndSwapLAcq(iRegINoSp res, indirect mem, iRegLNoSp oldval, iRegLNoSp newval, rFlagsReg cr) %{
 8798 
 8799   predicate(needs_acquiring_load_exclusive(n));
 8800   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 8801   ins_cost(VOLATILE_REF_COST);
 8802 
 8803   effect(KILL cr);
 8804 
 8805  format %{
 8806     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (long) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8807     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8808  %}
 8809 
 8810  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8811             aarch64_enc_cset_eq(res));
 8812 
 8813   ins_pipe(pipe_slow);
 8814 %}
 8815 
 8816 instruct compareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8817 
 8818   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 8819   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 8820   ins_cost(VOLATILE_REF_COST);
 8821 
 8822   effect(KILL cr);
 8823 
 8824  format %{
 8825     &quot;cmpxchg_acq $mem, $oldval, $newval\t# (ptr) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8826     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8827  %}
 8828 
 8829  ins_encode(aarch64_enc_cmpxchg_acq(mem, oldval, newval),
 8830             aarch64_enc_cset_eq(res));
 8831 
 8832   ins_pipe(pipe_slow);
 8833 %}
 8834 
 8835 instruct compareAndSwapNAcq(iRegINoSp res, indirect mem, iRegNNoSp oldval, iRegNNoSp newval, rFlagsReg cr) %{
 8836 
 8837   predicate(needs_acquiring_load_exclusive(n));
 8838   match(Set res (CompareAndSwapN mem (Binary oldval newval)));
 8839   ins_cost(VOLATILE_REF_COST);
 8840 
 8841   effect(KILL cr);
 8842 
 8843  format %{
 8844     &quot;cmpxchgw_acq $mem, $oldval, $newval\t# (narrow oop) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8845     &quot;cset $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 8846  %}
 8847 
 8848  ins_encode(aarch64_enc_cmpxchgw_acq(mem, oldval, newval),
 8849             aarch64_enc_cset_eq(res));
 8850 
 8851   ins_pipe(pipe_slow);
 8852 %}
 8853 
 8854 
 8855 // ---------------------------------------------------------------------
 8856 
 8857 
 8858 // BEGIN This section of the file is automatically generated. Do not edit --------------
 8859 
 8860 // Sundry CAS operations.  Note that release is always true,
 8861 // regardless of the memory ordering of the CAS.  This is because we
 8862 // need the volatile case to be sequentially consistent but there is
 8863 // no trailing StoreLoad barrier emitted by C2.  Unfortunately we
 8864 // can&#39;t check the type of memory ordering here, so we always emit a
 8865 // STLXR.
 8866 
 8867 // This section is generated from aarch64_ad_cas.m4
 8868 
 8869 
 8870 
 8871 instruct compareAndExchangeB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8872   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8873   ins_cost(2 * VOLATILE_REF_COST);
 8874   effect(TEMP_DEF res, KILL cr);
 8875   format %{
 8876     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8877   %}
 8878   ins_encode %{
 8879     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8880                Assembler::byte, /*acquire*/ false, /*release*/ true,
 8881                /*weak*/ false, $res$$Register);
 8882     __ sxtbw($res$$Register, $res$$Register);
 8883   %}
 8884   ins_pipe(pipe_slow);
 8885 %}
 8886 
 8887 instruct compareAndExchangeS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8888   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8889   ins_cost(2 * VOLATILE_REF_COST);
 8890   effect(TEMP_DEF res, KILL cr);
 8891   format %{
 8892     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8893   %}
 8894   ins_encode %{
 8895     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8896                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 8897                /*weak*/ false, $res$$Register);
 8898     __ sxthw($res$$Register, $res$$Register);
 8899   %}
 8900   ins_pipe(pipe_slow);
 8901 %}
 8902 
 8903 instruct compareAndExchangeI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8904   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 8905   ins_cost(2 * VOLATILE_REF_COST);
 8906   effect(TEMP_DEF res, KILL cr);
 8907   format %{
 8908     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8909   %}
 8910   ins_encode %{
 8911     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8912                Assembler::word, /*acquire*/ false, /*release*/ true,
 8913                /*weak*/ false, $res$$Register);
 8914   %}
 8915   ins_pipe(pipe_slow);
 8916 %}
 8917 
 8918 instruct compareAndExchangeL(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 8919   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 8920   ins_cost(2 * VOLATILE_REF_COST);
 8921   effect(TEMP_DEF res, KILL cr);
 8922   format %{
 8923     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8924   %}
 8925   ins_encode %{
 8926     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8927                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8928                /*weak*/ false, $res$$Register);
 8929   %}
 8930   ins_pipe(pipe_slow);
 8931 %}
 8932 
 8933 instruct compareAndExchangeN(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 8934   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 8935   ins_cost(2 * VOLATILE_REF_COST);
 8936   effect(TEMP_DEF res, KILL cr);
 8937   format %{
 8938     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8939   %}
 8940   ins_encode %{
 8941     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8942                Assembler::word, /*acquire*/ false, /*release*/ true,
 8943                /*weak*/ false, $res$$Register);
 8944   %}
 8945   ins_pipe(pipe_slow);
 8946 %}
 8947 
 8948 instruct compareAndExchangeP(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 8949   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 8950   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 8951   ins_cost(2 * VOLATILE_REF_COST);
 8952   effect(TEMP_DEF res, KILL cr);
 8953   format %{
 8954     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8955   %}
 8956   ins_encode %{
 8957     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8958                Assembler::xword, /*acquire*/ false, /*release*/ true,
 8959                /*weak*/ false, $res$$Register);
 8960   %}
 8961   ins_pipe(pipe_slow);
 8962 %}
 8963 
 8964 instruct compareAndExchangeBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8965   predicate(needs_acquiring_load_exclusive(n));
 8966   match(Set res (CompareAndExchangeB mem (Binary oldval newval)));
 8967   ins_cost(VOLATILE_REF_COST);
 8968   effect(TEMP_DEF res, KILL cr);
 8969   format %{
 8970     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8971   %}
 8972   ins_encode %{
 8973     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8974                Assembler::byte, /*acquire*/ true, /*release*/ true,
 8975                /*weak*/ false, $res$$Register);
 8976     __ sxtbw($res$$Register, $res$$Register);
 8977   %}
 8978   ins_pipe(pipe_slow);
 8979 %}
 8980 
 8981 instruct compareAndExchangeSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 8982   predicate(needs_acquiring_load_exclusive(n));
 8983   match(Set res (CompareAndExchangeS mem (Binary oldval newval)));
 8984   ins_cost(VOLATILE_REF_COST);
 8985   effect(TEMP_DEF res, KILL cr);
 8986   format %{
 8987     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 8988   %}
 8989   ins_encode %{
 8990     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 8991                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 8992                /*weak*/ false, $res$$Register);
 8993     __ sxthw($res$$Register, $res$$Register);
 8994   %}
 8995   ins_pipe(pipe_slow);
 8996 %}
 8997 
 8998 
 8999 instruct compareAndExchangeIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9000   predicate(needs_acquiring_load_exclusive(n));
 9001   match(Set res (CompareAndExchangeI mem (Binary oldval newval)));
 9002   ins_cost(VOLATILE_REF_COST);
 9003   effect(TEMP_DEF res, KILL cr);
 9004   format %{
 9005     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9006   %}
 9007   ins_encode %{
 9008     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9009                Assembler::word, /*acquire*/ true, /*release*/ true,
 9010                /*weak*/ false, $res$$Register);
 9011   %}
 9012   ins_pipe(pipe_slow);
 9013 %}
 9014 
 9015 instruct compareAndExchangeLAcq(iRegLNoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9016   predicate(needs_acquiring_load_exclusive(n));
 9017   match(Set res (CompareAndExchangeL mem (Binary oldval newval)));
 9018   ins_cost(VOLATILE_REF_COST);
 9019   effect(TEMP_DEF res, KILL cr);
 9020   format %{
 9021     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9022   %}
 9023   ins_encode %{
 9024     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9025                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9026                /*weak*/ false, $res$$Register);
 9027   %}
 9028   ins_pipe(pipe_slow);
 9029 %}
 9030 
 9031 
 9032 instruct compareAndExchangeNAcq(iRegNNoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9033   predicate(needs_acquiring_load_exclusive(n));
 9034   match(Set res (CompareAndExchangeN mem (Binary oldval newval)));
 9035   ins_cost(VOLATILE_REF_COST);
 9036   effect(TEMP_DEF res, KILL cr);
 9037   format %{
 9038     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9039   %}
 9040   ins_encode %{
 9041     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9042                Assembler::word, /*acquire*/ true, /*release*/ true,
 9043                /*weak*/ false, $res$$Register);
 9044   %}
 9045   ins_pipe(pipe_slow);
 9046 %}
 9047 
 9048 instruct compareAndExchangePAcq(iRegPNoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9049   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9050   match(Set res (CompareAndExchangeP mem (Binary oldval newval)));
 9051   ins_cost(VOLATILE_REF_COST);
 9052   effect(TEMP_DEF res, KILL cr);
 9053   format %{
 9054     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9055   %}
 9056   ins_encode %{
 9057     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9058                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9059                /*weak*/ false, $res$$Register);
 9060   %}
 9061   ins_pipe(pipe_slow);
 9062 %}
 9063 
 9064 instruct weakCompareAndSwapB(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9065   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9066   ins_cost(2 * VOLATILE_REF_COST);
 9067   effect(KILL cr);
 9068   format %{
 9069     &quot;cmpxchgb $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9070     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9071   %}
 9072   ins_encode %{
 9073     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9074                Assembler::byte, /*acquire*/ false, /*release*/ true,
 9075                /*weak*/ true, noreg);
 9076     __ csetw($res$$Register, Assembler::EQ);
 9077   %}
 9078   ins_pipe(pipe_slow);
 9079 %}
 9080 
 9081 instruct weakCompareAndSwapS(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9082   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9083   ins_cost(2 * VOLATILE_REF_COST);
 9084   effect(KILL cr);
 9085   format %{
 9086     &quot;cmpxchgs $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9087     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9088   %}
 9089   ins_encode %{
 9090     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9091                Assembler::halfword, /*acquire*/ false, /*release*/ true,
 9092                /*weak*/ true, noreg);
 9093     __ csetw($res$$Register, Assembler::EQ);
 9094   %}
 9095   ins_pipe(pipe_slow);
 9096 %}
 9097 
 9098 instruct weakCompareAndSwapI(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9099   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9100   ins_cost(2 * VOLATILE_REF_COST);
 9101   effect(KILL cr);
 9102   format %{
 9103     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9104     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9105   %}
 9106   ins_encode %{
 9107     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9108                Assembler::word, /*acquire*/ false, /*release*/ true,
 9109                /*weak*/ true, noreg);
 9110     __ csetw($res$$Register, Assembler::EQ);
 9111   %}
 9112   ins_pipe(pipe_slow);
 9113 %}
 9114 
 9115 instruct weakCompareAndSwapL(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9116   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9117   ins_cost(2 * VOLATILE_REF_COST);
 9118   effect(KILL cr);
 9119   format %{
 9120     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9121     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9122   %}
 9123   ins_encode %{
 9124     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9125                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9126                /*weak*/ true, noreg);
 9127     __ csetw($res$$Register, Assembler::EQ);
 9128   %}
 9129   ins_pipe(pipe_slow);
 9130 %}
 9131 
 9132 instruct weakCompareAndSwapN(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9133   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9134   ins_cost(2 * VOLATILE_REF_COST);
 9135   effect(KILL cr);
 9136   format %{
 9137     &quot;cmpxchgw $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9138     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9139   %}
 9140   ins_encode %{
 9141     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9142                Assembler::word, /*acquire*/ false, /*release*/ true,
 9143                /*weak*/ true, noreg);
 9144     __ csetw($res$$Register, Assembler::EQ);
 9145   %}
 9146   ins_pipe(pipe_slow);
 9147 %}
 9148 
 9149 instruct weakCompareAndSwapP(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9150   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9151   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9152   ins_cost(2 * VOLATILE_REF_COST);
 9153   effect(KILL cr);
 9154   format %{
 9155     &quot;cmpxchg $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9156     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9157   %}
 9158   ins_encode %{
 9159     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9160                Assembler::xword, /*acquire*/ false, /*release*/ true,
 9161                /*weak*/ true, noreg);
 9162     __ csetw($res$$Register, Assembler::EQ);
 9163   %}
 9164   ins_pipe(pipe_slow);
 9165 %}
 9166 
 9167 instruct weakCompareAndSwapBAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9168   predicate(needs_acquiring_load_exclusive(n));
 9169   match(Set res (WeakCompareAndSwapB mem (Binary oldval newval)));
 9170   ins_cost(VOLATILE_REF_COST);
 9171   effect(KILL cr);
 9172   format %{
 9173     &quot;cmpxchgb_acq $res = $mem, $oldval, $newval\t# (byte, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9174     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9175   %}
 9176   ins_encode %{
 9177     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9178                Assembler::byte, /*acquire*/ true, /*release*/ true,
 9179                /*weak*/ true, noreg);
 9180     __ csetw($res$$Register, Assembler::EQ);
 9181   %}
 9182   ins_pipe(pipe_slow);
 9183 %}
 9184 
 9185 instruct weakCompareAndSwapSAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9186   predicate(needs_acquiring_load_exclusive(n));
 9187   match(Set res (WeakCompareAndSwapS mem (Binary oldval newval)));
 9188   ins_cost(VOLATILE_REF_COST);
 9189   effect(KILL cr);
 9190   format %{
 9191     &quot;cmpxchgs_acq $res = $mem, $oldval, $newval\t# (short, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9192     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9193   %}
 9194   ins_encode %{
 9195     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9196                Assembler::halfword, /*acquire*/ true, /*release*/ true,
 9197                /*weak*/ true, noreg);
 9198     __ csetw($res$$Register, Assembler::EQ);
 9199   %}
 9200   ins_pipe(pipe_slow);
 9201 %}
 9202 
 9203 instruct weakCompareAndSwapIAcq(iRegINoSp res, indirect mem, iRegI oldval, iRegI newval, rFlagsReg cr) %{
 9204   predicate(needs_acquiring_load_exclusive(n));
 9205   match(Set res (WeakCompareAndSwapI mem (Binary oldval newval)));
 9206   ins_cost(VOLATILE_REF_COST);
 9207   effect(KILL cr);
 9208   format %{
 9209     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (int, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9210     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9211   %}
 9212   ins_encode %{
 9213     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9214                Assembler::word, /*acquire*/ true, /*release*/ true,
 9215                /*weak*/ true, noreg);
 9216     __ csetw($res$$Register, Assembler::EQ);
 9217   %}
 9218   ins_pipe(pipe_slow);
 9219 %}
 9220 
 9221 instruct weakCompareAndSwapLAcq(iRegINoSp res, indirect mem, iRegL oldval, iRegL newval, rFlagsReg cr) %{
 9222   predicate(needs_acquiring_load_exclusive(n));
 9223   match(Set res (WeakCompareAndSwapL mem (Binary oldval newval)));
 9224   ins_cost(VOLATILE_REF_COST);
 9225   effect(KILL cr);
 9226   format %{
 9227     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (long, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9228     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9229   %}
 9230   ins_encode %{
 9231     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9232                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9233                /*weak*/ true, noreg);
 9234     __ csetw($res$$Register, Assembler::EQ);
 9235   %}
 9236   ins_pipe(pipe_slow);
 9237 %}
 9238 
 9239 instruct weakCompareAndSwapNAcq(iRegINoSp res, indirect mem, iRegN oldval, iRegN newval, rFlagsReg cr) %{
 9240   predicate(needs_acquiring_load_exclusive(n));
 9241   match(Set res (WeakCompareAndSwapN mem (Binary oldval newval)));
 9242   ins_cost(VOLATILE_REF_COST);
 9243   effect(KILL cr);
 9244   format %{
 9245     &quot;cmpxchgw_acq $res = $mem, $oldval, $newval\t# (narrow oop, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9246     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9247   %}
 9248   ins_encode %{
 9249     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9250                Assembler::word, /*acquire*/ true, /*release*/ true,
 9251                /*weak*/ true, noreg);
 9252     __ csetw($res$$Register, Assembler::EQ);
 9253   %}
 9254   ins_pipe(pipe_slow);
 9255 %}
 9256 
 9257 instruct weakCompareAndSwapPAcq(iRegINoSp res, indirect mem, iRegP oldval, iRegP newval, rFlagsReg cr) %{
 9258   match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));
 9259   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9260   ins_cost(VOLATILE_REF_COST);
 9261   effect(KILL cr);
 9262   format %{
 9263     &quot;cmpxchg_acq $res = $mem, $oldval, $newval\t# (ptr, weak) if $mem == $oldval then $mem &lt;-- $newval&quot;
 9264     &quot;csetw $res, EQ\t# $res &lt;-- (EQ ? 1 : 0)&quot;
 9265   %}
 9266   ins_encode %{
 9267     __ cmpxchg($mem$$Register, $oldval$$Register, $newval$$Register,
 9268                Assembler::xword, /*acquire*/ true, /*release*/ true,
 9269                /*weak*/ true, noreg);
 9270     __ csetw($res$$Register, Assembler::EQ);
 9271   %}
 9272   ins_pipe(pipe_slow);
 9273 %}
 9274 
 9275 // END This section of the file is automatically generated. Do not edit --------------
 9276 // ---------------------------------------------------------------------
 9277 
 9278 instruct get_and_setI(indirect mem, iRegI newv, iRegINoSp prev) %{
 9279   match(Set prev (GetAndSetI mem newv));
 9280   ins_cost(2 * VOLATILE_REF_COST);
 9281   format %{ &quot;atomic_xchgw  $prev, $newv, [$mem]&quot; %}
 9282   ins_encode %{
 9283     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9284   %}
 9285   ins_pipe(pipe_serial);
 9286 %}
 9287 
 9288 instruct get_and_setL(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9289   match(Set prev (GetAndSetL mem newv));
 9290   ins_cost(2 * VOLATILE_REF_COST);
 9291   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9292   ins_encode %{
 9293     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9294   %}
 9295   ins_pipe(pipe_serial);
 9296 %}
 9297 
 9298 instruct get_and_setN(indirect mem, iRegN newv, iRegINoSp prev) %{
 9299   match(Set prev (GetAndSetN mem newv));
 9300   ins_cost(2 * VOLATILE_REF_COST);
 9301   format %{ &quot;atomic_xchgw $prev, $newv, [$mem]&quot; %}
 9302   ins_encode %{
 9303     __ atomic_xchgw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9304   %}
 9305   ins_pipe(pipe_serial);
 9306 %}
 9307 
 9308 instruct get_and_setP(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9309   predicate(n-&gt;as_LoadStore()-&gt;barrier_data() == 0);
 9310   match(Set prev (GetAndSetP mem newv));
 9311   ins_cost(2 * VOLATILE_REF_COST);
 9312   format %{ &quot;atomic_xchg  $prev, $newv, [$mem]&quot; %}
 9313   ins_encode %{
 9314     __ atomic_xchg($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9315   %}
 9316   ins_pipe(pipe_serial);
 9317 %}
 9318 
 9319 instruct get_and_setIAcq(indirect mem, iRegI newv, iRegINoSp prev) %{
 9320   predicate(needs_acquiring_load_exclusive(n));
 9321   match(Set prev (GetAndSetI mem newv));
 9322   ins_cost(VOLATILE_REF_COST);
 9323   format %{ &quot;atomic_xchgw_acq  $prev, $newv, [$mem]&quot; %}
 9324   ins_encode %{
 9325     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9326   %}
 9327   ins_pipe(pipe_serial);
 9328 %}
 9329 
 9330 instruct get_and_setLAcq(indirect mem, iRegL newv, iRegLNoSp prev) %{
 9331   predicate(needs_acquiring_load_exclusive(n));
 9332   match(Set prev (GetAndSetL mem newv));
 9333   ins_cost(VOLATILE_REF_COST);
 9334   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9335   ins_encode %{
 9336     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9337   %}
 9338   ins_pipe(pipe_serial);
 9339 %}
 9340 
 9341 instruct get_and_setNAcq(indirect mem, iRegN newv, iRegINoSp prev) %{
 9342   predicate(needs_acquiring_load_exclusive(n));
 9343   match(Set prev (GetAndSetN mem newv));
 9344   ins_cost(VOLATILE_REF_COST);
 9345   format %{ &quot;atomic_xchgw_acq $prev, $newv, [$mem]&quot; %}
 9346   ins_encode %{
 9347     __ atomic_xchgalw($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9348   %}
 9349   ins_pipe(pipe_serial);
 9350 %}
 9351 
 9352 instruct get_and_setPAcq(indirect mem, iRegP newv, iRegPNoSp prev) %{
 9353   predicate(needs_acquiring_load_exclusive(n) &amp;&amp; (n-&gt;as_LoadStore()-&gt;barrier_data() == 0));
 9354   match(Set prev (GetAndSetP mem newv));
 9355   ins_cost(VOLATILE_REF_COST);
 9356   format %{ &quot;atomic_xchg_acq  $prev, $newv, [$mem]&quot; %}
 9357   ins_encode %{
 9358     __ atomic_xchgal($prev$$Register, $newv$$Register, as_Register($mem$$base));
 9359   %}
 9360   ins_pipe(pipe_serial);
 9361 %}
 9362 
 9363 
 9364 instruct get_and_addL(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9365   match(Set newval (GetAndAddL mem incr));
 9366   ins_cost(2 * VOLATILE_REF_COST + 1);
 9367   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9368   ins_encode %{
 9369     __ atomic_add($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9370   %}
 9371   ins_pipe(pipe_serial);
 9372 %}
 9373 
 9374 instruct get_and_addL_no_res(indirect mem, Universe dummy, iRegL incr) %{
 9375   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9376   match(Set dummy (GetAndAddL mem incr));
 9377   ins_cost(2 * VOLATILE_REF_COST);
 9378   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9379   ins_encode %{
 9380     __ atomic_add(noreg, $incr$$Register, as_Register($mem$$base));
 9381   %}
 9382   ins_pipe(pipe_serial);
 9383 %}
 9384 
 9385 instruct get_and_addLi(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9386   match(Set newval (GetAndAddL mem incr));
 9387   ins_cost(2 * VOLATILE_REF_COST + 1);
 9388   format %{ &quot;get_and_addL $newval, [$mem], $incr&quot; %}
 9389   ins_encode %{
 9390     __ atomic_add($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9391   %}
 9392   ins_pipe(pipe_serial);
 9393 %}
 9394 
 9395 instruct get_and_addLi_no_res(indirect mem, Universe dummy, immLAddSub incr) %{
 9396   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9397   match(Set dummy (GetAndAddL mem incr));
 9398   ins_cost(2 * VOLATILE_REF_COST);
 9399   format %{ &quot;get_and_addL [$mem], $incr&quot; %}
 9400   ins_encode %{
 9401     __ atomic_add(noreg, $incr$$constant, as_Register($mem$$base));
 9402   %}
 9403   ins_pipe(pipe_serial);
 9404 %}
 9405 
 9406 instruct get_and_addI(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9407   match(Set newval (GetAndAddI mem incr));
 9408   ins_cost(2 * VOLATILE_REF_COST + 1);
 9409   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9410   ins_encode %{
 9411     __ atomic_addw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9412   %}
 9413   ins_pipe(pipe_serial);
 9414 %}
 9415 
 9416 instruct get_and_addI_no_res(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9417   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9418   match(Set dummy (GetAndAddI mem incr));
 9419   ins_cost(2 * VOLATILE_REF_COST);
 9420   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9421   ins_encode %{
 9422     __ atomic_addw(noreg, $incr$$Register, as_Register($mem$$base));
 9423   %}
 9424   ins_pipe(pipe_serial);
 9425 %}
 9426 
 9427 instruct get_and_addIi(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9428   match(Set newval (GetAndAddI mem incr));
 9429   ins_cost(2 * VOLATILE_REF_COST + 1);
 9430   format %{ &quot;get_and_addI $newval, [$mem], $incr&quot; %}
 9431   ins_encode %{
 9432     __ atomic_addw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9433   %}
 9434   ins_pipe(pipe_serial);
 9435 %}
 9436 
 9437 instruct get_and_addIi_no_res(indirect mem, Universe dummy, immIAddSub incr) %{
 9438   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 9439   match(Set dummy (GetAndAddI mem incr));
 9440   ins_cost(2 * VOLATILE_REF_COST);
 9441   format %{ &quot;get_and_addI [$mem], $incr&quot; %}
 9442   ins_encode %{
 9443     __ atomic_addw(noreg, $incr$$constant, as_Register($mem$$base));
 9444   %}
 9445   ins_pipe(pipe_serial);
 9446 %}
 9447 
 9448 instruct get_and_addLAcq(indirect mem, iRegLNoSp newval, iRegL incr) %{
 9449   predicate(needs_acquiring_load_exclusive(n));
 9450   match(Set newval (GetAndAddL mem incr));
 9451   ins_cost(VOLATILE_REF_COST + 1);
 9452   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9453   ins_encode %{
 9454     __ atomic_addal($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9455   %}
 9456   ins_pipe(pipe_serial);
 9457 %}
 9458 
 9459 instruct get_and_addL_no_resAcq(indirect mem, Universe dummy, iRegL incr) %{
 9460   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9461   match(Set dummy (GetAndAddL mem incr));
 9462   ins_cost(VOLATILE_REF_COST);
 9463   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9464   ins_encode %{
 9465     __ atomic_addal(noreg, $incr$$Register, as_Register($mem$$base));
 9466   %}
 9467   ins_pipe(pipe_serial);
 9468 %}
 9469 
 9470 instruct get_and_addLiAcq(indirect mem, iRegLNoSp newval, immLAddSub incr) %{
 9471   predicate(needs_acquiring_load_exclusive(n));
 9472   match(Set newval (GetAndAddL mem incr));
 9473   ins_cost(VOLATILE_REF_COST + 1);
 9474   format %{ &quot;get_and_addL_acq $newval, [$mem], $incr&quot; %}
 9475   ins_encode %{
 9476     __ atomic_addal($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9477   %}
 9478   ins_pipe(pipe_serial);
 9479 %}
 9480 
 9481 instruct get_and_addLi_no_resAcq(indirect mem, Universe dummy, immLAddSub incr) %{
 9482   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9483   match(Set dummy (GetAndAddL mem incr));
 9484   ins_cost(VOLATILE_REF_COST);
 9485   format %{ &quot;get_and_addL_acq [$mem], $incr&quot; %}
 9486   ins_encode %{
 9487     __ atomic_addal(noreg, $incr$$constant, as_Register($mem$$base));
 9488   %}
 9489   ins_pipe(pipe_serial);
 9490 %}
 9491 
 9492 instruct get_and_addIAcq(indirect mem, iRegINoSp newval, iRegIorL2I incr) %{
 9493   predicate(needs_acquiring_load_exclusive(n));
 9494   match(Set newval (GetAndAddI mem incr));
 9495   ins_cost(VOLATILE_REF_COST + 1);
 9496   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9497   ins_encode %{
 9498     __ atomic_addalw($newval$$Register, $incr$$Register, as_Register($mem$$base));
 9499   %}
 9500   ins_pipe(pipe_serial);
 9501 %}
 9502 
 9503 instruct get_and_addI_no_resAcq(indirect mem, Universe dummy, iRegIorL2I incr) %{
 9504   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9505   match(Set dummy (GetAndAddI mem incr));
 9506   ins_cost(VOLATILE_REF_COST);
 9507   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9508   ins_encode %{
 9509     __ atomic_addalw(noreg, $incr$$Register, as_Register($mem$$base));
 9510   %}
 9511   ins_pipe(pipe_serial);
 9512 %}
 9513 
 9514 instruct get_and_addIiAcq(indirect mem, iRegINoSp newval, immIAddSub incr) %{
 9515   predicate(needs_acquiring_load_exclusive(n));
 9516   match(Set newval (GetAndAddI mem incr));
 9517   ins_cost(VOLATILE_REF_COST + 1);
 9518   format %{ &quot;get_and_addI_acq $newval, [$mem], $incr&quot; %}
 9519   ins_encode %{
 9520     __ atomic_addalw($newval$$Register, $incr$$constant, as_Register($mem$$base));
 9521   %}
 9522   ins_pipe(pipe_serial);
 9523 %}
 9524 
 9525 instruct get_and_addIi_no_resAcq(indirect mem, Universe dummy, immIAddSub incr) %{
 9526   predicate(n-&gt;as_LoadStore()-&gt;result_not_used() &amp;&amp; needs_acquiring_load_exclusive(n));
 9527   match(Set dummy (GetAndAddI mem incr));
 9528   ins_cost(VOLATILE_REF_COST);
 9529   format %{ &quot;get_and_addI_acq [$mem], $incr&quot; %}
 9530   ins_encode %{
 9531     __ atomic_addalw(noreg, $incr$$constant, as_Register($mem$$base));
 9532   %}
 9533   ins_pipe(pipe_serial);
 9534 %}
 9535 
 9536 // Manifest a CmpL result in an integer register.
 9537 // (src1 &lt; src2) ? -1 : ((src1 &gt; src2) ? 1 : 0)
 9538 instruct cmpL3_reg_reg(iRegINoSp dst, iRegL src1, iRegL src2, rFlagsReg flags)
 9539 %{
 9540   match(Set dst (CmpL3 src1 src2));
 9541   effect(KILL flags);
 9542 
 9543   ins_cost(INSN_COST * 6);
 9544   format %{
 9545       &quot;cmp $src1, $src2&quot;
 9546       &quot;csetw $dst, ne&quot;
 9547       &quot;cnegw $dst, lt&quot;
 9548   %}
 9549   // format %{ &quot;CmpL3 $dst, $src1, $src2&quot; %}
 9550   ins_encode %{
 9551     __ cmp($src1$$Register, $src2$$Register);
 9552     __ csetw($dst$$Register, Assembler::NE);
 9553     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9554   %}
 9555 
 9556   ins_pipe(pipe_class_default);
 9557 %}
 9558 
 9559 instruct cmpL3_reg_imm(iRegINoSp dst, iRegL src1, immLAddSub src2, rFlagsReg flags)
 9560 %{
 9561   match(Set dst (CmpL3 src1 src2));
 9562   effect(KILL flags);
 9563 
 9564   ins_cost(INSN_COST * 6);
 9565   format %{
 9566       &quot;cmp $src1, $src2&quot;
 9567       &quot;csetw $dst, ne&quot;
 9568       &quot;cnegw $dst, lt&quot;
 9569   %}
 9570   ins_encode %{
 9571     int32_t con = (int32_t)$src2$$constant;
 9572      if (con &lt; 0) {
 9573       __ adds(zr, $src1$$Register, -con);
 9574     } else {
 9575       __ subs(zr, $src1$$Register, con);
 9576     }
 9577     __ csetw($dst$$Register, Assembler::NE);
 9578     __ cnegw($dst$$Register, $dst$$Register, Assembler::LT);
 9579   %}
 9580 
 9581   ins_pipe(pipe_class_default);
 9582 %}
 9583 
 9584 // ============================================================================
 9585 // Conditional Move Instructions
 9586 
 9587 // n.b. we have identical rules for both a signed compare op (cmpOp)
 9588 // and an unsigned compare op (cmpOpU). it would be nice if we could
 9589 // define an op class which merged both inputs and use it to type the
 9590 // argument to a single rule. unfortunatelyt his fails because the
 9591 // opclass does not live up to the COND_INTER interface of its
 9592 // component operands. When the generic code tries to negate the
 9593 // operand it ends up running the generci Machoper::negate method
 9594 // which throws a ShouldNotHappen. So, we have to provide two flavours
 9595 // of each rule, one for a cmpOp and a second for a cmpOpU (sigh).
 9596 
 9597 instruct cmovI_reg_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9598   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9599 
 9600   ins_cost(INSN_COST * 2);
 9601   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, int&quot;  %}
 9602 
 9603   ins_encode %{
 9604     __ cselw(as_Register($dst$$reg),
 9605              as_Register($src2$$reg),
 9606              as_Register($src1$$reg),
 9607              (Assembler::Condition)$cmp$$cmpcode);
 9608   %}
 9609 
 9610   ins_pipe(icond_reg_reg);
 9611 %}
 9612 
 9613 instruct cmovUI_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
 9614   match(Set dst (CMoveI (Binary cmp cr) (Binary src1 src2)));
 9615 
 9616   ins_cost(INSN_COST * 2);
 9617   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# unsigned, int&quot;  %}
 9618 
 9619   ins_encode %{
 9620     __ cselw(as_Register($dst$$reg),
 9621              as_Register($src2$$reg),
 9622              as_Register($src1$$reg),
 9623              (Assembler::Condition)$cmp$$cmpcode);
 9624   %}
 9625 
 9626   ins_pipe(icond_reg_reg);
 9627 %}
 9628 
 9629 // special cases where one arg is zero
 9630 
 9631 // n.b. this is selected in preference to the rule above because it
 9632 // avoids loading constant 0 into a source register
 9633 
 9634 // TODO
 9635 // we ought only to be able to cull one of these variants as the ideal
 9636 // transforms ought always to order the zero consistently (to left/right?)
 9637 
 9638 instruct cmovI_zero_reg(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9639   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9640 
 9641   ins_cost(INSN_COST * 2);
 9642   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, int&quot;  %}
 9643 
 9644   ins_encode %{
 9645     __ cselw(as_Register($dst$$reg),
 9646              as_Register($src$$reg),
 9647              zr,
 9648              (Assembler::Condition)$cmp$$cmpcode);
 9649   %}
 9650 
 9651   ins_pipe(icond_reg);
 9652 %}
 9653 
 9654 instruct cmovUI_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, iRegIorL2I src) %{
 9655   match(Set dst (CMoveI (Binary cmp cr) (Binary zero src)));
 9656 
 9657   ins_cost(INSN_COST * 2);
 9658   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, int&quot;  %}
 9659 
 9660   ins_encode %{
 9661     __ cselw(as_Register($dst$$reg),
 9662              as_Register($src$$reg),
 9663              zr,
 9664              (Assembler::Condition)$cmp$$cmpcode);
 9665   %}
 9666 
 9667   ins_pipe(icond_reg);
 9668 %}
 9669 
 9670 instruct cmovI_reg_zero(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9671   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9672 
 9673   ins_cost(INSN_COST * 2);
 9674   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, int&quot;  %}
 9675 
 9676   ins_encode %{
 9677     __ cselw(as_Register($dst$$reg),
 9678              zr,
 9679              as_Register($src$$reg),
 9680              (Assembler::Condition)$cmp$$cmpcode);
 9681   %}
 9682 
 9683   ins_pipe(icond_reg);
 9684 %}
 9685 
 9686 instruct cmovUI_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, iRegIorL2I src, immI0 zero) %{
 9687   match(Set dst (CMoveI (Binary cmp cr) (Binary src zero)));
 9688 
 9689   ins_cost(INSN_COST * 2);
 9690   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, int&quot;  %}
 9691 
 9692   ins_encode %{
 9693     __ cselw(as_Register($dst$$reg),
 9694              zr,
 9695              as_Register($src$$reg),
 9696              (Assembler::Condition)$cmp$$cmpcode);
 9697   %}
 9698 
 9699   ins_pipe(icond_reg);
 9700 %}
 9701 
 9702 // special case for creating a boolean 0 or 1
 9703 
 9704 // n.b. this is selected in preference to the rule above because it
 9705 // avoids loading constants 0 and 1 into a source register
 9706 
 9707 instruct cmovI_reg_zero_one(cmpOp cmp, rFlagsReg cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9708   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9709 
 9710   ins_cost(INSN_COST * 2);
 9711   format %{ &quot;csincw $dst, zr, zr $cmp\t# signed, int&quot;  %}
 9712 
 9713   ins_encode %{
 9714     // equivalently
 9715     // cset(as_Register($dst$$reg),
 9716     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9717     __ csincw(as_Register($dst$$reg),
 9718              zr,
 9719              zr,
 9720              (Assembler::Condition)$cmp$$cmpcode);
 9721   %}
 9722 
 9723   ins_pipe(icond_none);
 9724 %}
 9725 
 9726 instruct cmovUI_reg_zero_one(cmpOpU cmp, rFlagsRegU cr, iRegINoSp dst, immI0 zero, immI_1 one) %{
 9727   match(Set dst (CMoveI (Binary cmp cr) (Binary one zero)));
 9728 
 9729   ins_cost(INSN_COST * 2);
 9730   format %{ &quot;csincw $dst, zr, zr $cmp\t# unsigned, int&quot;  %}
 9731 
 9732   ins_encode %{
 9733     // equivalently
 9734     // cset(as_Register($dst$$reg),
 9735     //      negate_condition((Assembler::Condition)$cmp$$cmpcode));
 9736     __ csincw(as_Register($dst$$reg),
 9737              zr,
 9738              zr,
 9739              (Assembler::Condition)$cmp$$cmpcode);
 9740   %}
 9741 
 9742   ins_pipe(icond_none);
 9743 %}
 9744 
 9745 instruct cmovL_reg_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9746   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9747 
 9748   ins_cost(INSN_COST * 2);
 9749   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, long&quot;  %}
 9750 
 9751   ins_encode %{
 9752     __ csel(as_Register($dst$$reg),
 9753             as_Register($src2$$reg),
 9754             as_Register($src1$$reg),
 9755             (Assembler::Condition)$cmp$$cmpcode);
 9756   %}
 9757 
 9758   ins_pipe(icond_reg_reg);
 9759 %}
 9760 
 9761 instruct cmovUL_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src1, iRegL src2) %{
 9762   match(Set dst (CMoveL (Binary cmp cr) (Binary src1 src2)));
 9763 
 9764   ins_cost(INSN_COST * 2);
 9765   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, long&quot;  %}
 9766 
 9767   ins_encode %{
 9768     __ csel(as_Register($dst$$reg),
 9769             as_Register($src2$$reg),
 9770             as_Register($src1$$reg),
 9771             (Assembler::Condition)$cmp$$cmpcode);
 9772   %}
 9773 
 9774   ins_pipe(icond_reg_reg);
 9775 %}
 9776 
 9777 // special cases where one arg is zero
 9778 
 9779 instruct cmovL_reg_zero(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9780   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9781 
 9782   ins_cost(INSN_COST * 2);
 9783   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, long&quot;  %}
 9784 
 9785   ins_encode %{
 9786     __ csel(as_Register($dst$$reg),
 9787             zr,
 9788             as_Register($src$$reg),
 9789             (Assembler::Condition)$cmp$$cmpcode);
 9790   %}
 9791 
 9792   ins_pipe(icond_reg);
 9793 %}
 9794 
 9795 instruct cmovUL_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, iRegL src, immL0 zero) %{
 9796   match(Set dst (CMoveL (Binary cmp cr) (Binary src zero)));
 9797 
 9798   ins_cost(INSN_COST * 2);
 9799   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, long&quot;  %}
 9800 
 9801   ins_encode %{
 9802     __ csel(as_Register($dst$$reg),
 9803             zr,
 9804             as_Register($src$$reg),
 9805             (Assembler::Condition)$cmp$$cmpcode);
 9806   %}
 9807 
 9808   ins_pipe(icond_reg);
 9809 %}
 9810 
 9811 instruct cmovL_zero_reg(cmpOp cmp, rFlagsReg cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9812   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9813 
 9814   ins_cost(INSN_COST * 2);
 9815   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, long&quot;  %}
 9816 
 9817   ins_encode %{
 9818     __ csel(as_Register($dst$$reg),
 9819             as_Register($src$$reg),
 9820             zr,
 9821             (Assembler::Condition)$cmp$$cmpcode);
 9822   %}
 9823 
 9824   ins_pipe(icond_reg);
 9825 %}
 9826 
 9827 instruct cmovUL_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegLNoSp dst, immL0 zero, iRegL src) %{
 9828   match(Set dst (CMoveL (Binary cmp cr) (Binary zero src)));
 9829 
 9830   ins_cost(INSN_COST * 2);
 9831   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, long&quot;  %}
 9832 
 9833   ins_encode %{
 9834     __ csel(as_Register($dst$$reg),
 9835             as_Register($src$$reg),
 9836             zr,
 9837             (Assembler::Condition)$cmp$$cmpcode);
 9838   %}
 9839 
 9840   ins_pipe(icond_reg);
 9841 %}
 9842 
 9843 instruct cmovP_reg_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9844   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9845 
 9846   ins_cost(INSN_COST * 2);
 9847   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# signed, ptr&quot;  %}
 9848 
 9849   ins_encode %{
 9850     __ csel(as_Register($dst$$reg),
 9851             as_Register($src2$$reg),
 9852             as_Register($src1$$reg),
 9853             (Assembler::Condition)$cmp$$cmpcode);
 9854   %}
 9855 
 9856   ins_pipe(icond_reg_reg);
 9857 %}
 9858 
 9859 instruct cmovUP_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src1, iRegP src2) %{
 9860   match(Set dst (CMoveP (Binary cmp cr) (Binary src1 src2)));
 9861 
 9862   ins_cost(INSN_COST * 2);
 9863   format %{ &quot;csel $dst, $src2, $src1 $cmp\t# unsigned, ptr&quot;  %}
 9864 
 9865   ins_encode %{
 9866     __ csel(as_Register($dst$$reg),
 9867             as_Register($src2$$reg),
 9868             as_Register($src1$$reg),
 9869             (Assembler::Condition)$cmp$$cmpcode);
 9870   %}
 9871 
 9872   ins_pipe(icond_reg_reg);
 9873 %}
 9874 
 9875 // special cases where one arg is zero
 9876 
 9877 instruct cmovP_reg_zero(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9878   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9879 
 9880   ins_cost(INSN_COST * 2);
 9881   format %{ &quot;csel $dst, zr, $src $cmp\t# signed, ptr&quot;  %}
 9882 
 9883   ins_encode %{
 9884     __ csel(as_Register($dst$$reg),
 9885             zr,
 9886             as_Register($src$$reg),
 9887             (Assembler::Condition)$cmp$$cmpcode);
 9888   %}
 9889 
 9890   ins_pipe(icond_reg);
 9891 %}
 9892 
 9893 instruct cmovUP_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, iRegP src, immP0 zero) %{
 9894   match(Set dst (CMoveP (Binary cmp cr) (Binary src zero)));
 9895 
 9896   ins_cost(INSN_COST * 2);
 9897   format %{ &quot;csel $dst, zr, $src $cmp\t# unsigned, ptr&quot;  %}
 9898 
 9899   ins_encode %{
 9900     __ csel(as_Register($dst$$reg),
 9901             zr,
 9902             as_Register($src$$reg),
 9903             (Assembler::Condition)$cmp$$cmpcode);
 9904   %}
 9905 
 9906   ins_pipe(icond_reg);
 9907 %}
 9908 
 9909 instruct cmovP_zero_reg(cmpOp cmp, rFlagsReg cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9910   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9911 
 9912   ins_cost(INSN_COST * 2);
 9913   format %{ &quot;csel $dst, $src, zr $cmp\t# signed, ptr&quot;  %}
 9914 
 9915   ins_encode %{
 9916     __ csel(as_Register($dst$$reg),
 9917             as_Register($src$$reg),
 9918             zr,
 9919             (Assembler::Condition)$cmp$$cmpcode);
 9920   %}
 9921 
 9922   ins_pipe(icond_reg);
 9923 %}
 9924 
 9925 instruct cmovUP_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegPNoSp dst, immP0 zero, iRegP src) %{
 9926   match(Set dst (CMoveP (Binary cmp cr) (Binary zero src)));
 9927 
 9928   ins_cost(INSN_COST * 2);
 9929   format %{ &quot;csel $dst, $src, zr $cmp\t# unsigned, ptr&quot;  %}
 9930 
 9931   ins_encode %{
 9932     __ csel(as_Register($dst$$reg),
 9933             as_Register($src$$reg),
 9934             zr,
 9935             (Assembler::Condition)$cmp$$cmpcode);
 9936   %}
 9937 
 9938   ins_pipe(icond_reg);
 9939 %}
 9940 
 9941 instruct cmovN_reg_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9942   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9943 
 9944   ins_cost(INSN_COST * 2);
 9945   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9946 
 9947   ins_encode %{
 9948     __ cselw(as_Register($dst$$reg),
 9949              as_Register($src2$$reg),
 9950              as_Register($src1$$reg),
 9951              (Assembler::Condition)$cmp$$cmpcode);
 9952   %}
 9953 
 9954   ins_pipe(icond_reg_reg);
 9955 %}
 9956 
 9957 instruct cmovUN_reg_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src1, iRegN src2) %{
 9958   match(Set dst (CMoveN (Binary cmp cr) (Binary src1 src2)));
 9959 
 9960   ins_cost(INSN_COST * 2);
 9961   format %{ &quot;cselw $dst, $src2, $src1 $cmp\t# signed, compressed ptr&quot;  %}
 9962 
 9963   ins_encode %{
 9964     __ cselw(as_Register($dst$$reg),
 9965              as_Register($src2$$reg),
 9966              as_Register($src1$$reg),
 9967              (Assembler::Condition)$cmp$$cmpcode);
 9968   %}
 9969 
 9970   ins_pipe(icond_reg_reg);
 9971 %}
 9972 
 9973 // special cases where one arg is zero
 9974 
 9975 instruct cmovN_reg_zero(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9976   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9977 
 9978   ins_cost(INSN_COST * 2);
 9979   format %{ &quot;cselw $dst, zr, $src $cmp\t# signed, compressed ptr&quot;  %}
 9980 
 9981   ins_encode %{
 9982     __ cselw(as_Register($dst$$reg),
 9983              zr,
 9984              as_Register($src$$reg),
 9985              (Assembler::Condition)$cmp$$cmpcode);
 9986   %}
 9987 
 9988   ins_pipe(icond_reg);
 9989 %}
 9990 
 9991 instruct cmovUN_reg_zero(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, iRegN src, immN0 zero) %{
 9992   match(Set dst (CMoveN (Binary cmp cr) (Binary src zero)));
 9993 
 9994   ins_cost(INSN_COST * 2);
 9995   format %{ &quot;cselw $dst, zr, $src $cmp\t# unsigned, compressed ptr&quot;  %}
 9996 
 9997   ins_encode %{
 9998     __ cselw(as_Register($dst$$reg),
 9999              zr,
10000              as_Register($src$$reg),
10001              (Assembler::Condition)$cmp$$cmpcode);
10002   %}
10003 
10004   ins_pipe(icond_reg);
10005 %}
10006 
10007 instruct cmovN_zero_reg(cmpOp cmp, rFlagsReg cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10008   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10009 
10010   ins_cost(INSN_COST * 2);
10011   format %{ &quot;cselw $dst, $src, zr $cmp\t# signed, compressed ptr&quot;  %}
10012 
10013   ins_encode %{
10014     __ cselw(as_Register($dst$$reg),
10015              as_Register($src$$reg),
10016              zr,
10017              (Assembler::Condition)$cmp$$cmpcode);
10018   %}
10019 
10020   ins_pipe(icond_reg);
10021 %}
10022 
10023 instruct cmovUN_zero_reg(cmpOpU cmp, rFlagsRegU cr, iRegNNoSp dst, immN0 zero, iRegN src) %{
10024   match(Set dst (CMoveN (Binary cmp cr) (Binary zero src)));
10025 
10026   ins_cost(INSN_COST * 2);
10027   format %{ &quot;cselw $dst, $src, zr $cmp\t# unsigned, compressed ptr&quot;  %}
10028 
10029   ins_encode %{
10030     __ cselw(as_Register($dst$$reg),
10031              as_Register($src$$reg),
10032              zr,
10033              (Assembler::Condition)$cmp$$cmpcode);
10034   %}
10035 
10036   ins_pipe(icond_reg);
10037 %}
10038 
10039 instruct cmovF_reg(cmpOp cmp, rFlagsReg cr, vRegF dst, vRegF src1,  vRegF src2)
10040 %{
10041   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10042 
10043   ins_cost(INSN_COST * 3);
10044 
10045   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10046   ins_encode %{
10047     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10048     __ fcsels(as_FloatRegister($dst$$reg),
10049               as_FloatRegister($src2$$reg),
10050               as_FloatRegister($src1$$reg),
10051               cond);
10052   %}
10053 
10054   ins_pipe(fp_cond_reg_reg_s);
10055 %}
10056 
10057 instruct cmovUF_reg(cmpOpU cmp, rFlagsRegU cr, vRegF dst, vRegF src1,  vRegF src2)
10058 %{
10059   match(Set dst (CMoveF (Binary cmp cr) (Binary src1 src2)));
10060 
10061   ins_cost(INSN_COST * 3);
10062 
10063   format %{ &quot;fcsels $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10064   ins_encode %{
10065     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10066     __ fcsels(as_FloatRegister($dst$$reg),
10067               as_FloatRegister($src2$$reg),
10068               as_FloatRegister($src1$$reg),
10069               cond);
10070   %}
10071 
10072   ins_pipe(fp_cond_reg_reg_s);
10073 %}
10074 
10075 instruct cmovD_reg(cmpOp cmp, rFlagsReg cr, vRegD dst, vRegD src1,  vRegD src2)
10076 %{
10077   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10078 
10079   ins_cost(INSN_COST * 3);
10080 
10081   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# signed cmove float\n\t&quot; %}
10082   ins_encode %{
10083     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10084     __ fcseld(as_FloatRegister($dst$$reg),
10085               as_FloatRegister($src2$$reg),
10086               as_FloatRegister($src1$$reg),
10087               cond);
10088   %}
10089 
10090   ins_pipe(fp_cond_reg_reg_d);
10091 %}
10092 
10093 instruct cmovUD_reg(cmpOpU cmp, rFlagsRegU cr, vRegD dst, vRegD src1,  vRegD src2)
10094 %{
10095   match(Set dst (CMoveD (Binary cmp cr) (Binary src1 src2)));
10096 
10097   ins_cost(INSN_COST * 3);
10098 
10099   format %{ &quot;fcseld $dst, $src1, $src2, $cmp\t# unsigned cmove float\n\t&quot; %}
10100   ins_encode %{
10101     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
10102     __ fcseld(as_FloatRegister($dst$$reg),
10103               as_FloatRegister($src2$$reg),
10104               as_FloatRegister($src1$$reg),
10105               cond);
10106   %}
10107 
10108   ins_pipe(fp_cond_reg_reg_d);
10109 %}
10110 
10111 // ============================================================================
10112 // Arithmetic Instructions
10113 //
10114 
10115 // Integer Addition
10116 
10117 // TODO
10118 // these currently employ operations which do not set CR and hence are
10119 // not flagged as killing CR but we would like to isolate the cases
10120 // where we want to set flags from those where we don&#39;t. need to work
10121 // out how to do that.
10122 
10123 instruct addI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10124   match(Set dst (AddI src1 src2));
10125 
10126   ins_cost(INSN_COST);
10127   format %{ &quot;addw  $dst, $src1, $src2&quot; %}
10128 
10129   ins_encode %{
10130     __ addw(as_Register($dst$$reg),
10131             as_Register($src1$$reg),
10132             as_Register($src2$$reg));
10133   %}
10134 
10135   ins_pipe(ialu_reg_reg);
10136 %}
10137 
10138 instruct addI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10139   match(Set dst (AddI src1 src2));
10140 
10141   ins_cost(INSN_COST);
10142   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10143 
10144   // use opcode to indicate that this is an add not a sub
10145   opcode(0x0);
10146 
10147   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10148 
10149   ins_pipe(ialu_reg_imm);
10150 %}
10151 
10152 instruct addI_reg_imm_i2l(iRegINoSp dst, iRegL src1, immIAddSub src2) %{
10153   match(Set dst (AddI (ConvL2I src1) src2));
10154 
10155   ins_cost(INSN_COST);
10156   format %{ &quot;addw $dst, $src1, $src2&quot; %}
10157 
10158   // use opcode to indicate that this is an add not a sub
10159   opcode(0x0);
10160 
10161   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10162 
10163   ins_pipe(ialu_reg_imm);
10164 %}
10165 
10166 // Pointer Addition
10167 instruct addP_reg_reg(iRegPNoSp dst, iRegP src1, iRegL src2) %{
10168   match(Set dst (AddP src1 src2));
10169 
10170   ins_cost(INSN_COST);
10171   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10172 
10173   ins_encode %{
10174     __ add(as_Register($dst$$reg),
10175            as_Register($src1$$reg),
10176            as_Register($src2$$reg));
10177   %}
10178 
10179   ins_pipe(ialu_reg_reg);
10180 %}
10181 
10182 instruct addP_reg_reg_ext(iRegPNoSp dst, iRegP src1, iRegIorL2I src2) %{
10183   match(Set dst (AddP src1 (ConvI2L src2)));
10184 
10185   ins_cost(1.9 * INSN_COST);
10186   format %{ &quot;add $dst, $src1, $src2, sxtw\t# ptr&quot; %}
10187 
10188   ins_encode %{
10189     __ add(as_Register($dst$$reg),
10190            as_Register($src1$$reg),
10191            as_Register($src2$$reg), ext::sxtw);
10192   %}
10193 
10194   ins_pipe(ialu_reg_reg);
10195 %}
10196 
10197 instruct addP_reg_reg_lsl(iRegPNoSp dst, iRegP src1, iRegL src2, immIScale scale) %{
10198   match(Set dst (AddP src1 (LShiftL src2 scale)));
10199 
10200   ins_cost(1.9 * INSN_COST);
10201   format %{ &quot;add $dst, $src1, $src2, LShiftL $scale\t# ptr&quot; %}
10202 
10203   ins_encode %{
10204     __ lea(as_Register($dst$$reg),
10205            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10206                    Address::lsl($scale$$constant)));
10207   %}
10208 
10209   ins_pipe(ialu_reg_reg_shift);
10210 %}
10211 
10212 instruct addP_reg_reg_ext_shift(iRegPNoSp dst, iRegP src1, iRegIorL2I src2, immIScale scale) %{
10213   match(Set dst (AddP src1 (LShiftL (ConvI2L src2) scale)));
10214 
10215   ins_cost(1.9 * INSN_COST);
10216   format %{ &quot;add $dst, $src1, $src2, I2L $scale\t# ptr&quot; %}
10217 
10218   ins_encode %{
10219     __ lea(as_Register($dst$$reg),
10220            Address(as_Register($src1$$reg), as_Register($src2$$reg),
10221                    Address::sxtw($scale$$constant)));
10222   %}
10223 
10224   ins_pipe(ialu_reg_reg_shift);
10225 %}
10226 
10227 instruct lshift_ext(iRegLNoSp dst, iRegIorL2I src, immI scale, rFlagsReg cr) %{
10228   match(Set dst (LShiftL (ConvI2L src) scale));
10229 
10230   ins_cost(INSN_COST);
10231   format %{ &quot;sbfiz $dst, $src, $scale &amp; 63, -$scale &amp; 63\t&quot; %}
10232 
10233   ins_encode %{
10234     __ sbfiz(as_Register($dst$$reg),
10235           as_Register($src$$reg),
10236           $scale$$constant &amp; 63, MIN(32, (-$scale$$constant) &amp; 63));
10237   %}
10238 
10239   ins_pipe(ialu_reg_shift);
10240 %}
10241 
10242 // Pointer Immediate Addition
10243 // n.b. this needs to be more expensive than using an indirect memory
10244 // operand
10245 instruct addP_reg_imm(iRegPNoSp dst, iRegP src1, immLAddSub src2) %{
10246   match(Set dst (AddP src1 src2));
10247 
10248   ins_cost(INSN_COST);
10249   format %{ &quot;add $dst, $src1, $src2\t# ptr&quot; %}
10250 
10251   // use opcode to indicate that this is an add not a sub
10252   opcode(0x0);
10253 
10254   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10255 
10256   ins_pipe(ialu_reg_imm);
10257 %}
10258 
10259 // Long Addition
10260 instruct addL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10261 
10262   match(Set dst (AddL src1 src2));
10263 
10264   ins_cost(INSN_COST);
10265   format %{ &quot;add  $dst, $src1, $src2&quot; %}
10266 
10267   ins_encode %{
10268     __ add(as_Register($dst$$reg),
10269            as_Register($src1$$reg),
10270            as_Register($src2$$reg));
10271   %}
10272 
10273   ins_pipe(ialu_reg_reg);
10274 %}
10275 
10276 // No constant pool entries requiredLong Immediate Addition.
10277 instruct addL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10278   match(Set dst (AddL src1 src2));
10279 
10280   ins_cost(INSN_COST);
10281   format %{ &quot;add $dst, $src1, $src2&quot; %}
10282 
10283   // use opcode to indicate that this is an add not a sub
10284   opcode(0x0);
10285 
10286   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10287 
10288   ins_pipe(ialu_reg_imm);
10289 %}
10290 
10291 // Integer Subtraction
10292 instruct subI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10293   match(Set dst (SubI src1 src2));
10294 
10295   ins_cost(INSN_COST);
10296   format %{ &quot;subw  $dst, $src1, $src2&quot; %}
10297 
10298   ins_encode %{
10299     __ subw(as_Register($dst$$reg),
10300             as_Register($src1$$reg),
10301             as_Register($src2$$reg));
10302   %}
10303 
10304   ins_pipe(ialu_reg_reg);
10305 %}
10306 
10307 // Immediate Subtraction
10308 instruct subI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immIAddSub src2) %{
10309   match(Set dst (SubI src1 src2));
10310 
10311   ins_cost(INSN_COST);
10312   format %{ &quot;subw $dst, $src1, $src2&quot; %}
10313 
10314   // use opcode to indicate that this is a sub not an add
10315   opcode(0x1);
10316 
10317   ins_encode(aarch64_enc_addsubw_imm(dst, src1, src2));
10318 
10319   ins_pipe(ialu_reg_imm);
10320 %}
10321 
10322 // Long Subtraction
10323 instruct subL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10324 
10325   match(Set dst (SubL src1 src2));
10326 
10327   ins_cost(INSN_COST);
10328   format %{ &quot;sub  $dst, $src1, $src2&quot; %}
10329 
10330   ins_encode %{
10331     __ sub(as_Register($dst$$reg),
10332            as_Register($src1$$reg),
10333            as_Register($src2$$reg));
10334   %}
10335 
10336   ins_pipe(ialu_reg_reg);
10337 %}
10338 
10339 // No constant pool entries requiredLong Immediate Subtraction.
10340 instruct subL_reg_imm(iRegLNoSp dst, iRegL src1, immLAddSub src2) %{
10341   match(Set dst (SubL src1 src2));
10342 
10343   ins_cost(INSN_COST);
10344   format %{ &quot;sub$dst, $src1, $src2&quot; %}
10345 
10346   // use opcode to indicate that this is a sub not an add
10347   opcode(0x1);
10348 
10349   ins_encode( aarch64_enc_addsub_imm(dst, src1, src2) );
10350 
10351   ins_pipe(ialu_reg_imm);
10352 %}
10353 
10354 // Integer Negation (special case for sub)
10355 
10356 instruct negI_reg(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr) %{
10357   match(Set dst (SubI zero src));
10358 
10359   ins_cost(INSN_COST);
10360   format %{ &quot;negw $dst, $src\t# int&quot; %}
10361 
10362   ins_encode %{
10363     __ negw(as_Register($dst$$reg),
10364             as_Register($src$$reg));
10365   %}
10366 
10367   ins_pipe(ialu_reg);
10368 %}
10369 
10370 // Long Negation
10371 
10372 instruct negL_reg(iRegLNoSp dst, iRegL src, immL0 zero, rFlagsReg cr) %{
10373   match(Set dst (SubL zero src));
10374 
10375   ins_cost(INSN_COST);
10376   format %{ &quot;neg $dst, $src\t# long&quot; %}
10377 
10378   ins_encode %{
10379     __ neg(as_Register($dst$$reg),
10380            as_Register($src$$reg));
10381   %}
10382 
10383   ins_pipe(ialu_reg);
10384 %}
10385 
10386 // Integer Multiply
10387 
10388 instruct mulI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10389   match(Set dst (MulI src1 src2));
10390 
10391   ins_cost(INSN_COST * 3);
10392   format %{ &quot;mulw  $dst, $src1, $src2&quot; %}
10393 
10394   ins_encode %{
10395     __ mulw(as_Register($dst$$reg),
10396             as_Register($src1$$reg),
10397             as_Register($src2$$reg));
10398   %}
10399 
10400   ins_pipe(imul_reg_reg);
10401 %}
10402 
10403 instruct smulI(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10404   match(Set dst (MulL (ConvI2L src1) (ConvI2L src2)));
10405 
10406   ins_cost(INSN_COST * 3);
10407   format %{ &quot;smull  $dst, $src1, $src2&quot; %}
10408 
10409   ins_encode %{
10410     __ smull(as_Register($dst$$reg),
10411              as_Register($src1$$reg),
10412              as_Register($src2$$reg));
10413   %}
10414 
10415   ins_pipe(imul_reg_reg);
10416 %}
10417 
10418 // Long Multiply
10419 
10420 instruct mulL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10421   match(Set dst (MulL src1 src2));
10422 
10423   ins_cost(INSN_COST * 5);
10424   format %{ &quot;mul  $dst, $src1, $src2&quot; %}
10425 
10426   ins_encode %{
10427     __ mul(as_Register($dst$$reg),
10428            as_Register($src1$$reg),
10429            as_Register($src2$$reg));
10430   %}
10431 
10432   ins_pipe(lmul_reg_reg);
10433 %}
10434 
10435 instruct mulHiL_rReg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr)
10436 %{
10437   match(Set dst (MulHiL src1 src2));
10438 
10439   ins_cost(INSN_COST * 7);
10440   format %{ &quot;smulh   $dst, $src1, $src2, \t# mulhi&quot; %}
10441 
10442   ins_encode %{
10443     __ smulh(as_Register($dst$$reg),
10444              as_Register($src1$$reg),
10445              as_Register($src2$$reg));
10446   %}
10447 
10448   ins_pipe(lmul_reg_reg);
10449 %}
10450 
10451 // Combined Integer Multiply &amp; Add/Sub
10452 
10453 instruct maddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10454   match(Set dst (AddI src3 (MulI src1 src2)));
10455 
10456   ins_cost(INSN_COST * 3);
10457   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10458 
10459   ins_encode %{
10460     __ maddw(as_Register($dst$$reg),
10461              as_Register($src1$$reg),
10462              as_Register($src2$$reg),
10463              as_Register($src3$$reg));
10464   %}
10465 
10466   ins_pipe(imac_reg_reg);
10467 %}
10468 
10469 instruct msubI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3) %{
10470   match(Set dst (SubI src3 (MulI src1 src2)));
10471 
10472   ins_cost(INSN_COST * 3);
10473   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10474 
10475   ins_encode %{
10476     __ msubw(as_Register($dst$$reg),
10477              as_Register($src1$$reg),
10478              as_Register($src2$$reg),
10479              as_Register($src3$$reg));
10480   %}
10481 
10482   ins_pipe(imac_reg_reg);
10483 %}
10484 
10485 // Combined Integer Multiply &amp; Neg
10486 
10487 instruct mnegI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI0 zero) %{
10488   match(Set dst (MulI (SubI zero src1) src2));
10489   match(Set dst (MulI src1 (SubI zero src2)));
10490 
10491   ins_cost(INSN_COST * 3);
10492   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10493 
10494   ins_encode %{
10495     __ mnegw(as_Register($dst$$reg),
10496              as_Register($src1$$reg),
10497              as_Register($src2$$reg));
10498   %}
10499 
10500   ins_pipe(imac_reg_reg);
10501 %}
10502 
10503 // Combined Long Multiply &amp; Add/Sub
10504 
10505 instruct maddL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10506   match(Set dst (AddL src3 (MulL src1 src2)));
10507 
10508   ins_cost(INSN_COST * 5);
10509   format %{ &quot;madd  $dst, $src1, $src2, $src3&quot; %}
10510 
10511   ins_encode %{
10512     __ madd(as_Register($dst$$reg),
10513             as_Register($src1$$reg),
10514             as_Register($src2$$reg),
10515             as_Register($src3$$reg));
10516   %}
10517 
10518   ins_pipe(lmac_reg_reg);
10519 %}
10520 
10521 instruct msubL(iRegLNoSp dst, iRegL src1, iRegL src2, iRegL src3) %{
10522   match(Set dst (SubL src3 (MulL src1 src2)));
10523 
10524   ins_cost(INSN_COST * 5);
10525   format %{ &quot;msub  $dst, $src1, $src2, $src3&quot; %}
10526 
10527   ins_encode %{
10528     __ msub(as_Register($dst$$reg),
10529             as_Register($src1$$reg),
10530             as_Register($src2$$reg),
10531             as_Register($src3$$reg));
10532   %}
10533 
10534   ins_pipe(lmac_reg_reg);
10535 %}
10536 
10537 // Combined Long Multiply &amp; Neg
10538 
10539 instruct mnegL(iRegLNoSp dst, iRegL src1, iRegL src2, immL0 zero) %{
10540   match(Set dst (MulL (SubL zero src1) src2));
10541   match(Set dst (MulL src1 (SubL zero src2)));
10542 
10543   ins_cost(INSN_COST * 5);
10544   format %{ &quot;mneg  $dst, $src1, $src2&quot; %}
10545 
10546   ins_encode %{
10547     __ mneg(as_Register($dst$$reg),
10548             as_Register($src1$$reg),
10549             as_Register($src2$$reg));
10550   %}
10551 
10552   ins_pipe(lmac_reg_reg);
10553 %}
10554 
10555 // Combine Integer Signed Multiply &amp; Add/Sub/Neg Long
10556 
10557 instruct smaddL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10558   match(Set dst (AddL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10559 
10560   ins_cost(INSN_COST * 3);
10561   format %{ &quot;smaddl  $dst, $src1, $src2, $src3&quot; %}
10562 
10563   ins_encode %{
10564     __ smaddl(as_Register($dst$$reg),
10565               as_Register($src1$$reg),
10566               as_Register($src2$$reg),
10567               as_Register($src3$$reg));
10568   %}
10569 
10570   ins_pipe(imac_reg_reg);
10571 %}
10572 
10573 instruct smsubL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegLNoSp src3) %{
10574   match(Set dst (SubL src3 (MulL (ConvI2L src1) (ConvI2L src2))));
10575 
10576   ins_cost(INSN_COST * 3);
10577   format %{ &quot;smsubl  $dst, $src1, $src2, $src3&quot; %}
10578 
10579   ins_encode %{
10580     __ smsubl(as_Register($dst$$reg),
10581               as_Register($src1$$reg),
10582               as_Register($src2$$reg),
10583               as_Register($src3$$reg));
10584   %}
10585 
10586   ins_pipe(imac_reg_reg);
10587 %}
10588 
10589 instruct smnegL(iRegLNoSp dst, iRegIorL2I src1, iRegIorL2I src2, immL0 zero) %{
10590   match(Set dst (MulL (SubL zero (ConvI2L src1)) (ConvI2L src2)));
10591   match(Set dst (MulL (ConvI2L src1) (SubL zero (ConvI2L src2))));
10592 
10593   ins_cost(INSN_COST * 3);
10594   format %{ &quot;smnegl  $dst, $src1, $src2&quot; %}
10595 
10596   ins_encode %{
10597     __ smnegl(as_Register($dst$$reg),
10598               as_Register($src1$$reg),
10599               as_Register($src2$$reg));
10600   %}
10601 
10602   ins_pipe(imac_reg_reg);
10603 %}
10604 
10605 // Combined Multiply-Add Shorts into Integer (dst = src1 * src2 + src3 * src4)
10606 
10607 instruct muladdS2I(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, iRegIorL2I src3, iRegIorL2I src4) %{
10608   match(Set dst (MulAddS2I (Binary src1 src2) (Binary src3 src4)));
10609 
10610   ins_cost(INSN_COST * 5);
10611   format %{ &quot;mulw  rscratch1, $src1, $src2\n\t&quot;
10612             &quot;maddw $dst, $src3, $src4, rscratch1&quot; %}
10613 
10614   ins_encode %{
10615     __ mulw(rscratch1, as_Register($src1$$reg), as_Register($src2$$reg));
10616     __ maddw(as_Register($dst$$reg), as_Register($src3$$reg), as_Register($src4$$reg), rscratch1); %}
10617 
10618   ins_pipe(imac_reg_reg);
10619 %}
10620 
10621 // Integer Divide
10622 
10623 instruct divI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10624   match(Set dst (DivI src1 src2));
10625 
10626   ins_cost(INSN_COST * 19);
10627   format %{ &quot;sdivw  $dst, $src1, $src2&quot; %}
10628 
10629   ins_encode(aarch64_enc_divw(dst, src1, src2));
10630   ins_pipe(idiv_reg_reg);
10631 %}
10632 
10633 // Long Divide
10634 
10635 instruct divL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10636   match(Set dst (DivL src1 src2));
10637 
10638   ins_cost(INSN_COST * 35);
10639   format %{ &quot;sdiv   $dst, $src1, $src2&quot; %}
10640 
10641   ins_encode(aarch64_enc_div(dst, src1, src2));
10642   ins_pipe(ldiv_reg_reg);
10643 %}
10644 
10645 // Integer Remainder
10646 
10647 instruct modI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10648   match(Set dst (ModI src1 src2));
10649 
10650   ins_cost(INSN_COST * 22);
10651   format %{ &quot;sdivw  rscratch1, $src1, $src2\n\t&quot;
10652             &quot;msubw($dst, rscratch1, $src2, $src1&quot; %}
10653 
10654   ins_encode(aarch64_enc_modw(dst, src1, src2));
10655   ins_pipe(idiv_reg_reg);
10656 %}
10657 
10658 // Long Remainder
10659 
10660 instruct modL(iRegLNoSp dst, iRegL src1, iRegL src2) %{
10661   match(Set dst (ModL src1 src2));
10662 
10663   ins_cost(INSN_COST * 38);
10664   format %{ &quot;sdiv   rscratch1, $src1, $src2\n&quot;
10665             &quot;msub($dst, rscratch1, $src2, $src1&quot; %}
10666 
10667   ins_encode(aarch64_enc_mod(dst, src1, src2));
10668   ins_pipe(ldiv_reg_reg);
10669 %}
10670 
10671 // Integer Shifts
10672 
10673 // Shift Left Register
10674 instruct lShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10675   match(Set dst (LShiftI src1 src2));
10676 
10677   ins_cost(INSN_COST * 2);
10678   format %{ &quot;lslvw  $dst, $src1, $src2&quot; %}
10679 
10680   ins_encode %{
10681     __ lslvw(as_Register($dst$$reg),
10682              as_Register($src1$$reg),
10683              as_Register($src2$$reg));
10684   %}
10685 
10686   ins_pipe(ialu_reg_reg_vshift);
10687 %}
10688 
10689 // Shift Left Immediate
10690 instruct lShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10691   match(Set dst (LShiftI src1 src2));
10692 
10693   ins_cost(INSN_COST);
10694   format %{ &quot;lslw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10695 
10696   ins_encode %{
10697     __ lslw(as_Register($dst$$reg),
10698             as_Register($src1$$reg),
10699             $src2$$constant &amp; 0x1f);
10700   %}
10701 
10702   ins_pipe(ialu_reg_shift);
10703 %}
10704 
10705 // Shift Right Logical Register
10706 instruct urShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10707   match(Set dst (URShiftI src1 src2));
10708 
10709   ins_cost(INSN_COST * 2);
10710   format %{ &quot;lsrvw  $dst, $src1, $src2&quot; %}
10711 
10712   ins_encode %{
10713     __ lsrvw(as_Register($dst$$reg),
10714              as_Register($src1$$reg),
10715              as_Register($src2$$reg));
10716   %}
10717 
10718   ins_pipe(ialu_reg_reg_vshift);
10719 %}
10720 
10721 // Shift Right Logical Immediate
10722 instruct urShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10723   match(Set dst (URShiftI src1 src2));
10724 
10725   ins_cost(INSN_COST);
10726   format %{ &quot;lsrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10727 
10728   ins_encode %{
10729     __ lsrw(as_Register($dst$$reg),
10730             as_Register($src1$$reg),
10731             $src2$$constant &amp; 0x1f);
10732   %}
10733 
10734   ins_pipe(ialu_reg_shift);
10735 %}
10736 
10737 // Shift Right Arithmetic Register
10738 instruct rShiftI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
10739   match(Set dst (RShiftI src1 src2));
10740 
10741   ins_cost(INSN_COST * 2);
10742   format %{ &quot;asrvw  $dst, $src1, $src2&quot; %}
10743 
10744   ins_encode %{
10745     __ asrvw(as_Register($dst$$reg),
10746              as_Register($src1$$reg),
10747              as_Register($src2$$reg));
10748   %}
10749 
10750   ins_pipe(ialu_reg_reg_vshift);
10751 %}
10752 
10753 // Shift Right Arithmetic Immediate
10754 instruct rShiftI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immI src2) %{
10755   match(Set dst (RShiftI src1 src2));
10756 
10757   ins_cost(INSN_COST);
10758   format %{ &quot;asrw $dst, $src1, ($src2 &amp; 0x1f)&quot; %}
10759 
10760   ins_encode %{
10761     __ asrw(as_Register($dst$$reg),
10762             as_Register($src1$$reg),
10763             $src2$$constant &amp; 0x1f);
10764   %}
10765 
10766   ins_pipe(ialu_reg_shift);
10767 %}
10768 
10769 // Combined Int Mask and Right Shift (using UBFM)
10770 // TODO
10771 
10772 // Long Shifts
10773 
10774 // Shift Left Register
10775 instruct lShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10776   match(Set dst (LShiftL src1 src2));
10777 
10778   ins_cost(INSN_COST * 2);
10779   format %{ &quot;lslv  $dst, $src1, $src2&quot; %}
10780 
10781   ins_encode %{
10782     __ lslv(as_Register($dst$$reg),
10783             as_Register($src1$$reg),
10784             as_Register($src2$$reg));
10785   %}
10786 
10787   ins_pipe(ialu_reg_reg_vshift);
10788 %}
10789 
10790 // Shift Left Immediate
10791 instruct lShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10792   match(Set dst (LShiftL src1 src2));
10793 
10794   ins_cost(INSN_COST);
10795   format %{ &quot;lsl $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10796 
10797   ins_encode %{
10798     __ lsl(as_Register($dst$$reg),
10799             as_Register($src1$$reg),
10800             $src2$$constant &amp; 0x3f);
10801   %}
10802 
10803   ins_pipe(ialu_reg_shift);
10804 %}
10805 
10806 // Shift Right Logical Register
10807 instruct urShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10808   match(Set dst (URShiftL src1 src2));
10809 
10810   ins_cost(INSN_COST * 2);
10811   format %{ &quot;lsrv  $dst, $src1, $src2&quot; %}
10812 
10813   ins_encode %{
10814     __ lsrv(as_Register($dst$$reg),
10815             as_Register($src1$$reg),
10816             as_Register($src2$$reg));
10817   %}
10818 
10819   ins_pipe(ialu_reg_reg_vshift);
10820 %}
10821 
10822 // Shift Right Logical Immediate
10823 instruct urShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10824   match(Set dst (URShiftL src1 src2));
10825 
10826   ins_cost(INSN_COST);
10827   format %{ &quot;lsr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10828 
10829   ins_encode %{
10830     __ lsr(as_Register($dst$$reg),
10831            as_Register($src1$$reg),
10832            $src2$$constant &amp; 0x3f);
10833   %}
10834 
10835   ins_pipe(ialu_reg_shift);
10836 %}
10837 
10838 // A special-case pattern for card table stores.
10839 instruct urShiftP_reg_imm(iRegLNoSp dst, iRegP src1, immI src2) %{
10840   match(Set dst (URShiftL (CastP2X src1) src2));
10841 
10842   ins_cost(INSN_COST);
10843   format %{ &quot;lsr $dst, p2x($src1), ($src2 &amp; 0x3f)&quot; %}
10844 
10845   ins_encode %{
10846     __ lsr(as_Register($dst$$reg),
10847            as_Register($src1$$reg),
10848            $src2$$constant &amp; 0x3f);
10849   %}
10850 
10851   ins_pipe(ialu_reg_shift);
10852 %}
10853 
10854 // Shift Right Arithmetic Register
10855 instruct rShiftL_reg_reg(iRegLNoSp dst, iRegL src1, iRegIorL2I src2) %{
10856   match(Set dst (RShiftL src1 src2));
10857 
10858   ins_cost(INSN_COST * 2);
10859   format %{ &quot;asrv  $dst, $src1, $src2&quot; %}
10860 
10861   ins_encode %{
10862     __ asrv(as_Register($dst$$reg),
10863             as_Register($src1$$reg),
10864             as_Register($src2$$reg));
10865   %}
10866 
10867   ins_pipe(ialu_reg_reg_vshift);
10868 %}
10869 
10870 // Shift Right Arithmetic Immediate
10871 instruct rShiftL_reg_imm(iRegLNoSp dst, iRegL src1, immI src2) %{
10872   match(Set dst (RShiftL src1 src2));
10873 
10874   ins_cost(INSN_COST);
10875   format %{ &quot;asr $dst, $src1, ($src2 &amp; 0x3f)&quot; %}
10876 
10877   ins_encode %{
10878     __ asr(as_Register($dst$$reg),
10879            as_Register($src1$$reg),
10880            $src2$$constant &amp; 0x3f);
10881   %}
10882 
10883   ins_pipe(ialu_reg_shift);
10884 %}
10885 
10886 // BEGIN This section of the file is automatically generated. Do not edit --------------
10887 
10888 instruct regL_not_reg(iRegLNoSp dst,
10889                          iRegL src1, immL_M1 m1,
10890                          rFlagsReg cr) %{
10891   match(Set dst (XorL src1 m1));
10892   ins_cost(INSN_COST);
10893   format %{ &quot;eon  $dst, $src1, zr&quot; %}
10894 
10895   ins_encode %{
10896     __ eon(as_Register($dst$$reg),
10897               as_Register($src1$$reg),
10898               zr,
10899               Assembler::LSL, 0);
10900   %}
10901 
10902   ins_pipe(ialu_reg);
10903 %}
10904 instruct regI_not_reg(iRegINoSp dst,
10905                          iRegIorL2I src1, immI_M1 m1,
10906                          rFlagsReg cr) %{
10907   match(Set dst (XorI src1 m1));
10908   ins_cost(INSN_COST);
10909   format %{ &quot;eonw  $dst, $src1, zr&quot; %}
10910 
10911   ins_encode %{
10912     __ eonw(as_Register($dst$$reg),
10913               as_Register($src1$$reg),
10914               zr,
10915               Assembler::LSL, 0);
10916   %}
10917 
10918   ins_pipe(ialu_reg);
10919 %}
10920 
10921 instruct AndI_reg_not_reg(iRegINoSp dst,
10922                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10923                          rFlagsReg cr) %{
10924   match(Set dst (AndI src1 (XorI src2 m1)));
10925   ins_cost(INSN_COST);
10926   format %{ &quot;bicw  $dst, $src1, $src2&quot; %}
10927 
10928   ins_encode %{
10929     __ bicw(as_Register($dst$$reg),
10930               as_Register($src1$$reg),
10931               as_Register($src2$$reg),
10932               Assembler::LSL, 0);
10933   %}
10934 
10935   ins_pipe(ialu_reg_reg);
10936 %}
10937 
10938 instruct AndL_reg_not_reg(iRegLNoSp dst,
10939                          iRegL src1, iRegL src2, immL_M1 m1,
10940                          rFlagsReg cr) %{
10941   match(Set dst (AndL src1 (XorL src2 m1)));
10942   ins_cost(INSN_COST);
10943   format %{ &quot;bic  $dst, $src1, $src2&quot; %}
10944 
10945   ins_encode %{
10946     __ bic(as_Register($dst$$reg),
10947               as_Register($src1$$reg),
10948               as_Register($src2$$reg),
10949               Assembler::LSL, 0);
10950   %}
10951 
10952   ins_pipe(ialu_reg_reg);
10953 %}
10954 
10955 instruct OrI_reg_not_reg(iRegINoSp dst,
10956                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10957                          rFlagsReg cr) %{
10958   match(Set dst (OrI src1 (XorI src2 m1)));
10959   ins_cost(INSN_COST);
10960   format %{ &quot;ornw  $dst, $src1, $src2&quot; %}
10961 
10962   ins_encode %{
10963     __ ornw(as_Register($dst$$reg),
10964               as_Register($src1$$reg),
10965               as_Register($src2$$reg),
10966               Assembler::LSL, 0);
10967   %}
10968 
10969   ins_pipe(ialu_reg_reg);
10970 %}
10971 
10972 instruct OrL_reg_not_reg(iRegLNoSp dst,
10973                          iRegL src1, iRegL src2, immL_M1 m1,
10974                          rFlagsReg cr) %{
10975   match(Set dst (OrL src1 (XorL src2 m1)));
10976   ins_cost(INSN_COST);
10977   format %{ &quot;orn  $dst, $src1, $src2&quot; %}
10978 
10979   ins_encode %{
10980     __ orn(as_Register($dst$$reg),
10981               as_Register($src1$$reg),
10982               as_Register($src2$$reg),
10983               Assembler::LSL, 0);
10984   %}
10985 
10986   ins_pipe(ialu_reg_reg);
10987 %}
10988 
10989 instruct XorI_reg_not_reg(iRegINoSp dst,
10990                          iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,
10991                          rFlagsReg cr) %{
10992   match(Set dst (XorI m1 (XorI src2 src1)));
10993   ins_cost(INSN_COST);
10994   format %{ &quot;eonw  $dst, $src1, $src2&quot; %}
10995 
10996   ins_encode %{
10997     __ eonw(as_Register($dst$$reg),
10998               as_Register($src1$$reg),
10999               as_Register($src2$$reg),
11000               Assembler::LSL, 0);
11001   %}
11002 
11003   ins_pipe(ialu_reg_reg);
11004 %}
11005 
11006 instruct XorL_reg_not_reg(iRegLNoSp dst,
11007                          iRegL src1, iRegL src2, immL_M1 m1,
11008                          rFlagsReg cr) %{
11009   match(Set dst (XorL m1 (XorL src2 src1)));
11010   ins_cost(INSN_COST);
11011   format %{ &quot;eon  $dst, $src1, $src2&quot; %}
11012 
11013   ins_encode %{
11014     __ eon(as_Register($dst$$reg),
11015               as_Register($src1$$reg),
11016               as_Register($src2$$reg),
11017               Assembler::LSL, 0);
11018   %}
11019 
11020   ins_pipe(ialu_reg_reg);
11021 %}
11022 
11023 instruct AndI_reg_URShift_not_reg(iRegINoSp dst,
11024                          iRegIorL2I src1, iRegIorL2I src2,
11025                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11026   match(Set dst (AndI src1 (XorI(URShiftI src2 src3) src4)));
11027   ins_cost(1.9 * INSN_COST);
11028   format %{ &quot;bicw  $dst, $src1, $src2, LSR $src3&quot; %}
11029 
11030   ins_encode %{
11031     __ bicw(as_Register($dst$$reg),
11032               as_Register($src1$$reg),
11033               as_Register($src2$$reg),
11034               Assembler::LSR,
11035               $src3$$constant &amp; 0x1f);
11036   %}
11037 
11038   ins_pipe(ialu_reg_reg_shift);
11039 %}
11040 
11041 instruct AndL_reg_URShift_not_reg(iRegLNoSp dst,
11042                          iRegL src1, iRegL src2,
11043                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11044   match(Set dst (AndL src1 (XorL(URShiftL src2 src3) src4)));
11045   ins_cost(1.9 * INSN_COST);
11046   format %{ &quot;bic  $dst, $src1, $src2, LSR $src3&quot; %}
11047 
11048   ins_encode %{
11049     __ bic(as_Register($dst$$reg),
11050               as_Register($src1$$reg),
11051               as_Register($src2$$reg),
11052               Assembler::LSR,
11053               $src3$$constant &amp; 0x3f);
11054   %}
11055 
11056   ins_pipe(ialu_reg_reg_shift);
11057 %}
11058 
11059 instruct AndI_reg_RShift_not_reg(iRegINoSp dst,
11060                          iRegIorL2I src1, iRegIorL2I src2,
11061                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11062   match(Set dst (AndI src1 (XorI(RShiftI src2 src3) src4)));
11063   ins_cost(1.9 * INSN_COST);
11064   format %{ &quot;bicw  $dst, $src1, $src2, ASR $src3&quot; %}
11065 
11066   ins_encode %{
11067     __ bicw(as_Register($dst$$reg),
11068               as_Register($src1$$reg),
11069               as_Register($src2$$reg),
11070               Assembler::ASR,
11071               $src3$$constant &amp; 0x1f);
11072   %}
11073 
11074   ins_pipe(ialu_reg_reg_shift);
11075 %}
11076 
11077 instruct AndL_reg_RShift_not_reg(iRegLNoSp dst,
11078                          iRegL src1, iRegL src2,
11079                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11080   match(Set dst (AndL src1 (XorL(RShiftL src2 src3) src4)));
11081   ins_cost(1.9 * INSN_COST);
11082   format %{ &quot;bic  $dst, $src1, $src2, ASR $src3&quot; %}
11083 
11084   ins_encode %{
11085     __ bic(as_Register($dst$$reg),
11086               as_Register($src1$$reg),
11087               as_Register($src2$$reg),
11088               Assembler::ASR,
11089               $src3$$constant &amp; 0x3f);
11090   %}
11091 
11092   ins_pipe(ialu_reg_reg_shift);
11093 %}
11094 
11095 instruct AndI_reg_LShift_not_reg(iRegINoSp dst,
11096                          iRegIorL2I src1, iRegIorL2I src2,
11097                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11098   match(Set dst (AndI src1 (XorI(LShiftI src2 src3) src4)));
11099   ins_cost(1.9 * INSN_COST);
11100   format %{ &quot;bicw  $dst, $src1, $src2, LSL $src3&quot; %}
11101 
11102   ins_encode %{
11103     __ bicw(as_Register($dst$$reg),
11104               as_Register($src1$$reg),
11105               as_Register($src2$$reg),
11106               Assembler::LSL,
11107               $src3$$constant &amp; 0x1f);
11108   %}
11109 
11110   ins_pipe(ialu_reg_reg_shift);
11111 %}
11112 
11113 instruct AndL_reg_LShift_not_reg(iRegLNoSp dst,
11114                          iRegL src1, iRegL src2,
11115                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11116   match(Set dst (AndL src1 (XorL(LShiftL src2 src3) src4)));
11117   ins_cost(1.9 * INSN_COST);
11118   format %{ &quot;bic  $dst, $src1, $src2, LSL $src3&quot; %}
11119 
11120   ins_encode %{
11121     __ bic(as_Register($dst$$reg),
11122               as_Register($src1$$reg),
11123               as_Register($src2$$reg),
11124               Assembler::LSL,
11125               $src3$$constant &amp; 0x3f);
11126   %}
11127 
11128   ins_pipe(ialu_reg_reg_shift);
11129 %}
11130 
11131 instruct XorI_reg_URShift_not_reg(iRegINoSp dst,
11132                          iRegIorL2I src1, iRegIorL2I src2,
11133                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11134   match(Set dst (XorI src4 (XorI(URShiftI src2 src3) src1)));
11135   ins_cost(1.9 * INSN_COST);
11136   format %{ &quot;eonw  $dst, $src1, $src2, LSR $src3&quot; %}
11137 
11138   ins_encode %{
11139     __ eonw(as_Register($dst$$reg),
11140               as_Register($src1$$reg),
11141               as_Register($src2$$reg),
11142               Assembler::LSR,
11143               $src3$$constant &amp; 0x1f);
11144   %}
11145 
11146   ins_pipe(ialu_reg_reg_shift);
11147 %}
11148 
11149 instruct XorL_reg_URShift_not_reg(iRegLNoSp dst,
11150                          iRegL src1, iRegL src2,
11151                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11152   match(Set dst (XorL src4 (XorL(URShiftL src2 src3) src1)));
11153   ins_cost(1.9 * INSN_COST);
11154   format %{ &quot;eon  $dst, $src1, $src2, LSR $src3&quot; %}
11155 
11156   ins_encode %{
11157     __ eon(as_Register($dst$$reg),
11158               as_Register($src1$$reg),
11159               as_Register($src2$$reg),
11160               Assembler::LSR,
11161               $src3$$constant &amp; 0x3f);
11162   %}
11163 
11164   ins_pipe(ialu_reg_reg_shift);
11165 %}
11166 
11167 instruct XorI_reg_RShift_not_reg(iRegINoSp dst,
11168                          iRegIorL2I src1, iRegIorL2I src2,
11169                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11170   match(Set dst (XorI src4 (XorI(RShiftI src2 src3) src1)));
11171   ins_cost(1.9 * INSN_COST);
11172   format %{ &quot;eonw  $dst, $src1, $src2, ASR $src3&quot; %}
11173 
11174   ins_encode %{
11175     __ eonw(as_Register($dst$$reg),
11176               as_Register($src1$$reg),
11177               as_Register($src2$$reg),
11178               Assembler::ASR,
11179               $src3$$constant &amp; 0x1f);
11180   %}
11181 
11182   ins_pipe(ialu_reg_reg_shift);
11183 %}
11184 
11185 instruct XorL_reg_RShift_not_reg(iRegLNoSp dst,
11186                          iRegL src1, iRegL src2,
11187                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11188   match(Set dst (XorL src4 (XorL(RShiftL src2 src3) src1)));
11189   ins_cost(1.9 * INSN_COST);
11190   format %{ &quot;eon  $dst, $src1, $src2, ASR $src3&quot; %}
11191 
11192   ins_encode %{
11193     __ eon(as_Register($dst$$reg),
11194               as_Register($src1$$reg),
11195               as_Register($src2$$reg),
11196               Assembler::ASR,
11197               $src3$$constant &amp; 0x3f);
11198   %}
11199 
11200   ins_pipe(ialu_reg_reg_shift);
11201 %}
11202 
11203 instruct XorI_reg_LShift_not_reg(iRegINoSp dst,
11204                          iRegIorL2I src1, iRegIorL2I src2,
11205                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11206   match(Set dst (XorI src4 (XorI(LShiftI src2 src3) src1)));
11207   ins_cost(1.9 * INSN_COST);
11208   format %{ &quot;eonw  $dst, $src1, $src2, LSL $src3&quot; %}
11209 
11210   ins_encode %{
11211     __ eonw(as_Register($dst$$reg),
11212               as_Register($src1$$reg),
11213               as_Register($src2$$reg),
11214               Assembler::LSL,
11215               $src3$$constant &amp; 0x1f);
11216   %}
11217 
11218   ins_pipe(ialu_reg_reg_shift);
11219 %}
11220 
11221 instruct XorL_reg_LShift_not_reg(iRegLNoSp dst,
11222                          iRegL src1, iRegL src2,
11223                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11224   match(Set dst (XorL src4 (XorL(LShiftL src2 src3) src1)));
11225   ins_cost(1.9 * INSN_COST);
11226   format %{ &quot;eon  $dst, $src1, $src2, LSL $src3&quot; %}
11227 
11228   ins_encode %{
11229     __ eon(as_Register($dst$$reg),
11230               as_Register($src1$$reg),
11231               as_Register($src2$$reg),
11232               Assembler::LSL,
11233               $src3$$constant &amp; 0x3f);
11234   %}
11235 
11236   ins_pipe(ialu_reg_reg_shift);
11237 %}
11238 
11239 instruct OrI_reg_URShift_not_reg(iRegINoSp dst,
11240                          iRegIorL2I src1, iRegIorL2I src2,
11241                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11242   match(Set dst (OrI src1 (XorI(URShiftI src2 src3) src4)));
11243   ins_cost(1.9 * INSN_COST);
11244   format %{ &quot;ornw  $dst, $src1, $src2, LSR $src3&quot; %}
11245 
11246   ins_encode %{
11247     __ ornw(as_Register($dst$$reg),
11248               as_Register($src1$$reg),
11249               as_Register($src2$$reg),
11250               Assembler::LSR,
11251               $src3$$constant &amp; 0x1f);
11252   %}
11253 
11254   ins_pipe(ialu_reg_reg_shift);
11255 %}
11256 
11257 instruct OrL_reg_URShift_not_reg(iRegLNoSp dst,
11258                          iRegL src1, iRegL src2,
11259                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11260   match(Set dst (OrL src1 (XorL(URShiftL src2 src3) src4)));
11261   ins_cost(1.9 * INSN_COST);
11262   format %{ &quot;orn  $dst, $src1, $src2, LSR $src3&quot; %}
11263 
11264   ins_encode %{
11265     __ orn(as_Register($dst$$reg),
11266               as_Register($src1$$reg),
11267               as_Register($src2$$reg),
11268               Assembler::LSR,
11269               $src3$$constant &amp; 0x3f);
11270   %}
11271 
11272   ins_pipe(ialu_reg_reg_shift);
11273 %}
11274 
11275 instruct OrI_reg_RShift_not_reg(iRegINoSp dst,
11276                          iRegIorL2I src1, iRegIorL2I src2,
11277                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11278   match(Set dst (OrI src1 (XorI(RShiftI src2 src3) src4)));
11279   ins_cost(1.9 * INSN_COST);
11280   format %{ &quot;ornw  $dst, $src1, $src2, ASR $src3&quot; %}
11281 
11282   ins_encode %{
11283     __ ornw(as_Register($dst$$reg),
11284               as_Register($src1$$reg),
11285               as_Register($src2$$reg),
11286               Assembler::ASR,
11287               $src3$$constant &amp; 0x1f);
11288   %}
11289 
11290   ins_pipe(ialu_reg_reg_shift);
11291 %}
11292 
11293 instruct OrL_reg_RShift_not_reg(iRegLNoSp dst,
11294                          iRegL src1, iRegL src2,
11295                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11296   match(Set dst (OrL src1 (XorL(RShiftL src2 src3) src4)));
11297   ins_cost(1.9 * INSN_COST);
11298   format %{ &quot;orn  $dst, $src1, $src2, ASR $src3&quot; %}
11299 
11300   ins_encode %{
11301     __ orn(as_Register($dst$$reg),
11302               as_Register($src1$$reg),
11303               as_Register($src2$$reg),
11304               Assembler::ASR,
11305               $src3$$constant &amp; 0x3f);
11306   %}
11307 
11308   ins_pipe(ialu_reg_reg_shift);
11309 %}
11310 
11311 instruct OrI_reg_LShift_not_reg(iRegINoSp dst,
11312                          iRegIorL2I src1, iRegIorL2I src2,
11313                          immI src3, immI_M1 src4, rFlagsReg cr) %{
11314   match(Set dst (OrI src1 (XorI(LShiftI src2 src3) src4)));
11315   ins_cost(1.9 * INSN_COST);
11316   format %{ &quot;ornw  $dst, $src1, $src2, LSL $src3&quot; %}
11317 
11318   ins_encode %{
11319     __ ornw(as_Register($dst$$reg),
11320               as_Register($src1$$reg),
11321               as_Register($src2$$reg),
11322               Assembler::LSL,
11323               $src3$$constant &amp; 0x1f);
11324   %}
11325 
11326   ins_pipe(ialu_reg_reg_shift);
11327 %}
11328 
11329 instruct OrL_reg_LShift_not_reg(iRegLNoSp dst,
11330                          iRegL src1, iRegL src2,
11331                          immI src3, immL_M1 src4, rFlagsReg cr) %{
11332   match(Set dst (OrL src1 (XorL(LShiftL src2 src3) src4)));
11333   ins_cost(1.9 * INSN_COST);
11334   format %{ &quot;orn  $dst, $src1, $src2, LSL $src3&quot; %}
11335 
11336   ins_encode %{
11337     __ orn(as_Register($dst$$reg),
11338               as_Register($src1$$reg),
11339               as_Register($src2$$reg),
11340               Assembler::LSL,
11341               $src3$$constant &amp; 0x3f);
11342   %}
11343 
11344   ins_pipe(ialu_reg_reg_shift);
11345 %}
11346 
11347 instruct AndI_reg_URShift_reg(iRegINoSp dst,
11348                          iRegIorL2I src1, iRegIorL2I src2,
11349                          immI src3, rFlagsReg cr) %{
11350   match(Set dst (AndI src1 (URShiftI src2 src3)));
11351 
11352   ins_cost(1.9 * INSN_COST);
11353   format %{ &quot;andw  $dst, $src1, $src2, LSR $src3&quot; %}
11354 
11355   ins_encode %{
11356     __ andw(as_Register($dst$$reg),
11357               as_Register($src1$$reg),
11358               as_Register($src2$$reg),
11359               Assembler::LSR,
11360               $src3$$constant &amp; 0x1f);
11361   %}
11362 
11363   ins_pipe(ialu_reg_reg_shift);
11364 %}
11365 
11366 instruct AndL_reg_URShift_reg(iRegLNoSp dst,
11367                          iRegL src1, iRegL src2,
11368                          immI src3, rFlagsReg cr) %{
11369   match(Set dst (AndL src1 (URShiftL src2 src3)));
11370 
11371   ins_cost(1.9 * INSN_COST);
11372   format %{ &quot;andr  $dst, $src1, $src2, LSR $src3&quot; %}
11373 
11374   ins_encode %{
11375     __ andr(as_Register($dst$$reg),
11376               as_Register($src1$$reg),
11377               as_Register($src2$$reg),
11378               Assembler::LSR,
11379               $src3$$constant &amp; 0x3f);
11380   %}
11381 
11382   ins_pipe(ialu_reg_reg_shift);
11383 %}
11384 
11385 instruct AndI_reg_RShift_reg(iRegINoSp dst,
11386                          iRegIorL2I src1, iRegIorL2I src2,
11387                          immI src3, rFlagsReg cr) %{
11388   match(Set dst (AndI src1 (RShiftI src2 src3)));
11389 
11390   ins_cost(1.9 * INSN_COST);
11391   format %{ &quot;andw  $dst, $src1, $src2, ASR $src3&quot; %}
11392 
11393   ins_encode %{
11394     __ andw(as_Register($dst$$reg),
11395               as_Register($src1$$reg),
11396               as_Register($src2$$reg),
11397               Assembler::ASR,
11398               $src3$$constant &amp; 0x1f);
11399   %}
11400 
11401   ins_pipe(ialu_reg_reg_shift);
11402 %}
11403 
11404 instruct AndL_reg_RShift_reg(iRegLNoSp dst,
11405                          iRegL src1, iRegL src2,
11406                          immI src3, rFlagsReg cr) %{
11407   match(Set dst (AndL src1 (RShiftL src2 src3)));
11408 
11409   ins_cost(1.9 * INSN_COST);
11410   format %{ &quot;andr  $dst, $src1, $src2, ASR $src3&quot; %}
11411 
11412   ins_encode %{
11413     __ andr(as_Register($dst$$reg),
11414               as_Register($src1$$reg),
11415               as_Register($src2$$reg),
11416               Assembler::ASR,
11417               $src3$$constant &amp; 0x3f);
11418   %}
11419 
11420   ins_pipe(ialu_reg_reg_shift);
11421 %}
11422 
11423 instruct AndI_reg_LShift_reg(iRegINoSp dst,
11424                          iRegIorL2I src1, iRegIorL2I src2,
11425                          immI src3, rFlagsReg cr) %{
11426   match(Set dst (AndI src1 (LShiftI src2 src3)));
11427 
11428   ins_cost(1.9 * INSN_COST);
11429   format %{ &quot;andw  $dst, $src1, $src2, LSL $src3&quot; %}
11430 
11431   ins_encode %{
11432     __ andw(as_Register($dst$$reg),
11433               as_Register($src1$$reg),
11434               as_Register($src2$$reg),
11435               Assembler::LSL,
11436               $src3$$constant &amp; 0x1f);
11437   %}
11438 
11439   ins_pipe(ialu_reg_reg_shift);
11440 %}
11441 
11442 instruct AndL_reg_LShift_reg(iRegLNoSp dst,
11443                          iRegL src1, iRegL src2,
11444                          immI src3, rFlagsReg cr) %{
11445   match(Set dst (AndL src1 (LShiftL src2 src3)));
11446 
11447   ins_cost(1.9 * INSN_COST);
11448   format %{ &quot;andr  $dst, $src1, $src2, LSL $src3&quot; %}
11449 
11450   ins_encode %{
11451     __ andr(as_Register($dst$$reg),
11452               as_Register($src1$$reg),
11453               as_Register($src2$$reg),
11454               Assembler::LSL,
11455               $src3$$constant &amp; 0x3f);
11456   %}
11457 
11458   ins_pipe(ialu_reg_reg_shift);
11459 %}
11460 
11461 instruct XorI_reg_URShift_reg(iRegINoSp dst,
11462                          iRegIorL2I src1, iRegIorL2I src2,
11463                          immI src3, rFlagsReg cr) %{
11464   match(Set dst (XorI src1 (URShiftI src2 src3)));
11465 
11466   ins_cost(1.9 * INSN_COST);
11467   format %{ &quot;eorw  $dst, $src1, $src2, LSR $src3&quot; %}
11468 
11469   ins_encode %{
11470     __ eorw(as_Register($dst$$reg),
11471               as_Register($src1$$reg),
11472               as_Register($src2$$reg),
11473               Assembler::LSR,
11474               $src3$$constant &amp; 0x1f);
11475   %}
11476 
11477   ins_pipe(ialu_reg_reg_shift);
11478 %}
11479 
11480 instruct XorL_reg_URShift_reg(iRegLNoSp dst,
11481                          iRegL src1, iRegL src2,
11482                          immI src3, rFlagsReg cr) %{
11483   match(Set dst (XorL src1 (URShiftL src2 src3)));
11484 
11485   ins_cost(1.9 * INSN_COST);
11486   format %{ &quot;eor  $dst, $src1, $src2, LSR $src3&quot; %}
11487 
11488   ins_encode %{
11489     __ eor(as_Register($dst$$reg),
11490               as_Register($src1$$reg),
11491               as_Register($src2$$reg),
11492               Assembler::LSR,
11493               $src3$$constant &amp; 0x3f);
11494   %}
11495 
11496   ins_pipe(ialu_reg_reg_shift);
11497 %}
11498 
11499 instruct XorI_reg_RShift_reg(iRegINoSp dst,
11500                          iRegIorL2I src1, iRegIorL2I src2,
11501                          immI src3, rFlagsReg cr) %{
11502   match(Set dst (XorI src1 (RShiftI src2 src3)));
11503 
11504   ins_cost(1.9 * INSN_COST);
11505   format %{ &quot;eorw  $dst, $src1, $src2, ASR $src3&quot; %}
11506 
11507   ins_encode %{
11508     __ eorw(as_Register($dst$$reg),
11509               as_Register($src1$$reg),
11510               as_Register($src2$$reg),
11511               Assembler::ASR,
11512               $src3$$constant &amp; 0x1f);
11513   %}
11514 
11515   ins_pipe(ialu_reg_reg_shift);
11516 %}
11517 
11518 instruct XorL_reg_RShift_reg(iRegLNoSp dst,
11519                          iRegL src1, iRegL src2,
11520                          immI src3, rFlagsReg cr) %{
11521   match(Set dst (XorL src1 (RShiftL src2 src3)));
11522 
11523   ins_cost(1.9 * INSN_COST);
11524   format %{ &quot;eor  $dst, $src1, $src2, ASR $src3&quot; %}
11525 
11526   ins_encode %{
11527     __ eor(as_Register($dst$$reg),
11528               as_Register($src1$$reg),
11529               as_Register($src2$$reg),
11530               Assembler::ASR,
11531               $src3$$constant &amp; 0x3f);
11532   %}
11533 
11534   ins_pipe(ialu_reg_reg_shift);
11535 %}
11536 
11537 instruct XorI_reg_LShift_reg(iRegINoSp dst,
11538                          iRegIorL2I src1, iRegIorL2I src2,
11539                          immI src3, rFlagsReg cr) %{
11540   match(Set dst (XorI src1 (LShiftI src2 src3)));
11541 
11542   ins_cost(1.9 * INSN_COST);
11543   format %{ &quot;eorw  $dst, $src1, $src2, LSL $src3&quot; %}
11544 
11545   ins_encode %{
11546     __ eorw(as_Register($dst$$reg),
11547               as_Register($src1$$reg),
11548               as_Register($src2$$reg),
11549               Assembler::LSL,
11550               $src3$$constant &amp; 0x1f);
11551   %}
11552 
11553   ins_pipe(ialu_reg_reg_shift);
11554 %}
11555 
11556 instruct XorL_reg_LShift_reg(iRegLNoSp dst,
11557                          iRegL src1, iRegL src2,
11558                          immI src3, rFlagsReg cr) %{
11559   match(Set dst (XorL src1 (LShiftL src2 src3)));
11560 
11561   ins_cost(1.9 * INSN_COST);
11562   format %{ &quot;eor  $dst, $src1, $src2, LSL $src3&quot; %}
11563 
11564   ins_encode %{
11565     __ eor(as_Register($dst$$reg),
11566               as_Register($src1$$reg),
11567               as_Register($src2$$reg),
11568               Assembler::LSL,
11569               $src3$$constant &amp; 0x3f);
11570   %}
11571 
11572   ins_pipe(ialu_reg_reg_shift);
11573 %}
11574 
11575 instruct OrI_reg_URShift_reg(iRegINoSp dst,
11576                          iRegIorL2I src1, iRegIorL2I src2,
11577                          immI src3, rFlagsReg cr) %{
11578   match(Set dst (OrI src1 (URShiftI src2 src3)));
11579 
11580   ins_cost(1.9 * INSN_COST);
11581   format %{ &quot;orrw  $dst, $src1, $src2, LSR $src3&quot; %}
11582 
11583   ins_encode %{
11584     __ orrw(as_Register($dst$$reg),
11585               as_Register($src1$$reg),
11586               as_Register($src2$$reg),
11587               Assembler::LSR,
11588               $src3$$constant &amp; 0x1f);
11589   %}
11590 
11591   ins_pipe(ialu_reg_reg_shift);
11592 %}
11593 
11594 instruct OrL_reg_URShift_reg(iRegLNoSp dst,
11595                          iRegL src1, iRegL src2,
11596                          immI src3, rFlagsReg cr) %{
11597   match(Set dst (OrL src1 (URShiftL src2 src3)));
11598 
11599   ins_cost(1.9 * INSN_COST);
11600   format %{ &quot;orr  $dst, $src1, $src2, LSR $src3&quot; %}
11601 
11602   ins_encode %{
11603     __ orr(as_Register($dst$$reg),
11604               as_Register($src1$$reg),
11605               as_Register($src2$$reg),
11606               Assembler::LSR,
11607               $src3$$constant &amp; 0x3f);
11608   %}
11609 
11610   ins_pipe(ialu_reg_reg_shift);
11611 %}
11612 
11613 instruct OrI_reg_RShift_reg(iRegINoSp dst,
11614                          iRegIorL2I src1, iRegIorL2I src2,
11615                          immI src3, rFlagsReg cr) %{
11616   match(Set dst (OrI src1 (RShiftI src2 src3)));
11617 
11618   ins_cost(1.9 * INSN_COST);
11619   format %{ &quot;orrw  $dst, $src1, $src2, ASR $src3&quot; %}
11620 
11621   ins_encode %{
11622     __ orrw(as_Register($dst$$reg),
11623               as_Register($src1$$reg),
11624               as_Register($src2$$reg),
11625               Assembler::ASR,
11626               $src3$$constant &amp; 0x1f);
11627   %}
11628 
11629   ins_pipe(ialu_reg_reg_shift);
11630 %}
11631 
11632 instruct OrL_reg_RShift_reg(iRegLNoSp dst,
11633                          iRegL src1, iRegL src2,
11634                          immI src3, rFlagsReg cr) %{
11635   match(Set dst (OrL src1 (RShiftL src2 src3)));
11636 
11637   ins_cost(1.9 * INSN_COST);
11638   format %{ &quot;orr  $dst, $src1, $src2, ASR $src3&quot; %}
11639 
11640   ins_encode %{
11641     __ orr(as_Register($dst$$reg),
11642               as_Register($src1$$reg),
11643               as_Register($src2$$reg),
11644               Assembler::ASR,
11645               $src3$$constant &amp; 0x3f);
11646   %}
11647 
11648   ins_pipe(ialu_reg_reg_shift);
11649 %}
11650 
11651 instruct OrI_reg_LShift_reg(iRegINoSp dst,
11652                          iRegIorL2I src1, iRegIorL2I src2,
11653                          immI src3, rFlagsReg cr) %{
11654   match(Set dst (OrI src1 (LShiftI src2 src3)));
11655 
11656   ins_cost(1.9 * INSN_COST);
11657   format %{ &quot;orrw  $dst, $src1, $src2, LSL $src3&quot; %}
11658 
11659   ins_encode %{
11660     __ orrw(as_Register($dst$$reg),
11661               as_Register($src1$$reg),
11662               as_Register($src2$$reg),
11663               Assembler::LSL,
11664               $src3$$constant &amp; 0x1f);
11665   %}
11666 
11667   ins_pipe(ialu_reg_reg_shift);
11668 %}
11669 
11670 instruct OrL_reg_LShift_reg(iRegLNoSp dst,
11671                          iRegL src1, iRegL src2,
11672                          immI src3, rFlagsReg cr) %{
11673   match(Set dst (OrL src1 (LShiftL src2 src3)));
11674 
11675   ins_cost(1.9 * INSN_COST);
11676   format %{ &quot;orr  $dst, $src1, $src2, LSL $src3&quot; %}
11677 
11678   ins_encode %{
11679     __ orr(as_Register($dst$$reg),
11680               as_Register($src1$$reg),
11681               as_Register($src2$$reg),
11682               Assembler::LSL,
11683               $src3$$constant &amp; 0x3f);
11684   %}
11685 
11686   ins_pipe(ialu_reg_reg_shift);
11687 %}
11688 
11689 instruct AddI_reg_URShift_reg(iRegINoSp dst,
11690                          iRegIorL2I src1, iRegIorL2I src2,
11691                          immI src3, rFlagsReg cr) %{
11692   match(Set dst (AddI src1 (URShiftI src2 src3)));
11693 
11694   ins_cost(1.9 * INSN_COST);
11695   format %{ &quot;addw  $dst, $src1, $src2, LSR $src3&quot; %}
11696 
11697   ins_encode %{
11698     __ addw(as_Register($dst$$reg),
11699               as_Register($src1$$reg),
11700               as_Register($src2$$reg),
11701               Assembler::LSR,
11702               $src3$$constant &amp; 0x1f);
11703   %}
11704 
11705   ins_pipe(ialu_reg_reg_shift);
11706 %}
11707 
11708 instruct AddL_reg_URShift_reg(iRegLNoSp dst,
11709                          iRegL src1, iRegL src2,
11710                          immI src3, rFlagsReg cr) %{
11711   match(Set dst (AddL src1 (URShiftL src2 src3)));
11712 
11713   ins_cost(1.9 * INSN_COST);
11714   format %{ &quot;add  $dst, $src1, $src2, LSR $src3&quot; %}
11715 
11716   ins_encode %{
11717     __ add(as_Register($dst$$reg),
11718               as_Register($src1$$reg),
11719               as_Register($src2$$reg),
11720               Assembler::LSR,
11721               $src3$$constant &amp; 0x3f);
11722   %}
11723 
11724   ins_pipe(ialu_reg_reg_shift);
11725 %}
11726 
11727 instruct AddI_reg_RShift_reg(iRegINoSp dst,
11728                          iRegIorL2I src1, iRegIorL2I src2,
11729                          immI src3, rFlagsReg cr) %{
11730   match(Set dst (AddI src1 (RShiftI src2 src3)));
11731 
11732   ins_cost(1.9 * INSN_COST);
11733   format %{ &quot;addw  $dst, $src1, $src2, ASR $src3&quot; %}
11734 
11735   ins_encode %{
11736     __ addw(as_Register($dst$$reg),
11737               as_Register($src1$$reg),
11738               as_Register($src2$$reg),
11739               Assembler::ASR,
11740               $src3$$constant &amp; 0x1f);
11741   %}
11742 
11743   ins_pipe(ialu_reg_reg_shift);
11744 %}
11745 
11746 instruct AddL_reg_RShift_reg(iRegLNoSp dst,
11747                          iRegL src1, iRegL src2,
11748                          immI src3, rFlagsReg cr) %{
11749   match(Set dst (AddL src1 (RShiftL src2 src3)));
11750 
11751   ins_cost(1.9 * INSN_COST);
11752   format %{ &quot;add  $dst, $src1, $src2, ASR $src3&quot; %}
11753 
11754   ins_encode %{
11755     __ add(as_Register($dst$$reg),
11756               as_Register($src1$$reg),
11757               as_Register($src2$$reg),
11758               Assembler::ASR,
11759               $src3$$constant &amp; 0x3f);
11760   %}
11761 
11762   ins_pipe(ialu_reg_reg_shift);
11763 %}
11764 
11765 instruct AddI_reg_LShift_reg(iRegINoSp dst,
11766                          iRegIorL2I src1, iRegIorL2I src2,
11767                          immI src3, rFlagsReg cr) %{
11768   match(Set dst (AddI src1 (LShiftI src2 src3)));
11769 
11770   ins_cost(1.9 * INSN_COST);
11771   format %{ &quot;addw  $dst, $src1, $src2, LSL $src3&quot; %}
11772 
11773   ins_encode %{
11774     __ addw(as_Register($dst$$reg),
11775               as_Register($src1$$reg),
11776               as_Register($src2$$reg),
11777               Assembler::LSL,
11778               $src3$$constant &amp; 0x1f);
11779   %}
11780 
11781   ins_pipe(ialu_reg_reg_shift);
11782 %}
11783 
11784 instruct AddL_reg_LShift_reg(iRegLNoSp dst,
11785                          iRegL src1, iRegL src2,
11786                          immI src3, rFlagsReg cr) %{
11787   match(Set dst (AddL src1 (LShiftL src2 src3)));
11788 
11789   ins_cost(1.9 * INSN_COST);
11790   format %{ &quot;add  $dst, $src1, $src2, LSL $src3&quot; %}
11791 
11792   ins_encode %{
11793     __ add(as_Register($dst$$reg),
11794               as_Register($src1$$reg),
11795               as_Register($src2$$reg),
11796               Assembler::LSL,
11797               $src3$$constant &amp; 0x3f);
11798   %}
11799 
11800   ins_pipe(ialu_reg_reg_shift);
11801 %}
11802 
11803 instruct SubI_reg_URShift_reg(iRegINoSp dst,
11804                          iRegIorL2I src1, iRegIorL2I src2,
11805                          immI src3, rFlagsReg cr) %{
11806   match(Set dst (SubI src1 (URShiftI src2 src3)));
11807 
11808   ins_cost(1.9 * INSN_COST);
11809   format %{ &quot;subw  $dst, $src1, $src2, LSR $src3&quot; %}
11810 
11811   ins_encode %{
11812     __ subw(as_Register($dst$$reg),
11813               as_Register($src1$$reg),
11814               as_Register($src2$$reg),
11815               Assembler::LSR,
11816               $src3$$constant &amp; 0x1f);
11817   %}
11818 
11819   ins_pipe(ialu_reg_reg_shift);
11820 %}
11821 
11822 instruct SubL_reg_URShift_reg(iRegLNoSp dst,
11823                          iRegL src1, iRegL src2,
11824                          immI src3, rFlagsReg cr) %{
11825   match(Set dst (SubL src1 (URShiftL src2 src3)));
11826 
11827   ins_cost(1.9 * INSN_COST);
11828   format %{ &quot;sub  $dst, $src1, $src2, LSR $src3&quot; %}
11829 
11830   ins_encode %{
11831     __ sub(as_Register($dst$$reg),
11832               as_Register($src1$$reg),
11833               as_Register($src2$$reg),
11834               Assembler::LSR,
11835               $src3$$constant &amp; 0x3f);
11836   %}
11837 
11838   ins_pipe(ialu_reg_reg_shift);
11839 %}
11840 
11841 instruct SubI_reg_RShift_reg(iRegINoSp dst,
11842                          iRegIorL2I src1, iRegIorL2I src2,
11843                          immI src3, rFlagsReg cr) %{
11844   match(Set dst (SubI src1 (RShiftI src2 src3)));
11845 
11846   ins_cost(1.9 * INSN_COST);
11847   format %{ &quot;subw  $dst, $src1, $src2, ASR $src3&quot; %}
11848 
11849   ins_encode %{
11850     __ subw(as_Register($dst$$reg),
11851               as_Register($src1$$reg),
11852               as_Register($src2$$reg),
11853               Assembler::ASR,
11854               $src3$$constant &amp; 0x1f);
11855   %}
11856 
11857   ins_pipe(ialu_reg_reg_shift);
11858 %}
11859 
11860 instruct SubL_reg_RShift_reg(iRegLNoSp dst,
11861                          iRegL src1, iRegL src2,
11862                          immI src3, rFlagsReg cr) %{
11863   match(Set dst (SubL src1 (RShiftL src2 src3)));
11864 
11865   ins_cost(1.9 * INSN_COST);
11866   format %{ &quot;sub  $dst, $src1, $src2, ASR $src3&quot; %}
11867 
11868   ins_encode %{
11869     __ sub(as_Register($dst$$reg),
11870               as_Register($src1$$reg),
11871               as_Register($src2$$reg),
11872               Assembler::ASR,
11873               $src3$$constant &amp; 0x3f);
11874   %}
11875 
11876   ins_pipe(ialu_reg_reg_shift);
11877 %}
11878 
11879 instruct SubI_reg_LShift_reg(iRegINoSp dst,
11880                          iRegIorL2I src1, iRegIorL2I src2,
11881                          immI src3, rFlagsReg cr) %{
11882   match(Set dst (SubI src1 (LShiftI src2 src3)));
11883 
11884   ins_cost(1.9 * INSN_COST);
11885   format %{ &quot;subw  $dst, $src1, $src2, LSL $src3&quot; %}
11886 
11887   ins_encode %{
11888     __ subw(as_Register($dst$$reg),
11889               as_Register($src1$$reg),
11890               as_Register($src2$$reg),
11891               Assembler::LSL,
11892               $src3$$constant &amp; 0x1f);
11893   %}
11894 
11895   ins_pipe(ialu_reg_reg_shift);
11896 %}
11897 
11898 instruct SubL_reg_LShift_reg(iRegLNoSp dst,
11899                          iRegL src1, iRegL src2,
11900                          immI src3, rFlagsReg cr) %{
11901   match(Set dst (SubL src1 (LShiftL src2 src3)));
11902 
11903   ins_cost(1.9 * INSN_COST);
11904   format %{ &quot;sub  $dst, $src1, $src2, LSL $src3&quot; %}
11905 
11906   ins_encode %{
11907     __ sub(as_Register($dst$$reg),
11908               as_Register($src1$$reg),
11909               as_Register($src2$$reg),
11910               Assembler::LSL,
11911               $src3$$constant &amp; 0x3f);
11912   %}
11913 
11914   ins_pipe(ialu_reg_reg_shift);
11915 %}
11916 
11917 
11918 
11919 // Shift Left followed by Shift Right.
11920 // This idiom is used by the compiler for the i2b bytecode etc.
11921 instruct sbfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11922 %{
11923   match(Set dst (RShiftL (LShiftL src lshift_count) rshift_count));
11924   ins_cost(INSN_COST * 2);
11925   format %{ &quot;sbfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11926   ins_encode %{
11927     int lshift = $lshift_count$$constant &amp; 63;
11928     int rshift = $rshift_count$$constant &amp; 63;
11929     int s = 63 - lshift;
11930     int r = (rshift - lshift) &amp; 63;
11931     __ sbfm(as_Register($dst$$reg),
11932             as_Register($src$$reg),
11933             r, s);
11934   %}
11935 
11936   ins_pipe(ialu_reg_shift);
11937 %}
11938 
11939 // Shift Left followed by Shift Right.
11940 // This idiom is used by the compiler for the i2b bytecode etc.
11941 instruct sbfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11942 %{
11943   match(Set dst (RShiftI (LShiftI src lshift_count) rshift_count));
11944   ins_cost(INSN_COST * 2);
11945   format %{ &quot;sbfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11946   ins_encode %{
11947     int lshift = $lshift_count$$constant &amp; 31;
11948     int rshift = $rshift_count$$constant &amp; 31;
11949     int s = 31 - lshift;
11950     int r = (rshift - lshift) &amp; 31;
11951     __ sbfmw(as_Register($dst$$reg),
11952             as_Register($src$$reg),
11953             r, s);
11954   %}
11955 
11956   ins_pipe(ialu_reg_shift);
11957 %}
11958 
11959 // Shift Left followed by Shift Right.
11960 // This idiom is used by the compiler for the i2b bytecode etc.
11961 instruct ubfmL(iRegLNoSp dst, iRegL src, immI lshift_count, immI rshift_count)
11962 %{
11963   match(Set dst (URShiftL (LShiftL src lshift_count) rshift_count));
11964   ins_cost(INSN_COST * 2);
11965   format %{ &quot;ubfm  $dst, $src, $rshift_count - $lshift_count, #63 - $lshift_count&quot; %}
11966   ins_encode %{
11967     int lshift = $lshift_count$$constant &amp; 63;
11968     int rshift = $rshift_count$$constant &amp; 63;
11969     int s = 63 - lshift;
11970     int r = (rshift - lshift) &amp; 63;
11971     __ ubfm(as_Register($dst$$reg),
11972             as_Register($src$$reg),
11973             r, s);
11974   %}
11975 
11976   ins_pipe(ialu_reg_shift);
11977 %}
11978 
11979 // Shift Left followed by Shift Right.
11980 // This idiom is used by the compiler for the i2b bytecode etc.
11981 instruct ubfmwI(iRegINoSp dst, iRegIorL2I src, immI lshift_count, immI rshift_count)
11982 %{
11983   match(Set dst (URShiftI (LShiftI src lshift_count) rshift_count));
11984   ins_cost(INSN_COST * 2);
11985   format %{ &quot;ubfmw  $dst, $src, $rshift_count - $lshift_count, #31 - $lshift_count&quot; %}
11986   ins_encode %{
11987     int lshift = $lshift_count$$constant &amp; 31;
11988     int rshift = $rshift_count$$constant &amp; 31;
11989     int s = 31 - lshift;
11990     int r = (rshift - lshift) &amp; 31;
11991     __ ubfmw(as_Register($dst$$reg),
11992             as_Register($src$$reg),
11993             r, s);
11994   %}
11995 
11996   ins_pipe(ialu_reg_shift);
11997 %}
11998 // Bitfield extract with shift &amp; mask
11999 
12000 instruct ubfxwI(iRegINoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12001 %{
12002   match(Set dst (AndI (URShiftI src rshift) mask));
12003   // Make sure we are not going to exceed what ubfxw can do.
12004   predicate((exact_log2(n-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12005 
12006   ins_cost(INSN_COST);
12007   format %{ &quot;ubfxw $dst, $src, $rshift, $mask&quot; %}
12008   ins_encode %{
12009     int rshift = $rshift$$constant &amp; 31;
12010     long mask = $mask$$constant;
12011     int width = exact_log2(mask+1);
12012     __ ubfxw(as_Register($dst$$reg),
12013             as_Register($src$$reg), rshift, width);
12014   %}
12015   ins_pipe(ialu_reg_shift);
12016 %}
12017 instruct ubfxL(iRegLNoSp dst, iRegL src, immI rshift, immL_bitmask mask)
12018 %{
12019   match(Set dst (AndL (URShiftL src rshift) mask));
12020   // Make sure we are not going to exceed what ubfx can do.
12021   predicate((exact_log2_long(n-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12022 
12023   ins_cost(INSN_COST);
12024   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12025   ins_encode %{
12026     int rshift = $rshift$$constant &amp; 63;
12027     long mask = $mask$$constant;
12028     int width = exact_log2_long(mask+1);
12029     __ ubfx(as_Register($dst$$reg),
12030             as_Register($src$$reg), rshift, width);
12031   %}
12032   ins_pipe(ialu_reg_shift);
12033 %}
12034 
12035 // We can use ubfx when extending an And with a mask when we know mask
12036 // is positive.  We know that because immI_bitmask guarantees it.
12037 instruct ubfxIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI rshift, immI_bitmask mask)
12038 %{
12039   match(Set dst (ConvI2L (AndI (URShiftI src rshift) mask)));
12040   // Make sure we are not going to exceed what ubfxw can do.
12041   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12042 
12043   ins_cost(INSN_COST * 2);
12044   format %{ &quot;ubfx $dst, $src, $rshift, $mask&quot; %}
12045   ins_encode %{
12046     int rshift = $rshift$$constant &amp; 31;
12047     long mask = $mask$$constant;
12048     int width = exact_log2(mask+1);
12049     __ ubfx(as_Register($dst$$reg),
12050             as_Register($src$$reg), rshift, width);
12051   %}
12052   ins_pipe(ialu_reg_shift);
12053 %}
12054 
12055 // We can use ubfiz when masking by a positive number and then left shifting the result.
12056 // We know that the mask is positive because immI_bitmask guarantees it.
12057 instruct ubfizwI(iRegINoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12058 %{
12059   match(Set dst (LShiftI (AndI src mask) lshift));
12060   predicate((exact_log2(n-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 31)) &lt;= (31 + 1));
12061 
12062   ins_cost(INSN_COST);
12063   format %{ &quot;ubfizw $dst, $src, $lshift, $mask&quot; %}
12064   ins_encode %{
12065     int lshift = $lshift$$constant &amp; 31;
12066     long mask = $mask$$constant;
12067     int width = exact_log2(mask+1);
12068     __ ubfizw(as_Register($dst$$reg),
12069           as_Register($src$$reg), lshift, width);
12070   %}
12071   ins_pipe(ialu_reg_shift);
12072 %}
12073 // We can use ubfiz when masking by a positive number and then left shifting the result.
12074 // We know that the mask is positive because immL_bitmask guarantees it.
12075 instruct ubfizL(iRegLNoSp dst, iRegL src, immI lshift, immL_bitmask mask)
12076 %{
12077   match(Set dst (LShiftL (AndL src mask) lshift));
12078   predicate((exact_log2_long(n-&gt;in(1)-&gt;in(2)-&gt;get_long() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12079 
12080   ins_cost(INSN_COST);
12081   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12082   ins_encode %{
12083     int lshift = $lshift$$constant &amp; 63;
12084     long mask = $mask$$constant;
12085     int width = exact_log2_long(mask+1);
12086     __ ubfiz(as_Register($dst$$reg),
12087           as_Register($src$$reg), lshift, width);
12088   %}
12089   ins_pipe(ialu_reg_shift);
12090 %}
12091 
12092 // If there is a convert I to L block between and AndI and a LShiftL, we can also match ubfiz
12093 instruct ubfizIConvI2L(iRegLNoSp dst, iRegIorL2I src, immI lshift, immI_bitmask mask)
12094 %{
12095   match(Set dst (LShiftL (ConvI2L (AndI src mask)) lshift));
12096   predicate((exact_log2(n-&gt;in(1)-&gt;in(1)-&gt;in(2)-&gt;get_int() + 1) + (n-&gt;in(2)-&gt;get_int() &amp; 63)) &lt;= (63 + 1));
12097 
12098   ins_cost(INSN_COST);
12099   format %{ &quot;ubfiz $dst, $src, $lshift, $mask&quot; %}
12100   ins_encode %{
12101     int lshift = $lshift$$constant &amp; 63;
12102     long mask = $mask$$constant;
12103     int width = exact_log2(mask+1);
12104     __ ubfiz(as_Register($dst$$reg),
12105              as_Register($src$$reg), lshift, width);
12106   %}
12107   ins_pipe(ialu_reg_shift);
12108 %}
12109 
12110 // Rotations
12111 
12112 instruct extrOrL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12113 %{
12114   match(Set dst (OrL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12115   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12116 
12117   ins_cost(INSN_COST);
12118   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12119 
12120   ins_encode %{
12121     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12122             $rshift$$constant &amp; 63);
12123   %}
12124   ins_pipe(ialu_reg_reg_extr);
12125 %}
12126 
12127 instruct extrOrI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12128 %{
12129   match(Set dst (OrI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12130   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12131 
12132   ins_cost(INSN_COST);
12133   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12134 
12135   ins_encode %{
12136     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12137             $rshift$$constant &amp; 31);
12138   %}
12139   ins_pipe(ialu_reg_reg_extr);
12140 %}
12141 
12142 instruct extrAddL(iRegLNoSp dst, iRegL src1, iRegL src2, immI lshift, immI rshift, rFlagsReg cr)
12143 %{
12144   match(Set dst (AddL (LShiftL src1 lshift) (URShiftL src2 rshift)));
12145   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 63) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 63)) &amp; 63));
12146 
12147   ins_cost(INSN_COST);
12148   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12149 
12150   ins_encode %{
12151     __ extr(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12152             $rshift$$constant &amp; 63);
12153   %}
12154   ins_pipe(ialu_reg_reg_extr);
12155 %}
12156 
12157 instruct extrAddI(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI lshift, immI rshift, rFlagsReg cr)
12158 %{
12159   match(Set dst (AddI (LShiftI src1 lshift) (URShiftI src2 rshift)));
12160   predicate(0 == (((n-&gt;in(1)-&gt;in(2)-&gt;get_int() &amp; 31) + (n-&gt;in(2)-&gt;in(2)-&gt;get_int() &amp; 31)) &amp; 31));
12161 
12162   ins_cost(INSN_COST);
12163   format %{ &quot;extr $dst, $src1, $src2, #$rshift&quot; %}
12164 
12165   ins_encode %{
12166     __ extrw(as_Register($dst$$reg), as_Register($src1$$reg), as_Register($src2$$reg),
12167             $rshift$$constant &amp; 31);
12168   %}
12169   ins_pipe(ialu_reg_reg_extr);
12170 %}
12171 
12172 
12173 // rol expander
12174 
12175 instruct rolL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12176 %{
12177   effect(DEF dst, USE src, USE shift);
12178 
12179   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12180   ins_cost(INSN_COST * 3);
12181   ins_encode %{
12182     __ subw(rscratch1, zr, as_Register($shift$$reg));
12183     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12184             rscratch1);
12185     %}
12186   ins_pipe(ialu_reg_reg_vshift);
12187 %}
12188 
12189 // rol expander
12190 
12191 instruct rolI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12192 %{
12193   effect(DEF dst, USE src, USE shift);
12194 
12195   format %{ &quot;rol    $dst, $src, $shift&quot; %}
12196   ins_cost(INSN_COST * 3);
12197   ins_encode %{
12198     __ subw(rscratch1, zr, as_Register($shift$$reg));
12199     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12200             rscratch1);
12201     %}
12202   ins_pipe(ialu_reg_reg_vshift);
12203 %}
12204 
12205 instruct rolL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12206 %{
12207   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c_64 shift))));
12208 
12209   expand %{
12210     rolL_rReg(dst, src, shift, cr);
12211   %}
12212 %}
12213 
12214 instruct rolL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12215 %{
12216   match(Set dst (OrL (LShiftL src shift) (URShiftL src (SubI c0 shift))));
12217 
12218   expand %{
12219     rolL_rReg(dst, src, shift, cr);
12220   %}
12221 %}
12222 
12223 instruct rolI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12224 %{
12225   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c_32 shift))));
12226 
12227   expand %{
12228     rolI_rReg(dst, src, shift, cr);
12229   %}
12230 %}
12231 
12232 instruct rolI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12233 %{
12234   match(Set dst (OrI (LShiftI src shift) (URShiftI src (SubI c0 shift))));
12235 
12236   expand %{
12237     rolI_rReg(dst, src, shift, cr);
12238   %}
12239 %}
12240 
12241 // ror expander
12242 
12243 instruct rorL_rReg(iRegLNoSp dst, iRegL src, iRegI shift, rFlagsReg cr)
12244 %{
12245   effect(DEF dst, USE src, USE shift);
12246 
12247   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12248   ins_cost(INSN_COST);
12249   ins_encode %{
12250     __ rorv(as_Register($dst$$reg), as_Register($src$$reg),
12251             as_Register($shift$$reg));
12252     %}
12253   ins_pipe(ialu_reg_reg_vshift);
12254 %}
12255 
12256 // ror expander
12257 
12258 instruct rorI_rReg(iRegINoSp dst, iRegI src, iRegI shift, rFlagsReg cr)
12259 %{
12260   effect(DEF dst, USE src, USE shift);
12261 
12262   format %{ &quot;ror    $dst, $src, $shift&quot; %}
12263   ins_cost(INSN_COST);
12264   ins_encode %{
12265     __ rorvw(as_Register($dst$$reg), as_Register($src$$reg),
12266             as_Register($shift$$reg));
12267     %}
12268   ins_pipe(ialu_reg_reg_vshift);
12269 %}
12270 
12271 instruct rorL_rReg_Var_C_64(iRegLNoSp dst, iRegL src, iRegI shift, immI_64 c_64, rFlagsReg cr)
12272 %{
12273   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c_64 shift))));
12274 
12275   expand %{
12276     rorL_rReg(dst, src, shift, cr);
12277   %}
12278 %}
12279 
12280 instruct rorL_rReg_Var_C0(iRegLNoSp dst, iRegL src, iRegI shift, immI0 c0, rFlagsReg cr)
12281 %{
12282   match(Set dst (OrL (URShiftL src shift) (LShiftL src (SubI c0 shift))));
12283 
12284   expand %{
12285     rorL_rReg(dst, src, shift, cr);
12286   %}
12287 %}
12288 
12289 instruct rorI_rReg_Var_C_32(iRegINoSp dst, iRegI src, iRegI shift, immI_32 c_32, rFlagsReg cr)
12290 %{
12291   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c_32 shift))));
12292 
12293   expand %{
12294     rorI_rReg(dst, src, shift, cr);
12295   %}
12296 %}
12297 
12298 instruct rorI_rReg_Var_C0(iRegINoSp dst, iRegI src, iRegI shift, immI0 c0, rFlagsReg cr)
12299 %{
12300   match(Set dst (OrI (URShiftI src shift) (LShiftI src (SubI c0 shift))));
12301 
12302   expand %{
12303     rorI_rReg(dst, src, shift, cr);
12304   %}
12305 %}
12306 
12307 // Add/subtract (extended)
12308 
12309 instruct AddExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12310 %{
12311   match(Set dst (AddL src1 (ConvI2L src2)));
12312   ins_cost(INSN_COST);
12313   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12314 
12315    ins_encode %{
12316      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12317             as_Register($src2$$reg), ext::sxtw);
12318    %}
12319   ins_pipe(ialu_reg_reg);
12320 %};
12321 
12322 instruct SubExtI(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, rFlagsReg cr)
12323 %{
12324   match(Set dst (SubL src1 (ConvI2L src2)));
12325   ins_cost(INSN_COST);
12326   format %{ &quot;sub  $dst, $src1, $src2, sxtw&quot; %}
12327 
12328    ins_encode %{
12329      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12330             as_Register($src2$$reg), ext::sxtw);
12331    %}
12332   ins_pipe(ialu_reg_reg);
12333 %};
12334 
12335 
12336 instruct AddExtI_sxth(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_16 lshift, immI_16 rshift, rFlagsReg cr)
12337 %{
12338   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12339   ins_cost(INSN_COST);
12340   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12341 
12342    ins_encode %{
12343      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12344             as_Register($src2$$reg), ext::sxth);
12345    %}
12346   ins_pipe(ialu_reg_reg);
12347 %}
12348 
12349 instruct AddExtI_sxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12350 %{
12351   match(Set dst (AddI src1 (RShiftI (LShiftI src2 lshift) rshift)));
12352   ins_cost(INSN_COST);
12353   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12354 
12355    ins_encode %{
12356      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12357             as_Register($src2$$reg), ext::sxtb);
12358    %}
12359   ins_pipe(ialu_reg_reg);
12360 %}
12361 
12362 instruct AddExtI_uxtb(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_24 lshift, immI_24 rshift, rFlagsReg cr)
12363 %{
12364   match(Set dst (AddI src1 (URShiftI (LShiftI src2 lshift) rshift)));
12365   ins_cost(INSN_COST);
12366   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12367 
12368    ins_encode %{
12369      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12370             as_Register($src2$$reg), ext::uxtb);
12371    %}
12372   ins_pipe(ialu_reg_reg);
12373 %}
12374 
12375 instruct AddExtL_sxth(iRegLNoSp dst, iRegL src1, iRegL src2, immI_48 lshift, immI_48 rshift, rFlagsReg cr)
12376 %{
12377   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12378   ins_cost(INSN_COST);
12379   format %{ &quot;add  $dst, $src1, $src2, sxth&quot; %}
12380 
12381    ins_encode %{
12382      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12383             as_Register($src2$$reg), ext::sxth);
12384    %}
12385   ins_pipe(ialu_reg_reg);
12386 %}
12387 
12388 instruct AddExtL_sxtw(iRegLNoSp dst, iRegL src1, iRegL src2, immI_32 lshift, immI_32 rshift, rFlagsReg cr)
12389 %{
12390   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12391   ins_cost(INSN_COST);
12392   format %{ &quot;add  $dst, $src1, $src2, sxtw&quot; %}
12393 
12394    ins_encode %{
12395      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12396             as_Register($src2$$reg), ext::sxtw);
12397    %}
12398   ins_pipe(ialu_reg_reg);
12399 %}
12400 
12401 instruct AddExtL_sxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12402 %{
12403   match(Set dst (AddL src1 (RShiftL (LShiftL src2 lshift) rshift)));
12404   ins_cost(INSN_COST);
12405   format %{ &quot;add  $dst, $src1, $src2, sxtb&quot; %}
12406 
12407    ins_encode %{
12408      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12409             as_Register($src2$$reg), ext::sxtb);
12410    %}
12411   ins_pipe(ialu_reg_reg);
12412 %}
12413 
12414 instruct AddExtL_uxtb(iRegLNoSp dst, iRegL src1, iRegL src2, immI_56 lshift, immI_56 rshift, rFlagsReg cr)
12415 %{
12416   match(Set dst (AddL src1 (URShiftL (LShiftL src2 lshift) rshift)));
12417   ins_cost(INSN_COST);
12418   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12419 
12420    ins_encode %{
12421      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12422             as_Register($src2$$reg), ext::uxtb);
12423    %}
12424   ins_pipe(ialu_reg_reg);
12425 %}
12426 
12427 
12428 instruct AddExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12429 %{
12430   match(Set dst (AddI src1 (AndI src2 mask)));
12431   ins_cost(INSN_COST);
12432   format %{ &quot;addw  $dst, $src1, $src2, uxtb&quot; %}
12433 
12434    ins_encode %{
12435      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12436             as_Register($src2$$reg), ext::uxtb);
12437    %}
12438   ins_pipe(ialu_reg_reg);
12439 %}
12440 
12441 instruct AddExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12442 %{
12443   match(Set dst (AddI src1 (AndI src2 mask)));
12444   ins_cost(INSN_COST);
12445   format %{ &quot;addw  $dst, $src1, $src2, uxth&quot; %}
12446 
12447    ins_encode %{
12448      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12449             as_Register($src2$$reg), ext::uxth);
12450    %}
12451   ins_pipe(ialu_reg_reg);
12452 %}
12453 
12454 instruct AddExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12455 %{
12456   match(Set dst (AddL src1 (AndL src2 mask)));
12457   ins_cost(INSN_COST);
12458   format %{ &quot;add  $dst, $src1, $src2, uxtb&quot; %}
12459 
12460    ins_encode %{
12461      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12462             as_Register($src2$$reg), ext::uxtb);
12463    %}
12464   ins_pipe(ialu_reg_reg);
12465 %}
12466 
12467 instruct AddExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12468 %{
12469   match(Set dst (AddL src1 (AndL src2 mask)));
12470   ins_cost(INSN_COST);
12471   format %{ &quot;add  $dst, $src1, $src2, uxth&quot; %}
12472 
12473    ins_encode %{
12474      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12475             as_Register($src2$$reg), ext::uxth);
12476    %}
12477   ins_pipe(ialu_reg_reg);
12478 %}
12479 
12480 instruct AddExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12481 %{
12482   match(Set dst (AddL src1 (AndL src2 mask)));
12483   ins_cost(INSN_COST);
12484   format %{ &quot;add  $dst, $src1, $src2, uxtw&quot; %}
12485 
12486    ins_encode %{
12487      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12488             as_Register($src2$$reg), ext::uxtw);
12489    %}
12490   ins_pipe(ialu_reg_reg);
12491 %}
12492 
12493 instruct SubExtI_uxtb_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, rFlagsReg cr)
12494 %{
12495   match(Set dst (SubI src1 (AndI src2 mask)));
12496   ins_cost(INSN_COST);
12497   format %{ &quot;subw  $dst, $src1, $src2, uxtb&quot; %}
12498 
12499    ins_encode %{
12500      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12501             as_Register($src2$$reg), ext::uxtb);
12502    %}
12503   ins_pipe(ialu_reg_reg);
12504 %}
12505 
12506 instruct SubExtI_uxth_and(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, rFlagsReg cr)
12507 %{
12508   match(Set dst (SubI src1 (AndI src2 mask)));
12509   ins_cost(INSN_COST);
12510   format %{ &quot;subw  $dst, $src1, $src2, uxth&quot; %}
12511 
12512    ins_encode %{
12513      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12514             as_Register($src2$$reg), ext::uxth);
12515    %}
12516   ins_pipe(ialu_reg_reg);
12517 %}
12518 
12519 instruct SubExtL_uxtb_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, rFlagsReg cr)
12520 %{
12521   match(Set dst (SubL src1 (AndL src2 mask)));
12522   ins_cost(INSN_COST);
12523   format %{ &quot;sub  $dst, $src1, $src2, uxtb&quot; %}
12524 
12525    ins_encode %{
12526      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12527             as_Register($src2$$reg), ext::uxtb);
12528    %}
12529   ins_pipe(ialu_reg_reg);
12530 %}
12531 
12532 instruct SubExtL_uxth_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, rFlagsReg cr)
12533 %{
12534   match(Set dst (SubL src1 (AndL src2 mask)));
12535   ins_cost(INSN_COST);
12536   format %{ &quot;sub  $dst, $src1, $src2, uxth&quot; %}
12537 
12538    ins_encode %{
12539      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12540             as_Register($src2$$reg), ext::uxth);
12541    %}
12542   ins_pipe(ialu_reg_reg);
12543 %}
12544 
12545 instruct SubExtL_uxtw_and(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, rFlagsReg cr)
12546 %{
12547   match(Set dst (SubL src1 (AndL src2 mask)));
12548   ins_cost(INSN_COST);
12549   format %{ &quot;sub  $dst, $src1, $src2, uxtw&quot; %}
12550 
12551    ins_encode %{
12552      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12553             as_Register($src2$$reg), ext::uxtw);
12554    %}
12555   ins_pipe(ialu_reg_reg);
12556 %}
12557 
12558 
12559 instruct AddExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12560 %{
12561   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12562   ins_cost(1.9 * INSN_COST);
12563   format %{ &quot;add  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12564 
12565    ins_encode %{
12566      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12567             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12568    %}
12569   ins_pipe(ialu_reg_reg_shift);
12570 %}
12571 
12572 instruct AddExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12573 %{
12574   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12575   ins_cost(1.9 * INSN_COST);
12576   format %{ &quot;add  $dst, $src1, $src2, sxth #lshift2&quot; %}
12577 
12578    ins_encode %{
12579      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12580             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12581    %}
12582   ins_pipe(ialu_reg_reg_shift);
12583 %}
12584 
12585 instruct AddExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12586 %{
12587   match(Set dst (AddL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12588   ins_cost(1.9 * INSN_COST);
12589   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12590 
12591    ins_encode %{
12592      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12593             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12594    %}
12595   ins_pipe(ialu_reg_reg_shift);
12596 %}
12597 
12598 instruct SubExtL_sxtb_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_56 lshift1, immI_56 rshift1, rFlagsReg cr)
12599 %{
12600   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12601   ins_cost(1.9 * INSN_COST);
12602   format %{ &quot;sub  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12603 
12604    ins_encode %{
12605      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12606             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12607    %}
12608   ins_pipe(ialu_reg_reg_shift);
12609 %}
12610 
12611 instruct SubExtL_sxth_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_48 lshift1, immI_48 rshift1, rFlagsReg cr)
12612 %{
12613   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12614   ins_cost(1.9 * INSN_COST);
12615   format %{ &quot;sub  $dst, $src1, $src2, sxth #lshift2&quot; %}
12616 
12617    ins_encode %{
12618      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12619             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12620    %}
12621   ins_pipe(ialu_reg_reg_shift);
12622 %}
12623 
12624 instruct SubExtL_sxtw_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immIExt lshift2, immI_32 lshift1, immI_32 rshift1, rFlagsReg cr)
12625 %{
12626   match(Set dst (SubL src1 (LShiftL (RShiftL (LShiftL src2 lshift1) rshift1) lshift2)));
12627   ins_cost(1.9 * INSN_COST);
12628   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift2&quot; %}
12629 
12630    ins_encode %{
12631      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12632             as_Register($src2$$reg), ext::sxtw, ($lshift2$$constant));
12633    %}
12634   ins_pipe(ialu_reg_reg_shift);
12635 %}
12636 
12637 instruct AddExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12638 %{
12639   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12640   ins_cost(1.9 * INSN_COST);
12641   format %{ &quot;addw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12642 
12643    ins_encode %{
12644      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12645             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12646    %}
12647   ins_pipe(ialu_reg_reg_shift);
12648 %}
12649 
12650 instruct AddExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12651 %{
12652   match(Set dst (AddI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12653   ins_cost(1.9 * INSN_COST);
12654   format %{ &quot;addw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12655 
12656    ins_encode %{
12657      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12658             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12659    %}
12660   ins_pipe(ialu_reg_reg_shift);
12661 %}
12662 
12663 instruct SubExtI_sxtb_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_24 lshift1, immI_24 rshift1, rFlagsReg cr)
12664 %{
12665   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12666   ins_cost(1.9 * INSN_COST);
12667   format %{ &quot;subw  $dst, $src1, $src2, sxtb #lshift2&quot; %}
12668 
12669    ins_encode %{
12670      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12671             as_Register($src2$$reg), ext::sxtb, ($lshift2$$constant));
12672    %}
12673   ins_pipe(ialu_reg_reg_shift);
12674 %}
12675 
12676 instruct SubExtI_sxth_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immIExt lshift2, immI_16 lshift1, immI_16 rshift1, rFlagsReg cr)
12677 %{
12678   match(Set dst (SubI src1 (LShiftI (RShiftI (LShiftI src2 lshift1) rshift1) lshift2)));
12679   ins_cost(1.9 * INSN_COST);
12680   format %{ &quot;subw  $dst, $src1, $src2, sxth #lshift2&quot; %}
12681 
12682    ins_encode %{
12683      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12684             as_Register($src2$$reg), ext::sxth, ($lshift2$$constant));
12685    %}
12686   ins_pipe(ialu_reg_reg_shift);
12687 %}
12688 
12689 
12690 instruct AddExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12691 %{
12692   match(Set dst (AddL src1 (LShiftL (ConvI2L src2) lshift)));
12693   ins_cost(1.9 * INSN_COST);
12694   format %{ &quot;add  $dst, $src1, $src2, sxtw #lshift&quot; %}
12695 
12696    ins_encode %{
12697      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12698             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12699    %}
12700   ins_pipe(ialu_reg_reg_shift);
12701 %};
12702 
12703 instruct SubExtI_shift(iRegLNoSp dst, iRegL src1, iRegIorL2I src2, immIExt lshift, rFlagsReg cr)
12704 %{
12705   match(Set dst (SubL src1 (LShiftL (ConvI2L src2) lshift)));
12706   ins_cost(1.9 * INSN_COST);
12707   format %{ &quot;sub  $dst, $src1, $src2, sxtw #lshift&quot; %}
12708 
12709    ins_encode %{
12710      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12711             as_Register($src2$$reg), ext::sxtw, ($lshift$$constant));
12712    %}
12713   ins_pipe(ialu_reg_reg_shift);
12714 %};
12715 
12716 
12717 instruct AddExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12718 %{
12719   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12720   ins_cost(1.9 * INSN_COST);
12721   format %{ &quot;add  $dst, $src1, $src2, uxtb #lshift&quot; %}
12722 
12723    ins_encode %{
12724      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12725             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12726    %}
12727   ins_pipe(ialu_reg_reg_shift);
12728 %}
12729 
12730 instruct AddExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12731 %{
12732   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12733   ins_cost(1.9 * INSN_COST);
12734   format %{ &quot;add  $dst, $src1, $src2, uxth #lshift&quot; %}
12735 
12736    ins_encode %{
12737      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12738             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12739    %}
12740   ins_pipe(ialu_reg_reg_shift);
12741 %}
12742 
12743 instruct AddExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12744 %{
12745   match(Set dst (AddL src1 (LShiftL (AndL src2 mask) lshift)));
12746   ins_cost(1.9 * INSN_COST);
12747   format %{ &quot;add  $dst, $src1, $src2, uxtw #lshift&quot; %}
12748 
12749    ins_encode %{
12750      __ add(as_Register($dst$$reg), as_Register($src1$$reg),
12751             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12752    %}
12753   ins_pipe(ialu_reg_reg_shift);
12754 %}
12755 
12756 instruct SubExtL_uxtb_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_255 mask, immIExt lshift, rFlagsReg cr)
12757 %{
12758   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12759   ins_cost(1.9 * INSN_COST);
12760   format %{ &quot;sub  $dst, $src1, $src2, uxtb #lshift&quot; %}
12761 
12762    ins_encode %{
12763      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12764             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12765    %}
12766   ins_pipe(ialu_reg_reg_shift);
12767 %}
12768 
12769 instruct SubExtL_uxth_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_65535 mask, immIExt lshift, rFlagsReg cr)
12770 %{
12771   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12772   ins_cost(1.9 * INSN_COST);
12773   format %{ &quot;sub  $dst, $src1, $src2, uxth #lshift&quot; %}
12774 
12775    ins_encode %{
12776      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12777             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12778    %}
12779   ins_pipe(ialu_reg_reg_shift);
12780 %}
12781 
12782 instruct SubExtL_uxtw_and_shift(iRegLNoSp dst, iRegL src1, iRegL src2, immL_4294967295 mask, immIExt lshift, rFlagsReg cr)
12783 %{
12784   match(Set dst (SubL src1 (LShiftL (AndL src2 mask) lshift)));
12785   ins_cost(1.9 * INSN_COST);
12786   format %{ &quot;sub  $dst, $src1, $src2, uxtw #lshift&quot; %}
12787 
12788    ins_encode %{
12789      __ sub(as_Register($dst$$reg), as_Register($src1$$reg),
12790             as_Register($src2$$reg), ext::uxtw, ($lshift$$constant));
12791    %}
12792   ins_pipe(ialu_reg_reg_shift);
12793 %}
12794 
12795 instruct AddExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12796 %{
12797   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12798   ins_cost(1.9 * INSN_COST);
12799   format %{ &quot;addw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12800 
12801    ins_encode %{
12802      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12803             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12804    %}
12805   ins_pipe(ialu_reg_reg_shift);
12806 %}
12807 
12808 instruct AddExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12809 %{
12810   match(Set dst (AddI src1 (LShiftI (AndI src2 mask) lshift)));
12811   ins_cost(1.9 * INSN_COST);
12812   format %{ &quot;addw  $dst, $src1, $src2, uxth #lshift&quot; %}
12813 
12814    ins_encode %{
12815      __ addw(as_Register($dst$$reg), as_Register($src1$$reg),
12816             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12817    %}
12818   ins_pipe(ialu_reg_reg_shift);
12819 %}
12820 
12821 instruct SubExtI_uxtb_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_255 mask, immIExt lshift, rFlagsReg cr)
12822 %{
12823   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12824   ins_cost(1.9 * INSN_COST);
12825   format %{ &quot;subw  $dst, $src1, $src2, uxtb #lshift&quot; %}
12826 
12827    ins_encode %{
12828      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12829             as_Register($src2$$reg), ext::uxtb, ($lshift$$constant));
12830    %}
12831   ins_pipe(ialu_reg_reg_shift);
12832 %}
12833 
12834 instruct SubExtI_uxth_and_shift(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, immI_65535 mask, immIExt lshift, rFlagsReg cr)
12835 %{
12836   match(Set dst (SubI src1 (LShiftI (AndI src2 mask) lshift)));
12837   ins_cost(1.9 * INSN_COST);
12838   format %{ &quot;subw  $dst, $src1, $src2, uxth #lshift&quot; %}
12839 
12840    ins_encode %{
12841      __ subw(as_Register($dst$$reg), as_Register($src1$$reg),
12842             as_Register($src2$$reg), ext::uxth, ($lshift$$constant));
12843    %}
12844   ins_pipe(ialu_reg_reg_shift);
12845 %}
12846 // END This section of the file is automatically generated. Do not edit --------------
12847 
12848 // ============================================================================
12849 // Floating Point Arithmetic Instructions
12850 
12851 instruct addF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12852   match(Set dst (AddF src1 src2));
12853 
12854   ins_cost(INSN_COST * 5);
12855   format %{ &quot;fadds   $dst, $src1, $src2&quot; %}
12856 
12857   ins_encode %{
12858     __ fadds(as_FloatRegister($dst$$reg),
12859              as_FloatRegister($src1$$reg),
12860              as_FloatRegister($src2$$reg));
12861   %}
12862 
12863   ins_pipe(fp_dop_reg_reg_s);
12864 %}
12865 
12866 instruct addD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12867   match(Set dst (AddD src1 src2));
12868 
12869   ins_cost(INSN_COST * 5);
12870   format %{ &quot;faddd   $dst, $src1, $src2&quot; %}
12871 
12872   ins_encode %{
12873     __ faddd(as_FloatRegister($dst$$reg),
12874              as_FloatRegister($src1$$reg),
12875              as_FloatRegister($src2$$reg));
12876   %}
12877 
12878   ins_pipe(fp_dop_reg_reg_d);
12879 %}
12880 
12881 instruct subF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12882   match(Set dst (SubF src1 src2));
12883 
12884   ins_cost(INSN_COST * 5);
12885   format %{ &quot;fsubs   $dst, $src1, $src2&quot; %}
12886 
12887   ins_encode %{
12888     __ fsubs(as_FloatRegister($dst$$reg),
12889              as_FloatRegister($src1$$reg),
12890              as_FloatRegister($src2$$reg));
12891   %}
12892 
12893   ins_pipe(fp_dop_reg_reg_s);
12894 %}
12895 
12896 instruct subD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12897   match(Set dst (SubD src1 src2));
12898 
12899   ins_cost(INSN_COST * 5);
12900   format %{ &quot;fsubd   $dst, $src1, $src2&quot; %}
12901 
12902   ins_encode %{
12903     __ fsubd(as_FloatRegister($dst$$reg),
12904              as_FloatRegister($src1$$reg),
12905              as_FloatRegister($src2$$reg));
12906   %}
12907 
12908   ins_pipe(fp_dop_reg_reg_d);
12909 %}
12910 
12911 instruct mulF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
12912   match(Set dst (MulF src1 src2));
12913 
12914   ins_cost(INSN_COST * 6);
12915   format %{ &quot;fmuls   $dst, $src1, $src2&quot; %}
12916 
12917   ins_encode %{
12918     __ fmuls(as_FloatRegister($dst$$reg),
12919              as_FloatRegister($src1$$reg),
12920              as_FloatRegister($src2$$reg));
12921   %}
12922 
12923   ins_pipe(fp_dop_reg_reg_s);
12924 %}
12925 
12926 instruct mulD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
12927   match(Set dst (MulD src1 src2));
12928 
12929   ins_cost(INSN_COST * 6);
12930   format %{ &quot;fmuld   $dst, $src1, $src2&quot; %}
12931 
12932   ins_encode %{
12933     __ fmuld(as_FloatRegister($dst$$reg),
12934              as_FloatRegister($src1$$reg),
12935              as_FloatRegister($src2$$reg));
12936   %}
12937 
12938   ins_pipe(fp_dop_reg_reg_d);
12939 %}
12940 
12941 // src1 * src2 + src3
12942 instruct maddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12943   predicate(UseFMA);
12944   match(Set dst (FmaF src3 (Binary src1 src2)));
12945 
12946   format %{ &quot;fmadds   $dst, $src1, $src2, $src3&quot; %}
12947 
12948   ins_encode %{
12949     __ fmadds(as_FloatRegister($dst$$reg),
12950              as_FloatRegister($src1$$reg),
12951              as_FloatRegister($src2$$reg),
12952              as_FloatRegister($src3$$reg));
12953   %}
12954 
12955   ins_pipe(pipe_class_default);
12956 %}
12957 
12958 // src1 * src2 + src3
12959 instruct maddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12960   predicate(UseFMA);
12961   match(Set dst (FmaD src3 (Binary src1 src2)));
12962 
12963   format %{ &quot;fmaddd   $dst, $src1, $src2, $src3&quot; %}
12964 
12965   ins_encode %{
12966     __ fmaddd(as_FloatRegister($dst$$reg),
12967              as_FloatRegister($src1$$reg),
12968              as_FloatRegister($src2$$reg),
12969              as_FloatRegister($src3$$reg));
12970   %}
12971 
12972   ins_pipe(pipe_class_default);
12973 %}
12974 
12975 // -src1 * src2 + src3
12976 instruct msubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
12977   predicate(UseFMA);
12978   match(Set dst (FmaF src3 (Binary (NegF src1) src2)));
12979   match(Set dst (FmaF src3 (Binary src1 (NegF src2))));
12980 
12981   format %{ &quot;fmsubs   $dst, $src1, $src2, $src3&quot; %}
12982 
12983   ins_encode %{
12984     __ fmsubs(as_FloatRegister($dst$$reg),
12985               as_FloatRegister($src1$$reg),
12986               as_FloatRegister($src2$$reg),
12987               as_FloatRegister($src3$$reg));
12988   %}
12989 
12990   ins_pipe(pipe_class_default);
12991 %}
12992 
12993 // -src1 * src2 + src3
12994 instruct msubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
12995   predicate(UseFMA);
12996   match(Set dst (FmaD src3 (Binary (NegD src1) src2)));
12997   match(Set dst (FmaD src3 (Binary src1 (NegD src2))));
12998 
12999   format %{ &quot;fmsubd   $dst, $src1, $src2, $src3&quot; %}
13000 
13001   ins_encode %{
13002     __ fmsubd(as_FloatRegister($dst$$reg),
13003               as_FloatRegister($src1$$reg),
13004               as_FloatRegister($src2$$reg),
13005               as_FloatRegister($src3$$reg));
13006   %}
13007 
13008   ins_pipe(pipe_class_default);
13009 %}
13010 
13011 // -src1 * src2 - src3
13012 instruct mnaddF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3) %{
13013   predicate(UseFMA);
13014   match(Set dst (FmaF (NegF src3) (Binary (NegF src1) src2)));
13015   match(Set dst (FmaF (NegF src3) (Binary src1 (NegF src2))));
13016 
13017   format %{ &quot;fnmadds  $dst, $src1, $src2, $src3&quot; %}
13018 
13019   ins_encode %{
13020     __ fnmadds(as_FloatRegister($dst$$reg),
13021                as_FloatRegister($src1$$reg),
13022                as_FloatRegister($src2$$reg),
13023                as_FloatRegister($src3$$reg));
13024   %}
13025 
13026   ins_pipe(pipe_class_default);
13027 %}
13028 
13029 // -src1 * src2 - src3
13030 instruct mnaddD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3) %{
13031   predicate(UseFMA);
13032   match(Set dst (FmaD (NegD src3) (Binary (NegD src1) src2)));
13033   match(Set dst (FmaD (NegD src3) (Binary src1 (NegD src2))));
13034 
13035   format %{ &quot;fnmaddd   $dst, $src1, $src2, $src3&quot; %}
13036 
13037   ins_encode %{
13038     __ fnmaddd(as_FloatRegister($dst$$reg),
13039                as_FloatRegister($src1$$reg),
13040                as_FloatRegister($src2$$reg),
13041                as_FloatRegister($src3$$reg));
13042   %}
13043 
13044   ins_pipe(pipe_class_default);
13045 %}
13046 
13047 // src1 * src2 - src3
13048 instruct mnsubF_reg_reg(vRegF dst, vRegF src1, vRegF src2, vRegF src3, immF0 zero) %{
13049   predicate(UseFMA);
13050   match(Set dst (FmaF (NegF src3) (Binary src1 src2)));
13051 
13052   format %{ &quot;fnmsubs  $dst, $src1, $src2, $src3&quot; %}
13053 
13054   ins_encode %{
13055     __ fnmsubs(as_FloatRegister($dst$$reg),
13056                as_FloatRegister($src1$$reg),
13057                as_FloatRegister($src2$$reg),
13058                as_FloatRegister($src3$$reg));
13059   %}
13060 
13061   ins_pipe(pipe_class_default);
13062 %}
13063 
13064 // src1 * src2 - src3
13065 instruct mnsubD_reg_reg(vRegD dst, vRegD src1, vRegD src2, vRegD src3, immD0 zero) %{
13066   predicate(UseFMA);
13067   match(Set dst (FmaD (NegD src3) (Binary src1 src2)));
13068 
13069   format %{ &quot;fnmsubd   $dst, $src1, $src2, $src3&quot; %}
13070 
13071   ins_encode %{
13072   // n.b. insn name should be fnmsubd
13073     __ fnmsub(as_FloatRegister($dst$$reg),
13074               as_FloatRegister($src1$$reg),
13075               as_FloatRegister($src2$$reg),
13076               as_FloatRegister($src3$$reg));
13077   %}
13078 
13079   ins_pipe(pipe_class_default);
13080 %}
13081 
13082 
13083 // Math.max(FF)F
13084 instruct maxF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13085   match(Set dst (MaxF src1 src2));
13086 
13087   format %{ &quot;fmaxs   $dst, $src1, $src2&quot; %}
13088   ins_encode %{
13089     __ fmaxs(as_FloatRegister($dst$$reg),
13090              as_FloatRegister($src1$$reg),
13091              as_FloatRegister($src2$$reg));
13092   %}
13093 
13094   ins_pipe(fp_dop_reg_reg_s);
13095 %}
13096 
13097 // Math.min(FF)F
13098 instruct minF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13099   match(Set dst (MinF src1 src2));
13100 
13101   format %{ &quot;fmins   $dst, $src1, $src2&quot; %}
13102   ins_encode %{
13103     __ fmins(as_FloatRegister($dst$$reg),
13104              as_FloatRegister($src1$$reg),
13105              as_FloatRegister($src2$$reg));
13106   %}
13107 
13108   ins_pipe(fp_dop_reg_reg_s);
13109 %}
13110 
13111 // Math.max(DD)D
13112 instruct maxD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13113   match(Set dst (MaxD src1 src2));
13114 
13115   format %{ &quot;fmaxd   $dst, $src1, $src2&quot; %}
13116   ins_encode %{
13117     __ fmaxd(as_FloatRegister($dst$$reg),
13118              as_FloatRegister($src1$$reg),
13119              as_FloatRegister($src2$$reg));
13120   %}
13121 
13122   ins_pipe(fp_dop_reg_reg_d);
13123 %}
13124 
13125 // Math.min(DD)D
13126 instruct minD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13127   match(Set dst (MinD src1 src2));
13128 
13129   format %{ &quot;fmind   $dst, $src1, $src2&quot; %}
13130   ins_encode %{
13131     __ fmind(as_FloatRegister($dst$$reg),
13132              as_FloatRegister($src1$$reg),
13133              as_FloatRegister($src2$$reg));
13134   %}
13135 
13136   ins_pipe(fp_dop_reg_reg_d);
13137 %}
13138 
13139 
13140 instruct divF_reg_reg(vRegF dst, vRegF src1, vRegF src2) %{
13141   match(Set dst (DivF src1  src2));
13142 
13143   ins_cost(INSN_COST * 18);
13144   format %{ &quot;fdivs   $dst, $src1, $src2&quot; %}
13145 
13146   ins_encode %{
13147     __ fdivs(as_FloatRegister($dst$$reg),
13148              as_FloatRegister($src1$$reg),
13149              as_FloatRegister($src2$$reg));
13150   %}
13151 
13152   ins_pipe(fp_div_s);
13153 %}
13154 
13155 instruct divD_reg_reg(vRegD dst, vRegD src1, vRegD src2) %{
13156   match(Set dst (DivD src1  src2));
13157 
13158   ins_cost(INSN_COST * 32);
13159   format %{ &quot;fdivd   $dst, $src1, $src2&quot; %}
13160 
13161   ins_encode %{
13162     __ fdivd(as_FloatRegister($dst$$reg),
13163              as_FloatRegister($src1$$reg),
13164              as_FloatRegister($src2$$reg));
13165   %}
13166 
13167   ins_pipe(fp_div_d);
13168 %}
13169 
13170 instruct negF_reg_reg(vRegF dst, vRegF src) %{
13171   match(Set dst (NegF src));
13172 
13173   ins_cost(INSN_COST * 3);
13174   format %{ &quot;fneg   $dst, $src&quot; %}
13175 
13176   ins_encode %{
13177     __ fnegs(as_FloatRegister($dst$$reg),
13178              as_FloatRegister($src$$reg));
13179   %}
13180 
13181   ins_pipe(fp_uop_s);
13182 %}
13183 
13184 instruct negD_reg_reg(vRegD dst, vRegD src) %{
13185   match(Set dst (NegD src));
13186 
13187   ins_cost(INSN_COST * 3);
13188   format %{ &quot;fnegd   $dst, $src&quot; %}
13189 
13190   ins_encode %{
13191     __ fnegd(as_FloatRegister($dst$$reg),
13192              as_FloatRegister($src$$reg));
13193   %}
13194 
13195   ins_pipe(fp_uop_d);
13196 %}
13197 
13198 instruct absI_reg(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13199 %{
13200   match(Set dst (AbsI src));
13201 
13202   effect(KILL cr);
13203   ins_cost(INSN_COST * 2);
13204   format %{ &quot;cmpw  $src, zr\n\t&quot;
13205             &quot;cnegw $dst, $src, Assembler::LT\t# int abs&quot;
13206   %}
13207 
13208   ins_encode %{
13209     __ cmpw(as_Register($src$$reg), zr);
13210     __ cnegw(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13211   %}
13212   ins_pipe(pipe_class_default);
13213 %}
13214 
13215 instruct absL_reg(iRegLNoSp dst, iRegL src, rFlagsReg cr)
13216 %{
13217   match(Set dst (AbsL src));
13218 
13219   effect(KILL cr);
13220   ins_cost(INSN_COST * 2);
13221   format %{ &quot;cmp  $src, zr\n\t&quot;
13222             &quot;cneg $dst, $src, Assembler::LT\t# long abs&quot;
13223   %}
13224 
13225   ins_encode %{
13226     __ cmp(as_Register($src$$reg), zr);
13227     __ cneg(as_Register($dst$$reg), as_Register($src$$reg), Assembler::LT);
13228   %}
13229   ins_pipe(pipe_class_default);
13230 %}
13231 
13232 instruct absF_reg(vRegF dst, vRegF src) %{
13233   match(Set dst (AbsF src));
13234 
13235   ins_cost(INSN_COST * 3);
13236   format %{ &quot;fabss   $dst, $src&quot; %}
13237   ins_encode %{
13238     __ fabss(as_FloatRegister($dst$$reg),
13239              as_FloatRegister($src$$reg));
13240   %}
13241 
13242   ins_pipe(fp_uop_s);
13243 %}
13244 
13245 instruct absD_reg(vRegD dst, vRegD src) %{
13246   match(Set dst (AbsD src));
13247 
13248   ins_cost(INSN_COST * 3);
13249   format %{ &quot;fabsd   $dst, $src&quot; %}
13250   ins_encode %{
13251     __ fabsd(as_FloatRegister($dst$$reg),
13252              as_FloatRegister($src$$reg));
13253   %}
13254 
13255   ins_pipe(fp_uop_d);
13256 %}
13257 
13258 instruct sqrtD_reg(vRegD dst, vRegD src) %{
13259   match(Set dst (SqrtD src));
13260 
13261   ins_cost(INSN_COST * 50);
13262   format %{ &quot;fsqrtd  $dst, $src&quot; %}
13263   ins_encode %{
13264     __ fsqrtd(as_FloatRegister($dst$$reg),
13265              as_FloatRegister($src$$reg));
13266   %}
13267 
13268   ins_pipe(fp_div_s);
13269 %}
13270 
13271 instruct sqrtF_reg(vRegF dst, vRegF src) %{
13272   match(Set dst (SqrtF src));
13273 
13274   ins_cost(INSN_COST * 50);
13275   format %{ &quot;fsqrts  $dst, $src&quot; %}
13276   ins_encode %{
13277     __ fsqrts(as_FloatRegister($dst$$reg),
13278              as_FloatRegister($src$$reg));
13279   %}
13280 
13281   ins_pipe(fp_div_d);
13282 %}
13283 
13284 // Math.rint, floor, ceil
13285 instruct roundD_reg(vRegD dst, vRegD src, immI rmode) %{
13286   match(Set dst (RoundDoubleMode src rmode));
13287   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
13288   ins_encode %{
13289     switch ($rmode$$constant) {
13290       case RoundDoubleModeNode::rmode_rint:
13291         __ frintnd(as_FloatRegister($dst$$reg),
13292                    as_FloatRegister($src$$reg));
13293         break;
13294       case RoundDoubleModeNode::rmode_floor:
13295         __ frintmd(as_FloatRegister($dst$$reg),
13296                    as_FloatRegister($src$$reg));
13297         break;
13298       case RoundDoubleModeNode::rmode_ceil:
13299         __ frintpd(as_FloatRegister($dst$$reg),
13300                    as_FloatRegister($src$$reg));
13301         break;
13302     }
13303   %}
13304   ins_pipe(fp_uop_d);
13305 %}
13306 
13307 // ============================================================================
13308 // Logical Instructions
13309 
13310 // Integer Logical Instructions
13311 
13312 // And Instructions
13313 
13314 
13315 instruct andI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2, rFlagsReg cr) %{
13316   match(Set dst (AndI src1 src2));
13317 
13318   format %{ &quot;andw  $dst, $src1, $src2\t# int&quot; %}
13319 
13320   ins_cost(INSN_COST);
13321   ins_encode %{
13322     __ andw(as_Register($dst$$reg),
13323             as_Register($src1$$reg),
13324             as_Register($src2$$reg));
13325   %}
13326 
13327   ins_pipe(ialu_reg_reg);
13328 %}
13329 
13330 instruct andI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2, rFlagsReg cr) %{
13331   match(Set dst (AndI src1 src2));
13332 
13333   format %{ &quot;andsw  $dst, $src1, $src2\t# int&quot; %}
13334 
13335   ins_cost(INSN_COST);
13336   ins_encode %{
13337     __ andw(as_Register($dst$$reg),
13338             as_Register($src1$$reg),
13339             (unsigned long)($src2$$constant));
13340   %}
13341 
13342   ins_pipe(ialu_reg_imm);
13343 %}
13344 
13345 // Or Instructions
13346 
13347 instruct orI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13348   match(Set dst (OrI src1 src2));
13349 
13350   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13351 
13352   ins_cost(INSN_COST);
13353   ins_encode %{
13354     __ orrw(as_Register($dst$$reg),
13355             as_Register($src1$$reg),
13356             as_Register($src2$$reg));
13357   %}
13358 
13359   ins_pipe(ialu_reg_reg);
13360 %}
13361 
13362 instruct orI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13363   match(Set dst (OrI src1 src2));
13364 
13365   format %{ &quot;orrw  $dst, $src1, $src2\t# int&quot; %}
13366 
13367   ins_cost(INSN_COST);
13368   ins_encode %{
13369     __ orrw(as_Register($dst$$reg),
13370             as_Register($src1$$reg),
13371             (unsigned long)($src2$$constant));
13372   %}
13373 
13374   ins_pipe(ialu_reg_imm);
13375 %}
13376 
13377 // Xor Instructions
13378 
13379 instruct xorI_reg_reg(iRegINoSp dst, iRegIorL2I src1, iRegIorL2I src2) %{
13380   match(Set dst (XorI src1 src2));
13381 
13382   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13383 
13384   ins_cost(INSN_COST);
13385   ins_encode %{
13386     __ eorw(as_Register($dst$$reg),
13387             as_Register($src1$$reg),
13388             as_Register($src2$$reg));
13389   %}
13390 
13391   ins_pipe(ialu_reg_reg);
13392 %}
13393 
13394 instruct xorI_reg_imm(iRegINoSp dst, iRegIorL2I src1, immILog src2) %{
13395   match(Set dst (XorI src1 src2));
13396 
13397   format %{ &quot;eorw  $dst, $src1, $src2\t# int&quot; %}
13398 
13399   ins_cost(INSN_COST);
13400   ins_encode %{
13401     __ eorw(as_Register($dst$$reg),
13402             as_Register($src1$$reg),
13403             (unsigned long)($src2$$constant));
13404   %}
13405 
13406   ins_pipe(ialu_reg_imm);
13407 %}
13408 
13409 // Long Logical Instructions
13410 // TODO
13411 
13412 instruct andL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2, rFlagsReg cr) %{
13413   match(Set dst (AndL src1 src2));
13414 
13415   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13416 
13417   ins_cost(INSN_COST);
13418   ins_encode %{
13419     __ andr(as_Register($dst$$reg),
13420             as_Register($src1$$reg),
13421             as_Register($src2$$reg));
13422   %}
13423 
13424   ins_pipe(ialu_reg_reg);
13425 %}
13426 
13427 instruct andL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2, rFlagsReg cr) %{
13428   match(Set dst (AndL src1 src2));
13429 
13430   format %{ &quot;and  $dst, $src1, $src2\t# int&quot; %}
13431 
13432   ins_cost(INSN_COST);
13433   ins_encode %{
13434     __ andr(as_Register($dst$$reg),
13435             as_Register($src1$$reg),
13436             (unsigned long)($src2$$constant));
13437   %}
13438 
13439   ins_pipe(ialu_reg_imm);
13440 %}
13441 
13442 // Or Instructions
13443 
13444 instruct orL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13445   match(Set dst (OrL src1 src2));
13446 
13447   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13448 
13449   ins_cost(INSN_COST);
13450   ins_encode %{
13451     __ orr(as_Register($dst$$reg),
13452            as_Register($src1$$reg),
13453            as_Register($src2$$reg));
13454   %}
13455 
13456   ins_pipe(ialu_reg_reg);
13457 %}
13458 
13459 instruct orL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13460   match(Set dst (OrL src1 src2));
13461 
13462   format %{ &quot;orr  $dst, $src1, $src2\t# int&quot; %}
13463 
13464   ins_cost(INSN_COST);
13465   ins_encode %{
13466     __ orr(as_Register($dst$$reg),
13467            as_Register($src1$$reg),
13468            (unsigned long)($src2$$constant));
13469   %}
13470 
13471   ins_pipe(ialu_reg_imm);
13472 %}
13473 
13474 // Xor Instructions
13475 
13476 instruct xorL_reg_reg(iRegLNoSp dst, iRegL src1, iRegL src2) %{
13477   match(Set dst (XorL src1 src2));
13478 
13479   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13480 
13481   ins_cost(INSN_COST);
13482   ins_encode %{
13483     __ eor(as_Register($dst$$reg),
13484            as_Register($src1$$reg),
13485            as_Register($src2$$reg));
13486   %}
13487 
13488   ins_pipe(ialu_reg_reg);
13489 %}
13490 
13491 instruct xorL_reg_imm(iRegLNoSp dst, iRegL src1, immLLog src2) %{
13492   match(Set dst (XorL src1 src2));
13493 
13494   ins_cost(INSN_COST);
13495   format %{ &quot;eor  $dst, $src1, $src2\t# int&quot; %}
13496 
13497   ins_encode %{
13498     __ eor(as_Register($dst$$reg),
13499            as_Register($src1$$reg),
13500            (unsigned long)($src2$$constant));
13501   %}
13502 
13503   ins_pipe(ialu_reg_imm);
13504 %}
13505 
13506 instruct convI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src)
13507 %{
13508   match(Set dst (ConvI2L src));
13509 
13510   ins_cost(INSN_COST);
13511   format %{ &quot;sxtw  $dst, $src\t# i2l&quot; %}
13512   ins_encode %{
13513     __ sbfm($dst$$Register, $src$$Register, 0, 31);
13514   %}
13515   ins_pipe(ialu_reg_shift);
13516 %}
13517 
13518 // this pattern occurs in bigmath arithmetic
13519 instruct convUI2L_reg_reg(iRegLNoSp dst, iRegIorL2I src, immL_32bits mask)
13520 %{
13521   match(Set dst (AndL (ConvI2L src) mask));
13522 
13523   ins_cost(INSN_COST);
13524   format %{ &quot;ubfm  $dst, $src, 0, 31\t# ui2l&quot; %}
13525   ins_encode %{
13526     __ ubfm($dst$$Register, $src$$Register, 0, 31);
13527   %}
13528 
13529   ins_pipe(ialu_reg_shift);
13530 %}
13531 
13532 instruct convL2I_reg(iRegINoSp dst, iRegL src) %{
13533   match(Set dst (ConvL2I src));
13534 
13535   ins_cost(INSN_COST);
13536   format %{ &quot;movw  $dst, $src \t// l2i&quot; %}
13537 
13538   ins_encode %{
13539     __ movw(as_Register($dst$$reg), as_Register($src$$reg));
13540   %}
13541 
13542   ins_pipe(ialu_reg);
13543 %}
13544 
13545 instruct convI2B(iRegINoSp dst, iRegIorL2I src, rFlagsReg cr)
13546 %{
13547   match(Set dst (Conv2B src));
13548   effect(KILL cr);
13549 
13550   format %{
13551     &quot;cmpw $src, zr\n\t&quot;
13552     &quot;cset $dst, ne&quot;
13553   %}
13554 
13555   ins_encode %{
13556     __ cmpw(as_Register($src$$reg), zr);
13557     __ cset(as_Register($dst$$reg), Assembler::NE);
13558   %}
13559 
13560   ins_pipe(ialu_reg);
13561 %}
13562 
13563 instruct convP2B(iRegINoSp dst, iRegP src, rFlagsReg cr)
13564 %{
13565   match(Set dst (Conv2B src));
13566   effect(KILL cr);
13567 
13568   format %{
13569     &quot;cmp  $src, zr\n\t&quot;
13570     &quot;cset $dst, ne&quot;
13571   %}
13572 
13573   ins_encode %{
13574     __ cmp(as_Register($src$$reg), zr);
13575     __ cset(as_Register($dst$$reg), Assembler::NE);
13576   %}
13577 
13578   ins_pipe(ialu_reg);
13579 %}
13580 
13581 instruct convD2F_reg(vRegF dst, vRegD src) %{
13582   match(Set dst (ConvD2F src));
13583 
13584   ins_cost(INSN_COST * 5);
13585   format %{ &quot;fcvtd  $dst, $src \t// d2f&quot; %}
13586 
13587   ins_encode %{
13588     __ fcvtd(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13589   %}
13590 
13591   ins_pipe(fp_d2f);
13592 %}
13593 
13594 instruct convF2D_reg(vRegD dst, vRegF src) %{
13595   match(Set dst (ConvF2D src));
13596 
13597   ins_cost(INSN_COST * 5);
13598   format %{ &quot;fcvts  $dst, $src \t// f2d&quot; %}
13599 
13600   ins_encode %{
13601     __ fcvts(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg));
13602   %}
13603 
13604   ins_pipe(fp_f2d);
13605 %}
13606 
13607 instruct convF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13608   match(Set dst (ConvF2I src));
13609 
13610   ins_cost(INSN_COST * 5);
13611   format %{ &quot;fcvtzsw  $dst, $src \t// f2i&quot; %}
13612 
13613   ins_encode %{
13614     __ fcvtzsw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13615   %}
13616 
13617   ins_pipe(fp_f2i);
13618 %}
13619 
13620 instruct convF2L_reg_reg(iRegLNoSp dst, vRegF src) %{
13621   match(Set dst (ConvF2L src));
13622 
13623   ins_cost(INSN_COST * 5);
13624   format %{ &quot;fcvtzs  $dst, $src \t// f2l&quot; %}
13625 
13626   ins_encode %{
13627     __ fcvtzs(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13628   %}
13629 
13630   ins_pipe(fp_f2l);
13631 %}
13632 
13633 instruct convI2F_reg_reg(vRegF dst, iRegIorL2I src) %{
13634   match(Set dst (ConvI2F src));
13635 
13636   ins_cost(INSN_COST * 5);
13637   format %{ &quot;scvtfws  $dst, $src \t// i2f&quot; %}
13638 
13639   ins_encode %{
13640     __ scvtfws(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13641   %}
13642 
13643   ins_pipe(fp_i2f);
13644 %}
13645 
13646 instruct convL2F_reg_reg(vRegF dst, iRegL src) %{
13647   match(Set dst (ConvL2F src));
13648 
13649   ins_cost(INSN_COST * 5);
13650   format %{ &quot;scvtfs  $dst, $src \t// l2f&quot; %}
13651 
13652   ins_encode %{
13653     __ scvtfs(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13654   %}
13655 
13656   ins_pipe(fp_l2f);
13657 %}
13658 
13659 instruct convD2I_reg_reg(iRegINoSp dst, vRegD src) %{
13660   match(Set dst (ConvD2I src));
13661 
13662   ins_cost(INSN_COST * 5);
13663   format %{ &quot;fcvtzdw  $dst, $src \t// d2i&quot; %}
13664 
13665   ins_encode %{
13666     __ fcvtzdw(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13667   %}
13668 
13669   ins_pipe(fp_d2i);
13670 %}
13671 
13672 instruct convD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13673   match(Set dst (ConvD2L src));
13674 
13675   ins_cost(INSN_COST * 5);
13676   format %{ &quot;fcvtzd  $dst, $src \t// d2l&quot; %}
13677 
13678   ins_encode %{
13679     __ fcvtzd(as_Register($dst$$reg), as_FloatRegister($src$$reg));
13680   %}
13681 
13682   ins_pipe(fp_d2l);
13683 %}
13684 
13685 instruct convI2D_reg_reg(vRegD dst, iRegIorL2I src) %{
13686   match(Set dst (ConvI2D src));
13687 
13688   ins_cost(INSN_COST * 5);
13689   format %{ &quot;scvtfwd  $dst, $src \t// i2d&quot; %}
13690 
13691   ins_encode %{
13692     __ scvtfwd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13693   %}
13694 
13695   ins_pipe(fp_i2d);
13696 %}
13697 
13698 instruct convL2D_reg_reg(vRegD dst, iRegL src) %{
13699   match(Set dst (ConvL2D src));
13700 
13701   ins_cost(INSN_COST * 5);
13702   format %{ &quot;scvtfd  $dst, $src \t// l2d&quot; %}
13703 
13704   ins_encode %{
13705     __ scvtfd(as_FloatRegister($dst$$reg), as_Register($src$$reg));
13706   %}
13707 
13708   ins_pipe(fp_l2d);
13709 %}
13710 
13711 // stack &lt;-&gt; reg and reg &lt;-&gt; reg shuffles with no conversion
13712 
13713 instruct MoveF2I_stack_reg(iRegINoSp dst, stackSlotF src) %{
13714 
13715   match(Set dst (MoveF2I src));
13716 
13717   effect(DEF dst, USE src);
13718 
13719   ins_cost(4 * INSN_COST);
13720 
13721   format %{ &quot;ldrw $dst, $src\t# MoveF2I_stack_reg&quot; %}
13722 
13723   ins_encode %{
13724     __ ldrw($dst$$Register, Address(sp, $src$$disp));
13725   %}
13726 
13727   ins_pipe(iload_reg_reg);
13728 
13729 %}
13730 
13731 instruct MoveI2F_stack_reg(vRegF dst, stackSlotI src) %{
13732 
13733   match(Set dst (MoveI2F src));
13734 
13735   effect(DEF dst, USE src);
13736 
13737   ins_cost(4 * INSN_COST);
13738 
13739   format %{ &quot;ldrs $dst, $src\t# MoveI2F_stack_reg&quot; %}
13740 
13741   ins_encode %{
13742     __ ldrs(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13743   %}
13744 
13745   ins_pipe(pipe_class_memory);
13746 
13747 %}
13748 
13749 instruct MoveD2L_stack_reg(iRegLNoSp dst, stackSlotD src) %{
13750 
13751   match(Set dst (MoveD2L src));
13752 
13753   effect(DEF dst, USE src);
13754 
13755   ins_cost(4 * INSN_COST);
13756 
13757   format %{ &quot;ldr $dst, $src\t# MoveD2L_stack_reg&quot; %}
13758 
13759   ins_encode %{
13760     __ ldr($dst$$Register, Address(sp, $src$$disp));
13761   %}
13762 
13763   ins_pipe(iload_reg_reg);
13764 
13765 %}
13766 
13767 instruct MoveL2D_stack_reg(vRegD dst, stackSlotL src) %{
13768 
13769   match(Set dst (MoveL2D src));
13770 
13771   effect(DEF dst, USE src);
13772 
13773   ins_cost(4 * INSN_COST);
13774 
13775   format %{ &quot;ldrd $dst, $src\t# MoveL2D_stack_reg&quot; %}
13776 
13777   ins_encode %{
13778     __ ldrd(as_FloatRegister($dst$$reg), Address(sp, $src$$disp));
13779   %}
13780 
13781   ins_pipe(pipe_class_memory);
13782 
13783 %}
13784 
13785 instruct MoveF2I_reg_stack(stackSlotI dst, vRegF src) %{
13786 
13787   match(Set dst (MoveF2I src));
13788 
13789   effect(DEF dst, USE src);
13790 
13791   ins_cost(INSN_COST);
13792 
13793   format %{ &quot;strs $src, $dst\t# MoveF2I_reg_stack&quot; %}
13794 
13795   ins_encode %{
13796     __ strs(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13797   %}
13798 
13799   ins_pipe(pipe_class_memory);
13800 
13801 %}
13802 
13803 instruct MoveI2F_reg_stack(stackSlotF dst, iRegI src) %{
13804 
13805   match(Set dst (MoveI2F src));
13806 
13807   effect(DEF dst, USE src);
13808 
13809   ins_cost(INSN_COST);
13810 
13811   format %{ &quot;strw $src, $dst\t# MoveI2F_reg_stack&quot; %}
13812 
13813   ins_encode %{
13814     __ strw($src$$Register, Address(sp, $dst$$disp));
13815   %}
13816 
13817   ins_pipe(istore_reg_reg);
13818 
13819 %}
13820 
13821 instruct MoveD2L_reg_stack(stackSlotL dst, vRegD src) %{
13822 
13823   match(Set dst (MoveD2L src));
13824 
13825   effect(DEF dst, USE src);
13826 
13827   ins_cost(INSN_COST);
13828 
13829   format %{ &quot;strd $dst, $src\t# MoveD2L_reg_stack&quot; %}
13830 
13831   ins_encode %{
13832     __ strd(as_FloatRegister($src$$reg), Address(sp, $dst$$disp));
13833   %}
13834 
13835   ins_pipe(pipe_class_memory);
13836 
13837 %}
13838 
13839 instruct MoveL2D_reg_stack(stackSlotD dst, iRegL src) %{
13840 
13841   match(Set dst (MoveL2D src));
13842 
13843   effect(DEF dst, USE src);
13844 
13845   ins_cost(INSN_COST);
13846 
13847   format %{ &quot;str $src, $dst\t# MoveL2D_reg_stack&quot; %}
13848 
13849   ins_encode %{
13850     __ str($src$$Register, Address(sp, $dst$$disp));
13851   %}
13852 
13853   ins_pipe(istore_reg_reg);
13854 
13855 %}
13856 
13857 instruct MoveF2I_reg_reg(iRegINoSp dst, vRegF src) %{
13858 
13859   match(Set dst (MoveF2I src));
13860 
13861   effect(DEF dst, USE src);
13862 
13863   ins_cost(INSN_COST);
13864 
13865   format %{ &quot;fmovs $dst, $src\t# MoveF2I_reg_reg&quot; %}
13866 
13867   ins_encode %{
13868     __ fmovs($dst$$Register, as_FloatRegister($src$$reg));
13869   %}
13870 
13871   ins_pipe(fp_f2i);
13872 
13873 %}
13874 
13875 instruct MoveI2F_reg_reg(vRegF dst, iRegI src) %{
13876 
13877   match(Set dst (MoveI2F src));
13878 
13879   effect(DEF dst, USE src);
13880 
13881   ins_cost(INSN_COST);
13882 
13883   format %{ &quot;fmovs $dst, $src\t# MoveI2F_reg_reg&quot; %}
13884 
13885   ins_encode %{
13886     __ fmovs(as_FloatRegister($dst$$reg), $src$$Register);
13887   %}
13888 
13889   ins_pipe(fp_i2f);
13890 
13891 %}
13892 
13893 instruct MoveD2L_reg_reg(iRegLNoSp dst, vRegD src) %{
13894 
13895   match(Set dst (MoveD2L src));
13896 
13897   effect(DEF dst, USE src);
13898 
13899   ins_cost(INSN_COST);
13900 
13901   format %{ &quot;fmovd $dst, $src\t# MoveD2L_reg_reg&quot; %}
13902 
13903   ins_encode %{
13904     __ fmovd($dst$$Register, as_FloatRegister($src$$reg));
13905   %}
13906 
13907   ins_pipe(fp_d2l);
13908 
13909 %}
13910 
13911 instruct MoveL2D_reg_reg(vRegD dst, iRegL src) %{
13912 
13913   match(Set dst (MoveL2D src));
13914 
13915   effect(DEF dst, USE src);
13916 
13917   ins_cost(INSN_COST);
13918 
13919   format %{ &quot;fmovd $dst, $src\t# MoveL2D_reg_reg&quot; %}
13920 
13921   ins_encode %{
13922     __ fmovd(as_FloatRegister($dst$$reg), $src$$Register);
13923   %}
13924 
13925   ins_pipe(fp_l2d);
13926 
13927 %}
13928 
13929 // ============================================================================
13930 // clearing of an array
13931 
13932 instruct clearArray_reg_reg(iRegL_R11 cnt, iRegP_R10 base, iRegL val, Universe dummy, rFlagsReg cr)
13933 %{
13934   match(Set dummy (ClearArray (Binary cnt base) val));
13935   effect(USE_KILL cnt, USE_KILL base);
13936 
13937   ins_cost(4 * INSN_COST);
13938   format %{ &quot;ClearArray $cnt, $base, $val&quot; %}
13939 
13940   ins_encode %{
13941     __ fill_words($base$$Register, $cnt$$Register, $val$$Register);
13942   %}
13943 
13944   ins_pipe(pipe_class_memory);
13945 %}
13946 
13947 // ============================================================================
13948 // Overflow Math Instructions
13949 
13950 instruct overflowAddI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
13951 %{
13952   match(Set cr (OverflowAddI op1 op2));
13953 
13954   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13955   ins_cost(INSN_COST);
13956   ins_encode %{
13957     __ cmnw($op1$$Register, $op2$$Register);
13958   %}
13959 
13960   ins_pipe(icmp_reg_reg);
13961 %}
13962 
13963 instruct overflowAddI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
13964 %{
13965   match(Set cr (OverflowAddI op1 op2));
13966 
13967   format %{ &quot;cmnw  $op1, $op2\t# overflow check int&quot; %}
13968   ins_cost(INSN_COST);
13969   ins_encode %{
13970     __ cmnw($op1$$Register, $op2$$constant);
13971   %}
13972 
13973   ins_pipe(icmp_reg_imm);
13974 %}
13975 
13976 instruct overflowAddL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
13977 %{
13978   match(Set cr (OverflowAddL op1 op2));
13979 
13980   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13981   ins_cost(INSN_COST);
13982   ins_encode %{
13983     __ cmn($op1$$Register, $op2$$Register);
13984   %}
13985 
13986   ins_pipe(icmp_reg_reg);
13987 %}
13988 
13989 instruct overflowAddL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
13990 %{
13991   match(Set cr (OverflowAddL op1 op2));
13992 
13993   format %{ &quot;cmn   $op1, $op2\t# overflow check long&quot; %}
13994   ins_cost(INSN_COST);
13995   ins_encode %{
13996     __ cmn($op1$$Register, $op2$$constant);
13997   %}
13998 
13999   ins_pipe(icmp_reg_imm);
14000 %}
14001 
14002 instruct overflowSubI_reg_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14003 %{
14004   match(Set cr (OverflowSubI op1 op2));
14005 
14006   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14007   ins_cost(INSN_COST);
14008   ins_encode %{
14009     __ cmpw($op1$$Register, $op2$$Register);
14010   %}
14011 
14012   ins_pipe(icmp_reg_reg);
14013 %}
14014 
14015 instruct overflowSubI_reg_imm(rFlagsReg cr, iRegIorL2I op1, immIAddSub op2)
14016 %{
14017   match(Set cr (OverflowSubI op1 op2));
14018 
14019   format %{ &quot;cmpw  $op1, $op2\t# overflow check int&quot; %}
14020   ins_cost(INSN_COST);
14021   ins_encode %{
14022     __ cmpw($op1$$Register, $op2$$constant);
14023   %}
14024 
14025   ins_pipe(icmp_reg_imm);
14026 %}
14027 
14028 instruct overflowSubL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14029 %{
14030   match(Set cr (OverflowSubL op1 op2));
14031 
14032   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14033   ins_cost(INSN_COST);
14034   ins_encode %{
14035     __ cmp($op1$$Register, $op2$$Register);
14036   %}
14037 
14038   ins_pipe(icmp_reg_reg);
14039 %}
14040 
14041 instruct overflowSubL_reg_imm(rFlagsReg cr, iRegL op1, immLAddSub op2)
14042 %{
14043   match(Set cr (OverflowSubL op1 op2));
14044 
14045   format %{ &quot;cmp   $op1, $op2\t# overflow check long&quot; %}
14046   ins_cost(INSN_COST);
14047   ins_encode %{
14048     __ subs(zr, $op1$$Register, $op2$$constant);
14049   %}
14050 
14051   ins_pipe(icmp_reg_imm);
14052 %}
14053 
14054 instruct overflowNegI_reg(rFlagsReg cr, immI0 zero, iRegIorL2I op1)
14055 %{
14056   match(Set cr (OverflowSubI zero op1));
14057 
14058   format %{ &quot;cmpw  zr, $op1\t# overflow check int&quot; %}
14059   ins_cost(INSN_COST);
14060   ins_encode %{
14061     __ cmpw(zr, $op1$$Register);
14062   %}
14063 
14064   ins_pipe(icmp_reg_imm);
14065 %}
14066 
14067 instruct overflowNegL_reg(rFlagsReg cr, immI0 zero, iRegL op1)
14068 %{
14069   match(Set cr (OverflowSubL zero op1));
14070 
14071   format %{ &quot;cmp   zr, $op1\t# overflow check long&quot; %}
14072   ins_cost(INSN_COST);
14073   ins_encode %{
14074     __ cmp(zr, $op1$$Register);
14075   %}
14076 
14077   ins_pipe(icmp_reg_imm);
14078 %}
14079 
14080 instruct overflowMulI_reg(rFlagsReg cr, iRegIorL2I op1, iRegIorL2I op2)
14081 %{
14082   match(Set cr (OverflowMulI op1 op2));
14083 
14084   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14085             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14086             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14087             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14088             &quot;cmpw  rscratch1, #1&quot; %}
14089   ins_cost(5 * INSN_COST);
14090   ins_encode %{
14091     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14092     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14093     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14094     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14095     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14096   %}
14097 
14098   ins_pipe(pipe_slow);
14099 %}
14100 
14101 instruct overflowMulI_reg_branch(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, label labl, rFlagsReg cr)
14102 %{
14103   match(If cmp (OverflowMulI op1 op2));
14104   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14105             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14106   effect(USE labl, KILL cr);
14107 
14108   format %{ &quot;smull rscratch1, $op1, $op2\t# overflow check int\n\t&quot;
14109             &quot;cmp   rscratch1, rscratch1, sxtw\n\t&quot;
14110             &quot;b$cmp   $labl&quot; %}
14111   ins_cost(3 * INSN_COST); // Branch is rare so treat as INSN_COST
14112   ins_encode %{
14113     Label* L = $labl$$label;
14114     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14115     __ smull(rscratch1, $op1$$Register, $op2$$Register);
14116     __ subs(zr, rscratch1, rscratch1, ext::sxtw);      // NE =&gt; overflow
14117     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14118   %}
14119 
14120   ins_pipe(pipe_serial);
14121 %}
14122 
14123 instruct overflowMulL_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14124 %{
14125   match(Set cr (OverflowMulL op1 op2));
14126 
14127   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14128             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14129             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14130             &quot;movw  rscratch1, #0x80000000\n\t&quot;
14131             &quot;cselw rscratch1, rscratch1, zr, NE\n\t&quot;
14132             &quot;cmpw  rscratch1, #1&quot; %}
14133   ins_cost(6 * INSN_COST);
14134   ins_encode %{
14135     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14136     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14137     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14138     __ movw(rscratch1, 0x80000000);                    // Develop 0 (EQ),
14139     __ cselw(rscratch1, rscratch1, zr, Assembler::NE); // or 0x80000000 (NE)
14140     __ cmpw(rscratch1, 1);                             // 0x80000000 - 1 =&gt; VS
14141   %}
14142 
14143   ins_pipe(pipe_slow);
14144 %}
14145 
14146 instruct overflowMulL_reg_branch(cmpOp cmp, iRegL op1, iRegL op2, label labl, rFlagsReg cr)
14147 %{
14148   match(If cmp (OverflowMulL op1 op2));
14149   predicate(n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::overflow
14150             || n-&gt;in(1)-&gt;as_Bool()-&gt;_test._test == BoolTest::no_overflow);
14151   effect(USE labl, KILL cr);
14152 
14153   format %{ &quot;mul   rscratch1, $op1, $op2\t#overflow check long\n\t&quot;
14154             &quot;smulh rscratch2, $op1, $op2\n\t&quot;
14155             &quot;cmp   rscratch2, rscratch1, ASR #63\n\t&quot;
14156             &quot;b$cmp $labl&quot; %}
14157   ins_cost(4 * INSN_COST); // Branch is rare so treat as INSN_COST
14158   ins_encode %{
14159     Label* L = $labl$$label;
14160     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14161     __ mul(rscratch1, $op1$$Register, $op2$$Register);   // Result bits 0..63
14162     __ smulh(rscratch2, $op1$$Register, $op2$$Register); // Result bits 64..127
14163     __ cmp(rscratch2, rscratch1, Assembler::ASR, 63);    // Top is pure sign ext
14164     __ br(cond == Assembler::VS ? Assembler::NE : Assembler::EQ, *L);
14165   %}
14166 
14167   ins_pipe(pipe_serial);
14168 %}
14169 
14170 // ============================================================================
14171 // Compare Instructions
14172 
14173 instruct compI_reg_reg(rFlagsReg cr, iRegI op1, iRegI op2)
14174 %{
14175   match(Set cr (CmpI op1 op2));
14176 
14177   effect(DEF cr, USE op1, USE op2);
14178 
14179   ins_cost(INSN_COST);
14180   format %{ &quot;cmpw  $op1, $op2&quot; %}
14181 
14182   ins_encode(aarch64_enc_cmpw(op1, op2));
14183 
14184   ins_pipe(icmp_reg_reg);
14185 %}
14186 
14187 instruct compI_reg_immI0(rFlagsReg cr, iRegI op1, immI0 zero)
14188 %{
14189   match(Set cr (CmpI op1 zero));
14190 
14191   effect(DEF cr, USE op1);
14192 
14193   ins_cost(INSN_COST);
14194   format %{ &quot;cmpw $op1, 0&quot; %}
14195 
14196   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14197 
14198   ins_pipe(icmp_reg_imm);
14199 %}
14200 
14201 instruct compI_reg_immIAddSub(rFlagsReg cr, iRegI op1, immIAddSub op2)
14202 %{
14203   match(Set cr (CmpI op1 op2));
14204 
14205   effect(DEF cr, USE op1);
14206 
14207   ins_cost(INSN_COST);
14208   format %{ &quot;cmpw  $op1, $op2&quot; %}
14209 
14210   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14211 
14212   ins_pipe(icmp_reg_imm);
14213 %}
14214 
14215 instruct compI_reg_immI(rFlagsReg cr, iRegI op1, immI op2)
14216 %{
14217   match(Set cr (CmpI op1 op2));
14218 
14219   effect(DEF cr, USE op1);
14220 
14221   ins_cost(INSN_COST * 2);
14222   format %{ &quot;cmpw  $op1, $op2&quot; %}
14223 
14224   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14225 
14226   ins_pipe(icmp_reg_imm);
14227 %}
14228 
14229 // Unsigned compare Instructions; really, same as signed compare
14230 // except it should only be used to feed an If or a CMovI which takes a
14231 // cmpOpU.
14232 
14233 instruct compU_reg_reg(rFlagsRegU cr, iRegI op1, iRegI op2)
14234 %{
14235   match(Set cr (CmpU op1 op2));
14236 
14237   effect(DEF cr, USE op1, USE op2);
14238 
14239   ins_cost(INSN_COST);
14240   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14241 
14242   ins_encode(aarch64_enc_cmpw(op1, op2));
14243 
14244   ins_pipe(icmp_reg_reg);
14245 %}
14246 
14247 instruct compU_reg_immI0(rFlagsRegU cr, iRegI op1, immI0 zero)
14248 %{
14249   match(Set cr (CmpU op1 zero));
14250 
14251   effect(DEF cr, USE op1);
14252 
14253   ins_cost(INSN_COST);
14254   format %{ &quot;cmpw $op1, #0\t# unsigned&quot; %}
14255 
14256   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, zero));
14257 
14258   ins_pipe(icmp_reg_imm);
14259 %}
14260 
14261 instruct compU_reg_immIAddSub(rFlagsRegU cr, iRegI op1, immIAddSub op2)
14262 %{
14263   match(Set cr (CmpU op1 op2));
14264 
14265   effect(DEF cr, USE op1);
14266 
14267   ins_cost(INSN_COST);
14268   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14269 
14270   ins_encode(aarch64_enc_cmpw_imm_addsub(op1, op2));
14271 
14272   ins_pipe(icmp_reg_imm);
14273 %}
14274 
14275 instruct compU_reg_immI(rFlagsRegU cr, iRegI op1, immI op2)
14276 %{
14277   match(Set cr (CmpU op1 op2));
14278 
14279   effect(DEF cr, USE op1);
14280 
14281   ins_cost(INSN_COST * 2);
14282   format %{ &quot;cmpw  $op1, $op2\t# unsigned&quot; %}
14283 
14284   ins_encode(aarch64_enc_cmpw_imm(op1, op2));
14285 
14286   ins_pipe(icmp_reg_imm);
14287 %}
14288 
14289 instruct compL_reg_reg(rFlagsReg cr, iRegL op1, iRegL op2)
14290 %{
14291   match(Set cr (CmpL op1 op2));
14292 
14293   effect(DEF cr, USE op1, USE op2);
14294 
14295   ins_cost(INSN_COST);
14296   format %{ &quot;cmp  $op1, $op2&quot; %}
14297 
14298   ins_encode(aarch64_enc_cmp(op1, op2));
14299 
14300   ins_pipe(icmp_reg_reg);
14301 %}
14302 
14303 instruct compL_reg_immL0(rFlagsReg cr, iRegL op1, immL0 zero)
14304 %{
14305   match(Set cr (CmpL op1 zero));
14306 
14307   effect(DEF cr, USE op1);
14308 
14309   ins_cost(INSN_COST);
14310   format %{ &quot;tst  $op1&quot; %}
14311 
14312   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14313 
14314   ins_pipe(icmp_reg_imm);
14315 %}
14316 
14317 instruct compL_reg_immLAddSub(rFlagsReg cr, iRegL op1, immLAddSub op2)
14318 %{
14319   match(Set cr (CmpL op1 op2));
14320 
14321   effect(DEF cr, USE op1);
14322 
14323   ins_cost(INSN_COST);
14324   format %{ &quot;cmp  $op1, $op2&quot; %}
14325 
14326   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14327 
14328   ins_pipe(icmp_reg_imm);
14329 %}
14330 
14331 instruct compL_reg_immL(rFlagsReg cr, iRegL op1, immL op2)
14332 %{
14333   match(Set cr (CmpL op1 op2));
14334 
14335   effect(DEF cr, USE op1);
14336 
14337   ins_cost(INSN_COST * 2);
14338   format %{ &quot;cmp  $op1, $op2&quot; %}
14339 
14340   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14341 
14342   ins_pipe(icmp_reg_imm);
14343 %}
14344 
14345 instruct compUL_reg_reg(rFlagsRegU cr, iRegL op1, iRegL op2)
14346 %{
14347   match(Set cr (CmpUL op1 op2));
14348 
14349   effect(DEF cr, USE op1, USE op2);
14350 
14351   ins_cost(INSN_COST);
14352   format %{ &quot;cmp  $op1, $op2&quot; %}
14353 
14354   ins_encode(aarch64_enc_cmp(op1, op2));
14355 
14356   ins_pipe(icmp_reg_reg);
14357 %}
14358 
14359 instruct compUL_reg_immL0(rFlagsRegU cr, iRegL op1, immL0 zero)
14360 %{
14361   match(Set cr (CmpUL op1 zero));
14362 
14363   effect(DEF cr, USE op1);
14364 
14365   ins_cost(INSN_COST);
14366   format %{ &quot;tst  $op1&quot; %}
14367 
14368   ins_encode(aarch64_enc_cmp_imm_addsub(op1, zero));
14369 
14370   ins_pipe(icmp_reg_imm);
14371 %}
14372 
14373 instruct compUL_reg_immLAddSub(rFlagsRegU cr, iRegL op1, immLAddSub op2)
14374 %{
14375   match(Set cr (CmpUL op1 op2));
14376 
14377   effect(DEF cr, USE op1);
14378 
14379   ins_cost(INSN_COST);
14380   format %{ &quot;cmp  $op1, $op2&quot; %}
14381 
14382   ins_encode(aarch64_enc_cmp_imm_addsub(op1, op2));
14383 
14384   ins_pipe(icmp_reg_imm);
14385 %}
14386 
14387 instruct compUL_reg_immL(rFlagsRegU cr, iRegL op1, immL op2)
14388 %{
14389   match(Set cr (CmpUL op1 op2));
14390 
14391   effect(DEF cr, USE op1);
14392 
14393   ins_cost(INSN_COST * 2);
14394   format %{ &quot;cmp  $op1, $op2&quot; %}
14395 
14396   ins_encode(aarch64_enc_cmp_imm(op1, op2));
14397 
14398   ins_pipe(icmp_reg_imm);
14399 %}
14400 
14401 instruct compP_reg_reg(rFlagsRegU cr, iRegP op1, iRegP op2)
14402 %{
14403   match(Set cr (CmpP op1 op2));
14404 
14405   effect(DEF cr, USE op1, USE op2);
14406 
14407   ins_cost(INSN_COST);
14408   format %{ &quot;cmp  $op1, $op2\t // ptr&quot; %}
14409 
14410   ins_encode(aarch64_enc_cmpp(op1, op2));
14411 
14412   ins_pipe(icmp_reg_reg);
14413 %}
14414 
14415 instruct compN_reg_reg(rFlagsRegU cr, iRegN op1, iRegN op2)
14416 %{
14417   match(Set cr (CmpN op1 op2));
14418 
14419   effect(DEF cr, USE op1, USE op2);
14420 
14421   ins_cost(INSN_COST);
14422   format %{ &quot;cmp  $op1, $op2\t // compressed ptr&quot; %}
14423 
14424   ins_encode(aarch64_enc_cmpn(op1, op2));
14425 
14426   ins_pipe(icmp_reg_reg);
14427 %}
14428 
14429 instruct testP_reg(rFlagsRegU cr, iRegP op1, immP0 zero)
14430 %{
14431   match(Set cr (CmpP op1 zero));
14432 
14433   effect(DEF cr, USE op1, USE zero);
14434 
14435   ins_cost(INSN_COST);
14436   format %{ &quot;cmp  $op1, 0\t // ptr&quot; %}
14437 
14438   ins_encode(aarch64_enc_testp(op1));
14439 
14440   ins_pipe(icmp_reg_imm);
14441 %}
14442 
14443 instruct testN_reg(rFlagsRegU cr, iRegN op1, immN0 zero)
14444 %{
14445   match(Set cr (CmpN op1 zero));
14446 
14447   effect(DEF cr, USE op1, USE zero);
14448 
14449   ins_cost(INSN_COST);
14450   format %{ &quot;cmp  $op1, 0\t // compressed ptr&quot; %}
14451 
14452   ins_encode(aarch64_enc_testn(op1));
14453 
14454   ins_pipe(icmp_reg_imm);
14455 %}
14456 
14457 // FP comparisons
14458 //
14459 // n.b. CmpF/CmpD set a normal flags reg which then gets compared
14460 // using normal cmpOp. See declaration of rFlagsReg for details.
14461 
14462 instruct compF_reg_reg(rFlagsReg cr, vRegF src1, vRegF src2)
14463 %{
14464   match(Set cr (CmpF src1 src2));
14465 
14466   ins_cost(3 * INSN_COST);
14467   format %{ &quot;fcmps $src1, $src2&quot; %}
14468 
14469   ins_encode %{
14470     __ fcmps(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14471   %}
14472 
14473   ins_pipe(pipe_class_compare);
14474 %}
14475 
14476 instruct compF_reg_zero(rFlagsReg cr, vRegF src1, immF0 src2)
14477 %{
14478   match(Set cr (CmpF src1 src2));
14479 
14480   ins_cost(3 * INSN_COST);
14481   format %{ &quot;fcmps $src1, 0.0&quot; %}
14482 
14483   ins_encode %{
14484     __ fcmps(as_FloatRegister($src1$$reg), 0.0);
14485   %}
14486 
14487   ins_pipe(pipe_class_compare);
14488 %}
14489 // FROM HERE
14490 
14491 instruct compD_reg_reg(rFlagsReg cr, vRegD src1, vRegD src2)
14492 %{
14493   match(Set cr (CmpD src1 src2));
14494 
14495   ins_cost(3 * INSN_COST);
14496   format %{ &quot;fcmpd $src1, $src2&quot; %}
14497 
14498   ins_encode %{
14499     __ fcmpd(as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));
14500   %}
14501 
14502   ins_pipe(pipe_class_compare);
14503 %}
14504 
14505 instruct compD_reg_zero(rFlagsReg cr, vRegD src1, immD0 src2)
14506 %{
14507   match(Set cr (CmpD src1 src2));
14508 
14509   ins_cost(3 * INSN_COST);
14510   format %{ &quot;fcmpd $src1, 0.0&quot; %}
14511 
14512   ins_encode %{
14513     __ fcmpd(as_FloatRegister($src1$$reg), 0.0);
14514   %}
14515 
14516   ins_pipe(pipe_class_compare);
14517 %}
14518 
14519 instruct compF3_reg_reg(iRegINoSp dst, vRegF src1, vRegF src2, rFlagsReg cr)
14520 %{
14521   match(Set dst (CmpF3 src1 src2));
14522   effect(KILL cr);
14523 
14524   ins_cost(5 * INSN_COST);
14525   format %{ &quot;fcmps $src1, $src2\n\t&quot;
14526             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14527             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14528   %}
14529 
14530   ins_encode %{
14531     Label done;
14532     FloatRegister s1 = as_FloatRegister($src1$$reg);
14533     FloatRegister s2 = as_FloatRegister($src2$$reg);
14534     Register d = as_Register($dst$$reg);
14535     __ fcmps(s1, s2);
14536     // installs 0 if EQ else -1
14537     __ csinvw(d, zr, zr, Assembler::EQ);
14538     // keeps -1 if less or unordered else installs 1
14539     __ csnegw(d, d, d, Assembler::LT);
14540     __ bind(done);
14541   %}
14542 
14543   ins_pipe(pipe_class_default);
14544 
14545 %}
14546 
14547 instruct compD3_reg_reg(iRegINoSp dst, vRegD src1, vRegD src2, rFlagsReg cr)
14548 %{
14549   match(Set dst (CmpD3 src1 src2));
14550   effect(KILL cr);
14551 
14552   ins_cost(5 * INSN_COST);
14553   format %{ &quot;fcmpd $src1, $src2\n\t&quot;
14554             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14555             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14556   %}
14557 
14558   ins_encode %{
14559     Label done;
14560     FloatRegister s1 = as_FloatRegister($src1$$reg);
14561     FloatRegister s2 = as_FloatRegister($src2$$reg);
14562     Register d = as_Register($dst$$reg);
14563     __ fcmpd(s1, s2);
14564     // installs 0 if EQ else -1
14565     __ csinvw(d, zr, zr, Assembler::EQ);
14566     // keeps -1 if less or unordered else installs 1
14567     __ csnegw(d, d, d, Assembler::LT);
14568     __ bind(done);
14569   %}
14570   ins_pipe(pipe_class_default);
14571 
14572 %}
14573 
14574 instruct compF3_reg_immF0(iRegINoSp dst, vRegF src1, immF0 zero, rFlagsReg cr)
14575 %{
14576   match(Set dst (CmpF3 src1 zero));
14577   effect(KILL cr);
14578 
14579   ins_cost(5 * INSN_COST);
14580   format %{ &quot;fcmps $src1, 0.0\n\t&quot;
14581             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14582             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14583   %}
14584 
14585   ins_encode %{
14586     Label done;
14587     FloatRegister s1 = as_FloatRegister($src1$$reg);
14588     Register d = as_Register($dst$$reg);
14589     __ fcmps(s1, 0.0);
14590     // installs 0 if EQ else -1
14591     __ csinvw(d, zr, zr, Assembler::EQ);
14592     // keeps -1 if less or unordered else installs 1
14593     __ csnegw(d, d, d, Assembler::LT);
14594     __ bind(done);
14595   %}
14596 
14597   ins_pipe(pipe_class_default);
14598 
14599 %}
14600 
14601 instruct compD3_reg_immD0(iRegINoSp dst, vRegD src1, immD0 zero, rFlagsReg cr)
14602 %{
14603   match(Set dst (CmpD3 src1 zero));
14604   effect(KILL cr);
14605 
14606   ins_cost(5 * INSN_COST);
14607   format %{ &quot;fcmpd $src1, 0.0\n\t&quot;
14608             &quot;csinvw($dst, zr, zr, eq\n\t&quot;
14609             &quot;csnegw($dst, $dst, $dst, lt)&quot;
14610   %}
14611 
14612   ins_encode %{
14613     Label done;
14614     FloatRegister s1 = as_FloatRegister($src1$$reg);
14615     Register d = as_Register($dst$$reg);
14616     __ fcmpd(s1, 0.0);
14617     // installs 0 if EQ else -1
14618     __ csinvw(d, zr, zr, Assembler::EQ);
14619     // keeps -1 if less or unordered else installs 1
14620     __ csnegw(d, d, d, Assembler::LT);
14621     __ bind(done);
14622   %}
14623   ins_pipe(pipe_class_default);
14624 
14625 %}
14626 
14627 instruct cmpLTMask_reg_reg(iRegINoSp dst, iRegIorL2I p, iRegIorL2I q, rFlagsReg cr)
14628 %{
14629   match(Set dst (CmpLTMask p q));
14630   effect(KILL cr);
14631 
14632   ins_cost(3 * INSN_COST);
14633 
14634   format %{ &quot;cmpw $p, $q\t# cmpLTMask\n\t&quot;
14635             &quot;csetw $dst, lt\n\t&quot;
14636             &quot;subw $dst, zr, $dst&quot;
14637   %}
14638 
14639   ins_encode %{
14640     __ cmpw(as_Register($p$$reg), as_Register($q$$reg));
14641     __ csetw(as_Register($dst$$reg), Assembler::LT);
14642     __ subw(as_Register($dst$$reg), zr, as_Register($dst$$reg));
14643   %}
14644 
14645   ins_pipe(ialu_reg_reg);
14646 %}
14647 
14648 instruct cmpLTMask_reg_zero(iRegINoSp dst, iRegIorL2I src, immI0 zero, rFlagsReg cr)
14649 %{
14650   match(Set dst (CmpLTMask src zero));
14651   effect(KILL cr);
14652 
14653   ins_cost(INSN_COST);
14654 
14655   format %{ &quot;asrw $dst, $src, #31\t# cmpLTMask0&quot; %}
14656 
14657   ins_encode %{
14658     __ asrw(as_Register($dst$$reg), as_Register($src$$reg), 31);
14659   %}
14660 
14661   ins_pipe(ialu_reg_shift);
14662 %}
14663 
14664 // ============================================================================
14665 // Max and Min
14666 
14667 instruct cmovI_reg_reg_lt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14668 %{
14669   effect( DEF dst, USE src1, USE src2, USE cr );
14670 
14671   ins_cost(INSN_COST * 2);
14672   format %{ &quot;cselw $dst, $src1, $src2 lt\t&quot;  %}
14673 
14674   ins_encode %{
14675     __ cselw(as_Register($dst$$reg),
14676              as_Register($src1$$reg),
14677              as_Register($src2$$reg),
14678              Assembler::LT);
14679   %}
14680 
14681   ins_pipe(icond_reg_reg);
14682 %}
14683 
14684 instruct minI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14685 %{
14686   match(Set dst (MinI src1 src2));
14687   ins_cost(INSN_COST * 3);
14688 
14689   expand %{
14690     rFlagsReg cr;
14691     compI_reg_reg(cr, src1, src2);
14692     cmovI_reg_reg_lt(dst, src1, src2, cr);
14693   %}
14694 
14695 %}
14696 // FROM HERE
14697 
14698 instruct cmovI_reg_reg_gt(iRegINoSp dst, iRegI src1, iRegI src2, rFlagsReg cr)
14699 %{
14700   effect( DEF dst, USE src1, USE src2, USE cr );
14701 
14702   ins_cost(INSN_COST * 2);
14703   format %{ &quot;cselw $dst, $src1, $src2 gt\t&quot;  %}
14704 
14705   ins_encode %{
14706     __ cselw(as_Register($dst$$reg),
14707              as_Register($src1$$reg),
14708              as_Register($src2$$reg),
14709              Assembler::GT);
14710   %}
14711 
14712   ins_pipe(icond_reg_reg);
14713 %}
14714 
14715 instruct maxI_rReg(iRegINoSp dst, iRegI src1, iRegI src2)
14716 %{
14717   match(Set dst (MaxI src1 src2));
14718   ins_cost(INSN_COST * 3);
14719   expand %{
14720     rFlagsReg cr;
14721     compI_reg_reg(cr, src1, src2);
14722     cmovI_reg_reg_gt(dst, src1, src2, cr);
14723   %}
14724 %}
14725 
14726 // ============================================================================
14727 // Branch Instructions
14728 
14729 // Direct Branch.
14730 instruct branch(label lbl)
14731 %{
14732   match(Goto);
14733 
14734   effect(USE lbl);
14735 
14736   ins_cost(BRANCH_COST);
14737   format %{ &quot;b  $lbl&quot; %}
14738 
14739   ins_encode(aarch64_enc_b(lbl));
14740 
14741   ins_pipe(pipe_branch);
14742 %}
14743 
14744 // Conditional Near Branch
14745 instruct branchCon(cmpOp cmp, rFlagsReg cr, label lbl)
14746 %{
14747   // Same match rule as `branchConFar&#39;.
14748   match(If cmp cr);
14749 
14750   effect(USE lbl);
14751 
14752   ins_cost(BRANCH_COST);
14753   // If set to 1 this indicates that the current instruction is a
14754   // short variant of a long branch. This avoids using this
14755   // instruction in first-pass matching. It will then only be used in
14756   // the `Shorten_branches&#39; pass.
14757   // ins_short_branch(1);
14758   format %{ &quot;b$cmp  $lbl&quot; %}
14759 
14760   ins_encode(aarch64_enc_br_con(cmp, lbl));
14761 
14762   ins_pipe(pipe_branch_cond);
14763 %}
14764 
14765 // Conditional Near Branch Unsigned
14766 instruct branchConU(cmpOpU cmp, rFlagsRegU cr, label lbl)
14767 %{
14768   // Same match rule as `branchConFar&#39;.
14769   match(If cmp cr);
14770 
14771   effect(USE lbl);
14772 
14773   ins_cost(BRANCH_COST);
14774   // If set to 1 this indicates that the current instruction is a
14775   // short variant of a long branch. This avoids using this
14776   // instruction in first-pass matching. It will then only be used in
14777   // the `Shorten_branches&#39; pass.
14778   // ins_short_branch(1);
14779   format %{ &quot;b$cmp  $lbl\t# unsigned&quot; %}
14780 
14781   ins_encode(aarch64_enc_br_conU(cmp, lbl));
14782 
14783   ins_pipe(pipe_branch_cond);
14784 %}
14785 
14786 // Make use of CBZ and CBNZ.  These instructions, as well as being
14787 // shorter than (cmp; branch), have the additional benefit of not
14788 // killing the flags.
14789 
14790 instruct cmpI_imm0_branch(cmpOpEqNe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsReg cr) %{
14791   match(If cmp (CmpI op1 op2));
14792   effect(USE labl);
14793 
14794   ins_cost(BRANCH_COST);
14795   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14796   ins_encode %{
14797     Label* L = $labl$$label;
14798     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14799     if (cond == Assembler::EQ)
14800       __ cbzw($op1$$Register, *L);
14801     else
14802       __ cbnzw($op1$$Register, *L);
14803   %}
14804   ins_pipe(pipe_cmp_branch);
14805 %}
14806 
14807 instruct cmpL_imm0_branch(cmpOpEqNe cmp, iRegL op1, immL0 op2, label labl, rFlagsReg cr) %{
14808   match(If cmp (CmpL op1 op2));
14809   effect(USE labl);
14810 
14811   ins_cost(BRANCH_COST);
14812   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14813   ins_encode %{
14814     Label* L = $labl$$label;
14815     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14816     if (cond == Assembler::EQ)
14817       __ cbz($op1$$Register, *L);
14818     else
14819       __ cbnz($op1$$Register, *L);
14820   %}
14821   ins_pipe(pipe_cmp_branch);
14822 %}
14823 
14824 instruct cmpP_imm0_branch(cmpOpEqNe cmp, iRegP op1, immP0 op2, label labl, rFlagsReg cr) %{
14825   match(If cmp (CmpP op1 op2));
14826   effect(USE labl);
14827 
14828   ins_cost(BRANCH_COST);
14829   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14830   ins_encode %{
14831     Label* L = $labl$$label;
14832     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14833     if (cond == Assembler::EQ)
14834       __ cbz($op1$$Register, *L);
14835     else
14836       __ cbnz($op1$$Register, *L);
14837   %}
14838   ins_pipe(pipe_cmp_branch);
14839 %}
14840 
14841 instruct cmpN_imm0_branch(cmpOpEqNe cmp, iRegN op1, immN0 op2, label labl, rFlagsReg cr) %{
14842   match(If cmp (CmpN op1 op2));
14843   effect(USE labl);
14844 
14845   ins_cost(BRANCH_COST);
14846   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14847   ins_encode %{
14848     Label* L = $labl$$label;
14849     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14850     if (cond == Assembler::EQ)
14851       __ cbzw($op1$$Register, *L);
14852     else
14853       __ cbnzw($op1$$Register, *L);
14854   %}
14855   ins_pipe(pipe_cmp_branch);
14856 %}
14857 
14858 instruct cmpP_narrowOop_imm0_branch(cmpOpEqNe cmp, iRegN oop, immP0 zero, label labl, rFlagsReg cr) %{
14859   match(If cmp (CmpP (DecodeN oop) zero));
14860   effect(USE labl);
14861 
14862   ins_cost(BRANCH_COST);
14863   format %{ &quot;cb$cmp   $oop, $labl&quot; %}
14864   ins_encode %{
14865     Label* L = $labl$$label;
14866     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14867     if (cond == Assembler::EQ)
14868       __ cbzw($oop$$Register, *L);
14869     else
14870       __ cbnzw($oop$$Register, *L);
14871   %}
14872   ins_pipe(pipe_cmp_branch);
14873 %}
14874 
14875 instruct cmpUI_imm0_branch(cmpOpUEqNeLtGe cmp, iRegIorL2I op1, immI0 op2, label labl, rFlagsRegU cr) %{
14876   match(If cmp (CmpU op1 op2));
14877   effect(USE labl);
14878 
14879   ins_cost(BRANCH_COST);
14880   format %{ &quot;cbw$cmp   $op1, $labl&quot; %}
14881   ins_encode %{
14882     Label* L = $labl$$label;
14883     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14884     if (cond == Assembler::EQ || cond == Assembler::LS)
14885       __ cbzw($op1$$Register, *L);
14886     else
14887       __ cbnzw($op1$$Register, *L);
14888   %}
14889   ins_pipe(pipe_cmp_branch);
14890 %}
14891 
14892 instruct cmpUL_imm0_branch(cmpOpUEqNeLtGe cmp, iRegL op1, immL0 op2, label labl, rFlagsRegU cr) %{
14893   match(If cmp (CmpUL op1 op2));
14894   effect(USE labl);
14895 
14896   ins_cost(BRANCH_COST);
14897   format %{ &quot;cb$cmp   $op1, $labl&quot; %}
14898   ins_encode %{
14899     Label* L = $labl$$label;
14900     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14901     if (cond == Assembler::EQ || cond == Assembler::LS)
14902       __ cbz($op1$$Register, *L);
14903     else
14904       __ cbnz($op1$$Register, *L);
14905   %}
14906   ins_pipe(pipe_cmp_branch);
14907 %}
14908 
14909 // Test bit and Branch
14910 
14911 // Patterns for short (&lt; 32KiB) variants
14912 instruct cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14913   match(If cmp (CmpL op1 op2));
14914   effect(USE labl);
14915 
14916   ins_cost(BRANCH_COST);
14917   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14918   ins_encode %{
14919     Label* L = $labl$$label;
14920     Assembler::Condition cond =
14921       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14922     __ tbr(cond, $op1$$Register, 63, *L);
14923   %}
14924   ins_pipe(pipe_cmp_branch);
14925   ins_short_branch(1);
14926 %}
14927 
14928 instruct cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14929   match(If cmp (CmpI op1 op2));
14930   effect(USE labl);
14931 
14932   ins_cost(BRANCH_COST);
14933   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
14934   ins_encode %{
14935     Label* L = $labl$$label;
14936     Assembler::Condition cond =
14937       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14938     __ tbr(cond, $op1$$Register, 31, *L);
14939   %}
14940   ins_pipe(pipe_cmp_branch);
14941   ins_short_branch(1);
14942 %}
14943 
14944 instruct cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
14945   match(If cmp (CmpL (AndL op1 op2) op3));
14946   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
14947   effect(USE labl);
14948 
14949   ins_cost(BRANCH_COST);
14950   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14951   ins_encode %{
14952     Label* L = $labl$$label;
14953     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14954     int bit = exact_log2_long($op2$$constant);
14955     __ tbr(cond, $op1$$Register, bit, *L);
14956   %}
14957   ins_pipe(pipe_cmp_branch);
14958   ins_short_branch(1);
14959 %}
14960 
14961 instruct cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
14962   match(If cmp (CmpI (AndI op1 op2) op3));
14963   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
14964   effect(USE labl);
14965 
14966   ins_cost(BRANCH_COST);
14967   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
14968   ins_encode %{
14969     Label* L = $labl$$label;
14970     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
14971     int bit = exact_log2((juint)$op2$$constant);
14972     __ tbr(cond, $op1$$Register, bit, *L);
14973   %}
14974   ins_pipe(pipe_cmp_branch);
14975   ins_short_branch(1);
14976 %}
14977 
14978 // And far variants
14979 instruct far_cmpL_branch_sign(cmpOpLtGe cmp, iRegL op1, immL0 op2, label labl) %{
14980   match(If cmp (CmpL op1 op2));
14981   effect(USE labl);
14982 
14983   ins_cost(BRANCH_COST);
14984   format %{ &quot;cb$cmp   $op1, $labl # long&quot; %}
14985   ins_encode %{
14986     Label* L = $labl$$label;
14987     Assembler::Condition cond =
14988       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
14989     __ tbr(cond, $op1$$Register, 63, *L, /*far*/true);
14990   %}
14991   ins_pipe(pipe_cmp_branch);
14992 %}
14993 
14994 instruct far_cmpI_branch_sign(cmpOpLtGe cmp, iRegIorL2I op1, immI0 op2, label labl) %{
14995   match(If cmp (CmpI op1 op2));
14996   effect(USE labl);
14997 
14998   ins_cost(BRANCH_COST);
14999   format %{ &quot;cb$cmp   $op1, $labl # int&quot; %}
15000   ins_encode %{
15001     Label* L = $labl$$label;
15002     Assembler::Condition cond =
15003       ((Assembler::Condition)$cmp$$cmpcode == Assembler::LT) ? Assembler::NE : Assembler::EQ;
15004     __ tbr(cond, $op1$$Register, 31, *L, /*far*/true);
15005   %}
15006   ins_pipe(pipe_cmp_branch);
15007 %}
15008 
15009 instruct far_cmpL_branch_bit(cmpOpEqNe cmp, iRegL op1, immL op2, immL0 op3, label labl) %{
15010   match(If cmp (CmpL (AndL op1 op2) op3));
15011   predicate(is_power_of_2((julong)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15012   effect(USE labl);
15013 
15014   ins_cost(BRANCH_COST);
15015   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15016   ins_encode %{
15017     Label* L = $labl$$label;
15018     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15019     int bit = exact_log2_long($op2$$constant);
15020     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15021   %}
15022   ins_pipe(pipe_cmp_branch);
15023 %}
15024 
15025 instruct far_cmpI_branch_bit(cmpOpEqNe cmp, iRegIorL2I op1, immI op2, immI0 op3, label labl) %{
15026   match(If cmp (CmpI (AndI op1 op2) op3));
15027   predicate(is_power_of_2((juint)n-&gt;in(2)-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15028   effect(USE labl);
15029 
15030   ins_cost(BRANCH_COST);
15031   format %{ &quot;tb$cmp   $op1, $op2, $labl&quot; %}
15032   ins_encode %{
15033     Label* L = $labl$$label;
15034     Assembler::Condition cond = (Assembler::Condition)$cmp$$cmpcode;
15035     int bit = exact_log2((juint)$op2$$constant);
15036     __ tbr(cond, $op1$$Register, bit, *L, /*far*/true);
15037   %}
15038   ins_pipe(pipe_cmp_branch);
15039 %}
15040 
15041 // Test bits
15042 
15043 instruct cmpL_and(cmpOp cmp, iRegL op1, immL op2, immL0 op3, rFlagsReg cr) %{
15044   match(Set cr (CmpL (AndL op1 op2) op3));
15045   predicate(Assembler::operand_valid_for_logical_immediate
15046             (/*is_32*/false, n-&gt;in(1)-&gt;in(2)-&gt;get_long()));
15047 
15048   ins_cost(INSN_COST);
15049   format %{ &quot;tst $op1, $op2 # long&quot; %}
15050   ins_encode %{
15051     __ tst($op1$$Register, $op2$$constant);
15052   %}
15053   ins_pipe(ialu_reg_reg);
15054 %}
15055 
15056 instruct cmpI_and(cmpOp cmp, iRegIorL2I op1, immI op2, immI0 op3, rFlagsReg cr) %{
15057   match(Set cr (CmpI (AndI op1 op2) op3));
15058   predicate(Assembler::operand_valid_for_logical_immediate
15059             (/*is_32*/true, n-&gt;in(1)-&gt;in(2)-&gt;get_int()));
15060 
15061   ins_cost(INSN_COST);
15062   format %{ &quot;tst $op1, $op2 # int&quot; %}
15063   ins_encode %{
15064     __ tstw($op1$$Register, $op2$$constant);
15065   %}
15066   ins_pipe(ialu_reg_reg);
15067 %}
15068 
15069 instruct cmpL_and_reg(cmpOp cmp, iRegL op1, iRegL op2, immL0 op3, rFlagsReg cr) %{
15070   match(Set cr (CmpL (AndL op1 op2) op3));
15071 
15072   ins_cost(INSN_COST);
15073   format %{ &quot;tst $op1, $op2 # long&quot; %}
15074   ins_encode %{
15075     __ tst($op1$$Register, $op2$$Register);
15076   %}
15077   ins_pipe(ialu_reg_reg);
15078 %}
15079 
15080 instruct cmpI_and_reg(cmpOp cmp, iRegIorL2I op1, iRegIorL2I op2, immI0 op3, rFlagsReg cr) %{
15081   match(Set cr (CmpI (AndI op1 op2) op3));
15082 
15083   ins_cost(INSN_COST);
15084   format %{ &quot;tstw $op1, $op2 # int&quot; %}
15085   ins_encode %{
15086     __ tstw($op1$$Register, $op2$$Register);
15087   %}
15088   ins_pipe(ialu_reg_reg);
15089 %}
15090 
15091 
15092 // Conditional Far Branch
15093 // Conditional Far Branch Unsigned
15094 // TODO: fixme
15095 
15096 // counted loop end branch near
15097 instruct branchLoopEnd(cmpOp cmp, rFlagsReg cr, label lbl)
15098 %{
15099   match(CountedLoopEnd cmp cr);
15100 
15101   effect(USE lbl);
15102 
15103   ins_cost(BRANCH_COST);
15104   // short variant.
15105   // ins_short_branch(1);
15106   format %{ &quot;b$cmp $lbl \t// counted loop end&quot; %}
15107 
15108   ins_encode(aarch64_enc_br_con(cmp, lbl));
15109 
15110   ins_pipe(pipe_branch);
15111 %}
15112 
15113 // counted loop end branch near Unsigned
15114 instruct branchLoopEndU(cmpOpU cmp, rFlagsRegU cr, label lbl)
15115 %{
15116   match(CountedLoopEnd cmp cr);
15117 
15118   effect(USE lbl);
15119 
15120   ins_cost(BRANCH_COST);
15121   // short variant.
15122   // ins_short_branch(1);
15123   format %{ &quot;b$cmp $lbl \t// counted loop end unsigned&quot; %}
15124 
15125   ins_encode(aarch64_enc_br_conU(cmp, lbl));
15126 
15127   ins_pipe(pipe_branch);
15128 %}
15129 
15130 // counted loop end branch far
15131 // counted loop end branch far unsigned
15132 // TODO: fixme
15133 
15134 // ============================================================================
15135 // inlined locking and unlocking
15136 
15137 instruct cmpFastLock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15138 %{
15139   match(Set cr (FastLock object box));
15140   effect(TEMP tmp, TEMP tmp2);
15141 
15142   // TODO
15143   // identify correct cost
15144   ins_cost(5 * INSN_COST);
15145   format %{ &quot;fastlock $object,$box\t! kills $tmp,$tmp2&quot; %}
15146 
15147   ins_encode(aarch64_enc_fast_lock(object, box, tmp, tmp2));
15148 
15149   ins_pipe(pipe_serial);
15150 %}
15151 
15152 instruct cmpFastUnlock(rFlagsReg cr, iRegP object, iRegP box, iRegPNoSp tmp, iRegPNoSp tmp2)
15153 %{
15154   match(Set cr (FastUnlock object box));
15155   effect(TEMP tmp, TEMP tmp2);
15156 
15157   ins_cost(5 * INSN_COST);
15158   format %{ &quot;fastunlock $object,$box\t! kills $tmp, $tmp2&quot; %}
15159 
15160   ins_encode(aarch64_enc_fast_unlock(object, box, tmp, tmp2));
15161 
15162   ins_pipe(pipe_serial);
15163 %}
15164 
15165 
15166 // ============================================================================
15167 // Safepoint Instructions
15168 
15169 // TODO
15170 // provide a near and far version of this code
15171 
15172 instruct safePoint(rFlagsReg cr, iRegP poll)
15173 %{
15174   match(SafePoint poll);
15175   effect(KILL cr);
15176 
15177   format %{
15178     &quot;ldrw zr, [$poll]\t# Safepoint: poll for GC&quot;
15179   %}
15180   ins_encode %{
15181     __ read_polling_page(as_Register($poll$$reg), relocInfo::poll_type);
15182   %}
15183   ins_pipe(pipe_serial); // ins_pipe(iload_reg_mem);
15184 %}
15185 
15186 
15187 // ============================================================================
15188 // Procedure Call/Return Instructions
15189 
15190 // Call Java Static Instruction
15191 
15192 instruct CallStaticJavaDirect(method meth)
15193 %{
15194   match(CallStaticJava);
15195 
15196   effect(USE meth);
15197 
15198   ins_cost(CALL_COST);
15199 
15200   format %{ &quot;call,static $meth \t// ==&gt; &quot; %}
15201 
15202   ins_encode( aarch64_enc_java_static_call(meth),
15203               aarch64_enc_call_epilog );
15204 
15205   ins_pipe(pipe_class_call);
15206 %}
15207 
15208 // TO HERE
15209 
15210 // Call Java Dynamic Instruction
15211 instruct CallDynamicJavaDirect(method meth)
15212 %{
15213   match(CallDynamicJava);
15214 
15215   effect(USE meth);
15216 
15217   ins_cost(CALL_COST);
15218 
15219   format %{ &quot;CALL,dynamic $meth \t// ==&gt; &quot; %}
15220 
15221   ins_encode( aarch64_enc_java_dynamic_call(meth),
15222                aarch64_enc_call_epilog );
15223 
15224   ins_pipe(pipe_class_call);
15225 %}
15226 
15227 // Call Runtime Instruction
15228 
15229 instruct CallRuntimeDirect(method meth)
15230 %{
15231   match(CallRuntime);
15232 
15233   effect(USE meth);
15234 
15235   ins_cost(CALL_COST);
15236 
15237   format %{ &quot;CALL, runtime $meth&quot; %}
15238 
15239   ins_encode( aarch64_enc_java_to_runtime(meth) );
15240 
15241   ins_pipe(pipe_class_call);
15242 %}
15243 
15244 // Call Runtime Instruction
15245 
15246 instruct CallLeafDirect(method meth)
15247 %{
15248   match(CallLeaf);
15249 
15250   effect(USE meth);
15251 
15252   ins_cost(CALL_COST);
15253 
15254   format %{ &quot;CALL, runtime leaf $meth&quot; %}
15255 
15256   ins_encode( aarch64_enc_java_to_runtime(meth) );
15257 
15258   ins_pipe(pipe_class_call);
15259 %}
15260 
15261 // Call Runtime Instruction
15262 
15263 instruct CallLeafNoFPDirect(method meth)
15264 %{
15265   match(CallLeafNoFP);
15266 
15267   effect(USE meth);
15268 
15269   ins_cost(CALL_COST);
15270 
15271   format %{ &quot;CALL, runtime leaf nofp $meth&quot; %}
15272 
15273   ins_encode( aarch64_enc_java_to_runtime(meth) );
15274 
15275   ins_pipe(pipe_class_call);
15276 %}
15277 
15278 // Tail Call; Jump from runtime stub to Java code.
15279 // Also known as an &#39;interprocedural jump&#39;.
15280 // Target of jump will eventually return to caller.
15281 // TailJump below removes the return address.
15282 instruct TailCalljmpInd(iRegPNoSp jump_target, inline_cache_RegP method_oop)
15283 %{
15284   match(TailCall jump_target method_oop);
15285 
15286   ins_cost(CALL_COST);
15287 
15288   format %{ &quot;br $jump_target\t# $method_oop holds method oop&quot; %}
15289 
15290   ins_encode(aarch64_enc_tail_call(jump_target));
15291 
15292   ins_pipe(pipe_class_call);
15293 %}
15294 
15295 instruct TailjmpInd(iRegPNoSp jump_target, iRegP_R0 ex_oop)
15296 %{
15297   match(TailJump jump_target ex_oop);
15298 
15299   ins_cost(CALL_COST);
15300 
15301   format %{ &quot;br $jump_target\t# $ex_oop holds exception oop&quot; %}
15302 
15303   ins_encode(aarch64_enc_tail_jmp(jump_target));
15304 
15305   ins_pipe(pipe_class_call);
15306 %}
15307 
15308 // Create exception oop: created by stack-crawling runtime code.
15309 // Created exception is now available to this handler, and is setup
15310 // just prior to jumping to this handler. No code emitted.
15311 // TODO check
15312 // should ex_oop be in r0? intel uses rax, ppc cannot use r0 so uses rarg1
15313 instruct CreateException(iRegP_R0 ex_oop)
15314 %{
15315   match(Set ex_oop (CreateEx));
15316 
15317   format %{ &quot; -- \t// exception oop; no code emitted&quot; %}
15318 
15319   size(0);
15320 
15321   ins_encode( /*empty*/ );
15322 
15323   ins_pipe(pipe_class_empty);
15324 %}
15325 
15326 // Rethrow exception: The exception oop will come in the first
15327 // argument position. Then JUMP (not call) to the rethrow stub code.
15328 instruct RethrowException() %{
15329   match(Rethrow);
15330   ins_cost(CALL_COST);
15331 
15332   format %{ &quot;b rethrow_stub&quot; %}
15333 
15334   ins_encode( aarch64_enc_rethrow() );
15335 
15336   ins_pipe(pipe_class_call);
15337 %}
15338 
15339 
15340 // Return Instruction
15341 // epilog node loads ret address into lr as part of frame pop
15342 instruct Ret()
15343 %{
15344   match(Return);
15345 
15346   format %{ &quot;ret\t// return register&quot; %}
15347 
15348   ins_encode( aarch64_enc_ret() );
15349 
15350   ins_pipe(pipe_branch);
15351 %}
15352 
15353 // Die now.
15354 instruct ShouldNotReachHere() %{
15355   match(Halt);
15356 
15357   ins_cost(CALL_COST);
15358   format %{ &quot;ShouldNotReachHere&quot; %}
15359 
15360   ins_encode %{
15361     if (is_reachable()) {
15362       __ stop(_halt_reason);
15363     }
15364   %}
15365 
15366   ins_pipe(pipe_class_default);
15367 %}
15368 
15369 // ============================================================================
15370 // Partial Subtype Check
15371 //
15372 // superklass array for an instance of the superklass.  Set a hidden
15373 // internal cache on a hit (cache is checked with exposed code in
15374 // gen_subtype_check()).  Return NZ for a miss or zero for a hit.  The
15375 // encoding ALSO sets flags.
15376 
15377 instruct partialSubtypeCheck(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, rFlagsReg cr)
15378 %{
15379   match(Set result (PartialSubtypeCheck sub super));
15380   effect(KILL cr, KILL temp);
15381 
15382   ins_cost(1100);  // slightly larger than the next version
15383   format %{ &quot;partialSubtypeCheck $result, $sub, $super&quot; %}
15384 
15385   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15386 
15387   opcode(0x1); // Force zero of result reg on hit
15388 
15389   ins_pipe(pipe_class_memory);
15390 %}
15391 
15392 instruct partialSubtypeCheckVsZero(iRegP_R4 sub, iRegP_R0 super, iRegP_R2 temp, iRegP_R5 result, immP0 zero, rFlagsReg cr)
15393 %{
15394   match(Set cr (CmpP (PartialSubtypeCheck sub super) zero));
15395   effect(KILL temp, KILL result);
15396 
15397   ins_cost(1100);  // slightly larger than the next version
15398   format %{ &quot;partialSubtypeCheck $result, $sub, $super == 0&quot; %}
15399 
15400   ins_encode(aarch64_enc_partial_subtype_check(sub, super, temp, result));
15401 
15402   opcode(0x0); // Don&#39;t zero result reg on hit
15403 
15404   ins_pipe(pipe_class_memory);
15405 %}
15406 
15407 instruct string_compareU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15408                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15409 %{
15410   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15411   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15412   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15413 
15414   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15415   ins_encode %{
15416     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15417     __ string_compare($str1$$Register, $str2$$Register,
15418                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15419                       $tmp1$$Register, $tmp2$$Register,
15420                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::UU);
15421   %}
15422   ins_pipe(pipe_class_memory);
15423 %}
15424 
15425 instruct string_compareL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15426                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2, rFlagsReg cr)
15427 %{
15428   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15429   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15430   effect(KILL tmp1, KILL tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15431 
15432   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1&quot; %}
15433   ins_encode %{
15434     __ string_compare($str1$$Register, $str2$$Register,
15435                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15436                       $tmp1$$Register, $tmp2$$Register,
15437                       fnoreg, fnoreg, fnoreg, StrIntrinsicNode::LL);
15438   %}
15439   ins_pipe(pipe_class_memory);
15440 %}
15441 
15442 instruct string_compareUL(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15443                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15444                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15445 %{
15446   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15447   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15448   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15449          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15450 
15451   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15452   ins_encode %{
15453     __ string_compare($str1$$Register, $str2$$Register,
15454                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15455                       $tmp1$$Register, $tmp2$$Register,
15456                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15457                       $vtmp3$$FloatRegister, StrIntrinsicNode::UL);
15458   %}
15459   ins_pipe(pipe_class_memory);
15460 %}
15461 
15462 instruct string_compareLU(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,
15463                         iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,
15464                         vRegD_V0 vtmp1, vRegD_V1 vtmp2, vRegD_V2 vtmp3, rFlagsReg cr)
15465 %{
15466   predicate(((StrCompNode*)n)-&gt;encoding() == StrIntrinsicNode::LU);
15467   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
15468   effect(KILL tmp1, KILL tmp2, KILL vtmp1, KILL vtmp2, KILL vtmp3,
15469          USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);
15470 
15471   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   # KILL $tmp1, $tmp2, $vtmp1, $vtmp2, $vtmp3&quot; %}
15472   ins_encode %{
15473     __ string_compare($str1$$Register, $str2$$Register,
15474                       $cnt1$$Register, $cnt2$$Register, $result$$Register,
15475                       $tmp1$$Register, $tmp2$$Register,
15476                       $vtmp1$$FloatRegister, $vtmp2$$FloatRegister,
15477                       $vtmp3$$FloatRegister,StrIntrinsicNode::LU);
15478   %}
15479   ins_pipe(pipe_class_memory);
15480 %}
15481 
15482 instruct string_indexofUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15483        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15484        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15485 %{
15486   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15487   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15488   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15489          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15490   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UU)&quot; %}
15491 
15492   ins_encode %{
15493     __ string_indexof($str1$$Register, $str2$$Register,
15494                       $cnt1$$Register, $cnt2$$Register,
15495                       $tmp1$$Register, $tmp2$$Register,
15496                       $tmp3$$Register, $tmp4$$Register,
15497                       $tmp5$$Register, $tmp6$$Register,
15498                       -1, $result$$Register, StrIntrinsicNode::UU);
15499   %}
15500   ins_pipe(pipe_class_memory);
15501 %}
15502 
15503 instruct string_indexofLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15504        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15505        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15506 %{
15507   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15508   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15509   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15510          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15511   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (LL)&quot; %}
15512 
15513   ins_encode %{
15514     __ string_indexof($str1$$Register, $str2$$Register,
15515                       $cnt1$$Register, $cnt2$$Register,
15516                       $tmp1$$Register, $tmp2$$Register,
15517                       $tmp3$$Register, $tmp4$$Register,
15518                       $tmp5$$Register, $tmp6$$Register,
15519                       -1, $result$$Register, StrIntrinsicNode::LL);
15520   %}
15521   ins_pipe(pipe_class_memory);
15522 %}
15523 
15524 instruct string_indexofUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2, iRegI_R2 cnt2,
15525        iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2, iRegINoSp tmp3,
15526        iRegINoSp tmp4, iRegINoSp tmp5, iRegINoSp tmp6, rFlagsReg cr)
15527 %{
15528   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15529   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 cnt2)));
15530   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2,
15531          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP tmp5, TEMP tmp6, KILL cr);
15532   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$cnt2 -&gt; $result (UL)&quot; %}
15533 
15534   ins_encode %{
15535     __ string_indexof($str1$$Register, $str2$$Register,
15536                       $cnt1$$Register, $cnt2$$Register,
15537                       $tmp1$$Register, $tmp2$$Register,
15538                       $tmp3$$Register, $tmp4$$Register,
15539                       $tmp5$$Register, $tmp6$$Register,
15540                       -1, $result$$Register, StrIntrinsicNode::UL);
15541   %}
15542   ins_pipe(pipe_class_memory);
15543 %}
15544 
15545 instruct string_indexof_conUU(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15546                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15547                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15548 %{
15549   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15550   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15551   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15552          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15553   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UU)&quot; %}
15554 
15555   ins_encode %{
15556     int icnt2 = (int)$int_cnt2$$constant;
15557     __ string_indexof($str1$$Register, $str2$$Register,
15558                       $cnt1$$Register, zr,
15559                       $tmp1$$Register, $tmp2$$Register,
15560                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15561                       icnt2, $result$$Register, StrIntrinsicNode::UU);
15562   %}
15563   ins_pipe(pipe_class_memory);
15564 %}
15565 
15566 instruct string_indexof_conLL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15567                  immI_le_4 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15568                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15569 %{
15570   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15571   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15572   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15573          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15574   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (LL)&quot; %}
15575 
15576   ins_encode %{
15577     int icnt2 = (int)$int_cnt2$$constant;
15578     __ string_indexof($str1$$Register, $str2$$Register,
15579                       $cnt1$$Register, zr,
15580                       $tmp1$$Register, $tmp2$$Register,
15581                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15582                       icnt2, $result$$Register, StrIntrinsicNode::LL);
15583   %}
15584   ins_pipe(pipe_class_memory);
15585 %}
15586 
15587 instruct string_indexof_conUL(iRegP_R1 str1, iRegI_R4 cnt1, iRegP_R3 str2,
15588                  immI_1 int_cnt2, iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15589                  iRegINoSp tmp3, iRegINoSp tmp4, rFlagsReg cr)
15590 %{
15591   predicate(((StrIndexOfNode*)n)-&gt;encoding() == StrIntrinsicNode::UL);
15592   match(Set result (StrIndexOf (Binary str1 cnt1) (Binary str2 int_cnt2)));
15593   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1,
15594          TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, KILL cr);
15595   format %{ &quot;String IndexOf $str1,$cnt1,$str2,$int_cnt2 -&gt; $result (UL)&quot; %}
15596 
15597   ins_encode %{
15598     int icnt2 = (int)$int_cnt2$$constant;
15599     __ string_indexof($str1$$Register, $str2$$Register,
15600                       $cnt1$$Register, zr,
15601                       $tmp1$$Register, $tmp2$$Register,
15602                       $tmp3$$Register, $tmp4$$Register, zr, zr,
15603                       icnt2, $result$$Register, StrIntrinsicNode::UL);
15604   %}
15605   ins_pipe(pipe_class_memory);
15606 %}
15607 
15608 instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,
15609                               iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,
15610                               iRegINoSp tmp3, rFlagsReg cr)
15611 %{
15612   match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));
15613   effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,
15614          TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15615 
15616   format %{ &quot;String IndexOf char[] $str1,$cnt1,$ch -&gt; $result&quot; %}
15617 
15618   ins_encode %{
15619     __ string_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,
15620                            $result$$Register, $tmp1$$Register, $tmp2$$Register,
15621                            $tmp3$$Register);
15622   %}
15623   ins_pipe(pipe_class_memory);
15624 %}
15625 
15626 instruct string_equalsL(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15627                         iRegI_R0 result, rFlagsReg cr)
15628 %{
15629   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15630   match(Set result (StrEquals (Binary str1 str2) cnt));
15631   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15632 
15633   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15634   ins_encode %{
15635     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15636     __ string_equals($str1$$Register, $str2$$Register,
15637                      $result$$Register, $cnt$$Register, 1);
15638   %}
15639   ins_pipe(pipe_class_memory);
15640 %}
15641 
15642 instruct string_equalsU(iRegP_R1 str1, iRegP_R3 str2, iRegI_R4 cnt,
15643                         iRegI_R0 result, rFlagsReg cr)
15644 %{
15645   predicate(((StrEqualsNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15646   match(Set result (StrEquals (Binary str1 str2) cnt));
15647   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL cr);
15648 
15649   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result&quot; %}
15650   ins_encode %{
15651     // Count is in 8-bit bytes; non-Compact chars are 16 bits.
15652     __ string_equals($str1$$Register, $str2$$Register,
15653                      $result$$Register, $cnt$$Register, 2);
15654   %}
15655   ins_pipe(pipe_class_memory);
15656 %}
15657 
15658 instruct array_equalsB(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15659                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15660                        iRegP_R10 tmp, rFlagsReg cr)
15661 %{
15662   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::LL);
15663   match(Set result (AryEq ary1 ary2));
15664   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15665 
15666   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15667   ins_encode %{
15668     __ arrays_equals($ary1$$Register, $ary2$$Register,
15669                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15670                      $result$$Register, $tmp$$Register, 1);
15671     %}
15672   ins_pipe(pipe_class_memory);
15673 %}
15674 
15675 instruct array_equalsC(iRegP_R1 ary1, iRegP_R2 ary2, iRegI_R0 result,
15676                        iRegP_R3 tmp1, iRegP_R4 tmp2, iRegP_R5 tmp3,
15677                        iRegP_R10 tmp, rFlagsReg cr)
15678 %{
15679   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
15680   match(Set result (AryEq ary1 ary2));
15681   effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);
15682 
15683   format %{ &quot;Array Equals $ary1,ary2 -&gt; $result    // KILL $tmp&quot; %}
15684   ins_encode %{
15685     __ arrays_equals($ary1$$Register, $ary2$$Register,
15686                      $tmp1$$Register, $tmp2$$Register, $tmp3$$Register,
15687                      $result$$Register, $tmp$$Register, 2);
15688   %}
15689   ins_pipe(pipe_class_memory);
15690 %}
15691 
15692 instruct has_negatives(iRegP_R1 ary1, iRegI_R2 len, iRegI_R0 result, rFlagsReg cr)
15693 %{
15694   match(Set result (HasNegatives ary1 len));
15695   effect(USE_KILL ary1, USE_KILL len, KILL cr);
15696   format %{ &quot;has negatives byte[] $ary1,$len -&gt; $result&quot; %}
15697   ins_encode %{
15698     __ has_negatives($ary1$$Register, $len$$Register, $result$$Register);
15699   %}
15700   ins_pipe( pipe_slow );
15701 %}
15702 
15703 // fast char[] to byte[] compression
15704 instruct string_compress(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15705                          vRegD_V0 tmp1, vRegD_V1 tmp2,
15706                          vRegD_V2 tmp3, vRegD_V3 tmp4,
15707                          iRegI_R0 result, rFlagsReg cr)
15708 %{
15709   match(Set result (StrCompressedCopy src (Binary dst len)));
15710   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15711 
15712   format %{ &quot;String Compress $src,$dst -&gt; $result    // KILL R1, R2, R3, R4&quot; %}
15713   ins_encode %{
15714     __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,
15715                            $tmp1$$FloatRegister, $tmp2$$FloatRegister,
15716                            $tmp3$$FloatRegister, $tmp4$$FloatRegister,
15717                            $result$$Register);
15718   %}
15719   ins_pipe( pipe_slow );
15720 %}
15721 
15722 // fast byte[] to char[] inflation
15723 instruct string_inflate(Universe dummy, iRegP_R0 src, iRegP_R1 dst, iRegI_R2 len,
15724                         vRegD_V0 tmp1, vRegD_V1 tmp2, vRegD_V2 tmp3, iRegP_R3 tmp4, rFlagsReg cr)
15725 %{
15726   match(Set dummy (StrInflatedCopy src (Binary dst len)));
15727   effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);
15728 
15729   format %{ &quot;String Inflate $src,$dst    // KILL $tmp1, $tmp2&quot; %}
15730   ins_encode %{
15731     __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,
15732                           $tmp1$$FloatRegister, $tmp2$$FloatRegister, $tmp3$$FloatRegister, $tmp4$$Register);
15733   %}
15734   ins_pipe(pipe_class_memory);
15735 %}
15736 
15737 // encode char[] to byte[] in ISO_8859_1
15738 instruct encode_iso_array(iRegP_R2 src, iRegP_R1 dst, iRegI_R3 len,
15739                           vRegD_V0 Vtmp1, vRegD_V1 Vtmp2,
15740                           vRegD_V2 Vtmp3, vRegD_V3 Vtmp4,
15741                           iRegI_R0 result, rFlagsReg cr)
15742 %{
15743   match(Set result (EncodeISOArray src (Binary dst len)));
15744   effect(USE_KILL src, USE_KILL dst, USE_KILL len,
15745          KILL Vtmp1, KILL Vtmp2, KILL Vtmp3, KILL Vtmp4, KILL cr);
15746 
15747   format %{ &quot;Encode array $src,$dst,$len -&gt; $result&quot; %}
15748   ins_encode %{
15749     __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,
15750          $result$$Register, $Vtmp1$$FloatRegister,  $Vtmp2$$FloatRegister,
15751          $Vtmp3$$FloatRegister,  $Vtmp4$$FloatRegister);
15752   %}
15753   ins_pipe( pipe_class_memory );
15754 %}
15755 
15756 // ============================================================================
15757 // This name is KNOWN by the ADLC and cannot be changed.
15758 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
15759 // for this guy.
15760 instruct tlsLoadP(thread_RegP dst)
15761 %{
15762   match(Set dst (ThreadLocal));
15763 
15764   ins_cost(0);
15765 
15766   format %{ &quot; -- \t// $dst=Thread::current(), empty&quot; %}
15767 
15768   size(0);
15769 
15770   ins_encode( /*empty*/ );
15771 
15772   ins_pipe(pipe_class_empty);
15773 %}
15774 
15775 // ====================VECTOR INSTRUCTIONS=====================================
15776 
15777 // Load vector (32 bits)
15778 instruct loadV4(vecD dst, vmem4 mem)
15779 %{
15780   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 4);
15781   match(Set dst (LoadVector mem));
15782   ins_cost(4 * INSN_COST);
15783   format %{ &quot;ldrs   $dst,$mem\t# vector (32 bits)&quot; %}
15784   ins_encode( aarch64_enc_ldrvS(dst, mem) );
15785   ins_pipe(vload_reg_mem64);
15786 %}
15787 
15788 // Load vector (64 bits)
15789 instruct loadV8(vecD dst, vmem8 mem)
15790 %{
15791   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
15792   match(Set dst (LoadVector mem));
15793   ins_cost(4 * INSN_COST);
15794   format %{ &quot;ldrd   $dst,$mem\t# vector (64 bits)&quot; %}
15795   ins_encode( aarch64_enc_ldrvD(dst, mem) );
15796   ins_pipe(vload_reg_mem64);
15797 %}
15798 
15799 // Load Vector (128 bits)
15800 instruct loadV16(vecX dst, vmem16 mem)
15801 %{
15802   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
15803   match(Set dst (LoadVector mem));
15804   ins_cost(4 * INSN_COST);
15805   format %{ &quot;ldrq   $dst,$mem\t# vector (128 bits)&quot; %}
15806   ins_encode( aarch64_enc_ldrvQ(dst, mem) );
15807   ins_pipe(vload_reg_mem128);
15808 %}
15809 
15810 // Store Vector (32 bits)
15811 instruct storeV4(vecD src, vmem4 mem)
15812 %{
15813   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 4);
15814   match(Set mem (StoreVector mem src));
15815   ins_cost(4 * INSN_COST);
15816   format %{ &quot;strs   $mem,$src\t# vector (32 bits)&quot; %}
15817   ins_encode( aarch64_enc_strvS(src, mem) );
15818   ins_pipe(vstore_reg_mem64);
15819 %}
15820 
15821 // Store Vector (64 bits)
15822 instruct storeV8(vecD src, vmem8 mem)
15823 %{
15824   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
15825   match(Set mem (StoreVector mem src));
15826   ins_cost(4 * INSN_COST);
15827   format %{ &quot;strd   $mem,$src\t# vector (64 bits)&quot; %}
15828   ins_encode( aarch64_enc_strvD(src, mem) );
15829   ins_pipe(vstore_reg_mem64);
15830 %}
15831 
15832 // Store Vector (128 bits)
15833 instruct storeV16(vecX src, vmem16 mem)
15834 %{
15835   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
15836   match(Set mem (StoreVector mem src));
15837   ins_cost(4 * INSN_COST);
15838   format %{ &quot;strq   $mem,$src\t# vector (128 bits)&quot; %}
15839   ins_encode( aarch64_enc_strvQ(src, mem) );
15840   ins_pipe(vstore_reg_mem128);
15841 %}
15842 
15843 instruct replicate8B(vecD dst, iRegIorL2I src)
15844 %{
15845   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15846             n-&gt;as_Vector()-&gt;length() == 8);
15847   match(Set dst (ReplicateB src));
15848   ins_cost(INSN_COST);
15849   format %{ &quot;dup  $dst, $src\t# vector (8B)&quot; %}
15850   ins_encode %{
15851     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($src$$reg));
15852   %}
15853   ins_pipe(vdup_reg_reg64);
15854 %}
15855 
15856 instruct replicate16B(vecX dst, iRegIorL2I src)
15857 %{
15858   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15859   match(Set dst (ReplicateB src));
15860   ins_cost(INSN_COST);
15861   format %{ &quot;dup  $dst, $src\t# vector (16B)&quot; %}
15862   ins_encode %{
15863     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($src$$reg));
15864   %}
15865   ins_pipe(vdup_reg_reg128);
15866 %}
15867 
15868 instruct replicate8B_imm(vecD dst, immI con)
15869 %{
15870   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
15871             n-&gt;as_Vector()-&gt;length() == 8);
15872   match(Set dst (ReplicateB con));
15873   ins_cost(INSN_COST);
15874   format %{ &quot;movi  $dst, $con\t# vector(8B)&quot; %}
15875   ins_encode %{
15876     __ mov(as_FloatRegister($dst$$reg), __ T8B, $con$$constant &amp; 0xff);
15877   %}
15878   ins_pipe(vmovi_reg_imm64);
15879 %}
15880 
15881 instruct replicate16B_imm(vecX dst, immI con)
15882 %{
15883   predicate(n-&gt;as_Vector()-&gt;length() == 16);
15884   match(Set dst (ReplicateB con));
15885   ins_cost(INSN_COST);
15886   format %{ &quot;movi  $dst, $con\t# vector(16B)&quot; %}
15887   ins_encode %{
15888     __ mov(as_FloatRegister($dst$$reg), __ T16B, $con$$constant &amp; 0xff);
15889   %}
15890   ins_pipe(vmovi_reg_imm128);
15891 %}
15892 
15893 instruct replicate4S(vecD dst, iRegIorL2I src)
15894 %{
15895   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15896             n-&gt;as_Vector()-&gt;length() == 4);
15897   match(Set dst (ReplicateS src));
15898   ins_cost(INSN_COST);
15899   format %{ &quot;dup  $dst, $src\t# vector (4S)&quot; %}
15900   ins_encode %{
15901     __ dup(as_FloatRegister($dst$$reg), __ T4H, as_Register($src$$reg));
15902   %}
15903   ins_pipe(vdup_reg_reg64);
15904 %}
15905 
15906 instruct replicate8S(vecX dst, iRegIorL2I src)
15907 %{
15908   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15909   match(Set dst (ReplicateS src));
15910   ins_cost(INSN_COST);
15911   format %{ &quot;dup  $dst, $src\t# vector (8S)&quot; %}
15912   ins_encode %{
15913     __ dup(as_FloatRegister($dst$$reg), __ T8H, as_Register($src$$reg));
15914   %}
15915   ins_pipe(vdup_reg_reg128);
15916 %}
15917 
15918 instruct replicate4S_imm(vecD dst, immI con)
15919 %{
15920   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
15921             n-&gt;as_Vector()-&gt;length() == 4);
15922   match(Set dst (ReplicateS con));
15923   ins_cost(INSN_COST);
15924   format %{ &quot;movi  $dst, $con\t# vector(4H)&quot; %}
15925   ins_encode %{
15926     __ mov(as_FloatRegister($dst$$reg), __ T4H, $con$$constant &amp; 0xffff);
15927   %}
15928   ins_pipe(vmovi_reg_imm64);
15929 %}
15930 
15931 instruct replicate8S_imm(vecX dst, immI con)
15932 %{
15933   predicate(n-&gt;as_Vector()-&gt;length() == 8);
15934   match(Set dst (ReplicateS con));
15935   ins_cost(INSN_COST);
15936   format %{ &quot;movi  $dst, $con\t# vector(8H)&quot; %}
15937   ins_encode %{
15938     __ mov(as_FloatRegister($dst$$reg), __ T8H, $con$$constant &amp; 0xffff);
15939   %}
15940   ins_pipe(vmovi_reg_imm128);
15941 %}
15942 
15943 instruct replicate2I(vecD dst, iRegIorL2I src)
15944 %{
15945   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15946   match(Set dst (ReplicateI src));
15947   ins_cost(INSN_COST);
15948   format %{ &quot;dup  $dst, $src\t# vector (2I)&quot; %}
15949   ins_encode %{
15950     __ dup(as_FloatRegister($dst$$reg), __ T2S, as_Register($src$$reg));
15951   %}
15952   ins_pipe(vdup_reg_reg64);
15953 %}
15954 
15955 instruct replicate4I(vecX dst, iRegIorL2I src)
15956 %{
15957   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15958   match(Set dst (ReplicateI src));
15959   ins_cost(INSN_COST);
15960   format %{ &quot;dup  $dst, $src\t# vector (4I)&quot; %}
15961   ins_encode %{
15962     __ dup(as_FloatRegister($dst$$reg), __ T4S, as_Register($src$$reg));
15963   %}
15964   ins_pipe(vdup_reg_reg128);
15965 %}
15966 
15967 instruct replicate2I_imm(vecD dst, immI con)
15968 %{
15969   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15970   match(Set dst (ReplicateI con));
15971   ins_cost(INSN_COST);
15972   format %{ &quot;movi  $dst, $con\t# vector(2I)&quot; %}
15973   ins_encode %{
15974     __ mov(as_FloatRegister($dst$$reg), __ T2S, $con$$constant);
15975   %}
15976   ins_pipe(vmovi_reg_imm64);
15977 %}
15978 
15979 instruct replicate4I_imm(vecX dst, immI con)
15980 %{
15981   predicate(n-&gt;as_Vector()-&gt;length() == 4);
15982   match(Set dst (ReplicateI con));
15983   ins_cost(INSN_COST);
15984   format %{ &quot;movi  $dst, $con\t# vector(4I)&quot; %}
15985   ins_encode %{
15986     __ mov(as_FloatRegister($dst$$reg), __ T4S, $con$$constant);
15987   %}
15988   ins_pipe(vmovi_reg_imm128);
15989 %}
15990 
15991 instruct replicate2L(vecX dst, iRegL src)
15992 %{
15993   predicate(n-&gt;as_Vector()-&gt;length() == 2);
15994   match(Set dst (ReplicateL src));
15995   ins_cost(INSN_COST);
15996   format %{ &quot;dup  $dst, $src\t# vector (2L)&quot; %}
15997   ins_encode %{
15998     __ dup(as_FloatRegister($dst$$reg), __ T2D, as_Register($src$$reg));
15999   %}
16000   ins_pipe(vdup_reg_reg128);
16001 %}
16002 
16003 instruct replicate2L_zero(vecX dst, immI0 zero)
16004 %{
16005   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16006   match(Set dst (ReplicateI zero));
16007   ins_cost(INSN_COST);
16008   format %{ &quot;movi  $dst, $zero\t# vector(4I)&quot; %}
16009   ins_encode %{
16010     __ eor(as_FloatRegister($dst$$reg), __ T16B,
16011            as_FloatRegister($dst$$reg),
16012            as_FloatRegister($dst$$reg));
16013   %}
16014   ins_pipe(vmovi_reg_imm128);
16015 %}
16016 
16017 instruct replicate2F(vecD dst, vRegF src)
16018 %{
16019   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16020   match(Set dst (ReplicateF src));
16021   ins_cost(INSN_COST);
16022   format %{ &quot;dup  $dst, $src\t# vector (2F)&quot; %}
16023   ins_encode %{
16024     __ dup(as_FloatRegister($dst$$reg), __ T2S,
16025            as_FloatRegister($src$$reg));
16026   %}
16027   ins_pipe(vdup_reg_freg64);
16028 %}
16029 
16030 instruct replicate4F(vecX dst, vRegF src)
16031 %{
16032   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16033   match(Set dst (ReplicateF src));
16034   ins_cost(INSN_COST);
16035   format %{ &quot;dup  $dst, $src\t# vector (4F)&quot; %}
16036   ins_encode %{
16037     __ dup(as_FloatRegister($dst$$reg), __ T4S,
16038            as_FloatRegister($src$$reg));
16039   %}
16040   ins_pipe(vdup_reg_freg128);
16041 %}
16042 
16043 instruct replicate2D(vecX dst, vRegD src)
16044 %{
16045   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16046   match(Set dst (ReplicateD src));
16047   ins_cost(INSN_COST);
16048   format %{ &quot;dup  $dst, $src\t# vector (2D)&quot; %}
16049   ins_encode %{
16050     __ dup(as_FloatRegister($dst$$reg), __ T2D,
16051            as_FloatRegister($src$$reg));
16052   %}
16053   ins_pipe(vdup_reg_dreg128);
16054 %}
16055 
16056 // ====================REDUCTION ARITHMETIC====================================
16057 
16058 instruct reduce_add2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp, iRegINoSp tmp2)
16059 %{
16060   match(Set dst (AddReductionVI isrc vsrc));
16061   ins_cost(INSN_COST);
16062   effect(TEMP tmp, TEMP tmp2);
16063   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16064             &quot;umov  $tmp2, $vsrc, S, 1\n\t&quot;
16065             &quot;addw  $tmp, $isrc, $tmp\n\t&quot;
16066             &quot;addw  $dst, $tmp, $tmp2\t# add reduction2I&quot;
16067   %}
16068   ins_encode %{
16069     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16070     __ umov($tmp2$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16071     __ addw($tmp$$Register, $isrc$$Register, $tmp$$Register);
16072     __ addw($dst$$Register, $tmp$$Register, $tmp2$$Register);
16073   %}
16074   ins_pipe(pipe_class_default);
16075 %}
16076 
16077 instruct reduce_add4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16078 %{
16079   match(Set dst (AddReductionVI isrc vsrc));
16080   ins_cost(INSN_COST);
16081   effect(TEMP vtmp, TEMP itmp);
16082   format %{ &quot;addv  $vtmp, T4S, $vsrc\n\t&quot;
16083             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16084             &quot;addw  $dst, $itmp, $isrc\t# add reduction4I&quot;
16085   %}
16086   ins_encode %{
16087     __ addv(as_FloatRegister($vtmp$$reg), __ T4S,
16088             as_FloatRegister($vsrc$$reg));
16089     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16090     __ addw($dst$$Register, $itmp$$Register, $isrc$$Register);
16091   %}
16092   ins_pipe(pipe_class_default);
16093 %}
16094 
16095 instruct reduce_mul2I(iRegINoSp dst, iRegIorL2I isrc, vecD vsrc, iRegINoSp tmp)
16096 %{
16097   match(Set dst (MulReductionVI isrc vsrc));
16098   ins_cost(INSN_COST);
16099   effect(TEMP tmp, TEMP dst);
16100   format %{ &quot;umov  $tmp, $vsrc, S, 0\n\t&quot;
16101             &quot;mul   $dst, $tmp, $isrc\n\t&quot;
16102             &quot;umov  $tmp, $vsrc, S, 1\n\t&quot;
16103             &quot;mul   $dst, $tmp, $dst\t# mul reduction2I&quot;
16104   %}
16105   ins_encode %{
16106     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 0);
16107     __ mul($dst$$Register, $tmp$$Register, $isrc$$Register);
16108     __ umov($tmp$$Register, as_FloatRegister($vsrc$$reg), __ S, 1);
16109     __ mul($dst$$Register, $tmp$$Register, $dst$$Register);
16110   %}
16111   ins_pipe(pipe_class_default);
16112 %}
16113 
16114 instruct reduce_mul4I(iRegINoSp dst, iRegIorL2I isrc, vecX vsrc, vecX vtmp, iRegINoSp itmp)
16115 %{
16116   match(Set dst (MulReductionVI isrc vsrc));
16117   ins_cost(INSN_COST);
16118   effect(TEMP vtmp, TEMP itmp, TEMP dst);
16119   format %{ &quot;ins   $vtmp, D, $vsrc, 0, 1\n\t&quot;
16120             &quot;mulv  $vtmp, T2S, $vtmp, $vsrc\n\t&quot;
16121             &quot;umov  $itmp, $vtmp, S, 0\n\t&quot;
16122             &quot;mul   $dst, $itmp, $isrc\n\t&quot;
16123             &quot;umov  $itmp, $vtmp, S, 1\n\t&quot;
16124             &quot;mul   $dst, $itmp, $dst\t# mul reduction4I&quot;
16125   %}
16126   ins_encode %{
16127     __ ins(as_FloatRegister($vtmp$$reg), __ D,
16128            as_FloatRegister($vsrc$$reg), 0, 1);
16129     __ mulv(as_FloatRegister($vtmp$$reg), __ T2S,
16130             as_FloatRegister($vtmp$$reg), as_FloatRegister($vsrc$$reg));
16131     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 0);
16132     __ mul($dst$$Register, $itmp$$Register, $isrc$$Register);
16133     __ umov($itmp$$Register, as_FloatRegister($vtmp$$reg), __ S, 1);
16134     __ mul($dst$$Register, $itmp$$Register, $dst$$Register);
16135   %}
16136   ins_pipe(pipe_class_default);
16137 %}
16138 
16139 instruct reduce_add2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16140 %{
16141   match(Set dst (AddReductionVF fsrc vsrc));
16142   ins_cost(INSN_COST);
16143   effect(TEMP tmp, TEMP dst);
16144   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16145             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16146             &quot;fadds $dst, $dst, $tmp\t# add reduction2F&quot;
16147   %}
16148   ins_encode %{
16149     __ fadds(as_FloatRegister($dst$$reg),
16150              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16151     __ ins(as_FloatRegister($tmp$$reg), __ S,
16152            as_FloatRegister($vsrc$$reg), 0, 1);
16153     __ fadds(as_FloatRegister($dst$$reg),
16154              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16155   %}
16156   ins_pipe(pipe_class_default);
16157 %}
16158 
16159 instruct reduce_add4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16160 %{
16161   match(Set dst (AddReductionVF fsrc vsrc));
16162   ins_cost(INSN_COST);
16163   effect(TEMP tmp, TEMP dst);
16164   format %{ &quot;fadds $dst, $fsrc, $vsrc\n\t&quot;
16165             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16166             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16167             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16168             &quot;fadds $dst, $dst, $tmp\n\t&quot;
16169             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16170             &quot;fadds $dst, $dst, $tmp\t# add reduction4F&quot;
16171   %}
16172   ins_encode %{
16173     __ fadds(as_FloatRegister($dst$$reg),
16174              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16175     __ ins(as_FloatRegister($tmp$$reg), __ S,
16176            as_FloatRegister($vsrc$$reg), 0, 1);
16177     __ fadds(as_FloatRegister($dst$$reg),
16178              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16179     __ ins(as_FloatRegister($tmp$$reg), __ S,
16180            as_FloatRegister($vsrc$$reg), 0, 2);
16181     __ fadds(as_FloatRegister($dst$$reg),
16182              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16183     __ ins(as_FloatRegister($tmp$$reg), __ S,
16184            as_FloatRegister($vsrc$$reg), 0, 3);
16185     __ fadds(as_FloatRegister($dst$$reg),
16186              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16187   %}
16188   ins_pipe(pipe_class_default);
16189 %}
16190 
16191 instruct reduce_mul2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp)
16192 %{
16193   match(Set dst (MulReductionVF fsrc vsrc));
16194   ins_cost(INSN_COST);
16195   effect(TEMP tmp, TEMP dst);
16196   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16197             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16198             &quot;fmuls $dst, $dst, $tmp\t# mul reduction2F&quot;
16199   %}
16200   ins_encode %{
16201     __ fmuls(as_FloatRegister($dst$$reg),
16202              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16203     __ ins(as_FloatRegister($tmp$$reg), __ S,
16204            as_FloatRegister($vsrc$$reg), 0, 1);
16205     __ fmuls(as_FloatRegister($dst$$reg),
16206              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16207   %}
16208   ins_pipe(pipe_class_default);
16209 %}
16210 
16211 instruct reduce_mul4F(vRegF dst, vRegF fsrc, vecX vsrc, vecX tmp)
16212 %{
16213   match(Set dst (MulReductionVF fsrc vsrc));
16214   ins_cost(INSN_COST);
16215   effect(TEMP tmp, TEMP dst);
16216   format %{ &quot;fmuls $dst, $fsrc, $vsrc\n\t&quot;
16217             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16218             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16219             &quot;ins   $tmp, S, $vsrc, 0, 2\n\t&quot;
16220             &quot;fmuls $dst, $dst, $tmp\n\t&quot;
16221             &quot;ins   $tmp, S, $vsrc, 0, 3\n\t&quot;
16222             &quot;fmuls $dst, $dst, $tmp\t# mul reduction4F&quot;
16223   %}
16224   ins_encode %{
16225     __ fmuls(as_FloatRegister($dst$$reg),
16226              as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16227     __ ins(as_FloatRegister($tmp$$reg), __ S,
16228            as_FloatRegister($vsrc$$reg), 0, 1);
16229     __ fmuls(as_FloatRegister($dst$$reg),
16230              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16231     __ ins(as_FloatRegister($tmp$$reg), __ S,
16232            as_FloatRegister($vsrc$$reg), 0, 2);
16233     __ fmuls(as_FloatRegister($dst$$reg),
16234              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16235     __ ins(as_FloatRegister($tmp$$reg), __ S,
16236            as_FloatRegister($vsrc$$reg), 0, 3);
16237     __ fmuls(as_FloatRegister($dst$$reg),
16238              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16239   %}
16240   ins_pipe(pipe_class_default);
16241 %}
16242 
16243 instruct reduce_add2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16244 %{
16245   match(Set dst (AddReductionVD dsrc vsrc));
16246   ins_cost(INSN_COST);
16247   effect(TEMP tmp, TEMP dst);
16248   format %{ &quot;faddd $dst, $dsrc, $vsrc\n\t&quot;
16249             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16250             &quot;faddd $dst, $dst, $tmp\t# add reduction2D&quot;
16251   %}
16252   ins_encode %{
16253     __ faddd(as_FloatRegister($dst$$reg),
16254              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16255     __ ins(as_FloatRegister($tmp$$reg), __ D,
16256            as_FloatRegister($vsrc$$reg), 0, 1);
16257     __ faddd(as_FloatRegister($dst$$reg),
16258              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16259   %}
16260   ins_pipe(pipe_class_default);
16261 %}
16262 
16263 instruct reduce_mul2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp)
16264 %{
16265   match(Set dst (MulReductionVD dsrc vsrc));
16266   ins_cost(INSN_COST);
16267   effect(TEMP tmp, TEMP dst);
16268   format %{ &quot;fmuld $dst, $dsrc, $vsrc\n\t&quot;
16269             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16270             &quot;fmuld $dst, $dst, $tmp\t# mul reduction2D&quot;
16271   %}
16272   ins_encode %{
16273     __ fmuld(as_FloatRegister($dst$$reg),
16274              as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16275     __ ins(as_FloatRegister($tmp$$reg), __ D,
16276            as_FloatRegister($vsrc$$reg), 0, 1);
16277     __ fmuld(as_FloatRegister($dst$$reg),
16278              as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16279   %}
16280   ins_pipe(pipe_class_default);
16281 %}
16282 
16283 instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16284   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16285   match(Set dst (MaxReductionV fsrc vsrc));
16286   ins_cost(INSN_COST);
16287   effect(TEMP_DEF dst, TEMP tmp);
16288   format %{ &quot;fmaxs $dst, $fsrc, $vsrc\n\t&quot;
16289             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16290             &quot;fmaxs $dst, $dst, $tmp\t# max reduction2F&quot; %}
16291   ins_encode %{
16292     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16293     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16294     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16295   %}
16296   ins_pipe(pipe_class_default);
16297 %}
16298 
16299 instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16300   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16301   match(Set dst (MaxReductionV fsrc vsrc));
16302   ins_cost(INSN_COST);
16303   effect(TEMP_DEF dst);
16304   format %{ &quot;fmaxv $dst, T4S, $vsrc\n\t&quot;
16305             &quot;fmaxs $dst, $dst, $fsrc\t# max reduction4F&quot; %}
16306   ins_encode %{
16307     __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16308     __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16309   %}
16310   ins_pipe(pipe_class_default);
16311 %}
16312 
16313 instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16314   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16315   match(Set dst (MaxReductionV dsrc vsrc));
16316   ins_cost(INSN_COST);
16317   effect(TEMP_DEF dst, TEMP tmp);
16318   format %{ &quot;fmaxd $dst, $dsrc, $vsrc\n\t&quot;
16319             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16320             &quot;fmaxd $dst, $dst, $tmp\t# max reduction2D&quot; %}
16321   ins_encode %{
16322     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16323     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16324     __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16325   %}
16326   ins_pipe(pipe_class_default);
16327 %}
16328 
16329 instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{
16330   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16331   match(Set dst (MinReductionV fsrc vsrc));
16332   ins_cost(INSN_COST);
16333   effect(TEMP_DEF dst, TEMP tmp);
16334   format %{ &quot;fmins $dst, $fsrc, $vsrc\n\t&quot;
16335             &quot;ins   $tmp, S, $vsrc, 0, 1\n\t&quot;
16336             &quot;fmins $dst, $dst, $tmp\t# min reduction2F&quot; %}
16337   ins_encode %{
16338     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));
16339     __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);
16340     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16341   %}
16342   ins_pipe(pipe_class_default);
16343 %}
16344 
16345 instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{
16346   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
16347   match(Set dst (MinReductionV fsrc vsrc));
16348   ins_cost(INSN_COST);
16349   effect(TEMP_DEF dst);
16350   format %{ &quot;fminv $dst, T4S, $vsrc\n\t&quot;
16351             &quot;fmins $dst, $dst, $fsrc\t# min reduction4F&quot; %}
16352   ins_encode %{
16353     __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));
16354     __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));
16355   %}
16356   ins_pipe(pipe_class_default);
16357 %}
16358 
16359 instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{
16360   predicate(n-&gt;in(2)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
16361   match(Set dst (MinReductionV dsrc vsrc));
16362   ins_cost(INSN_COST);
16363   effect(TEMP_DEF dst, TEMP tmp);
16364   format %{ &quot;fmind $dst, $dsrc, $vsrc\n\t&quot;
16365             &quot;ins   $tmp, D, $vsrc, 0, 1\n\t&quot;
16366             &quot;fmind $dst, $dst, $tmp\t# min reduction2D&quot; %}
16367   ins_encode %{
16368     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));
16369     __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);
16370     __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));
16371   %}
16372   ins_pipe(pipe_class_default);
16373 %}
16374 
16375 // ====================VECTOR ARITHMETIC=======================================
16376 
16377 // --------------------------------- ADD --------------------------------------
16378 
16379 instruct vadd8B(vecD dst, vecD src1, vecD src2)
16380 %{
16381   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16382             n-&gt;as_Vector()-&gt;length() == 8);
16383   match(Set dst (AddVB src1 src2));
16384   ins_cost(INSN_COST);
16385   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16386   ins_encode %{
16387     __ addv(as_FloatRegister($dst$$reg), __ T8B,
16388             as_FloatRegister($src1$$reg),
16389             as_FloatRegister($src2$$reg));
16390   %}
16391   ins_pipe(vdop64);
16392 %}
16393 
16394 instruct vadd16B(vecX dst, vecX src1, vecX src2)
16395 %{
16396   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16397   match(Set dst (AddVB src1 src2));
16398   ins_cost(INSN_COST);
16399   format %{ &quot;addv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16400   ins_encode %{
16401     __ addv(as_FloatRegister($dst$$reg), __ T16B,
16402             as_FloatRegister($src1$$reg),
16403             as_FloatRegister($src2$$reg));
16404   %}
16405   ins_pipe(vdop128);
16406 %}
16407 
16408 instruct vadd4S(vecD dst, vecD src1, vecD src2)
16409 %{
16410   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16411             n-&gt;as_Vector()-&gt;length() == 4);
16412   match(Set dst (AddVS src1 src2));
16413   ins_cost(INSN_COST);
16414   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16415   ins_encode %{
16416     __ addv(as_FloatRegister($dst$$reg), __ T4H,
16417             as_FloatRegister($src1$$reg),
16418             as_FloatRegister($src2$$reg));
16419   %}
16420   ins_pipe(vdop64);
16421 %}
16422 
16423 instruct vadd8S(vecX dst, vecX src1, vecX src2)
16424 %{
16425   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16426   match(Set dst (AddVS src1 src2));
16427   ins_cost(INSN_COST);
16428   format %{ &quot;addv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16429   ins_encode %{
16430     __ addv(as_FloatRegister($dst$$reg), __ T8H,
16431             as_FloatRegister($src1$$reg),
16432             as_FloatRegister($src2$$reg));
16433   %}
16434   ins_pipe(vdop128);
16435 %}
16436 
16437 instruct vadd2I(vecD dst, vecD src1, vecD src2)
16438 %{
16439   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16440   match(Set dst (AddVI src1 src2));
16441   ins_cost(INSN_COST);
16442   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16443   ins_encode %{
16444     __ addv(as_FloatRegister($dst$$reg), __ T2S,
16445             as_FloatRegister($src1$$reg),
16446             as_FloatRegister($src2$$reg));
16447   %}
16448   ins_pipe(vdop64);
16449 %}
16450 
16451 instruct vadd4I(vecX dst, vecX src1, vecX src2)
16452 %{
16453   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16454   match(Set dst (AddVI src1 src2));
16455   ins_cost(INSN_COST);
16456   format %{ &quot;addv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16457   ins_encode %{
16458     __ addv(as_FloatRegister($dst$$reg), __ T4S,
16459             as_FloatRegister($src1$$reg),
16460             as_FloatRegister($src2$$reg));
16461   %}
16462   ins_pipe(vdop128);
16463 %}
16464 
16465 instruct vadd2L(vecX dst, vecX src1, vecX src2)
16466 %{
16467   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16468   match(Set dst (AddVL src1 src2));
16469   ins_cost(INSN_COST);
16470   format %{ &quot;addv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16471   ins_encode %{
16472     __ addv(as_FloatRegister($dst$$reg), __ T2D,
16473             as_FloatRegister($src1$$reg),
16474             as_FloatRegister($src2$$reg));
16475   %}
16476   ins_pipe(vdop128);
16477 %}
16478 
16479 instruct vadd2F(vecD dst, vecD src1, vecD src2)
16480 %{
16481   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16482   match(Set dst (AddVF src1 src2));
16483   ins_cost(INSN_COST);
16484   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2S)&quot; %}
16485   ins_encode %{
16486     __ fadd(as_FloatRegister($dst$$reg), __ T2S,
16487             as_FloatRegister($src1$$reg),
16488             as_FloatRegister($src2$$reg));
16489   %}
16490   ins_pipe(vdop_fp64);
16491 %}
16492 
16493 instruct vadd4F(vecX dst, vecX src1, vecX src2)
16494 %{
16495   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16496   match(Set dst (AddVF src1 src2));
16497   ins_cost(INSN_COST);
16498   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (4S)&quot; %}
16499   ins_encode %{
16500     __ fadd(as_FloatRegister($dst$$reg), __ T4S,
16501             as_FloatRegister($src1$$reg),
16502             as_FloatRegister($src2$$reg));
16503   %}
16504   ins_pipe(vdop_fp128);
16505 %}
16506 
16507 instruct vadd2D(vecX dst, vecX src1, vecX src2)
16508 %{
16509   match(Set dst (AddVD src1 src2));
16510   ins_cost(INSN_COST);
16511   format %{ &quot;fadd  $dst,$src1,$src2\t# vector (2D)&quot; %}
16512   ins_encode %{
16513     __ fadd(as_FloatRegister($dst$$reg), __ T2D,
16514             as_FloatRegister($src1$$reg),
16515             as_FloatRegister($src2$$reg));
16516   %}
16517   ins_pipe(vdop_fp128);
16518 %}
16519 
16520 // --------------------------------- SUB --------------------------------------
16521 
16522 instruct vsub8B(vecD dst, vecD src1, vecD src2)
16523 %{
16524   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16525             n-&gt;as_Vector()-&gt;length() == 8);
16526   match(Set dst (SubVB src1 src2));
16527   ins_cost(INSN_COST);
16528   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16529   ins_encode %{
16530     __ subv(as_FloatRegister($dst$$reg), __ T8B,
16531             as_FloatRegister($src1$$reg),
16532             as_FloatRegister($src2$$reg));
16533   %}
16534   ins_pipe(vdop64);
16535 %}
16536 
16537 instruct vsub16B(vecX dst, vecX src1, vecX src2)
16538 %{
16539   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16540   match(Set dst (SubVB src1 src2));
16541   ins_cost(INSN_COST);
16542   format %{ &quot;subv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16543   ins_encode %{
16544     __ subv(as_FloatRegister($dst$$reg), __ T16B,
16545             as_FloatRegister($src1$$reg),
16546             as_FloatRegister($src2$$reg));
16547   %}
16548   ins_pipe(vdop128);
16549 %}
16550 
16551 instruct vsub4S(vecD dst, vecD src1, vecD src2)
16552 %{
16553   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16554             n-&gt;as_Vector()-&gt;length() == 4);
16555   match(Set dst (SubVS src1 src2));
16556   ins_cost(INSN_COST);
16557   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16558   ins_encode %{
16559     __ subv(as_FloatRegister($dst$$reg), __ T4H,
16560             as_FloatRegister($src1$$reg),
16561             as_FloatRegister($src2$$reg));
16562   %}
16563   ins_pipe(vdop64);
16564 %}
16565 
16566 instruct vsub8S(vecX dst, vecX src1, vecX src2)
16567 %{
16568   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16569   match(Set dst (SubVS src1 src2));
16570   ins_cost(INSN_COST);
16571   format %{ &quot;subv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16572   ins_encode %{
16573     __ subv(as_FloatRegister($dst$$reg), __ T8H,
16574             as_FloatRegister($src1$$reg),
16575             as_FloatRegister($src2$$reg));
16576   %}
16577   ins_pipe(vdop128);
16578 %}
16579 
16580 instruct vsub2I(vecD dst, vecD src1, vecD src2)
16581 %{
16582   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16583   match(Set dst (SubVI src1 src2));
16584   ins_cost(INSN_COST);
16585   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16586   ins_encode %{
16587     __ subv(as_FloatRegister($dst$$reg), __ T2S,
16588             as_FloatRegister($src1$$reg),
16589             as_FloatRegister($src2$$reg));
16590   %}
16591   ins_pipe(vdop64);
16592 %}
16593 
16594 instruct vsub4I(vecX dst, vecX src1, vecX src2)
16595 %{
16596   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16597   match(Set dst (SubVI src1 src2));
16598   ins_cost(INSN_COST);
16599   format %{ &quot;subv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16600   ins_encode %{
16601     __ subv(as_FloatRegister($dst$$reg), __ T4S,
16602             as_FloatRegister($src1$$reg),
16603             as_FloatRegister($src2$$reg));
16604   %}
16605   ins_pipe(vdop128);
16606 %}
16607 
16608 instruct vsub2L(vecX dst, vecX src1, vecX src2)
16609 %{
16610   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16611   match(Set dst (SubVL src1 src2));
16612   ins_cost(INSN_COST);
16613   format %{ &quot;subv  $dst,$src1,$src2\t# vector (2L)&quot; %}
16614   ins_encode %{
16615     __ subv(as_FloatRegister($dst$$reg), __ T2D,
16616             as_FloatRegister($src1$$reg),
16617             as_FloatRegister($src2$$reg));
16618   %}
16619   ins_pipe(vdop128);
16620 %}
16621 
16622 instruct vsub2F(vecD dst, vecD src1, vecD src2)
16623 %{
16624   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16625   match(Set dst (SubVF src1 src2));
16626   ins_cost(INSN_COST);
16627   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2S)&quot; %}
16628   ins_encode %{
16629     __ fsub(as_FloatRegister($dst$$reg), __ T2S,
16630             as_FloatRegister($src1$$reg),
16631             as_FloatRegister($src2$$reg));
16632   %}
16633   ins_pipe(vdop_fp64);
16634 %}
16635 
16636 instruct vsub4F(vecX dst, vecX src1, vecX src2)
16637 %{
16638   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16639   match(Set dst (SubVF src1 src2));
16640   ins_cost(INSN_COST);
16641   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (4S)&quot; %}
16642   ins_encode %{
16643     __ fsub(as_FloatRegister($dst$$reg), __ T4S,
16644             as_FloatRegister($src1$$reg),
16645             as_FloatRegister($src2$$reg));
16646   %}
16647   ins_pipe(vdop_fp128);
16648 %}
16649 
16650 instruct vsub2D(vecX dst, vecX src1, vecX src2)
16651 %{
16652   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16653   match(Set dst (SubVD src1 src2));
16654   ins_cost(INSN_COST);
16655   format %{ &quot;fsub  $dst,$src1,$src2\t# vector (2D)&quot; %}
16656   ins_encode %{
16657     __ fsub(as_FloatRegister($dst$$reg), __ T2D,
16658             as_FloatRegister($src1$$reg),
16659             as_FloatRegister($src2$$reg));
16660   %}
16661   ins_pipe(vdop_fp128);
16662 %}
16663 
16664 // --------------------------------- MUL --------------------------------------
16665 
16666 instruct vmul8B(vecD dst, vecD src1, vecD src2)
16667 %{
16668   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
16669             n-&gt;as_Vector()-&gt;length() == 8);
16670   match(Set dst (MulVB src1 src2));
16671   ins_cost(INSN_COST);
16672   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8B)&quot; %}
16673   ins_encode %{
16674     __ mulv(as_FloatRegister($dst$$reg), __ T8B,
16675             as_FloatRegister($src1$$reg),
16676             as_FloatRegister($src2$$reg));
16677   %}
16678   ins_pipe(vmul64);
16679 %}
16680 
16681 instruct vmul16B(vecX dst, vecX src1, vecX src2)
16682 %{
16683   predicate(n-&gt;as_Vector()-&gt;length() == 16);
16684   match(Set dst (MulVB src1 src2));
16685   ins_cost(INSN_COST);
16686   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (16B)&quot; %}
16687   ins_encode %{
16688     __ mulv(as_FloatRegister($dst$$reg), __ T16B,
16689             as_FloatRegister($src1$$reg),
16690             as_FloatRegister($src2$$reg));
16691   %}
16692   ins_pipe(vmul128);
16693 %}
16694 
16695 instruct vmul4S(vecD dst, vecD src1, vecD src2)
16696 %{
16697   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16698             n-&gt;as_Vector()-&gt;length() == 4);
16699   match(Set dst (MulVS src1 src2));
16700   ins_cost(INSN_COST);
16701   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16702   ins_encode %{
16703     __ mulv(as_FloatRegister($dst$$reg), __ T4H,
16704             as_FloatRegister($src1$$reg),
16705             as_FloatRegister($src2$$reg));
16706   %}
16707   ins_pipe(vmul64);
16708 %}
16709 
16710 instruct vmul8S(vecX dst, vecX src1, vecX src2)
16711 %{
16712   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16713   match(Set dst (MulVS src1 src2));
16714   ins_cost(INSN_COST);
16715   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16716   ins_encode %{
16717     __ mulv(as_FloatRegister($dst$$reg), __ T8H,
16718             as_FloatRegister($src1$$reg),
16719             as_FloatRegister($src2$$reg));
16720   %}
16721   ins_pipe(vmul128);
16722 %}
16723 
16724 instruct vmul2I(vecD dst, vecD src1, vecD src2)
16725 %{
16726   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16727   match(Set dst (MulVI src1 src2));
16728   ins_cost(INSN_COST);
16729   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16730   ins_encode %{
16731     __ mulv(as_FloatRegister($dst$$reg), __ T2S,
16732             as_FloatRegister($src1$$reg),
16733             as_FloatRegister($src2$$reg));
16734   %}
16735   ins_pipe(vmul64);
16736 %}
16737 
16738 instruct vmul4I(vecX dst, vecX src1, vecX src2)
16739 %{
16740   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16741   match(Set dst (MulVI src1 src2));
16742   ins_cost(INSN_COST);
16743   format %{ &quot;mulv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16744   ins_encode %{
16745     __ mulv(as_FloatRegister($dst$$reg), __ T4S,
16746             as_FloatRegister($src1$$reg),
16747             as_FloatRegister($src2$$reg));
16748   %}
16749   ins_pipe(vmul128);
16750 %}
16751 
16752 instruct vmul2F(vecD dst, vecD src1, vecD src2)
16753 %{
16754   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16755   match(Set dst (MulVF src1 src2));
16756   ins_cost(INSN_COST);
16757   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2S)&quot; %}
16758   ins_encode %{
16759     __ fmul(as_FloatRegister($dst$$reg), __ T2S,
16760             as_FloatRegister($src1$$reg),
16761             as_FloatRegister($src2$$reg));
16762   %}
16763   ins_pipe(vmuldiv_fp64);
16764 %}
16765 
16766 instruct vmul4F(vecX dst, vecX src1, vecX src2)
16767 %{
16768   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16769   match(Set dst (MulVF src1 src2));
16770   ins_cost(INSN_COST);
16771   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (4S)&quot; %}
16772   ins_encode %{
16773     __ fmul(as_FloatRegister($dst$$reg), __ T4S,
16774             as_FloatRegister($src1$$reg),
16775             as_FloatRegister($src2$$reg));
16776   %}
16777   ins_pipe(vmuldiv_fp128);
16778 %}
16779 
16780 instruct vmul2D(vecX dst, vecX src1, vecX src2)
16781 %{
16782   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16783   match(Set dst (MulVD src1 src2));
16784   ins_cost(INSN_COST);
16785   format %{ &quot;fmul  $dst,$src1,$src2\t# vector (2D)&quot; %}
16786   ins_encode %{
16787     __ fmul(as_FloatRegister($dst$$reg), __ T2D,
16788             as_FloatRegister($src1$$reg),
16789             as_FloatRegister($src2$$reg));
16790   %}
16791   ins_pipe(vmuldiv_fp128);
16792 %}
16793 
16794 // --------------------------------- MLA --------------------------------------
16795 
16796 instruct vmla4S(vecD dst, vecD src1, vecD src2)
16797 %{
16798   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16799             n-&gt;as_Vector()-&gt;length() == 4);
16800   match(Set dst (AddVS dst (MulVS src1 src2)));
16801   ins_cost(INSN_COST);
16802   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4H)&quot; %}
16803   ins_encode %{
16804     __ mlav(as_FloatRegister($dst$$reg), __ T4H,
16805             as_FloatRegister($src1$$reg),
16806             as_FloatRegister($src2$$reg));
16807   %}
16808   ins_pipe(vmla64);
16809 %}
16810 
16811 instruct vmla8S(vecX dst, vecX src1, vecX src2)
16812 %{
16813   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16814   match(Set dst (AddVS dst (MulVS src1 src2)));
16815   ins_cost(INSN_COST);
16816   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (8H)&quot; %}
16817   ins_encode %{
16818     __ mlav(as_FloatRegister($dst$$reg), __ T8H,
16819             as_FloatRegister($src1$$reg),
16820             as_FloatRegister($src2$$reg));
16821   %}
16822   ins_pipe(vmla128);
16823 %}
16824 
16825 instruct vmla2I(vecD dst, vecD src1, vecD src2)
16826 %{
16827   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16828   match(Set dst (AddVI dst (MulVI src1 src2)));
16829   ins_cost(INSN_COST);
16830   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (2S)&quot; %}
16831   ins_encode %{
16832     __ mlav(as_FloatRegister($dst$$reg), __ T2S,
16833             as_FloatRegister($src1$$reg),
16834             as_FloatRegister($src2$$reg));
16835   %}
16836   ins_pipe(vmla64);
16837 %}
16838 
16839 instruct vmla4I(vecX dst, vecX src1, vecX src2)
16840 %{
16841   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16842   match(Set dst (AddVI dst (MulVI src1 src2)));
16843   ins_cost(INSN_COST);
16844   format %{ &quot;mlav  $dst,$src1,$src2\t# vector (4S)&quot; %}
16845   ins_encode %{
16846     __ mlav(as_FloatRegister($dst$$reg), __ T4S,
16847             as_FloatRegister($src1$$reg),
16848             as_FloatRegister($src2$$reg));
16849   %}
16850   ins_pipe(vmla128);
16851 %}
16852 
16853 // dst + src1 * src2
16854 instruct vmla2F(vecD dst, vecD src1, vecD src2) %{
16855   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16856   match(Set dst (FmaVF  dst (Binary src1 src2)));
16857   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2S)&quot; %}
16858   ins_cost(INSN_COST);
16859   ins_encode %{
16860     __ fmla(as_FloatRegister($dst$$reg), __ T2S,
16861             as_FloatRegister($src1$$reg),
16862             as_FloatRegister($src2$$reg));
16863   %}
16864   ins_pipe(vmuldiv_fp64);
16865 %}
16866 
16867 // dst + src1 * src2
16868 instruct vmla4F(vecX dst, vecX src1, vecX src2) %{
16869   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16870   match(Set dst (FmaVF  dst (Binary src1 src2)));
16871   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (4S)&quot; %}
16872   ins_cost(INSN_COST);
16873   ins_encode %{
16874     __ fmla(as_FloatRegister($dst$$reg), __ T4S,
16875             as_FloatRegister($src1$$reg),
16876             as_FloatRegister($src2$$reg));
16877   %}
16878   ins_pipe(vmuldiv_fp128);
16879 %}
16880 
16881 // dst + src1 * src2
16882 instruct vmla2D(vecX dst, vecX src1, vecX src2) %{
16883   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16884   match(Set dst (FmaVD  dst (Binary src1 src2)));
16885   format %{ &quot;fmla  $dst,$src1,$src2\t# vector (2D)&quot; %}
16886   ins_cost(INSN_COST);
16887   ins_encode %{
16888     __ fmla(as_FloatRegister($dst$$reg), __ T2D,
16889             as_FloatRegister($src1$$reg),
16890             as_FloatRegister($src2$$reg));
16891   %}
16892   ins_pipe(vmuldiv_fp128);
16893 %}
16894 
16895 // --------------------------------- MLS --------------------------------------
16896 
16897 instruct vmls4S(vecD dst, vecD src1, vecD src2)
16898 %{
16899   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
16900             n-&gt;as_Vector()-&gt;length() == 4);
16901   match(Set dst (SubVS dst (MulVS src1 src2)));
16902   ins_cost(INSN_COST);
16903   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4H)&quot; %}
16904   ins_encode %{
16905     __ mlsv(as_FloatRegister($dst$$reg), __ T4H,
16906             as_FloatRegister($src1$$reg),
16907             as_FloatRegister($src2$$reg));
16908   %}
16909   ins_pipe(vmla64);
16910 %}
16911 
16912 instruct vmls8S(vecX dst, vecX src1, vecX src2)
16913 %{
16914   predicate(n-&gt;as_Vector()-&gt;length() == 8);
16915   match(Set dst (SubVS dst (MulVS src1 src2)));
16916   ins_cost(INSN_COST);
16917   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (8H)&quot; %}
16918   ins_encode %{
16919     __ mlsv(as_FloatRegister($dst$$reg), __ T8H,
16920             as_FloatRegister($src1$$reg),
16921             as_FloatRegister($src2$$reg));
16922   %}
16923   ins_pipe(vmla128);
16924 %}
16925 
16926 instruct vmls2I(vecD dst, vecD src1, vecD src2)
16927 %{
16928   predicate(n-&gt;as_Vector()-&gt;length() == 2);
16929   match(Set dst (SubVI dst (MulVI src1 src2)));
16930   ins_cost(INSN_COST);
16931   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (2S)&quot; %}
16932   ins_encode %{
16933     __ mlsv(as_FloatRegister($dst$$reg), __ T2S,
16934             as_FloatRegister($src1$$reg),
16935             as_FloatRegister($src2$$reg));
16936   %}
16937   ins_pipe(vmla64);
16938 %}
16939 
16940 instruct vmls4I(vecX dst, vecX src1, vecX src2)
16941 %{
16942   predicate(n-&gt;as_Vector()-&gt;length() == 4);
16943   match(Set dst (SubVI dst (MulVI src1 src2)));
16944   ins_cost(INSN_COST);
16945   format %{ &quot;mlsv  $dst,$src1,$src2\t# vector (4S)&quot; %}
16946   ins_encode %{
16947     __ mlsv(as_FloatRegister($dst$$reg), __ T4S,
16948             as_FloatRegister($src1$$reg),
16949             as_FloatRegister($src2$$reg));
16950   %}
16951   ins_pipe(vmla128);
16952 %}
16953 
16954 // dst - src1 * src2
16955 instruct vmls2F(vecD dst, vecD src1, vecD src2) %{
16956   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16957   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16958   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16959   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2S)&quot; %}
16960   ins_cost(INSN_COST);
16961   ins_encode %{
16962     __ fmls(as_FloatRegister($dst$$reg), __ T2S,
16963             as_FloatRegister($src1$$reg),
16964             as_FloatRegister($src2$$reg));
16965   %}
16966   ins_pipe(vmuldiv_fp64);
16967 %}
16968 
16969 // dst - src1 * src2
16970 instruct vmls4F(vecX dst, vecX src1, vecX src2) %{
16971   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
16972   match(Set dst (FmaVF  dst (Binary (NegVF src1) src2)));
16973   match(Set dst (FmaVF  dst (Binary src1 (NegVF src2))));
16974   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (4S)&quot; %}
16975   ins_cost(INSN_COST);
16976   ins_encode %{
16977     __ fmls(as_FloatRegister($dst$$reg), __ T4S,
16978             as_FloatRegister($src1$$reg),
16979             as_FloatRegister($src2$$reg));
16980   %}
16981   ins_pipe(vmuldiv_fp128);
16982 %}
16983 
16984 // dst - src1 * src2
16985 instruct vmls2D(vecX dst, vecX src1, vecX src2) %{
16986   predicate(UseFMA &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
16987   match(Set dst (FmaVD  dst (Binary (NegVD src1) src2)));
16988   match(Set dst (FmaVD  dst (Binary src1 (NegVD src2))));
16989   format %{ &quot;fmls  $dst,$src1,$src2\t# vector (2D)&quot; %}
16990   ins_cost(INSN_COST);
16991   ins_encode %{
16992     __ fmls(as_FloatRegister($dst$$reg), __ T2D,
16993             as_FloatRegister($src1$$reg),
16994             as_FloatRegister($src2$$reg));
16995   %}
16996   ins_pipe(vmuldiv_fp128);
16997 %}
16998 
16999 // --------------- Vector Multiply-Add Shorts into Integer --------------------
17000 
17001 instruct vmuladdS2I(vecX dst, vecX src1, vecX src2, vecX tmp) %{
17002   predicate(n-&gt;in(1)-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_SHORT);
17003   match(Set dst (MulAddVS2VI src1 src2));
17004   ins_cost(INSN_COST);
17005   effect(TEMP_DEF dst, TEMP tmp);
17006   format %{ &quot;smullv  $tmp, $src1, $src2\t# vector (4H)\n\t&quot;
17007             &quot;smullv  $dst, $src1, $src2\t# vector (8H)\n\t&quot;
17008             &quot;addpv   $dst, $tmp, $dst\t# vector (4S)\n\t&quot; %}
17009   ins_encode %{
17010     __ smullv(as_FloatRegister($tmp$$reg), __ T4H,
17011               as_FloatRegister($src1$$reg),
17012               as_FloatRegister($src2$$reg));
17013     __ smullv(as_FloatRegister($dst$$reg), __ T8H,
17014               as_FloatRegister($src1$$reg),
17015               as_FloatRegister($src2$$reg));
17016     __ addpv(as_FloatRegister($dst$$reg), __ T4S,
17017              as_FloatRegister($tmp$$reg),
17018              as_FloatRegister($dst$$reg));
17019   %}
17020   ins_pipe(vmuldiv_fp128);
17021 %}
17022 
17023 // --------------------------------- DIV --------------------------------------
17024 
17025 instruct vdiv2F(vecD dst, vecD src1, vecD src2)
17026 %{
17027   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17028   match(Set dst (DivVF src1 src2));
17029   ins_cost(INSN_COST);
17030   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2S)&quot; %}
17031   ins_encode %{
17032     __ fdiv(as_FloatRegister($dst$$reg), __ T2S,
17033             as_FloatRegister($src1$$reg),
17034             as_FloatRegister($src2$$reg));
17035   %}
17036   ins_pipe(vmuldiv_fp64);
17037 %}
17038 
17039 instruct vdiv4F(vecX dst, vecX src1, vecX src2)
17040 %{
17041   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17042   match(Set dst (DivVF src1 src2));
17043   ins_cost(INSN_COST);
17044   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (4S)&quot; %}
17045   ins_encode %{
17046     __ fdiv(as_FloatRegister($dst$$reg), __ T4S,
17047             as_FloatRegister($src1$$reg),
17048             as_FloatRegister($src2$$reg));
17049   %}
17050   ins_pipe(vmuldiv_fp128);
17051 %}
17052 
17053 instruct vdiv2D(vecX dst, vecX src1, vecX src2)
17054 %{
17055   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17056   match(Set dst (DivVD src1 src2));
17057   ins_cost(INSN_COST);
17058   format %{ &quot;fdiv  $dst,$src1,$src2\t# vector (2D)&quot; %}
17059   ins_encode %{
17060     __ fdiv(as_FloatRegister($dst$$reg), __ T2D,
17061             as_FloatRegister($src1$$reg),
17062             as_FloatRegister($src2$$reg));
17063   %}
17064   ins_pipe(vmuldiv_fp128);
17065 %}
17066 
17067 // --------------------------------- SQRT -------------------------------------
17068 
17069 instruct vsqrt2F(vecD dst, vecD src)
17070 %{
17071   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17072   match(Set dst (SqrtVF src));
17073   format %{ &quot;fsqrt  $dst, $src\t# vector (2F)&quot; %}
17074   ins_encode %{
17075     __ fsqrt(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17076   %}
17077   ins_pipe(vunop_fp64);
17078 %}
17079 
17080 instruct vsqrt4F(vecX dst, vecX src)
17081 %{
17082   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17083   match(Set dst (SqrtVF src));
17084   format %{ &quot;fsqrt  $dst, $src\t# vector (4F)&quot; %}
17085   ins_encode %{
17086     __ fsqrt(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17087   %}
17088   ins_pipe(vsqrt_fp128);
17089 %}
17090 
17091 instruct vsqrt2D(vecX dst, vecX src)
17092 %{
17093   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17094   match(Set dst (SqrtVD src));
17095   format %{ &quot;fsqrt  $dst, $src\t# vector (2D)&quot; %}
17096   ins_encode %{
17097     __ fsqrt(as_FloatRegister($dst$$reg), __ T2D,
17098              as_FloatRegister($src$$reg));
17099   %}
17100   ins_pipe(vsqrt_fp128);
17101 %}
17102 
17103 // --------------------------------- ABS --------------------------------------
17104 
17105 instruct vabs8B(vecD dst, vecD src)
17106 %{
17107   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17108             n-&gt;as_Vector()-&gt;length() == 8);
17109   match(Set dst (AbsVB src));
17110   ins_cost(INSN_COST);
17111   format %{ &quot;abs  $dst, $src\t# vector (8B)&quot; %}
17112   ins_encode %{
17113     __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));
17114   %}
17115   ins_pipe(vlogical64);
17116 %}
17117 
17118 instruct vabs16B(vecX dst, vecX src)
17119 %{
17120   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17121   match(Set dst (AbsVB src));
17122   ins_cost(INSN_COST);
17123   format %{ &quot;abs  $dst, $src\t# vector (16B)&quot; %}
17124   ins_encode %{
17125     __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));
17126   %}
17127   ins_pipe(vlogical128);
17128 %}
17129 
17130 instruct vabs4S(vecD dst, vecD src)
17131 %{
17132   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17133   match(Set dst (AbsVS src));
17134   ins_cost(INSN_COST);
17135   format %{ &quot;abs  $dst, $src\t# vector (4H)&quot; %}
17136   ins_encode %{
17137     __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));
17138   %}
17139   ins_pipe(vlogical64);
17140 %}
17141 
17142 instruct vabs8S(vecX dst, vecX src)
17143 %{
17144   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17145   match(Set dst (AbsVS src));
17146   ins_cost(INSN_COST);
17147   format %{ &quot;abs  $dst, $src\t# vector (8H)&quot; %}
17148   ins_encode %{
17149     __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));
17150   %}
17151   ins_pipe(vlogical128);
17152 %}
17153 
17154 instruct vabs2I(vecD dst, vecD src)
17155 %{
17156   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17157   match(Set dst (AbsVI src));
17158   ins_cost(INSN_COST);
17159   format %{ &quot;abs  $dst, $src\t# vector (2S)&quot; %}
17160   ins_encode %{
17161     __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));
17162   %}
17163   ins_pipe(vlogical64);
17164 %}
17165 
17166 instruct vabs4I(vecX dst, vecX src)
17167 %{
17168   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17169   match(Set dst (AbsVI src));
17170   ins_cost(INSN_COST);
17171   format %{ &quot;abs  $dst, $src\t# vector (4S)&quot; %}
17172   ins_encode %{
17173     __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));
17174   %}
17175   ins_pipe(vlogical128);
17176 %}
17177 
17178 instruct vabs2L(vecX dst, vecX src)
17179 %{
17180   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17181   match(Set dst (AbsVL src));
17182   ins_cost(INSN_COST);
17183   format %{ &quot;abs  $dst, $src\t# vector (2D)&quot; %}
17184   ins_encode %{
17185     __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));
17186   %}
17187   ins_pipe(vlogical128);
17188 %}
17189 
17190 instruct vabs2F(vecD dst, vecD src)
17191 %{
17192   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17193   match(Set dst (AbsVF src));
17194   ins_cost(INSN_COST * 3);
17195   format %{ &quot;fabs  $dst,$src\t# vector (2S)&quot; %}
17196   ins_encode %{
17197     __ fabs(as_FloatRegister($dst$$reg), __ T2S,
17198             as_FloatRegister($src$$reg));
17199   %}
17200   ins_pipe(vunop_fp64);
17201 %}
17202 
17203 instruct vabs4F(vecX dst, vecX src)
17204 %{
17205   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17206   match(Set dst (AbsVF src));
17207   ins_cost(INSN_COST * 3);
17208   format %{ &quot;fabs  $dst,$src\t# vector (4S)&quot; %}
17209   ins_encode %{
17210     __ fabs(as_FloatRegister($dst$$reg), __ T4S,
17211             as_FloatRegister($src$$reg));
17212   %}
17213   ins_pipe(vunop_fp128);
17214 %}
17215 
17216 instruct vabs2D(vecX dst, vecX src)
17217 %{
17218   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17219   match(Set dst (AbsVD src));
17220   ins_cost(INSN_COST * 3);
17221   format %{ &quot;fabs  $dst,$src\t# vector (2D)&quot; %}
17222   ins_encode %{
17223     __ fabs(as_FloatRegister($dst$$reg), __ T2D,
17224             as_FloatRegister($src$$reg));
17225   %}
17226   ins_pipe(vunop_fp128);
17227 %}
17228 
17229 // --------------------------------- NEG --------------------------------------
17230 
17231 instruct vneg2F(vecD dst, vecD src)
17232 %{
17233   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17234   match(Set dst (NegVF src));
17235   ins_cost(INSN_COST * 3);
17236   format %{ &quot;fneg  $dst,$src\t# vector (2S)&quot; %}
17237   ins_encode %{
17238     __ fneg(as_FloatRegister($dst$$reg), __ T2S,
17239             as_FloatRegister($src$$reg));
17240   %}
17241   ins_pipe(vunop_fp64);
17242 %}
17243 
17244 instruct vneg4F(vecX dst, vecX src)
17245 %{
17246   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17247   match(Set dst (NegVF src));
17248   ins_cost(INSN_COST * 3);
17249   format %{ &quot;fneg  $dst,$src\t# vector (4S)&quot; %}
17250   ins_encode %{
17251     __ fneg(as_FloatRegister($dst$$reg), __ T4S,
17252             as_FloatRegister($src$$reg));
17253   %}
17254   ins_pipe(vunop_fp128);
17255 %}
17256 
17257 instruct vneg2D(vecX dst, vecX src)
17258 %{
17259   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17260   match(Set dst (NegVD src));
17261   ins_cost(INSN_COST * 3);
17262   format %{ &quot;fneg  $dst,$src\t# vector (2D)&quot; %}
17263   ins_encode %{
17264     __ fneg(as_FloatRegister($dst$$reg), __ T2D,
17265             as_FloatRegister($src$$reg));
17266   %}
17267   ins_pipe(vunop_fp128);
17268 %}
17269 
17270 // --------------------------------- AND --------------------------------------
17271 
17272 instruct vand8B(vecD dst, vecD src1, vecD src2)
17273 %{
17274   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17275             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17276   match(Set dst (AndV src1 src2));
17277   ins_cost(INSN_COST);
17278   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17279   ins_encode %{
17280     __ andr(as_FloatRegister($dst$$reg), __ T8B,
17281             as_FloatRegister($src1$$reg),
17282             as_FloatRegister($src2$$reg));
17283   %}
17284   ins_pipe(vlogical64);
17285 %}
17286 
17287 instruct vand16B(vecX dst, vecX src1, vecX src2)
17288 %{
17289   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17290   match(Set dst (AndV src1 src2));
17291   ins_cost(INSN_COST);
17292   format %{ &quot;and  $dst,$src1,$src2\t# vector (16B)&quot; %}
17293   ins_encode %{
17294     __ andr(as_FloatRegister($dst$$reg), __ T16B,
17295             as_FloatRegister($src1$$reg),
17296             as_FloatRegister($src2$$reg));
17297   %}
17298   ins_pipe(vlogical128);
17299 %}
17300 
17301 // --------------------------------- OR ---------------------------------------
17302 
17303 instruct vor8B(vecD dst, vecD src1, vecD src2)
17304 %{
17305   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17306             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17307   match(Set dst (OrV src1 src2));
17308   ins_cost(INSN_COST);
17309   format %{ &quot;and  $dst,$src1,$src2\t# vector (8B)&quot; %}
17310   ins_encode %{
17311     __ orr(as_FloatRegister($dst$$reg), __ T8B,
17312             as_FloatRegister($src1$$reg),
17313             as_FloatRegister($src2$$reg));
17314   %}
17315   ins_pipe(vlogical64);
17316 %}
17317 
17318 instruct vor16B(vecX dst, vecX src1, vecX src2)
17319 %{
17320   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17321   match(Set dst (OrV src1 src2));
17322   ins_cost(INSN_COST);
17323   format %{ &quot;orr  $dst,$src1,$src2\t# vector (16B)&quot; %}
17324   ins_encode %{
17325     __ orr(as_FloatRegister($dst$$reg), __ T16B,
17326             as_FloatRegister($src1$$reg),
17327             as_FloatRegister($src2$$reg));
17328   %}
17329   ins_pipe(vlogical128);
17330 %}
17331 
17332 // --------------------------------- XOR --------------------------------------
17333 
17334 instruct vxor8B(vecD dst, vecD src1, vecD src2)
17335 %{
17336   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 4 ||
17337             n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17338   match(Set dst (XorV src1 src2));
17339   ins_cost(INSN_COST);
17340   format %{ &quot;xor  $dst,$src1,$src2\t# vector (8B)&quot; %}
17341   ins_encode %{
17342     __ eor(as_FloatRegister($dst$$reg), __ T8B,
17343             as_FloatRegister($src1$$reg),
17344             as_FloatRegister($src2$$reg));
17345   %}
17346   ins_pipe(vlogical64);
17347 %}
17348 
17349 instruct vxor16B(vecX dst, vecX src1, vecX src2)
17350 %{
17351   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17352   match(Set dst (XorV src1 src2));
17353   ins_cost(INSN_COST);
17354   format %{ &quot;xor  $dst,$src1,$src2\t# vector (16B)&quot; %}
17355   ins_encode %{
17356     __ eor(as_FloatRegister($dst$$reg), __ T16B,
17357             as_FloatRegister($src1$$reg),
17358             as_FloatRegister($src2$$reg));
17359   %}
17360   ins_pipe(vlogical128);
17361 %}
17362 
17363 // ------------------------------ Shift ---------------------------------------
17364 instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{
17365   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
17366   match(Set dst (LShiftCntV cnt));
17367   match(Set dst (RShiftCntV cnt));
17368   format %{ &quot;dup  $dst, $cnt\t# shift count vector (8B)&quot; %}
17369   ins_encode %{
17370     __ dup(as_FloatRegister($dst$$reg), __ T8B, as_Register($cnt$$reg));
17371   %}
17372   ins_pipe(vdup_reg_reg64);
17373 %}
17374 
17375 instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{
17376   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
17377   match(Set dst (LShiftCntV cnt));
17378   match(Set dst (RShiftCntV cnt));
17379   format %{ &quot;dup  $dst, $cnt\t# shift count vector (16B)&quot; %}
17380   ins_encode %{
17381     __ dup(as_FloatRegister($dst$$reg), __ T16B, as_Register($cnt$$reg));
17382   %}
17383   ins_pipe(vdup_reg_reg128);
17384 %}
17385 
17386 instruct vsll8B(vecD dst, vecD src, vecD shift) %{
17387   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17388             n-&gt;as_Vector()-&gt;length() == 8);
17389   match(Set dst (LShiftVB src shift));
17390   ins_cost(INSN_COST);
17391   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8B)&quot; %}
17392   ins_encode %{
17393     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17394             as_FloatRegister($src$$reg),
17395             as_FloatRegister($shift$$reg));
17396   %}
17397   ins_pipe(vshift64);
17398 %}
17399 
17400 instruct vsll16B(vecX dst, vecX src, vecX shift) %{
17401   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17402   match(Set dst (LShiftVB src shift));
17403   ins_cost(INSN_COST);
17404   format %{ &quot;sshl  $dst,$src,$shift\t# vector (16B)&quot; %}
17405   ins_encode %{
17406     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17407             as_FloatRegister($src$$reg),
17408             as_FloatRegister($shift$$reg));
17409   %}
17410   ins_pipe(vshift128);
17411 %}
17412 
17413 // Right shifts with vector shift count on aarch64 SIMD are implemented
17414 // as left shift by negative shift count.
17415 // There are two cases for vector shift count.
17416 //
17417 // Case 1: The vector shift count is from replication.
17418 //        |            |
17419 //    LoadVector  RShiftCntV
17420 //        |       /
17421 //     RShiftVI
17422 // Note: In inner loop, multiple neg instructions are used, which can be
17423 // moved to outer loop and merge into one neg instruction.
17424 //
17425 // Case 2: The vector shift count is from loading.
17426 // This case isn&#39;t supported by middle-end now. But it&#39;s supported by
17427 // panama/vectorIntrinsics(JEP 338: Vector API).
17428 //        |            |
17429 //    LoadVector  LoadVector
17430 //        |       /
17431 //     RShiftVI
17432 //
17433 
17434 instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17435   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17436             n-&gt;as_Vector()-&gt;length() == 8);
17437   match(Set dst (RShiftVB src shift));
17438   ins_cost(INSN_COST);
17439   effect(TEMP tmp);
17440   format %{ &quot;negr  $tmp,$shift\t&quot;
17441             &quot;sshl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17442   ins_encode %{
17443     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17444             as_FloatRegister($shift$$reg));
17445     __ sshl(as_FloatRegister($dst$$reg), __ T8B,
17446             as_FloatRegister($src$$reg),
17447             as_FloatRegister($tmp$$reg));
17448   %}
17449   ins_pipe(vshift64);
17450 %}
17451 
17452 instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17453   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17454   match(Set dst (RShiftVB src shift));
17455   ins_cost(INSN_COST);
17456   effect(TEMP tmp);
17457   format %{ &quot;negr  $tmp,$shift\t&quot;
17458             &quot;sshl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17459   ins_encode %{
17460     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17461             as_FloatRegister($shift$$reg));
17462     __ sshl(as_FloatRegister($dst$$reg), __ T16B,
17463             as_FloatRegister($src$$reg),
17464             as_FloatRegister($tmp$$reg));
17465   %}
17466   ins_pipe(vshift128);
17467 %}
17468 
17469 instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{
17470   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17471             n-&gt;as_Vector()-&gt;length() == 8);
17472   match(Set dst (URShiftVB src shift));
17473   ins_cost(INSN_COST);
17474   effect(TEMP tmp);
17475   format %{ &quot;negr  $tmp,$shift\t&quot;
17476             &quot;ushl  $dst,$src,$tmp\t# vector (8B)&quot; %}
17477   ins_encode %{
17478     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17479             as_FloatRegister($shift$$reg));
17480     __ ushl(as_FloatRegister($dst$$reg), __ T8B,
17481             as_FloatRegister($src$$reg),
17482             as_FloatRegister($tmp$$reg));
17483   %}
17484   ins_pipe(vshift64);
17485 %}
17486 
17487 instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{
17488   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17489   match(Set dst (URShiftVB src shift));
17490   ins_cost(INSN_COST);
17491   effect(TEMP tmp);
17492   format %{ &quot;negr  $tmp,$shift\t&quot;
17493             &quot;ushl  $dst,$src,$tmp\t# vector (16B)&quot; %}
17494   ins_encode %{
17495     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17496             as_FloatRegister($shift$$reg));
17497     __ ushl(as_FloatRegister($dst$$reg), __ T16B,
17498             as_FloatRegister($src$$reg),
17499             as_FloatRegister($tmp$$reg));
17500   %}
17501   ins_pipe(vshift128);
17502 %}
17503 
17504 instruct vsll8B_imm(vecD dst, vecD src, immI shift) %{
17505   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17506             n-&gt;as_Vector()-&gt;length() == 8);
17507   match(Set dst (LShiftVB src (LShiftCntV shift)));
17508   ins_cost(INSN_COST);
17509   format %{ &quot;shl    $dst, $src, $shift\t# vector (8B)&quot; %}
17510   ins_encode %{
17511     int sh = (int)$shift$$constant;
17512     if (sh &gt;= 8) {
17513       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17514              as_FloatRegister($src$$reg),
17515              as_FloatRegister($src$$reg));
17516     } else {
17517       __ shl(as_FloatRegister($dst$$reg), __ T8B,
17518              as_FloatRegister($src$$reg), sh);
17519     }
17520   %}
17521   ins_pipe(vshift64_imm);
17522 %}
17523 
17524 instruct vsll16B_imm(vecX dst, vecX src, immI shift) %{
17525   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17526   match(Set dst (LShiftVB src (LShiftCntV shift)));
17527   ins_cost(INSN_COST);
17528   format %{ &quot;shl    $dst, $src, $shift\t# vector (16B)&quot; %}
17529   ins_encode %{
17530     int sh = (int)$shift$$constant;
17531     if (sh &gt;= 8) {
17532       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17533              as_FloatRegister($src$$reg),
17534              as_FloatRegister($src$$reg));
17535     } else {
17536       __ shl(as_FloatRegister($dst$$reg), __ T16B,
17537              as_FloatRegister($src$$reg), sh);
17538     }
17539   %}
17540   ins_pipe(vshift128_imm);
17541 %}
17542 
17543 instruct vsra8B_imm(vecD dst, vecD src, immI shift) %{
17544   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17545             n-&gt;as_Vector()-&gt;length() == 8);
17546   match(Set dst (RShiftVB src (RShiftCntV shift)));
17547   ins_cost(INSN_COST);
17548   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8B)&quot; %}
17549   ins_encode %{
17550     int sh = (int)$shift$$constant;
17551     if (sh &gt;= 8) sh = 7;
17552     __ sshr(as_FloatRegister($dst$$reg), __ T8B,
17553            as_FloatRegister($src$$reg), sh);
17554   %}
17555   ins_pipe(vshift64_imm);
17556 %}
17557 
17558 instruct vsra16B_imm(vecX dst, vecX src, immI shift) %{
17559   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17560   match(Set dst (RShiftVB src (RShiftCntV shift)));
17561   ins_cost(INSN_COST);
17562   format %{ &quot;sshr    $dst, $src, $shift\t# vector (16B)&quot; %}
17563   ins_encode %{
17564     int sh = (int)$shift$$constant;
17565     if (sh &gt;= 8) sh = 7;
17566     __ sshr(as_FloatRegister($dst$$reg), __ T16B,
17567            as_FloatRegister($src$$reg), sh);
17568   %}
17569   ins_pipe(vshift128_imm);
17570 %}
17571 
17572 instruct vsrl8B_imm(vecD dst, vecD src, immI shift) %{
17573   predicate(n-&gt;as_Vector()-&gt;length() == 4 ||
17574             n-&gt;as_Vector()-&gt;length() == 8);
17575   match(Set dst (URShiftVB src (RShiftCntV shift)));
17576   ins_cost(INSN_COST);
17577   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8B)&quot; %}
17578   ins_encode %{
17579     int sh = (int)$shift$$constant;
17580     if (sh &gt;= 8) {
17581       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17582              as_FloatRegister($src$$reg),
17583              as_FloatRegister($src$$reg));
17584     } else {
17585       __ ushr(as_FloatRegister($dst$$reg), __ T8B,
17586              as_FloatRegister($src$$reg), sh);
17587     }
17588   %}
17589   ins_pipe(vshift64_imm);
17590 %}
17591 
17592 instruct vsrl16B_imm(vecX dst, vecX src, immI shift) %{
17593   predicate(n-&gt;as_Vector()-&gt;length() == 16);
17594   match(Set dst (URShiftVB src (RShiftCntV shift)));
17595   ins_cost(INSN_COST);
17596   format %{ &quot;ushr    $dst, $src, $shift\t# vector (16B)&quot; %}
17597   ins_encode %{
17598     int sh = (int)$shift$$constant;
17599     if (sh &gt;= 8) {
17600       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17601              as_FloatRegister($src$$reg),
17602              as_FloatRegister($src$$reg));
17603     } else {
17604       __ ushr(as_FloatRegister($dst$$reg), __ T16B,
17605              as_FloatRegister($src$$reg), sh);
17606     }
17607   %}
17608   ins_pipe(vshift128_imm);
17609 %}
17610 
17611 instruct vsll4S(vecD dst, vecD src, vecD shift) %{
17612   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17613             n-&gt;as_Vector()-&gt;length() == 4);
17614   match(Set dst (LShiftVS src shift));
17615   ins_cost(INSN_COST);
17616   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4H)&quot; %}
17617   ins_encode %{
17618     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17619             as_FloatRegister($src$$reg),
17620             as_FloatRegister($shift$$reg));
17621   %}
17622   ins_pipe(vshift64);
17623 %}
17624 
17625 instruct vsll8S(vecX dst, vecX src, vecX shift) %{
17626   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17627   match(Set dst (LShiftVS src shift));
17628   ins_cost(INSN_COST);
17629   format %{ &quot;sshl  $dst,$src,$shift\t# vector (8H)&quot; %}
17630   ins_encode %{
17631     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17632             as_FloatRegister($src$$reg),
17633             as_FloatRegister($shift$$reg));
17634   %}
17635   ins_pipe(vshift128);
17636 %}
17637 
17638 instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17639   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17640             n-&gt;as_Vector()-&gt;length() == 4);
17641   match(Set dst (RShiftVS src shift));
17642   ins_cost(INSN_COST);
17643   effect(TEMP tmp);
17644   format %{ &quot;negr  $tmp,$shift\t&quot;
17645             &quot;sshl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17646   ins_encode %{
17647     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17648             as_FloatRegister($shift$$reg));
17649     __ sshl(as_FloatRegister($dst$$reg), __ T4H,
17650             as_FloatRegister($src$$reg),
17651             as_FloatRegister($tmp$$reg));
17652   %}
17653   ins_pipe(vshift64);
17654 %}
17655 
17656 instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17657   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17658   match(Set dst (RShiftVS src shift));
17659   ins_cost(INSN_COST);
17660   effect(TEMP tmp);
17661   format %{ &quot;negr  $tmp,$shift\t&quot;
17662             &quot;sshl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17663   ins_encode %{
17664     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17665             as_FloatRegister($shift$$reg));
17666     __ sshl(as_FloatRegister($dst$$reg), __ T8H,
17667             as_FloatRegister($src$$reg),
17668             as_FloatRegister($tmp$$reg));
17669   %}
17670   ins_pipe(vshift128);
17671 %}
17672 
17673 instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{
17674   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17675             n-&gt;as_Vector()-&gt;length() == 4);
17676   match(Set dst (URShiftVS src shift));
17677   ins_cost(INSN_COST);
17678   effect(TEMP tmp);
17679   format %{ &quot;negr  $tmp,$shift\t&quot;
17680             &quot;ushl  $dst,$src,$tmp\t# vector (4H)&quot; %}
17681   ins_encode %{
17682     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17683             as_FloatRegister($shift$$reg));
17684     __ ushl(as_FloatRegister($dst$$reg), __ T4H,
17685             as_FloatRegister($src$$reg),
17686             as_FloatRegister($tmp$$reg));
17687   %}
17688   ins_pipe(vshift64);
17689 %}
17690 
17691 instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{
17692   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17693   match(Set dst (URShiftVS src shift));
17694   ins_cost(INSN_COST);
17695   effect(TEMP tmp);
17696   format %{ &quot;negr  $tmp,$shift\t&quot;
17697             &quot;ushl  $dst,$src,$tmp\t# vector (8H)&quot; %}
17698   ins_encode %{
17699     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17700             as_FloatRegister($shift$$reg));
17701     __ ushl(as_FloatRegister($dst$$reg), __ T8H,
17702             as_FloatRegister($src$$reg),
17703             as_FloatRegister($tmp$$reg));
17704   %}
17705   ins_pipe(vshift128);
17706 %}
17707 
17708 instruct vsll4S_imm(vecD dst, vecD src, immI shift) %{
17709   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17710             n-&gt;as_Vector()-&gt;length() == 4);
17711   match(Set dst (LShiftVS src (LShiftCntV shift)));
17712   ins_cost(INSN_COST);
17713   format %{ &quot;shl    $dst, $src, $shift\t# vector (4H)&quot; %}
17714   ins_encode %{
17715     int sh = (int)$shift$$constant;
17716     if (sh &gt;= 16) {
17717       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17718              as_FloatRegister($src$$reg),
17719              as_FloatRegister($src$$reg));
17720     } else {
17721       __ shl(as_FloatRegister($dst$$reg), __ T4H,
17722              as_FloatRegister($src$$reg), sh);
17723     }
17724   %}
17725   ins_pipe(vshift64_imm);
17726 %}
17727 
17728 instruct vsll8S_imm(vecX dst, vecX src, immI shift) %{
17729   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17730   match(Set dst (LShiftVS src (LShiftCntV shift)));
17731   ins_cost(INSN_COST);
17732   format %{ &quot;shl    $dst, $src, $shift\t# vector (8H)&quot; %}
17733   ins_encode %{
17734     int sh = (int)$shift$$constant;
17735     if (sh &gt;= 16) {
17736       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17737              as_FloatRegister($src$$reg),
17738              as_FloatRegister($src$$reg));
17739     } else {
17740       __ shl(as_FloatRegister($dst$$reg), __ T8H,
17741              as_FloatRegister($src$$reg), sh);
17742     }
17743   %}
17744   ins_pipe(vshift128_imm);
17745 %}
17746 
17747 instruct vsra4S_imm(vecD dst, vecD src, immI shift) %{
17748   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17749             n-&gt;as_Vector()-&gt;length() == 4);
17750   match(Set dst (RShiftVS src (RShiftCntV shift)));
17751   ins_cost(INSN_COST);
17752   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4H)&quot; %}
17753   ins_encode %{
17754     int sh = (int)$shift$$constant;
17755     if (sh &gt;= 16) sh = 15;
17756     __ sshr(as_FloatRegister($dst$$reg), __ T4H,
17757            as_FloatRegister($src$$reg), sh);
17758   %}
17759   ins_pipe(vshift64_imm);
17760 %}
17761 
17762 instruct vsra8S_imm(vecX dst, vecX src, immI shift) %{
17763   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17764   match(Set dst (RShiftVS src (RShiftCntV shift)));
17765   ins_cost(INSN_COST);
17766   format %{ &quot;sshr    $dst, $src, $shift\t# vector (8H)&quot; %}
17767   ins_encode %{
17768     int sh = (int)$shift$$constant;
17769     if (sh &gt;= 16) sh = 15;
17770     __ sshr(as_FloatRegister($dst$$reg), __ T8H,
17771            as_FloatRegister($src$$reg), sh);
17772   %}
17773   ins_pipe(vshift128_imm);
17774 %}
17775 
17776 instruct vsrl4S_imm(vecD dst, vecD src, immI shift) %{
17777   predicate(n-&gt;as_Vector()-&gt;length() == 2 ||
17778             n-&gt;as_Vector()-&gt;length() == 4);
17779   match(Set dst (URShiftVS src (RShiftCntV shift)));
17780   ins_cost(INSN_COST);
17781   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4H)&quot; %}
17782   ins_encode %{
17783     int sh = (int)$shift$$constant;
17784     if (sh &gt;= 16) {
17785       __ eor(as_FloatRegister($dst$$reg), __ T8B,
17786              as_FloatRegister($src$$reg),
17787              as_FloatRegister($src$$reg));
17788     } else {
17789       __ ushr(as_FloatRegister($dst$$reg), __ T4H,
17790              as_FloatRegister($src$$reg), sh);
17791     }
17792   %}
17793   ins_pipe(vshift64_imm);
17794 %}
17795 
17796 instruct vsrl8S_imm(vecX dst, vecX src, immI shift) %{
17797   predicate(n-&gt;as_Vector()-&gt;length() == 8);
17798   match(Set dst (URShiftVS src (RShiftCntV shift)));
17799   ins_cost(INSN_COST);
17800   format %{ &quot;ushr    $dst, $src, $shift\t# vector (8H)&quot; %}
17801   ins_encode %{
17802     int sh = (int)$shift$$constant;
17803     if (sh &gt;= 16) {
17804       __ eor(as_FloatRegister($dst$$reg), __ T16B,
17805              as_FloatRegister($src$$reg),
17806              as_FloatRegister($src$$reg));
17807     } else {
17808       __ ushr(as_FloatRegister($dst$$reg), __ T8H,
17809              as_FloatRegister($src$$reg), sh);
17810     }
17811   %}
17812   ins_pipe(vshift128_imm);
17813 %}
17814 
17815 instruct vsll2I(vecD dst, vecD src, vecD shift) %{
17816   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17817   match(Set dst (LShiftVI src shift));
17818   ins_cost(INSN_COST);
17819   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2S)&quot; %}
17820   ins_encode %{
17821     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17822             as_FloatRegister($src$$reg),
17823             as_FloatRegister($shift$$reg));
17824   %}
17825   ins_pipe(vshift64);
17826 %}
17827 
17828 instruct vsll4I(vecX dst, vecX src, vecX shift) %{
17829   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17830   match(Set dst (LShiftVI src shift));
17831   ins_cost(INSN_COST);
17832   format %{ &quot;sshl  $dst,$src,$shift\t# vector (4S)&quot; %}
17833   ins_encode %{
17834     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17835             as_FloatRegister($src$$reg),
17836             as_FloatRegister($shift$$reg));
17837   %}
17838   ins_pipe(vshift128);
17839 %}
17840 
17841 instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17842   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17843   match(Set dst (RShiftVI src shift));
17844   ins_cost(INSN_COST);
17845   effect(TEMP tmp);
17846   format %{ &quot;negr  $tmp,$shift\t&quot;
17847             &quot;sshl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17848   ins_encode %{
17849     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17850             as_FloatRegister($shift$$reg));
17851     __ sshl(as_FloatRegister($dst$$reg), __ T2S,
17852             as_FloatRegister($src$$reg),
17853             as_FloatRegister($tmp$$reg));
17854   %}
17855   ins_pipe(vshift64);
17856 %}
17857 
17858 instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17859   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17860   match(Set dst (RShiftVI src shift));
17861   ins_cost(INSN_COST);
17862   effect(TEMP tmp);
17863   format %{ &quot;negr  $tmp,$shift\t&quot;
17864             &quot;sshl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17865   ins_encode %{
17866     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17867             as_FloatRegister($shift$$reg));
17868     __ sshl(as_FloatRegister($dst$$reg), __ T4S,
17869             as_FloatRegister($src$$reg),
17870             as_FloatRegister($tmp$$reg));
17871   %}
17872   ins_pipe(vshift128);
17873 %}
17874 
17875 instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{
17876   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17877   match(Set dst (URShiftVI src shift));
17878   ins_cost(INSN_COST);
17879   effect(TEMP tmp);
17880   format %{ &quot;negr  $tmp,$shift\t&quot;
17881             &quot;ushl  $dst,$src,$tmp\t# vector (2S)&quot; %}
17882   ins_encode %{
17883     __ negr(as_FloatRegister($tmp$$reg), __ T8B,
17884             as_FloatRegister($shift$$reg));
17885     __ ushl(as_FloatRegister($dst$$reg), __ T2S,
17886             as_FloatRegister($src$$reg),
17887             as_FloatRegister($tmp$$reg));
17888   %}
17889   ins_pipe(vshift64);
17890 %}
17891 
17892 instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{
17893   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17894   match(Set dst (URShiftVI src shift));
17895   ins_cost(INSN_COST);
17896   effect(TEMP tmp);
17897   format %{ &quot;negr  $tmp,$shift\t&quot;
17898             &quot;ushl  $dst,$src,$tmp\t# vector (4S)&quot; %}
17899   ins_encode %{
17900     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
17901             as_FloatRegister($shift$$reg));
17902     __ ushl(as_FloatRegister($dst$$reg), __ T4S,
17903             as_FloatRegister($src$$reg),
17904             as_FloatRegister($tmp$$reg));
17905   %}
17906   ins_pipe(vshift128);
17907 %}
17908 
17909 instruct vsll2I_imm(vecD dst, vecD src, immI shift) %{
17910   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17911   match(Set dst (LShiftVI src (LShiftCntV shift)));
17912   ins_cost(INSN_COST);
17913   format %{ &quot;shl    $dst, $src, $shift\t# vector (2S)&quot; %}
17914   ins_encode %{
17915     __ shl(as_FloatRegister($dst$$reg), __ T2S,
17916            as_FloatRegister($src$$reg),
17917            (int)$shift$$constant);
17918   %}
17919   ins_pipe(vshift64_imm);
17920 %}
17921 
17922 instruct vsll4I_imm(vecX dst, vecX src, immI shift) %{
17923   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17924   match(Set dst (LShiftVI src (LShiftCntV shift)));
17925   ins_cost(INSN_COST);
17926   format %{ &quot;shl    $dst, $src, $shift\t# vector (4S)&quot; %}
17927   ins_encode %{
17928     __ shl(as_FloatRegister($dst$$reg), __ T4S,
17929            as_FloatRegister($src$$reg),
17930            (int)$shift$$constant);
17931   %}
17932   ins_pipe(vshift128_imm);
17933 %}
17934 
17935 instruct vsra2I_imm(vecD dst, vecD src, immI shift) %{
17936   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17937   match(Set dst (RShiftVI src (RShiftCntV shift)));
17938   ins_cost(INSN_COST);
17939   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2S)&quot; %}
17940   ins_encode %{
17941     __ sshr(as_FloatRegister($dst$$reg), __ T2S,
17942             as_FloatRegister($src$$reg),
17943             (int)$shift$$constant);
17944   %}
17945   ins_pipe(vshift64_imm);
17946 %}
17947 
17948 instruct vsra4I_imm(vecX dst, vecX src, immI shift) %{
17949   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17950   match(Set dst (RShiftVI src (RShiftCntV shift)));
17951   ins_cost(INSN_COST);
17952   format %{ &quot;sshr    $dst, $src, $shift\t# vector (4S)&quot; %}
17953   ins_encode %{
17954     __ sshr(as_FloatRegister($dst$$reg), __ T4S,
17955             as_FloatRegister($src$$reg),
17956             (int)$shift$$constant);
17957   %}
17958   ins_pipe(vshift128_imm);
17959 %}
17960 
17961 instruct vsrl2I_imm(vecD dst, vecD src, immI shift) %{
17962   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17963   match(Set dst (URShiftVI src (RShiftCntV shift)));
17964   ins_cost(INSN_COST);
17965   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2S)&quot; %}
17966   ins_encode %{
17967     __ ushr(as_FloatRegister($dst$$reg), __ T2S,
17968             as_FloatRegister($src$$reg),
17969             (int)$shift$$constant);
17970   %}
17971   ins_pipe(vshift64_imm);
17972 %}
17973 
17974 instruct vsrl4I_imm(vecX dst, vecX src, immI shift) %{
17975   predicate(n-&gt;as_Vector()-&gt;length() == 4);
17976   match(Set dst (URShiftVI src (RShiftCntV shift)));
17977   ins_cost(INSN_COST);
17978   format %{ &quot;ushr    $dst, $src, $shift\t# vector (4S)&quot; %}
17979   ins_encode %{
17980     __ ushr(as_FloatRegister($dst$$reg), __ T4S,
17981             as_FloatRegister($src$$reg),
17982             (int)$shift$$constant);
17983   %}
17984   ins_pipe(vshift128_imm);
17985 %}
17986 
17987 instruct vsll2L(vecX dst, vecX src, vecX shift) %{
17988   predicate(n-&gt;as_Vector()-&gt;length() == 2);
17989   match(Set dst (LShiftVL src shift));
17990   ins_cost(INSN_COST);
17991   format %{ &quot;sshl  $dst,$src,$shift\t# vector (2D)&quot; %}
17992   ins_encode %{
17993     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
17994             as_FloatRegister($src$$reg),
17995             as_FloatRegister($shift$$reg));
17996   %}
17997   ins_pipe(vshift128);
17998 %}
17999 
18000 instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18001   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18002   match(Set dst (RShiftVL src shift));
18003   ins_cost(INSN_COST);
18004   effect(TEMP tmp);
18005   format %{ &quot;negr  $tmp,$shift\t&quot;
18006             &quot;sshl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18007   ins_encode %{
18008     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18009             as_FloatRegister($shift$$reg));
18010     __ sshl(as_FloatRegister($dst$$reg), __ T2D,
18011             as_FloatRegister($src$$reg),
18012             as_FloatRegister($tmp$$reg));
18013   %}
18014   ins_pipe(vshift128);
18015 %}
18016 
18017 instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{
18018   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18019   match(Set dst (URShiftVL src shift));
18020   ins_cost(INSN_COST);
18021   effect(TEMP tmp);
18022   format %{ &quot;negr  $tmp,$shift\t&quot;
18023             &quot;ushl  $dst,$src,$tmp\t# vector (2D)&quot; %}
18024   ins_encode %{
18025     __ negr(as_FloatRegister($tmp$$reg), __ T16B,
18026             as_FloatRegister($shift$$reg));
18027     __ ushl(as_FloatRegister($dst$$reg), __ T2D,
18028             as_FloatRegister($src$$reg),
18029             as_FloatRegister($tmp$$reg));
18030   %}
18031   ins_pipe(vshift128);
18032 %}
18033 
18034 instruct vsll2L_imm(vecX dst, vecX src, immI shift) %{
18035   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18036   match(Set dst (LShiftVL src (LShiftCntV shift)));
18037   ins_cost(INSN_COST);
18038   format %{ &quot;shl    $dst, $src, $shift\t# vector (2D)&quot; %}
18039   ins_encode %{
18040     __ shl(as_FloatRegister($dst$$reg), __ T2D,
18041            as_FloatRegister($src$$reg),
18042            (int)$shift$$constant);
18043   %}
18044   ins_pipe(vshift128_imm);
18045 %}
18046 
18047 instruct vsra2L_imm(vecX dst, vecX src, immI shift) %{
18048   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18049   match(Set dst (RShiftVL src (RShiftCntV shift)));
18050   ins_cost(INSN_COST);
18051   format %{ &quot;sshr    $dst, $src, $shift\t# vector (2D)&quot; %}
18052   ins_encode %{
18053     __ sshr(as_FloatRegister($dst$$reg), __ T2D,
18054             as_FloatRegister($src$$reg),
18055             (int)$shift$$constant);
18056   %}
18057   ins_pipe(vshift128_imm);
18058 %}
18059 
18060 instruct vsrl2L_imm(vecX dst, vecX src, immI shift) %{
18061   predicate(n-&gt;as_Vector()-&gt;length() == 2);
18062   match(Set dst (URShiftVL src (RShiftCntV shift)));
18063   ins_cost(INSN_COST);
18064   format %{ &quot;ushr    $dst, $src, $shift\t# vector (2D)&quot; %}
18065   ins_encode %{
18066     __ ushr(as_FloatRegister($dst$$reg), __ T2D,
18067             as_FloatRegister($src$$reg),
18068             (int)$shift$$constant);
18069   %}
18070   ins_pipe(vshift128_imm);
18071 %}
18072 
18073 instruct vmax2F(vecD dst, vecD src1, vecD src2)
18074 %{
18075   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18076   match(Set dst (MaxV src1 src2));
18077   ins_cost(INSN_COST);
18078   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2F)&quot; %}
18079   ins_encode %{
18080     __ fmax(as_FloatRegister($dst$$reg), __ T2S,
18081             as_FloatRegister($src1$$reg),
18082             as_FloatRegister($src2$$reg));
18083   %}
18084   ins_pipe(vdop_fp64);
18085 %}
18086 
18087 instruct vmax4F(vecX dst, vecX src1, vecX src2)
18088 %{
18089   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18090   match(Set dst (MaxV src1 src2));
18091   ins_cost(INSN_COST);
18092   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (4S)&quot; %}
18093   ins_encode %{
18094     __ fmax(as_FloatRegister($dst$$reg), __ T4S,
18095             as_FloatRegister($src1$$reg),
18096             as_FloatRegister($src2$$reg));
18097   %}
18098   ins_pipe(vdop_fp128);
18099 %}
18100 
18101 instruct vmax2D(vecX dst, vecX src1, vecX src2)
18102 %{
18103   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18104   match(Set dst (MaxV src1 src2));
18105   ins_cost(INSN_COST);
18106   format %{ &quot;fmax  $dst,$src1,$src2\t# vector (2D)&quot; %}
18107   ins_encode %{
18108     __ fmax(as_FloatRegister($dst$$reg), __ T2D,
18109             as_FloatRegister($src1$$reg),
18110             as_FloatRegister($src2$$reg));
18111   %}
18112   ins_pipe(vdop_fp128);
18113 %}
18114 
18115 instruct vmin2F(vecD dst, vecD src1, vecD src2)
18116 %{
18117   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18118   match(Set dst (MinV src1 src2));
18119   ins_cost(INSN_COST);
18120   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2F)&quot; %}
18121   ins_encode %{
18122     __ fmin(as_FloatRegister($dst$$reg), __ T2S,
18123             as_FloatRegister($src1$$reg),
18124             as_FloatRegister($src2$$reg));
18125   %}
18126   ins_pipe(vdop_fp64);
18127 %}
18128 
18129 instruct vmin4F(vecX dst, vecX src1, vecX src2)
18130 %{
18131   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_FLOAT);
18132   match(Set dst (MinV src1 src2));
18133   ins_cost(INSN_COST);
18134   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (4S)&quot; %}
18135   ins_encode %{
18136     __ fmin(as_FloatRegister($dst$$reg), __ T4S,
18137             as_FloatRegister($src1$$reg),
18138             as_FloatRegister($src2$$reg));
18139   %}
18140   ins_pipe(vdop_fp128);
18141 %}
18142 
18143 instruct vmin2D(vecX dst, vecX src1, vecX src2)
18144 %{
18145   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18146   match(Set dst (MinV src1 src2));
18147   ins_cost(INSN_COST);
18148   format %{ &quot;fmin  $dst,$src1,$src2\t# vector (2D)&quot; %}
18149   ins_encode %{
18150     __ fmin(as_FloatRegister($dst$$reg), __ T2D,
18151             as_FloatRegister($src1$$reg),
18152             as_FloatRegister($src2$$reg));
18153   %}
18154   ins_pipe(vdop_fp128);
18155 %}
18156 
18157 instruct vround2D_reg(vecX dst, vecX src, immI rmode) %{
18158   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; n-&gt;bottom_type()-&gt;is_vect()-&gt;element_basic_type() == T_DOUBLE);
18159   match(Set dst (RoundDoubleModeV src rmode));
18160   format %{ &quot;frint  $dst, $src, $rmode&quot; %}
18161   ins_encode %{
18162     switch ($rmode$$constant) {
18163       case RoundDoubleModeNode::rmode_rint:
18164         __ frintn(as_FloatRegister($dst$$reg), __ T2D,
18165                   as_FloatRegister($src$$reg));
18166         break;
18167       case RoundDoubleModeNode::rmode_floor:
18168         __ frintm(as_FloatRegister($dst$$reg), __ T2D,
18169                   as_FloatRegister($src$$reg));
18170         break;
18171       case RoundDoubleModeNode::rmode_ceil:
18172         __ frintp(as_FloatRegister($dst$$reg), __ T2D,
18173                   as_FloatRegister($src$$reg));
18174         break;
18175     }
18176   %}
18177   ins_pipe(vdop_fp128);
18178 %}
18179 
18180 instruct vpopcount4I(vecX dst, vecX src) %{
18181   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 4);
18182   match(Set dst (PopCountVI src));
18183   format %{
18184     &quot;cnt     $dst, $src\t# vector (16B)\n\t&quot;
18185     &quot;uaddlp  $dst, $dst\t# vector (16B)\n\t&quot;
18186     &quot;uaddlp  $dst, $dst\t# vector (8H)&quot;
18187   %}
18188   ins_encode %{
18189      __ cnt(as_FloatRegister($dst$$reg), __ T16B,
18190             as_FloatRegister($src$$reg));
18191      __ uaddlp(as_FloatRegister($dst$$reg), __ T16B,
18192                as_FloatRegister($dst$$reg));
18193      __ uaddlp(as_FloatRegister($dst$$reg), __ T8H,
18194                as_FloatRegister($dst$$reg));
18195   %}
18196   ins_pipe(pipe_class_default);
18197 %}
18198 
18199 instruct vpopcount2I(vecD dst, vecD src) %{
18200   predicate(UsePopCountInstruction &amp;&amp; n-&gt;as_Vector()-&gt;length() == 2);
18201   match(Set dst (PopCountVI src));
18202   format %{
18203     &quot;cnt     $dst, $src\t# vector (8B)\n\t&quot;
18204     &quot;uaddlp  $dst, $dst\t# vector (8B)\n\t&quot;
18205     &quot;uaddlp  $dst, $dst\t# vector (4H)&quot;
18206   %}
18207   ins_encode %{
18208      __ cnt(as_FloatRegister($dst$$reg), __ T8B,
18209             as_FloatRegister($src$$reg));
18210      __ uaddlp(as_FloatRegister($dst$$reg), __ T8B,
18211                as_FloatRegister($dst$$reg));
18212      __ uaddlp(as_FloatRegister($dst$$reg), __ T4H,
18213                as_FloatRegister($dst$$reg));
18214   %}
18215   ins_pipe(pipe_class_default);
18216 %}
18217 
18218 //----------PEEPHOLE RULES-----------------------------------------------------
18219 // These must follow all instruction definitions as they use the names
18220 // defined in the instructions definitions.
18221 //
18222 // peepmatch ( root_instr_name [preceding_instruction]* );
18223 //
18224 // peepconstraint %{
18225 // (instruction_number.operand_name relational_op instruction_number.operand_name
18226 //  [, ...] );
18227 // // instruction numbers are zero-based using left to right order in peepmatch
18228 //
18229 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
18230 // // provide an instruction_number.operand_name for each operand that appears
18231 // // in the replacement instruction&#39;s match rule
18232 //
18233 // ---------VM FLAGS---------------------------------------------------------
18234 //
18235 // All peephole optimizations can be turned off using -XX:-OptoPeephole
18236 //
18237 // Each peephole rule is given an identifying number starting with zero and
18238 // increasing by one in the order seen by the parser.  An individual peephole
18239 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
18240 // on the command-line.
18241 //
18242 // ---------CURRENT LIMITATIONS----------------------------------------------
18243 //
18244 // Only match adjacent instructions in same basic block
18245 // Only equality constraints
18246 // Only constraints between operands, not (0.dest_reg == RAX_enc)
18247 // Only one replacement instruction
18248 //
18249 // ---------EXAMPLE----------------------------------------------------------
18250 //
18251 // // pertinent parts of existing instructions in architecture description
18252 // instruct movI(iRegINoSp dst, iRegI src)
18253 // %{
18254 //   match(Set dst (CopyI src));
18255 // %}
18256 //
18257 // instruct incI_iReg(iRegINoSp dst, immI1 src, rFlagsReg cr)
18258 // %{
18259 //   match(Set dst (AddI dst src));
18260 //   effect(KILL cr);
18261 // %}
18262 //
18263 // // Change (inc mov) to lea
18264 // peephole %{
18265 //   // increment preceeded by register-register move
18266 //   peepmatch ( incI_iReg movI );
18267 //   // require that the destination register of the increment
18268 //   // match the destination register of the move
18269 //   peepconstraint ( 0.dst == 1.dst );
18270 //   // construct a replacement instruction that sets
18271 //   // the destination to ( move&#39;s source register + one )
18272 //   peepreplace ( leaI_iReg_immI( 0.dst 1.src 0.src ) );
18273 // %}
18274 //
18275 
18276 // Implementation no longer uses movX instructions since
18277 // machine-independent system no longer uses CopyX nodes.
18278 //
18279 // peephole
18280 // %{
18281 //   peepmatch (incI_iReg movI);
18282 //   peepconstraint (0.dst == 1.dst);
18283 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18284 // %}
18285 
18286 // peephole
18287 // %{
18288 //   peepmatch (decI_iReg movI);
18289 //   peepconstraint (0.dst == 1.dst);
18290 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18291 // %}
18292 
18293 // peephole
18294 // %{
18295 //   peepmatch (addI_iReg_imm movI);
18296 //   peepconstraint (0.dst == 1.dst);
18297 //   peepreplace (leaI_iReg_immI(0.dst 1.src 0.src));
18298 // %}
18299 
18300 // peephole
18301 // %{
18302 //   peepmatch (incL_iReg movL);
18303 //   peepconstraint (0.dst == 1.dst);
18304 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18305 // %}
18306 
18307 // peephole
18308 // %{
18309 //   peepmatch (decL_iReg movL);
18310 //   peepconstraint (0.dst == 1.dst);
18311 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18312 // %}
18313 
18314 // peephole
18315 // %{
18316 //   peepmatch (addL_iReg_imm movL);
18317 //   peepconstraint (0.dst == 1.dst);
18318 //   peepreplace (leaL_iReg_immL(0.dst 1.src 0.src));
18319 // %}
18320 
18321 // peephole
18322 // %{
18323 //   peepmatch (addP_iReg_imm movP);
18324 //   peepconstraint (0.dst == 1.dst);
18325 //   peepreplace (leaP_iReg_imm(0.dst 1.src 0.src));
18326 // %}
18327 
18328 // // Change load of spilled value to only a spill
18329 // instruct storeI(memory mem, iRegI src)
18330 // %{
18331 //   match(Set mem (StoreI mem src));
18332 // %}
18333 //
18334 // instruct loadI(iRegINoSp dst, memory mem)
18335 // %{
18336 //   match(Set dst (LoadI mem));
18337 // %}
18338 //
18339 
18340 //----------SMARTSPILL RULES---------------------------------------------------
18341 // These must follow all instruction definitions as they use the names
18342 // defined in the instructions definitions.
18343 
18344 // Local Variables:
18345 // mode: c++
18346 // End:
    </pre>
  </body>
</html>