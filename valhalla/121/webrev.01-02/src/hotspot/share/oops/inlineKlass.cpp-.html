<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/oops/inlineKlass.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2017, 2020, Oracle and/or its affiliates. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/shared/barrierSet.hpp&quot;
 27 #include &quot;gc/shared/collectedHeap.inline.hpp&quot;
 28 #include &quot;gc/shared/gcLocker.inline.hpp&quot;
 29 #include &quot;interpreter/interpreter.hpp&quot;
 30 #include &quot;logging/log.hpp&quot;
 31 #include &quot;memory/metaspaceClosure.hpp&quot;
 32 #include &quot;memory/metadataFactory.hpp&quot;
 33 #include &quot;oops/access.hpp&quot;
 34 #include &quot;oops/compressedOops.inline.hpp&quot;
 35 #include &quot;oops/fieldStreams.inline.hpp&quot;
 36 #include &quot;oops/flatArrayKlass.hpp&quot;
 37 #include &quot;oops/inlineKlass.inline.hpp&quot;
 38 #include &quot;oops/instanceKlass.inline.hpp&quot;
 39 #include &quot;oops/method.hpp&quot;
 40 #include &quot;oops/oop.inline.hpp&quot;
 41 #include &quot;oops/objArrayKlass.hpp&quot;
 42 #include &quot;runtime/fieldDescriptor.inline.hpp&quot;
 43 #include &quot;runtime/handles.inline.hpp&quot;
 44 #include &quot;runtime/safepointVerifiers.hpp&quot;
 45 #include &quot;runtime/sharedRuntime.hpp&quot;
 46 #include &quot;runtime/signature.hpp&quot;
 47 #include &quot;runtime/thread.inline.hpp&quot;
 48 #include &quot;utilities/copy.hpp&quot;
 49 
 50   // Constructor
 51 InlineKlass::InlineKlass(const ClassFileParser&amp; parser)
 52     : InstanceKlass(parser, InstanceKlass::_kind_inline_type, InstanceKlass::ID) {
 53   _adr_inlineklass_fixed_block = inlineklass_static_block();
 54   // Addresses used for inline type calling convention
 55   *((Array&lt;SigEntry&gt;**)adr_extended_sig()) = NULL;
 56   *((Array&lt;VMRegPair&gt;**)adr_return_regs()) = NULL;
 57   *((address*)adr_pack_handler()) = NULL;
 58   *((address*)adr_pack_handler_jobject()) = NULL;
 59   *((address*)adr_unpack_handler()) = NULL;
 60   assert(pack_handler() == NULL, &quot;pack handler not null&quot;);
 61   *((int*)adr_default_value_offset()) = 0;
 62   *((Klass**)adr_flat_array_klass()) = NULL;
 63   set_prototype_header(markWord::always_locked_prototype());
 64   assert(is_inline_type_klass(), &quot;invariant&quot;);
 65 }
 66 
 67 oop InlineKlass::default_value() {
 68   oop val = java_mirror()-&gt;obj_field_acquire(default_value_offset());
 69   assert(oopDesc::is_oop(val), &quot;Sanity check&quot;);
 70   assert(val-&gt;is_inline_type(), &quot;Sanity check&quot;);
 71   assert(val-&gt;klass() == this, &quot;sanity check&quot;);
 72   return val;
 73 }
 74 
 75 int InlineKlass::first_field_offset_old() {
 76 #ifdef ASSERT
 77   int first_offset = INT_MAX;
 78   for (AllFieldStream fs(this); !fs.done(); fs.next()) {
 79     if (fs.offset() &lt; first_offset) first_offset= fs.offset();
 80   }
 81 #endif
 82   int base_offset = instanceOopDesc::base_offset_in_bytes();
 83   // The first field of line types is aligned on a long boundary
 84   base_offset = align_up(base_offset, BytesPerLong);
 85   assert(base_offset == first_offset, &quot;inconsistent offsets&quot;);
 86   return base_offset;
 87 }
 88 
 89 int InlineKlass::raw_value_byte_size() {
 90   int heapOopAlignedSize = nonstatic_field_size() &lt;&lt; LogBytesPerHeapOop;
 91   // If bigger than 64 bits or needs oop alignment, then use jlong aligned
 92   // which for values should be jlong aligned, asserts in raw_field_copy otherwise
 93   if (heapOopAlignedSize &gt;= longSize || contains_oops()) {
 94     return heapOopAlignedSize;
 95   }
 96   // Small primitives...
 97   // If a few small basic type fields, return the actual size, i.e.
 98   // 1 byte = 1
 99   // 2 byte = 2
100   // 3 byte = 4, because pow2 needed for element stores
101   int first_offset = first_field_offset();
102   int last_offset  = 0; // find the last offset, add basic type size
103   int last_tsz     = 0;
104   for (AllFieldStream fs(this); !fs.done(); fs.next()) {
105     if (fs.access_flags().is_static()) {
106       continue;
107     } else if (fs.offset() &gt; last_offset) {
108       BasicType type = Signature::basic_type(fs.signature());
109       if (is_java_primitive(type)) {
110         last_tsz = type2aelembytes(type);
111       } else if (type == T_INLINE_TYPE) {
112         // Not just primitives. Layout aligns embedded value, so use jlong aligned it is
113         return heapOopAlignedSize;
114       } else {
115         guarantee(0, &quot;Unknown type %d&quot;, type);
116       }
117       assert(last_tsz != 0, &quot;Invariant&quot;);
118       last_offset = fs.offset();
119     }
120   }
121   // Assumes VT with no fields are meaningless and illegal
122   last_offset += last_tsz;
123   assert(last_offset &gt; first_offset &amp;&amp; last_tsz, &quot;Invariant&quot;);
124   return 1 &lt;&lt; upper_log2(last_offset - first_offset);
125 }
126 
127 instanceOop InlineKlass::allocate_instance(TRAPS) {
128   int size = size_helper();  // Query before forming handle.
129 
130   instanceOop oop = (instanceOop)Universe::heap()-&gt;obj_allocate(this, size, CHECK_NULL);
131   assert(oop-&gt;mark().is_always_locked(), &quot;Unlocked inline type&quot;);
132   return oop;
133 }
134 
135 instanceOop InlineKlass::allocate_instance_buffer(TRAPS) {
136   int size = size_helper();  // Query before forming handle.
137 
138   instanceOop oop = (instanceOop)Universe::heap()-&gt;obj_buffer_allocate(this, size, CHECK_NULL);
139   assert(oop-&gt;mark().is_always_locked(), &quot;Unlocked inline type&quot;);
140   return oop;
141 }
142 
143 int InlineKlass::nonstatic_oop_count() {
144   int oops = 0;
145   int map_count = nonstatic_oop_map_count();
146   OopMapBlock* block = start_of_nonstatic_oop_maps();
147   OopMapBlock* end = block + map_count;
148   while (block != end) {
149     oops += block-&gt;count();
150     block++;
151   }
152   return oops;
153 }
154 
155 oop InlineKlass::read_inlined_field(oop obj, int offset, TRAPS) {
156   oop res = NULL;
157   this-&gt;initialize(CHECK_NULL); // will throw an exception if in error state
158   if (is_empty_inline_type()) {
159     res = (instanceOop)default_value();
160   } else {
161     Handle obj_h(THREAD, obj);
162     res = allocate_instance_buffer(CHECK_NULL);
163     inline_copy_payload_to_new_oop(((char*)(oopDesc*)obj_h()) + offset, res);
164   }
165   assert(res != NULL, &quot;Must be set in one of two paths above&quot;);
166   return res;
167 }
168 
169 void InlineKlass::write_inlined_field(oop obj, int offset, oop value, TRAPS) {
170   if (value == NULL) {
171     THROW(vmSymbols::java_lang_NullPointerException());
172   }
173   if (!is_empty_inline_type()) {
174     inline_copy_oop_to_payload(value, ((char*)(oopDesc*)obj) + offset);
175   }
176 }
177 
178 // Arrays of...
179 
180 bool InlineKlass::flatten_array() {
181   if (!UseFlatArray) {
182     return false;
183   }
184   // Too big
185   int elem_bytes = raw_value_byte_size();
186   if ((FlatArrayElementMaxSize &gt;= 0) &amp;&amp; (elem_bytes &gt; FlatArrayElementMaxSize)) {
187     return false;
188   }
189   // Too many embedded oops
190   if ((FlatArrayElementMaxOops &gt;= 0) &amp;&amp; (nonstatic_oop_count() &gt; FlatArrayElementMaxOops)) {
191     return false;
192   }
193   // Declared atomic but not naturally atomic.
194   if (is_declared_atomic() &amp;&amp; !is_naturally_atomic()) {
195     return false;
196   }
197   // VM enforcing InlineArrayAtomicAccess only...
198   if (InlineArrayAtomicAccess &amp;&amp; (!is_naturally_atomic())) {
199     return false;
200   }
201   return true;
202 }
203 
204 void InlineKlass::remove_unshareable_info() {
205   InstanceKlass::remove_unshareable_info();
206 
207   *((Array&lt;SigEntry&gt;**)adr_extended_sig()) = NULL;
208   *((Array&lt;VMRegPair&gt;**)adr_return_regs()) = NULL;
209   *((address*)adr_pack_handler()) = NULL;
210   *((address*)adr_pack_handler_jobject()) = NULL;
211   *((address*)adr_unpack_handler()) = NULL;
212   assert(pack_handler() == NULL, &quot;pack handler not null&quot;);
213   *((Klass**)adr_flat_array_klass()) = NULL;
214 }
215 
216 void InlineKlass::restore_unshareable_info(ClassLoaderData* loader_data, Handle protection_domain, PackageEntry* pkg_entry, TRAPS) {
217   InstanceKlass::restore_unshareable_info(loader_data, protection_domain, pkg_entry, CHECK);
218 }
219 
220 
221 Klass* InlineKlass::array_klass_impl(bool or_null, int n, TRAPS) {
222   if (flatten_array()) {
223     return flat_array_klass(or_null, n, THREAD);
224   } else {
225     return InstanceKlass::array_klass_impl(or_null, n, THREAD);
226   }
227 }
228 
229 Klass* InlineKlass::array_klass_impl(bool or_null, TRAPS) {
230   return array_klass_impl(or_null, 1, THREAD);
231 }
232 
233 Klass* InlineKlass::flat_array_klass(bool or_null, int rank, TRAPS) {
234   Klass* vak = acquire_flat_array_klass();
235   if (vak == NULL) {
236     if (or_null) return NULL;
237     ResourceMark rm;
238     {
239       // Atomic creation of array_klasses
240       MutexLocker ma(THREAD, MultiArray_lock);
241       if (get_flat_array_klass() == NULL) {
242         vak = allocate_flat_array_klass(CHECK_NULL);
243         Atomic::release_store((Klass**)adr_flat_array_klass(), vak);
244       }
245     }
246   }
247   if (or_null) {
248     return vak-&gt;array_klass_or_null(rank);
249   }
250   return vak-&gt;array_klass(rank, THREAD);
251 }
252 
253 Klass* InlineKlass::allocate_flat_array_klass(TRAPS) {
254   if (flatten_array()) {
255     return FlatArrayKlass::allocate_klass(this, THREAD);
256   }
257   return ObjArrayKlass::allocate_objArray_klass(class_loader_data(), 1, this, THREAD);
258 }
259 
260 void InlineKlass::array_klasses_do(void f(Klass* k, TRAPS), TRAPS) {
261   InstanceKlass::array_klasses_do(f, THREAD);
262   if (get_flat_array_klass() != NULL)
263     ArrayKlass::cast(get_flat_array_klass())-&gt;array_klasses_do(f, THREAD);
264 }
265 
266 void InlineKlass::array_klasses_do(void f(Klass* k)) {
267   InstanceKlass::array_klasses_do(f);
268   if (get_flat_array_klass() != NULL)
269     ArrayKlass::cast(get_flat_array_klass())-&gt;array_klasses_do(f);
270 }
271 
272 // Inline type arguments are not passed by reference, instead each
273 // field of the inline type is passed as an argument. This helper
274 // function collects the inlined field (recursively)
275 // in a list. Included with the field&#39;s type is
276 // the offset of each field in the inline type: i2c and c2i adapters
277 // need that to load or store fields. Finally, the list of fields is
278 // sorted in order of increasing offsets: the adapters and the
279 // compiled code need to agree upon the order of fields.
280 //
281 // The list of basic types that is returned starts with a T_INLINE_TYPE
282 // and ends with an extra T_VOID. T_INLINE_TYPE/T_VOID pairs are used as
283 // delimiters. Every entry between the two is a field of the inline
284 // type. If there&#39;s an embedded inline type in the list, it also starts
285 // with a T_INLINE_TYPE and ends with a T_VOID. This is so we can
286 // generate a unique fingerprint for the method&#39;s adapters and we can
287 // generate the list of basic types from the interpreter point of view
288 // (inline types passed as reference: iterate on the list until a
289 // T_INLINE_TYPE, drop everything until and including the closing
290 // T_VOID) or the compiler point of view (each field of the inline
291 // types is an argument: drop all T_INLINE_TYPE/T_VOID from the list).
292 int InlineKlass::collect_fields(GrowableArray&lt;SigEntry&gt;* sig, int base_off) {
293   int count = 0;
294   SigEntry::add_entry(sig, T_INLINE_TYPE, base_off);
295   for (AllFieldStream fs(this); !fs.done(); fs.next()) {
296     if (fs.access_flags().is_static()) continue;
297     int offset = base_off + fs.offset() - (base_off &gt; 0 ? first_field_offset() : 0);
298     if (fs.is_inlined()) {
299       // Resolve klass of inlined field and recursively collect fields
300       Klass* vk = get_inline_type_field_klass(fs.index());
301       count += InlineKlass::cast(vk)-&gt;collect_fields(sig, offset);
302     } else {
303       BasicType bt = Signature::basic_type(fs.signature());
304       if (bt == T_INLINE_TYPE) {
305         bt = T_OBJECT;
306       }
307       SigEntry::add_entry(sig, bt, offset);
308       count += type2size[bt];
309     }
310   }
311   int offset = base_off + size_helper()*HeapWordSize - (base_off &gt; 0 ? first_field_offset() : 0);
312   SigEntry::add_entry(sig, T_VOID, offset);
313   if (base_off == 0) {
314     sig-&gt;sort(SigEntry::compare);
315   }
316   assert(sig-&gt;at(0)._bt == T_INLINE_TYPE &amp;&amp; sig-&gt;at(sig-&gt;length()-1)._bt == T_VOID, &quot;broken structure&quot;);
317   return count;
318 }
319 
320 void InlineKlass::initialize_calling_convention(TRAPS) {
321   // Because the pack and unpack handler addresses need to be loadable from generated code,
322   // they are stored at a fixed offset in the klass metadata. Since inline type klasses do
323   // not have a vtable, the vtable offset is used to store these addresses.
324   if (InlineTypeReturnedAsFields || InlineTypePassFieldsAsArgs) {
325     ResourceMark rm;
326     GrowableArray&lt;SigEntry&gt; sig_vk;
327     int nb_fields = collect_fields(&amp;sig_vk);
328     Array&lt;SigEntry&gt;* extended_sig = MetadataFactory::new_array&lt;SigEntry&gt;(class_loader_data(), sig_vk.length(), CHECK);
329     *((Array&lt;SigEntry&gt;**)adr_extended_sig()) = extended_sig;
330     for (int i = 0; i &lt; sig_vk.length(); i++) {
331       extended_sig-&gt;at_put(i, sig_vk.at(i));
332     }
333     if (can_be_returned_as_fields(/* init= */ true)) {
334       nb_fields++;
335       BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, nb_fields);
336       sig_bt[0] = T_METADATA;
337       SigEntry::fill_sig_bt(&amp;sig_vk, sig_bt+1);
338       VMRegPair* regs = NEW_RESOURCE_ARRAY(VMRegPair, nb_fields);
339       int total = SharedRuntime::java_return_convention(sig_bt, regs, nb_fields);
340 
341       if (total &gt; 0) {
342         Array&lt;VMRegPair&gt;* return_regs = MetadataFactory::new_array&lt;VMRegPair&gt;(class_loader_data(), nb_fields, CHECK);
343         *((Array&lt;VMRegPair&gt;**)adr_return_regs()) = return_regs;
344         for (int i = 0; i &lt; nb_fields; i++) {
345           return_regs-&gt;at_put(i, regs[i]);
346         }
347 
348         BufferedInlineTypeBlob* buffered_blob = SharedRuntime::generate_buffered_inline_type_adapter(this);
349         *((address*)adr_pack_handler()) = buffered_blob-&gt;pack_fields();
350         *((address*)adr_pack_handler_jobject()) = buffered_blob-&gt;pack_fields_jobject();
351         *((address*)adr_unpack_handler()) = buffered_blob-&gt;unpack_fields();
352         assert(CodeCache::find_blob(pack_handler()) == buffered_blob, &quot;lost track of blob&quot;);
353         assert(can_be_returned_as_fields(), &quot;sanity&quot;);
354       }
355     }
356     if (!can_be_returned_as_fields() &amp;&amp; !can_be_passed_as_fields()) {
357       MetadataFactory::free_array&lt;SigEntry&gt;(class_loader_data(), extended_sig);
358       assert(return_regs() == NULL, &quot;sanity&quot;);
359     }
360   }
361 }
362 
363 void InlineKlass::deallocate_contents(ClassLoaderData* loader_data) {
364   if (extended_sig() != NULL) {
365     MetadataFactory::free_array&lt;SigEntry&gt;(loader_data, extended_sig());
366   }
367   if (return_regs() != NULL) {
368     MetadataFactory::free_array&lt;VMRegPair&gt;(loader_data, return_regs());
369   }
370   cleanup_blobs();
371   InstanceKlass::deallocate_contents(loader_data);
372 }
373 
374 void InlineKlass::cleanup(InlineKlass* ik) {
375   ik-&gt;cleanup_blobs();
376 }
377 
378 void InlineKlass::cleanup_blobs() {
379   if (pack_handler() != NULL) {
380     CodeBlob* buffered_blob = CodeCache::find_blob(pack_handler());
381     assert(buffered_blob-&gt;is_buffered_inline_type_blob(), &quot;bad blob type&quot;);
382     BufferBlob::free((BufferBlob*)buffered_blob);
383     *((address*)adr_pack_handler()) = NULL;
384     *((address*)adr_pack_handler_jobject()) = NULL;
385     *((address*)adr_unpack_handler()) = NULL;
386   }
387 }
388 
389 // Can this inline type be scalarized?
390 bool InlineKlass::is_scalarizable() const {
391   return ScalarizeInlineTypes;
392 }
393 
394 // Can this inline type be passed as multiple values?
395 bool InlineKlass::can_be_passed_as_fields() const {
396   return InlineTypePassFieldsAsArgs &amp;&amp; is_scalarizable() &amp;&amp; !is_empty_inline_type();
397 }
398 
399 // Can this inline type be returned as multiple values?
400 bool InlineKlass::can_be_returned_as_fields(bool init) const {
401   return InlineTypeReturnedAsFields &amp;&amp; is_scalarizable() &amp;&amp; !is_empty_inline_type() &amp;&amp; (init || return_regs() != NULL);
402 }
403 
404 // Create handles for all oop fields returned in registers that are going to be live across a safepoint
405 void InlineKlass::save_oop_fields(const RegisterMap&amp; reg_map, GrowableArray&lt;Handle&gt;&amp; handles) const {
406   Thread* thread = Thread::current();
407   const Array&lt;SigEntry&gt;* sig_vk = extended_sig();
408   const Array&lt;VMRegPair&gt;* regs = return_regs();
409   int j = 1;
410 
411   for (int i = 0; i &lt; sig_vk-&gt;length(); i++) {
412     BasicType bt = sig_vk-&gt;at(i)._bt;
413     if (bt == T_OBJECT || bt == T_ARRAY) {
414       VMRegPair pair = regs-&gt;at(j);
415       address loc = reg_map.location(pair.first());
416       oop v = *(oop*)loc;
417       assert(v == NULL || oopDesc::is_oop(v), &quot;not an oop?&quot;);
418       assert(Universe::heap()-&gt;is_in_or_null(v), &quot;must be heap pointer&quot;);
419       handles.push(Handle(thread, v));
420     }
421     if (bt == T_INLINE_TYPE) {
422       continue;
423     }
424     if (bt == T_VOID &amp;&amp;
425         sig_vk-&gt;at(i-1)._bt != T_LONG &amp;&amp;
426         sig_vk-&gt;at(i-1)._bt != T_DOUBLE) {
427       continue;
428     }
429     j++;
430   }
431   assert(j == regs-&gt;length(), &quot;missed a field?&quot;);
432 }
433 
434 // Update oop fields in registers from handles after a safepoint
435 void InlineKlass::restore_oop_results(RegisterMap&amp; reg_map, GrowableArray&lt;Handle&gt;&amp; handles) const {
436   assert(InlineTypeReturnedAsFields, &quot;inconsistent&quot;);
437   const Array&lt;SigEntry&gt;* sig_vk = extended_sig();
438   const Array&lt;VMRegPair&gt;* regs = return_regs();
439   assert(regs != NULL, &quot;inconsistent&quot;);
440 
441   int j = 1;
442   for (int i = 0, k = 0; i &lt; sig_vk-&gt;length(); i++) {
443     BasicType bt = sig_vk-&gt;at(i)._bt;
444     if (bt == T_OBJECT || bt == T_ARRAY) {
445       VMRegPair pair = regs-&gt;at(j);
446       address loc = reg_map.location(pair.first());
447       *(oop*)loc = handles.at(k++)();
448     }
449     if (bt == T_INLINE_TYPE) {
450       continue;
451     }
452     if (bt == T_VOID &amp;&amp;
453         sig_vk-&gt;at(i-1)._bt != T_LONG &amp;&amp;
454         sig_vk-&gt;at(i-1)._bt != T_DOUBLE) {
455       continue;
456     }
457     j++;
458   }
459   assert(j == regs-&gt;length(), &quot;missed a field?&quot;);
460 }
461 
462 // Fields are in registers. Create an instance of the inline type and
463 // initialize it with the values of the fields.
464 oop InlineKlass::realloc_result(const RegisterMap&amp; reg_map, const GrowableArray&lt;Handle&gt;&amp; handles, TRAPS) {
465   oop new_vt = allocate_instance(CHECK_NULL);
466   const Array&lt;SigEntry&gt;* sig_vk = extended_sig();
467   const Array&lt;VMRegPair&gt;* regs = return_regs();
468 
469   int j = 1;
470   int k = 0;
471   for (int i = 0; i &lt; sig_vk-&gt;length(); i++) {
472     BasicType bt = sig_vk-&gt;at(i)._bt;
473     if (bt == T_INLINE_TYPE) {
474       continue;
475     }
476     if (bt == T_VOID) {
477       if (sig_vk-&gt;at(i-1)._bt == T_LONG ||
478           sig_vk-&gt;at(i-1)._bt == T_DOUBLE) {
479         j++;
480       }
481       continue;
482     }
483     int off = sig_vk-&gt;at(i)._offset;
484     assert(off &gt; 0, &quot;offset in object should be positive&quot;);
485     VMRegPair pair = regs-&gt;at(j);
486     address loc = reg_map.location(pair.first());
487     switch(bt) {
488     case T_BOOLEAN: {
489       new_vt-&gt;bool_field_put(off, *(jboolean*)loc);
490       break;
491     }
492     case T_CHAR: {
493       new_vt-&gt;char_field_put(off, *(jchar*)loc);
494       break;
495     }
496     case T_BYTE: {
497       new_vt-&gt;byte_field_put(off, *(jbyte*)loc);
498       break;
499     }
500     case T_SHORT: {
501       new_vt-&gt;short_field_put(off, *(jshort*)loc);
502       break;
503     }
504     case T_INT: {
505       new_vt-&gt;int_field_put(off, *(jint*)loc);
506       break;
507     }
508     case T_LONG: {
509 #ifdef _LP64
510       new_vt-&gt;double_field_put(off,  *(jdouble*)loc);
511 #else
512       Unimplemented();
513 #endif
514       break;
515     }
516     case T_OBJECT:
517     case T_ARRAY: {
518       Handle handle = handles.at(k++);
519       new_vt-&gt;obj_field_put(off, handle());
520       break;
521     }
522     case T_FLOAT: {
523       new_vt-&gt;float_field_put(off,  *(jfloat*)loc);
524       break;
525     }
526     case T_DOUBLE: {
527       new_vt-&gt;double_field_put(off, *(jdouble*)loc);
528       break;
529     }
530     default:
531       ShouldNotReachHere();
532     }
533     *(intptr_t*)loc = 0xDEAD;
534     j++;
535   }
536   assert(j == regs-&gt;length(), &quot;missed a field?&quot;);
537   assert(k == handles.length(), &quot;missed an oop?&quot;);
538   return new_vt;
539 }
540 
541 // Check the return register for a InlineKlass oop
542 InlineKlass* InlineKlass::returned_inline_klass(const RegisterMap&amp; map) {
543   BasicType bt = T_METADATA;
544   VMRegPair pair;
545   int nb = SharedRuntime::java_return_convention(&amp;bt, &amp;pair, 1);
546   assert(nb == 1, &quot;broken&quot;);
547 
548   address loc = map.location(pair.first());
549   intptr_t ptr = *(intptr_t*)loc;
550   if (is_set_nth_bit(ptr, 0)) {
551     // Oop is tagged, must be a InlineKlass oop
552     clear_nth_bit(ptr, 0);
553     assert(Metaspace::contains((void*)ptr), &quot;should be klass&quot;);
554     InlineKlass* vk = (InlineKlass*)ptr;
555     assert(vk-&gt;can_be_returned_as_fields(), &quot;must be able to return as fields&quot;);
556     return vk;
557   }
558 #ifdef ASSERT
559   // Oop is not tagged, must be a valid oop
560   if (VerifyOops) {
561     oopDesc::verify(oop((HeapWord*)ptr));
562   }
563 #endif
564   return NULL;
565 }
566 
567 void InlineKlass::verify_on(outputStream* st) {
568   InstanceKlass::verify_on(st);
569   guarantee(prototype_header().is_always_locked(), &quot;Prototype header is not always locked&quot;);
570 }
571 
572 void InlineKlass::oop_verify_on(oop obj, outputStream* st) {
573   InstanceKlass::oop_verify_on(obj, st);
574   guarantee(obj-&gt;mark().is_always_locked(), &quot;Header is not always locked&quot;);
575 }
576 
577 void InlineKlass::metaspace_pointers_do(MetaspaceClosure* it) {
578   InstanceKlass::metaspace_pointers_do(it);
579 
580   InlineKlass* this_ptr = this;
581   it-&gt;push_internal_pointer(&amp;this_ptr, (intptr_t*)&amp;_adr_inlineklass_fixed_block);
582 }
    </pre>
  </body>
</html>